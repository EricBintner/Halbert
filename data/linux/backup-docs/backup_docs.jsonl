{"text": "rsync\nhome\nFAQ\nresources\nfeatures\nexamples\nmailing lists\nbug-tracking\ncurrent issues and debugging\ndownload\ndocumentation\nsearch\nWelcome to the rsync web pages\nrsync is an\nopen source\nutility that provides fast incremental file transfer. rsync is freely\navailable under the\nGNU General Public\nLicense\nand is currently being maintained by\nAndrew Tridgell\n.\nA full changelog of all the releases, including upcoming releases, is in the\nNEWS file\n.\nRsync version 3.4.1 released\nJanuary 15th, 2025\nRsync version 3.4.1 has been released.\nThis is a fix for some regressions in 3.4.0\nSee the\n3.4.1 NEWS\nfor a detailed changelog.\nThe latest manpages are also available for:\nrsync\n(1)\nrsync-ssl\n(1)\nrsyncd.conf\n(5)\nrrsync\n(1)\nThe source tar is available here:\nrsync-3.4.1.tar.gz\n(\nsignature\n)\n,\nwith a tar file of the \"rsync-patches\" repository released in a separate file:\nrsync-patches-3.4.1.tar.gz\n(\nsignature\n)\n,\nand the diffs from version 3.4.0 are available here:\nrsync-3.4.0-3.4.1.diffs.gz\n(\nsignature\n)\n.\nRsync version 3.4.0 released\nJanuary 14th, 2025\nRsync version 3.4.0 has been released.\nThis is a security release, fixing several important security vulnerabilities.\nSee the\n3.4.0 NEWS\nfor a detailed changelog.\nThe source tar is available here:\nrsync-3.4.0.tar.gz\n(\nsignature\n)\n,\nwith a tar file of the \"rsync-patches\" repository released in a separate file:\nrsync-patches-3.4.0.tar.gz\n(\nsignature\n)\n,\nand the diffs from version 3.3.0 are available here:\nrsync-3.3.0-3.4.0.diffs.gz\n(\nsignature\n)\n.\nRsync version 3.3.0 released\nApril 6th, 2024\nRsync version 3.3.0 has been released.\nThis is a bug-fix release.\nSee the\n3.3.0 NEWS\nfor a detailed changelog.\nThe source tar is available here:\nrsync-3.3.0.tar.gz\n(\nsignature\n)\n,\nwith a tar file of the \"rsync-patches\" repository released in a separate file:\nrsync-patches-3.3.0.tar.gz\n(\nsignature\n)\n,\nand the diffs from version 3.2.2 are available here:\nrsync-3.2.7-3.3.0.diffs.gz\n(\nsignature\n)\n.\nRsync version 3.2.7 released\nOctober 20th, 2022\nRsync version 3.2.7 has been released.\nThis has some new features & fixes, including various bug fixes for arg validation & filter-rule validation.\nSee the\n3.2.7 NEWS\nfor a detailed changelog.\nThe source tar is available here:\nrsync-3.2.7.tar.gz\n(\nsignature\n)\n,\nwith a tar file of the \"rsync-patches\" repository released in a separate file:\nrsync-patches-3.2.7.tar.gz\n(\nsignature\n)\n,\nand the diffs from version 3.2.2 are available here:\nrsync-3.2.6-3.2.7.diffs.gz\n(\nsignature\n)\n.\nRsync version 3.2.6 released\nSeptember 9th, 2022\nRsync version 3.2.6 has been released.\nThis is a bug-fix release.\nSee the\n3.2.6 NEWS\nfor a detailed changelog.\nThe source tar is available here:\nrsync-3.2.6.tar.gz\n(\nsignature\n)\n,\nwith a tar file of the \"rsync-patches\" repository released in a separate file:\nrsync-patches-3.2.6.tar.gz\n(\nsignature\n)\n,\nand the diffs from version 3.2.2 are available here:\nrsync-3.2.5-3.2.6.diffs.gz\n(\nsignature\n)\n.\nRsync version 3.2.5 released\nAugust 14th, 2022\nRsync version 3.2.5 has been released.\nThis is a bug-fix and\nsecurity\nrelease.\nSee the\n3.2.5 NEWS\nfor a detailed changelog.\nRsync version 3.2.4 released\nApril 15th, 2022\nRsync version 3.2.4 has been released.\nAnother typical release with both bug fixes and some enhancements. It also contains a\nsecurity fix\nfor the bundled zlib 1.2.8, which may or may not be used in your particular build configuration.\nSee the\n3.2.4 NEWS\nfor a detailed changelog.\nRsync version 3.2.3 released\nAugust 6th, 2020\nRsync version 3.2.3 has been released.\nIt contains a smattering of bug fixes and various enhancements.\nSee the\n3.2.3 NEWS\nfor a detailed changelog.\nRsync version 3.2.2 released\nJuly 4th, 2020\nRsync version 3.2.2 has been released.\nThis is a few more portability fixes, some improvements to the newest features, and some\nother simple changes.  Hopefully this will be the last of these recent touch-up releases.\nSee the\n3.2.2 NEWS\nfor a detailed changelog.\nRsync version 3.2.1 released\nJune 22th, 2020\nRsync version 3.2.1 has been released.\nThis is mainly a few fixes for some release issues and portability problems.\nThere's also a couple new features, just for good measure.\nSee the\n3.2.1 NEWS\nfor a detailed changelog.\nRsync version 3.2.0 released\nJune 19th, 2020\nRsync version 3.2.0 has been released.\nThis release has a good number of a few new features and various bug fixes.\nSee the\n3.2.0 NEWS\nfor a detailed changelog.\nRsync version 3.1.3 released\nJanuary 28th, 2018\nRsync version 3.1.3 has been released.\nThis release has a\ncouple security fixes\n,\na few new features, and various bug fixes.\nSee the\n3.1.3 NEWS\nfor a detailed changelog.\nRsync version 3.1.2 released\nDecember 21st, 2015\nRsync version 3.1.2 has been released.  This is a bug-fix release.\nIt includes a\nsecurity fix\nfor a transfer from a sender that you don't fully trust.\nSee the\n3.1.2 NEWS\nfor a detailed changelog.\nRsync version 3.1.1 released\nJune 22nd, 2014\nRsync version 3.1.1 has been released.  This is a bug-fix release.\nSee the\n3.1.1 NEWS\nfor a detailed changelog.\nRsync version 3.1.0 released\nSeptember 28th, 2013\nRsync version 3.1.0 has been released.  This is a\nfeature release that improves performance, provides several new options, and\nfixes a few bugs along the way.\nSee the\n3.1.0 NEWS\nfor a detailed changelog.\nRsync version 3.0.9 released\nSeptember 23th, 2011\nRsync version 3.0.9 has been released.  This is a bug-fix release.\nSee the\n3.0.9 NEWS\nfor a detailed changelog.\nRsync version 3.0.8 released\nMarch 26th, 2011\nRsync version 3.0.8 has been released.  This is a bug-fix release.\nSee the\n3.0.8 NEWS\nfor a detailed changelog.\nRsync version 3.0.7 released\nDecember 31th, 2009\nRsync version 3.0.7 has been released.  This is a bug-fix release.\nSee the\n3.0.7 NEWS\nfor a detailed changelog.\nRsync version 3.0.6 released\nMay 8th, 2009\nRsync version 3.0.6 has been released.  This is a bug-fix release.\nSee the\n3.0.6 NEWS\nfor a detailed changelog.\nRsync version 3.0.5 released\nDecember 28th, 2008\nRsync version 3.0.5 has been released.  This is another bug-fix release.\nSee the\n3.0.5 NEWS\nfor a detailed changelog.\nRsync version 3.0.4 released\nSeptember 6th, 2008\nRsync version 3.0.4 has been released.  This is a bug-fix release with the\nonly enhancement being the adding of a way to interact with an\noverly-restrictive server that refuses rsync's behind-the-scenes use of the -e\noption.\nSee the\n3.0.4 NEWS\nfor a detailed changelog.\nRsync version 3.0.3 released\nJune 29th, 2008\nRsync version 3.0.3 has been released.  This is a bug-fix release that has\nno new features (though it does have one new script in the support directory).\nSee the\n3.0.3 NEWS\nfor a detailed changelog.\nRsync version 3.0.2 released\nApril 8th, 2008\nRsync version 3.0.2 has been released.  This is a\nsecurity release\nthat fixes a potential buffer-overflow issue.\nSee the\n3.0.2 NEWS\nfor a detailed changelog.\nRsync version 3.0.1 released\nApril 3rd, 2008\nRsync version 3.0.1 has been released.  This is a bug-fix release, which also\nincludes fixes/improvements for several issues in the daemon-exclude code.\nSee the\n3.0.1 NEWS\nfor a detailed changelog.\nRsync version 3.0.0 released\nMarch 1st, 2008\nRsync version 3.0.0 is finally here!  This is a feature release that\nalso includes quite a few bug fixes.\nThe 3.0.0 version number is such a large bump up from 2.6.9 due to the\naddition of an\nincremental recursion scan (which helps a lot with large transfers) and the\nofficial arrival of several other new features, including ACL support, extended\nattribute support, filename character-set conversion, etc.\nSee the\n3.0.0 NEWS\nfor a detailed changelog.\nRsync version 2.6.9 released\nNovember 6th, 2006\nRsync version 2.6.9 has been released.  This is primarily a bug-fix\nrelease with a few minor new features.\nSee the\n2.6.9 NEWS\nfor a detailed changelog.\nRsync version 2.6.8 released\nApril 22th, 2006\nRsync version 2.6.8 has been released.  This is a bug-fix release that\nprimarily addresses an exclude problem that affected the --relative option,\nbut also includes a\nsecurity fix\nfor\nthe xattrs.diff patch (which is not an\nofficial part of rsync, but some packagers include it in their release).\nSee the\n2.6.8 NEWS\nfor a detailed changelog.\nRsync 2.6.7 released\nMarch 11th, 2006\nRsync version 2.6.7 has been released.  This release has both several new\nfeatures and the usual accompaniment of bug fixes.\nSee the\n2.6.7 NEWS\nfor a detailed changelog.\nRsync 2.6.6 released\nJuly 28th, 2005\nRsync version 2.6.6 has been released.  This release is a bug-fix release\nwhich contains a\nsecurity fix\nto handle a null-pointer bug that turned up in rsync's version of zlib\n1.1.4 (this is not the recent zlib 1.2.2 security fix, which did not\naffect rsync) and to squash a few other minor bugs.  To deal with the\nzlib issue, rsync has been upgraded to include zlib 1.2.3.\nSee the\n2.6.6 NEWS\nfor a detailed changelog.\nRsync 2.6.5 released\nJune 1st, 2005\nRsync version 2.6.5 has been released.  This release is primarily a bug-fix\nrelease to squash some annoying problems that made it into the (feature-filled)\nrelease of 2.6.4, plus a few minor enhancements.\nSee the\n2.6.5 NEWS\nfor a detailed changelog.\nRsync 2.6.4 released\nMarch 30th, 2005\nRsync version 2.6.4 has been released.  This release combines quite a\nfew new features, some improved delete efficiency, and the usual array of\nbug fixes.\nSee the\n2.6.4 NEWS\nfor a detailed changelog.\nRsync 2.6.3 released\nSeptember 30th, 2004\nRsync version 2.6.3 has been released.  It contains several new features\nand quite a few bug fixes, including a\nsecurity\nfix\nfor a patch-sanitizing bug in the daemon code.\nSee the\n2.6.3 NEWS\nfor a detailed changelog.\nRsync 2.6.2 released\nApril 30th, 2004\nRsync version 2.6.2 has been released.  It is a bug-fix release that mainly\nfixes\na bug with the --relative option (-R) in 2.6.1\nthat could cause files to be transferred incorrectly.  This only affected a\nsource right at the root of the filesystem, such as \"/\" or \"/*\" (if you\nfirst \"cd /\" and then copy from \".\", it would not tickle the bug).\nSee the\n2.6.2 NEWS\nfor a detailed changelog.\nRsync 2.6.1 released\nApril 26th, 2004\nRsync version 2.6.1 has been released.  It is primarily a performance\nrelease that requires less memory to run, makes fewer write calls to the socket\n(lowering the system CPU time), does less string copying (lowering the user CPU\ntime), and also reduces the amount of data that is transmitted over the wire.\nThere have also been quite a few bug fixes, including a\nsecurity fix\nfor a daemon problem when chroot\nis not enabled.  See the\n2.6.1 NEWS\nfor a detailed changelog.\nOne Cygwin hang-problem resolved\nThe problem with rsync hanging at the end of the transfer on\nCygwin\nhad been previously traced to a\nsignal-handling bug in their compatibility DLL.  This bug appears to now be\nfixed in DLL version 1.5.7-1, and Cygwin users are reporting that upgrading the\nDLL removes the hang-at-end-of-transfer problem for their existing rsync executable.\n(Note that this doesn't solve a hang that some folks see in the middle of a\ntransfer -- using daemon mode instead of ssh can work around that one.)\nRsync 2.6.0 released\nJanuary 1st, 2004\nTwo important things to note in the new release:\nThe default remote shell is now \"ssh\" unless you tell configure you want to\nmake something else the default.\nSome bug fixes in the include/exclude code, while making things work\nproperly, have resulted in some user-visible changes for certain wildcard\nstrings.  Read the BUG FIXES section in the\n2.6.0 NEWS\nto see if any of these changes apply to you.\n(Most people should be unaffected.)\nOne other item of note is that the oft-requested option \"--files-from\" is now\navailable.  This option lets you specify a list of files to transfer, and can\nbe much more efficient than a recursive descent using include/exclude\nstatements (if you know in advance what files you want to transfer).  The list\nof files can come from either side of the connection, so it is possible for a\nserver to provide the file-list that lets someone grab a server-specified set of\nfiles, for example.  See the\nrsync man page\nfor more details.\nSee the\n2.6.0 NEWS\nfor a detailed changelog.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://rsync.samba.org/"}}
{"text": "rsync(1) manpage\nNAME\nrsync -⁠ a fast, versatile, remote (and local) file-copying tool\nSYNOPSIS\nLocal:\nrsync [OPTION...] SRC... [DEST]\nAccess via remote shell:\nPull:\nrsync [OPTION...] [USER@]HOST:SRC... [DEST]\nPush:\nrsync [OPTION...] SRC... [USER@]HOST:DEST\nAccess via rsync daemon:\nPull:\nrsync [OPTION...] [USER@]HOST::SRC... [DEST]\nrsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]\nPush:\nrsync [OPTION...] SRC... [USER@]HOST::DEST\nrsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST)\nUsages with just one SRC arg and no DEST arg will list the source files instead\nof copying.\nThe online version of this manpage (that includes cross-linking of topics)\nis available at\nhttps://download.samba.org/pub/rsync/rsync.1\n.\nDESCRIPTION\nRsync is a fast and extraordinarily versatile file copying tool.  It can copy\nlocally, to/from another host over any remote shell, or to/from a remote rsync\ndaemon.  It offers a large number of options that control every aspect of its\nbehavior and permit very flexible specification of the set of files to be\ncopied.  It is famous for its delta-transfer algorithm, which reduces the\namount of data sent over the network by sending only the differences between\nthe source files and the existing files in the destination.  Rsync is widely\nused for backups and mirroring and as an improved copy command for everyday\nuse.\nRsync finds files that need to be transferred using a \"quick check\" algorithm\n(by default) that looks for files that have changed in size or in last-modified\ntime.  Any changes in the other preserved attributes (as requested by options)\nare made on the destination file directly when the quick check indicates that\nthe file's data does not need to be updated.\nSome of the additional features of rsync are:\nsupport for copying links, devices, owners, groups, and permissions\nexclude and exclude-from options similar to GNU tar\na CVS exclude mode for ignoring the same files that CVS would ignore\ncan use any transparent remote shell, including ssh or rsh\ndoes not require super-user privileges\npipelining of file transfers to minimize latency costs\nsupport for anonymous or authenticated rsync daemons (ideal for mirroring)\nGENERAL\nRsync copies files either to or from a remote host, or locally on the current\nhost (it does not support copying files between two remote hosts).\nThere are two different ways for rsync to contact a remote system: using a\nremote-shell program as the transport (such as ssh or rsh) or contacting an\nrsync daemon directly via TCP.  The remote-shell transport is used whenever the\nsource or destination path contains a single colon (:) separator after a host\nspecification.  Contacting an rsync daemon directly happens when the source or\ndestination path contains a double colon (::) separator after a host\nspecification, OR when an rsync:// URL is specified (see also the\nUSING\nRSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION\nsection for an\nexception to this latter rule).\nAs a special case, if a single source arg is specified without a destination,\nthe files are listed in an output format similar to \"\nls -l\n\".\nAs expected, if neither the source or destination path specify a remote host,\nthe copy occurs locally (see also the\n--list-only\noption).\nRsync refers to the local side as the client and the remote side as the server.\nDon't confuse server with an rsync daemon.  A daemon is always a server, but a\nserver can be either a daemon or a remote-shell spawned process.\nSETUP\nSee the file README.md for installation instructions.\nOnce installed, you can use rsync to any machine that you can access via a\nremote shell (as well as some that you can access using the rsync daemon-mode\nprotocol).  For remote transfers, a modern rsync uses ssh for its\ncommunications, but it may have been configured to use a different remote shell\nby default, such as rsh or remsh.\nYou can also specify any remote shell you like, either by using the\n-e\ncommand line option, or by setting the\nRSYNC_RSH\nenvironment variable.\nNote that rsync must be installed on both the source and destination machines.\nUSAGE\nYou use rsync in the same way you use rcp.  You must specify a source and a\ndestination, one of which may be remote.\nPerhaps the best way to explain the syntax is with some examples:\nrsync -t *.c foo:src/\nThis would transfer all files matching the pattern\n*.c\nfrom the current\ndirectory to the directory src on the machine foo.  If any of the files already\nexist on the remote system then the rsync remote-update protocol is used to\nupdate the file by sending only the differences in the data.  Note that the\nexpansion of wildcards on the command-line (\n*.c\n) into a list of files is\nhandled by the shell before it runs rsync and not by rsync itself (exactly the\nsame as all other Posix-style programs).\nrsync -avz foo:src/bar /data/tmp\nThis would recursively transfer all files from the directory src/bar on the\nmachine foo into the /data/tmp/bar directory on the local machine.  The files\nare transferred in archive mode, which ensures that symbolic links, devices,\nattributes, permissions, ownerships, etc. are preserved in the transfer.\nAdditionally, compression will be used to reduce the size of data portions of\nthe transfer.\nrsync -avz foo:src/bar/ /data/tmp\nA trailing slash on the source changes this behavior to avoid creating an\nadditional directory level at the destination.  You can think of a trailing /\non a source as meaning \"copy the contents of this directory\" as opposed to\n\"copy the directory by name\", but in both cases the attributes of the\ncontaining directory are transferred to the containing directory on the\ndestination.  In other words, each of the following commands copies the files\nin the same way, including their setting of the attributes of /dest/foo:\nrsync -av /src/foo /dest\nrsync -av /src/foo/ /dest/foo\nNote also that host and module references don't require a trailing slash to\ncopy the contents of the default directory.  For example, both of these copy\nthe remote directory's contents into \"/dest\":\nrsync -av host: /dest\nrsync -av host::module /dest\nYou can also use rsync in local-only mode, where both the source and\ndestination don't have a ':' in the name.  In this case it behaves like an\nimproved copy command.\nFinally, you can list all the (listable) modules available from a particular\nrsync daemon by leaving off the module name:\nrsync somehost.mydomain.com::\nCOPYING TO A DIFFERENT NAME\nWhen you want to copy a directory to a different name, use a trailing slash on\nthe source directory to put the contents of the directory into any destination\ndirectory you like:\nrsync -ai foo/ bar/\nRsync also has the ability to customize a destination file's name when copying\na single item.  The rules for this are:\nThe transfer list must consist of a single item (either a file or an empty\ndirectory)\nThe final element of the destination path must not exist as a directory\nThe destination path must not have been specified with a trailing slash\nUnder those circumstances, rsync will set the name of the destination's single\nitem to the last element of the destination path.  Keep in mind that it is best\nto only use this idiom when copying a file and use the above trailing-slash\nidiom when copying a directory.\nThe following example copies the\nfoo.c\nfile as\nbar.c\nin the\nsave\ndir\n(assuming that\nbar.c\nisn't a directory):\nrsync -ai src/foo.c save/bar.c\nThe single-item copy rule might accidentally bite you if you unknowingly copy a\nsingle item and specify a destination dir that doesn't exist (without using a\ntrailing slash).  For example, if\nsrc/*.c\nmatches one file and\nsave/dir\ndoesn't exist, this will confuse you by naming the destination file\nsave/dir\n:\nrsync -ai src/*.c save/dir\nTo prevent such an accident, either make sure the destination dir exists or\nspecify the destination path with a trailing slash:\nrsync -ai src/*.c save/dir/\nSORTED TRANSFER ORDER\nRsync always sorts the specified filenames into its internal transfer list.\nThis handles the merging together of the contents of identically named\ndirectories, makes it easy to remove duplicate filenames. It can, however,\nconfuse someone when the files are transferred in a different order than what\nwas given on the command-line.\nIf you need a particular file to be transferred prior to another, either\nseparate the files into different rsync calls, or consider using\n--delay-updates\n(which doesn't affect the sorted transfer order, but\ndoes make the final file-updating phase happen much more rapidly).\nMULTI-HOST SECURITY\nRsync takes steps to ensure that the file requests that are shared in a\ntransfer are protected against various security issues.  Most of the potential\nproblems arise on the receiving side where rsync takes steps to ensure that the\nlist of files being transferred remains within the bounds of what was\nrequested.\nToward this end, rsync 3.1.2 and later have aborted when a file list contains\nan absolute or relative path that tries to escape out of the top of the\ntransfer.  Also, beginning with version 3.2.5, rsync does two more safety\nchecks of the file list to (1) ensure that no extra source arguments were added\ninto the transfer other than those that the client requested and (2) ensure\nthat the file list obeys the exclude rules that were sent to the sender.\nFor those that don't yet have a 3.2.5 client rsync (or those that want to be\nextra careful), it is safest to do a copy into a dedicated destination\ndirectory for the remote files when you don't trust the remote host.  For\nexample, instead of doing an rsync copy into your home directory:\nrsync -aiv host1:dir1 ~\nDedicate a \"host1-files\" dir to the remote content:\nrsync -aiv host1:dir1 ~/host1-files\nSee the\n--trust-sender\noption for additional details.\nCAUTION: it is not particularly safe to use rsync to copy files from a\ncase-preserving filesystem to a case-ignoring filesystem.  If you must perform\nsuch a copy, you should either disable symlinks via\n--no-links\nor enable the\nmunging of symlinks via\n--munge-links\n(and make sure you use the\nright local or remote option).  This will prevent rsync from doing potentially\ndangerous things if a symlink name overlaps with a file or directory. It does\nnot, however, ensure that you get a full copy of all the files (since that may\nnot be possible when the names overlap). A potentially better solution is to\nlist all the source files and create a safe list of filenames that you pass to\nthe\n--files-from\noption.  Any files that conflict in name would need\nto be copied to different destination directories using more than one copy.\nWhile a copy of a case-ignoring filesystem to a case-ignoring filesystem can\nwork out fairly well, if no\n--delete-during\nor\n--delete-before\noption is\nactive, rsync can potentially update an existing file on the receiving side\nwithout noticing that the upper-/lower-case of the filename should be changed\nto match the sender.\nADVANCED USAGE\nThe syntax for requesting multiple files from a remote host is done by\nspecifying additional remote-host args in the same style as the first, or with\nthe hostname omitted.  For instance, all these work:\nrsync -aiv host:file1 :file2 host:file{3,4} /dest/\nrsync -aiv host::modname/file{1,2} host::modname/extra /dest/\nrsync -aiv host::modname/first ::extra-file{1,2} /dest/\nNote that a daemon connection only supports accessing one module per copy\ncommand, so if the start of a follow-up path doesn't begin with the\nmodname of the first path, it is assumed to be a path in the module (such as\nthe extra-file1 & extra-file2 that are grabbed above).\nReally old versions of rsync (2.6.9 and before) only allowed specifying one\nremote-source arg, so some people have instead relied on the remote-shell\nperforming space splitting to break up an arg into multiple paths. Such\nunintuitive behavior is no longer supported by default (though you can request\nit, as described below).\nStarting in 3.2.4, filenames are passed to a remote shell in such a way as to\npreserve the characters you give it. Thus, if you ask for a file with spaces\nin the name, that's what the remote rsync looks for:\nrsync -aiv host:'a simple file.pdf' /dest/\nIf you use scripts that have been written to manually apply extra quoting to\nthe remote rsync args (or to require remote arg splitting), you can ask rsync\nto let your script handle the extra escaping.  This is done by either adding\nthe\n--old-args\noption to the rsync runs in the script (which requires\na new rsync) or exporting\nRSYNC_OLD_ARGS\n=1 and\nRSYNC_PROTECT_ARGS\n=0\n(which works with old or new rsync versions).\nCONNECTING TO AN RSYNC DAEMON\nIt is also possible to use rsync without a remote shell as the transport.  In\nthis case you will directly connect to a remote rsync daemon, typically using\nTCP port 873. (This obviously requires the daemon to be running on the remote\nsystem, so refer to the\nSTARTING AN RSYNC DAEMON TO ACCEPT CONNECTIONS\nsection below for information on that.)\nUsing rsync in this way is the same as using it with a remote shell except\nthat:\nUse either double-colon syntax or rsync:// URL syntax instead of the\nsingle-colon (remote shell) syntax.\nThe first element of the \"path\" is actually a module name.\nAdditional remote source args can use an abbreviated syntax that omits the\nhostname and/or the module name, as discussed in\nADVANCED USAGE\n.\nThe remote daemon may print a \"message of the day\" when you connect.\nIf you specify only the host (with no module or path) then a list of\naccessible modules on the daemon is output.\nIf you specify a remote source path but no destination, a listing of the\nmatching files on the remote daemon is output.\nThe\n--rsh\n(\n-e\n) option must be omitted to avoid changing the\nconnection style from using a socket connection to\nUSING RSYNC-DAEMON\nFEATURES VIA A REMOTE-SHELL CONNECTION\n.\nAn example that copies all the files in a remote module named \"src\":\nrsync -av host::src /dest\nSome modules on the remote daemon may require authentication.  If so, you will\nreceive a password prompt when you connect.  You can avoid the password prompt\nby setting the environment variable\nRSYNC_PASSWORD\nto the password you\nwant to use or using the\n--password-file\noption.  This may be useful\nwhen scripting rsync.\nWARNING: On some systems environment variables are visible to all users.  On\nthose systems using\n--password-file\nis recommended.\nYou may establish the connection via a web proxy by setting the environment\nvariable\nRSYNC_PROXY\nto a hostname:port pair pointing to your web proxy.\nNote that your web proxy's configuration must support proxy connections to port\n873.\nYou may also establish a daemon connection using a program as a proxy by\nsetting the environment variable\nRSYNC_CONNECT_PROG\nto the commands you\nwish to run in place of making a direct socket connection.  The string may\ncontain the escape \"%H\" to represent the hostname specified in the rsync\ncommand (so use \"%%\" if you need a single \"%\" in your string).  For example:\nexport RSYNC_CONNECT_PROG='ssh proxyhost nc %H 873'\nrsync -av targethost1::module/src/ /dest/\nrsync -av rsync://targethost2/module/src/ /dest/\nThe command specified above uses ssh to run nc (netcat) on a proxyhost, which\nforwards all data to port 873 (the rsync daemon) on the targethost (%H).\nNote also that if the\nRSYNC_SHELL\nenvironment variable is set, that\nprogram will be used to run the\nRSYNC_CONNECT_PROG\ncommand instead of using\nthe default shell of the\nsystem()\ncall.\nUSING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION\nIt is sometimes useful to use various features of an rsync daemon (such as\nnamed modules) without actually allowing any new socket connections into a\nsystem (other than what is already required to allow remote-shell access).\nRsync supports connecting to a host using a remote shell and then spawning a\nsingle-use \"daemon\" server that expects to read its config file in the home dir\nof the remote user.  This can be useful if you want to encrypt a daemon-style\ntransfer's data, but since the daemon is started up fresh by the remote user,\nyou may not be able to use features such as chroot or change the uid used by\nthe daemon. (For another way to encrypt a daemon transfer, consider using ssh\nto tunnel a local port to a remote machine and configure a normal rsync daemon\non that remote host to only allow connections from \"localhost\".)\nFrom the user's perspective, a daemon transfer via a remote-shell connection\nuses nearly the same command-line syntax as a normal rsync-daemon transfer,\nwith the only exception being that you must explicitly set the remote shell\nprogram on the command-line with the\n--rsh=COMMAND\noption. (Setting the\nRSYNC_RSH in the environment will not turn on this functionality.) For example:\nrsync -av --rsh=ssh host::module /dest\nIf you need to specify a different remote-shell user, keep in mind that the\nuser@ prefix in front of the host is specifying the rsync-user value (for a\nmodule that requires user-based authentication).  This means that you must give\nthe '-⁠l user' option to ssh when specifying the remote-shell, as in this\nexample that uses the short version of the\n--rsh\noption:\nrsync -av -e \"ssh -l ssh-user\" rsync-user@host::module /dest\nThe \"ssh-user\" will be used at the ssh level; the \"rsync-user\" will be used to\nlog-in to the \"module\".\nIn this setup, the daemon is started by the ssh command that is accessing the\nsystem (which can be forced via the\n~/.ssh/authorized_keys\nfile, if desired).\nHowever, when accessing a daemon directly, it needs to be started beforehand.\nSTARTING AN RSYNC DAEMON TO ACCEPT CONNECTIONS\nIn order to connect to an rsync daemon, the remote system needs to have a\ndaemon already running (or it needs to have configured something like inetd to\nspawn an rsync daemon for incoming connections on a particular port).  For full\ninformation on how to start a daemon that will handling incoming socket\nconnections, see the\nrsyncd.conf\n(5)\nmanpage -⁠-⁠ that is\nthe config file for the daemon, and it contains the full details for how to run\nthe daemon (including stand-alone and inetd configurations).\nIf you're using one of the remote-shell transports for the transfer, there is\nno need to manually start an rsync daemon.\nEXAMPLES\nHere are some examples of how rsync can be used.\nTo backup a home directory, which consists of large MS Word files and mail\nfolders, a per-user cron job can be used that runs this each day:\nrsync -aiz . bkhost:backup/joe/\nTo move some files from a remote host to the local host, you could run:\nrsync -aiv --remove-source-files rhost:/tmp/{file1,file2}.c ~/src/\nOPTION SUMMARY\nHere is a short summary of the options available in rsync.  Each option also\nhas its own detailed description later in this manpage.\n--verbose, -v            increase verbosity\n--info=FLAGS             fine-grained informational verbosity\n--debug=FLAGS            fine-grained debug verbosity\n--stderr=e|a|c           change stderr output mode (default: errors)\n--quiet, -q              suppress non-error messages\n--no-motd                suppress daemon-mode MOTD\n--checksum, -c           skip based on checksum, not mod-time & size\n--archive, -a            archive mode is -rlptgoD (no -A,-X,-U,-N,-H)\n--no-OPTION              turn off an implied OPTION (e.g. --no-D)\n--recursive, -r          recurse into directories\n--relative, -R           use relative path names\n--no-implied-dirs        don't send implied dirs with --relative\n--backup, -b             make backups (see --suffix & --backup-dir)\n--backup-dir=DIR         make backups into hierarchy based in DIR\n--suffix=SUFFIX          backup suffix (default ~ w/o --backup-dir)\n--update, -u             skip files that are newer on the receiver\n--inplace                update destination files in-place\n--append                 append data onto shorter files\n--append-verify          --append w/old data in file checksum\n--dirs, -d               transfer directories without recursing\n--old-dirs, --old-d      works like --dirs when talking to old rsync\n--mkpath                 create destination's missing path components\n--links, -l              copy symlinks as symlinks\n--copy-links, -L         transform symlink into referent file/dir\n--copy-unsafe-links      only \"unsafe\" symlinks are transformed\n--safe-links             ignore symlinks that point outside the tree\n--munge-links            munge symlinks to make them safe & unusable\n--copy-dirlinks, -k      transform symlink to dir into referent dir\n--keep-dirlinks, -K      treat symlinked dir on receiver as dir\n--hard-links, -H         preserve hard links\n--perms, -p              preserve permissions\n--executability, -E      preserve executability\n--chmod=CHMOD            affect file and/or directory permissions\n--acls, -A               preserve ACLs (implies --perms)\n--xattrs, -X             preserve extended attributes\n--owner, -o              preserve owner (super-user only)\n--group, -g              preserve group\n--devices                preserve device files (super-user only)\n--copy-devices           copy device contents as a regular file\n--write-devices          write to devices as files (implies --inplace)\n--specials               preserve special files\n-D                       same as --devices --specials\n--times, -t              preserve modification times\n--atimes, -U             preserve access (use) times\n--open-noatime           avoid changing the atime on opened files\n--crtimes, -N            preserve create times (newness)\n--omit-dir-times, -O     omit directories from --times\n--omit-link-times, -J    omit symlinks from --times\n--super                  receiver attempts super-user activities\n--fake-super             store/recover privileged attrs using xattrs\n--sparse, -S             turn sequences of nulls into sparse blocks\n--preallocate            allocate dest files before writing them\n--dry-run, -n            perform a trial run with no changes made\n--whole-file, -W         copy files whole (w/o delta-xfer algorithm)\n--checksum-choice=STR    choose the checksum algorithm (aka --cc)\n--one-file-system, -x    don't cross filesystem boundaries\n--block-size=SIZE, -B    force a fixed checksum block-size\n--rsh=COMMAND, -e        specify the remote shell to use\n--rsync-path=PROGRAM     specify the rsync to run on remote machine\n--existing               skip creating new files on receiver\n--ignore-existing        skip updating files that exist on receiver\n--remove-source-files    sender removes synchronized files (non-dir)\n--del                    an alias for --delete-during\n--delete                 delete extraneous files from dest dirs\n--delete-before          receiver deletes before xfer, not during\n--delete-during          receiver deletes during the transfer\n--delete-delay           find deletions during, delete after\n--delete-after           receiver deletes after transfer, not during\n--delete-excluded        also delete excluded files from dest dirs\n--ignore-missing-args    ignore missing source args without error\n--delete-missing-args    delete missing source args from destination\n--ignore-errors          delete even if there are I/O errors\n--force                  force deletion of dirs even if not empty\n--max-delete=NUM         don't delete more than NUM files\n--max-size=SIZE          don't transfer any file larger than SIZE\n--min-size=SIZE          don't transfer any file smaller than SIZE\n--max-alloc=SIZE         change a limit relating to memory alloc\n--partial                keep partially transferred files\n--partial-dir=DIR        put a partially transferred file into DIR\n--delay-updates          put all updated files into place at end\n--prune-empty-dirs, -m   prune empty directory chains from file-list\n--numeric-ids            don't map uid/gid values by user/group name\n--usermap=STRING         custom username mapping\n--groupmap=STRING        custom groupname mapping\n--chown=USER:GROUP       simple username/groupname mapping\n--timeout=SECONDS        set I/O timeout in seconds\n--contimeout=SECONDS     set daemon connection timeout in seconds\n--ignore-times, -I       don't skip files that match size and time\n--size-only              skip files that match in size\n--modify-window=NUM, -@  set the accuracy for mod-time comparisons\n--temp-dir=DIR, -T       create temporary files in directory DIR\n--fuzzy, -y              find similar file for basis if no dest file\n--compare-dest=DIR       also compare destination files relative to DIR\n--copy-dest=DIR          ... and include copies of unchanged files\n--link-dest=DIR          hardlink to files in DIR when unchanged\n--compress, -z           compress file data during the transfer\n--compress-choice=STR    choose the compression algorithm (aka --zc)\n--compress-level=NUM     explicitly set compression level (aka --zl)\n--skip-compress=LIST     skip compressing files with suffix in LIST\n--cvs-exclude, -C        auto-ignore files in the same way CVS does\n--filter=RULE, -f        add a file-filtering RULE\n-F                       same as --filter='dir-merge /.rsync-filter'\nrepeated: --filter='- .rsync-filter'\n--exclude=PATTERN        exclude files matching PATTERN\n--exclude-from=FILE      read exclude patterns from FILE\n--include=PATTERN        don't exclude files matching PATTERN\n--include-from=FILE      read include patterns from FILE\n--files-from=FILE        read list of source-file names from FILE\n--from0, -0              all *-from/filter files are delimited by 0s\n--old-args               disable the modern arg-protection idiom\n--secluded-args, -s      use the protocol to safely send the args\n--trust-sender           trust the remote sender's file list\n--copy-as=USER[:GROUP]   specify user & optional group for the copy\n--address=ADDRESS        bind address for outgoing socket to daemon\n--port=PORT              specify double-colon alternate port number\n--sockopts=OPTIONS       specify custom TCP options\n--blocking-io            use blocking I/O for the remote shell\n--outbuf=N|L|B           set out buffering to None, Line, or Block\n--stats                  give some file-transfer stats\n--8-bit-output, -8       leave high-bit chars unescaped in output\n--human-readable, -h     output numbers in a human-readable format\n--progress               show progress during transfer\n-P                       same as --partial --progress\n--itemize-changes, -i    output a change-summary for all updates\n--remote-option=OPT, -M  send OPTION to the remote side only\n--out-format=FORMAT      output updates using the specified FORMAT\n--log-file=FILE          log what we're doing to the specified FILE\n--log-file-format=FMT    log updates using the specified FMT\n--password-file=FILE     read daemon-access password from FILE\n--early-input=FILE       use FILE for daemon's early exec input\n--list-only              list the files instead of copying them\n--bwlimit=RATE           limit socket I/O bandwidth\n--stop-after=MINS        Stop rsync after MINS minutes have elapsed\n--stop-at=y-m-dTh:m      Stop rsync at the specified point in time\n--fsync                  fsync every written file\n--write-batch=FILE       write a batched update to FILE\n--only-write-batch=FILE  like --write-batch but w/o updating dest\n--read-batch=FILE        read a batched update from FILE\n--protocol=NUM           force an older protocol version to be used\n--iconv=CONVERT_SPEC     request charset conversion of filenames\n--checksum-seed=NUM      set block/file checksum seed (advanced)\n--ipv4, -4               prefer IPv4\n--ipv6, -6               prefer IPv6\n--version, -V            print the version + other info and exit\n--help, -h (*)           show this help (* -h is help only on its own)\nRsync can also be run as a daemon, in which case the following options are\naccepted:\n--daemon                 run as an rsync daemon\n--address=ADDRESS        bind to the specified address\n--bwlimit=RATE           limit socket I/O bandwidth\n--config=FILE            specify alternate rsyncd.conf file\n--dparam=OVERRIDE, -M    override global daemon config parameter\n--no-detach              do not detach from the parent\n--port=PORT              listen on alternate port number\n--log-file=FILE          override the \"log file\" setting\n--log-file-format=FMT    override the \"log format\" setting\n--sockopts=OPTIONS       specify custom TCP options\n--verbose, -v            increase verbosity\n--ipv4, -4               prefer IPv4\n--ipv6, -6               prefer IPv6\n--help, -h               show this help (when used with --daemon)\nOPTIONS\nRsync accepts both long (double-dash + word) and short (single-dash + letter)\noptions.  The full list of the available options are described below.  If an\noption can be specified in more than one way, the choices are comma-separated.\nSome options only have a long variant, not a short.\nIf the option takes a parameter, the parameter is only listed after the long\nvariant, even though it must also be specified for the short.  When specifying\na parameter, you can either use the form\n--option=param\n,\n--option param\n,\n-o=param\n,\n-o param\n, or\n-oparam\n(the latter choices assume that your\noption has a short variant).\nThe parameter may need to be quoted in some manner for it to survive the\nshell's command-line parsing.  Also keep in mind that a leading tilde (\n~\n) in\na pathname is substituted by your shell, so make sure that you separate the\noption name from the pathname using a space if you want the local shell to\nexpand it.\n--help\nPrint a short help page describing the options available in rsync and exit.\nYou can also use\n-h\nfor\n--help\nwhen it is used without any other\noptions (since it normally means\n--human-readable\n).\n--version\n,\n-V\nPrint the rsync version plus other info and exit.  When repeated, the\ninformation is output is a JSON format that is still fairly readable\n(client side only).\nThe output includes a list of compiled-in capabilities, a list of\noptimizations, the default list of checksum algorithms, the default list of\ncompression algorithms, the default list of daemon auth digests, a link to\nthe rsync web site, and a few other items.\n--verbose\n,\n-v\nThis option increases the amount of information you are given during the\ntransfer.  By default, rsync works silently.  A single\n-v\nwill give you\ninformation about what files are being transferred and a brief summary at\nthe end.  Two\n-v\noptions will give you information on what files are\nbeing skipped and slightly more information at the end.  More than two\n-v\noptions should only be used if you are debugging rsync.\nThe end-of-run summary tells you the number of bytes sent to the remote\nrsync (which is the receiving side on a local copy), the number of bytes\nreceived from the remote host, and the average bytes per second of the\ntransferred data computed over the entire length of the rsync run. The\nsecond line shows the total size (in bytes), which is the sum of all the\nfile sizes that rsync considered transferring.  It also shows a \"speedup\"\nvalue, which is a ratio of the total file size divided by the sum of the\nsent and received bytes (which is really just a feel-good bigger-is-better\nnumber).  Note that these byte values can be made more (or less)\nhuman-readable by using the\n--human-readable\n(or\n--no-human-readable\n) options.\nIn a modern rsync, the\n-v\noption is equivalent to the setting of groups\nof\n--info\nand\n--debug\noptions.  You can choose to use\nthese newer options in addition to, or in place of using\n--verbose\n, as\nany fine-grained settings override the implied settings of\n-v\n.  Both\n--info\nand\n--debug\nhave a way to ask for help that\ntells you exactly what flags are set for each increase in verbosity.\nHowever, do keep in mind that a daemon's \"\nmax verbosity\n\" setting will limit\nhow high of a level the various individual flags can be set on the daemon\nside.  For instance, if the max is 2, then any info and/or debug flag that\nis set to a higher value than what would be set by\n-vv\nwill be downgraded\nto the\n-vv\nlevel in the daemon's logging.\n--info=FLAGS\nThis option lets you have fine-grained control over the information output\nyou want to see.  An individual flag name may be followed by a level\nnumber, with 0 meaning to silence that output, 1 being the default output\nlevel, and higher numbers increasing the output of that flag (for those\nthat support higher levels).  Use\n--info=help\nto see all the available\nflag names, what they output, and what flag names are added for each\nincrease in the verbose level.  Some examples:\nrsync -a --info=progress2 src/ dest/\nrsync -avv --info=stats2,misc1,flist0 src/ dest/\nNote that\n--info=name\n's output is affected by the\n--out-format\nand\n--itemize-changes\n(\n-i\n) options.  See those options for more\ninformation on what is output and when.\nThis option was added to 3.1.0, so an older rsync on the server side might\nreject your attempts at fine-grained control (if one or more flags needed\nto be send to the server and the server was too old to understand them).\nSee also the \"\nmax verbosity\n\" caveat above when dealing with a daemon.\n--debug=FLAGS\nThis option lets you have fine-grained control over the debug output you\nwant to see.  An individual flag name may be followed by a level number,\nwith 0 meaning to silence that output, 1 being the default output level,\nand higher numbers increasing the output of that flag (for those that\nsupport higher levels).  Use\n--debug=help\nto see all the available flag\nnames, what they output, and what flag names are added for each increase in\nthe verbose level.  Some examples:\nrsync -avvv --debug=none src/ dest/\nrsync -avA --del --debug=del2,acl src/ dest/\nNote that some debug messages will only be output when the\n--stderr=all\noption is specified, especially those pertaining to I/O and buffer debugging.\nBeginning in 3.2.0, this option is no longer auto-forwarded to the server\nside in order to allow you to specify different debug values for each side\nof the transfer, as well as to specify a new debug option that is only\npresent in one of the rsync versions.  If you want to duplicate the same\noption on both sides, using brace expansion is an easy way to save you some\ntyping.  This works in zsh and bash:\nrsync -aiv {-M,}--debug=del2 src/ dest/\n--stderr=errors|all|client\nThis option controls which processes output to stderr and if info messages\nare also changed to stderr.  The mode strings can be abbreviated, so feel\nfree to use a single letter value.  The 3 possible choices are:\nerrors\n-⁠ (the default) causes all the rsync processes to send an\nerror directly to stderr, even if the process is on the remote side of\nthe transfer.  Info messages are sent to the client side via the protocol\nstream.  If stderr is not available (i.e. when directly connecting with a\ndaemon via a socket) errors fall back to being sent via the protocol\nstream.\nall\n-⁠ causes all rsync messages (info and error) to get written\ndirectly to stderr from all (possible) processes.  This causes stderr to\nbecome line-buffered (instead of raw) and eliminates the ability to\ndivide up the info and error messages by file handle.  For those doing\ndebugging or using several levels of verbosity, this option can help to\navoid clogging up the transfer stream (which should prevent any chance of\na deadlock bug hanging things up).  It also allows\n--debug\nto\nenable some extra I/O related messages.\nclient\n-⁠ causes all rsync messages to be sent to the client side\nvia the protocol stream.  One client process outputs all messages, with\nerrors on stderr and info messages on stdout.  This\nwas\nthe default\nin older rsync versions, but can cause error delays when a lot of\ntransfer data is ahead of the messages.  If you're pushing files to an\nolder rsync, you may want to use\n--stderr=all\nsince that idiom has\nbeen around for several releases.\nThis option was added in rsync 3.2.3.  This version also began the\nforwarding of a non-default setting to the remote side, though rsync uses\nthe backward-compatible options\n--msgs2stderr\nand\n--no-msgs2stderr\nto\nrepresent the\nall\nand\nclient\nsettings, respectively.  A newer rsync\nwill continue to accept these older option names to maintain compatibility.\n--quiet\n,\n-q\nThis option decreases the amount of information you are given during the\ntransfer, notably suppressing information messages from the remote server.\nThis option is useful when invoking rsync from cron.\n--no-motd\nThis option affects the information that is output by the client at the\nstart of a daemon transfer.  This suppresses the message-of-the-day (MOTD)\ntext, but it also affects the list of modules that the daemon sends in\nresponse to the \"rsync host::\" request (due to a limitation in the rsync\nprotocol), so omit this option if you want to request the list of modules\nfrom the daemon.\n--ignore-times\n,\n-I\nNormally rsync will skip any files that are already the same size and have\nthe same modification timestamp.  This option turns off this \"quick check\"\nbehavior, causing all files to be updated.\nThis option can be confusing compared to\n--ignore-existing\nand\n--ignore-non-existing\nin that that they cause rsync to transfer\nfewer files, while this option causes rsync to transfer more files.\n--size-only\nThis modifies rsync's \"quick check\" algorithm for finding files that need\nto be transferred, changing it from the default of transferring files with\neither a changed size or a changed last-modified time to just looking for\nfiles that have changed in size.  This is useful when starting to use rsync\nafter using another mirroring system which may not preserve timestamps\nexactly.\n--modify-window=NUM\n,\n-@\nWhen comparing two timestamps, rsync treats the timestamps as being equal\nif they differ by no more than the modify-window value.  The default is 0,\nwhich matches just integer seconds.  If you specify a negative value (and\nthe receiver is at least version 3.1.3) then nanoseconds will also be taken\ninto account.  Specifying 1 is useful for copies to/from MS Windows FAT\nfilesystems, because FAT represents times with a 2-second resolution\n(allowing times to differ from the original by up to 1 second).\nIf you want all your transfers to default to comparing nanoseconds, you can\ncreate a\n~/.popt\nfile and put these lines in it:\nrsync alias -a -a@-1\nrsync alias -t -t@-1\nWith that as the default, you'd need to specify\n--modify-window=0\n(aka\n-@0\n) to override it and ignore nanoseconds, e.g. if you're copying\nbetween ext3 and ext4, or if the receiving rsync is older than 3.1.3.\n--checksum\n,\n-c\nThis changes the way rsync checks if the files have been changed and are in\nneed of a transfer.  Without this option, rsync uses a \"quick check\" that\n(by default) checks if each file's size and time of last modification match\nbetween the sender and receiver.  This option changes this to compare a\n128-bit checksum for each file that has a matching size.  Generating the\nchecksums means that both sides will expend a lot of disk I/O reading all\nthe data in the files in the transfer, so this can slow things down\nsignificantly (and this is prior to any reading that will be done to\ntransfer changed files)\nThe sending side generates its checksums while it is doing the file-system\nscan that builds the list of the available files.  The receiver generates\nits checksums when it is scanning for changed files, and will checksum any\nfile that has the same size as the corresponding sender's file: files with\neither a changed size or a changed checksum are selected for transfer.\nNote that rsync always verifies that each\ntransferred\nfile was correctly\nreconstructed on the receiving side by checking a whole-file checksum that\nis generated as the file is transferred, but that automatic\nafter-the-transfer verification has nothing to do with this option's\nbefore-the-transfer \"Does this file need to be updated?\" check.\nThe checksum used is auto-negotiated between the client and the server, but\ncan be overridden using either the\n--checksum-choice\n(\n--cc\n)\noption or an environment variable that is discussed in that option's\nsection.\n--archive\n,\n-a\nThis is equivalent to\n-rlptgoD\n.  It is a quick way of saying you want\nrecursion and want to preserve almost everything.  Be aware that it does\nnot\ninclude preserving ACLs (\n-A\n), xattrs (\n-X\n), atimes (\n-U\n),\ncrtimes (\n-N\n), nor the finding and preserving of hardlinks (\n-H\n).\nThe only exception to the above equivalence is when\n--files-from\nis specified, in which case\n-r\nis not implied.\n--no-OPTION\nYou may turn off one or more implied options by prefixing the option name\nwith \"no-\".  Not all positive options have a negated opposite, but a lot\ndo, including those that can be used to disable an implied option (e.g.\n--no-D\n,\n--no-perms\n) or have different defaults in various circumstances\n(e.g.\n--no-whole-file\n,\n--no-blocking-io\n,\n--no-dirs\n).  Every\nvalid negated option accepts both the short and the long option name after\nthe \"no-\" prefix (e.g.\n--no-R\nis the same as\n--no-relative\n).\nAs an example, if you want to use\n--archive\n(\n-a\n) but don't want\n--owner\n(\n-o\n), instead of converting\n-a\ninto\n-rlptgD\n, you\ncan specify\n-a --no-o\n(aka\n--archive --no-owner\n).\nThe order of the options is important: if you specify\n--no-r -a\n, the\n-r\noption would end up being turned on, the opposite of\n-a --no-r\n.  Note\nalso that the side-effects of the\n--files-from\noption are NOT\npositional, as it affects the default state of several options and slightly\nchanges the meaning of\n-a\n(see the\n--files-from\noption\nfor more details).\n--recursive\n,\n-r\nThis tells rsync to copy directories recursively.  See also\n--dirs\n(\n-d\n) for an option that allows the scanning of a single\ndirectory.\nSee the\n--inc-recursive\noption for a discussion of the\nincremental recursion for creating the list of files to transfer.\n--inc-recursive\n,\n--i-r\nThis option explicitly enables on incremental recursion when scanning for\nfiles, which is enabled by default when using the\n--recursive\noption and both sides of the transfer are running rsync 3.0.0 or newer.\nIncremental recursion uses much less memory than non-incremental, while\nalso beginning the transfer more quickly (since it doesn't need to scan the\nentire transfer hierarchy before it starts transferring files).  If no\nrecursion is enabled in the source files, this option has no effect.\nSome options require rsync to know the full file list, so these options\ndisable the incremental recursion mode.  These include:\n--delete-before\n(the old default of\n--delete\n)\n--delete-after\n--prune-empty-dirs\n--delay-updates\nIn order to make\n--delete\ncompatible with incremental recursion,\nrsync 3.0.0 made\n--delete-during\nthe default delete mode (which\nwas first added in 2.6.4).\nOne side-effect of incremental recursion is that any missing\nsub-directories inside a recursively-scanned directory are (by default)\ncreated prior to recursing into the sub-dirs.  This earlier creation point\n(compared to a non-incremental recursion) allows rsync to then set the\nmodify time of the finished directory right away (without having to delay\nthat until a bunch of recursive copying has finished).  However, these\nearly directories don't yet have their completed mode, mtime, or ownership\nset -⁠-⁠ they have more restrictive rights until the subdirectory's copying\nactually begins.  This early-creation idiom can be avoided by using the\n--omit-dir-times\noption.\nIncremental recursion can be disabled using the\n--no-inc-recursive\n(\n--no-i-r\n) option.\n--no-inc-recursive\n,\n--no-i-r\nDisables the new incremental recursion algorithm of the\n--recursive\noption.  This makes rsync scan the full file list\nbefore it begins to transfer files.  See\n--inc-recursive\nfor more\ninfo.\n--relative\n,\n-R\nUse relative paths.  This means that the full path names specified on the\ncommand line are sent to the server rather than just the last parts of the\nfilenames.  This is particularly useful when you want to send several\ndifferent directories at the same time.  For example, if you used this\ncommand:\nrsync -av /foo/bar/baz.c remote:/tmp/\nwould create a file named baz.c in /tmp/ on the remote machine.  If instead\nyou used\nrsync -avR /foo/bar/baz.c remote:/tmp/\nthen a file named /tmp/foo/bar/baz.c would be created on the remote\nmachine, preserving its full path.  These extra path elements are called\n\"implied directories\" (i.e. the \"foo\" and the \"foo/bar\" directories in the\nabove example).\nBeginning with rsync 3.0.0, rsync always sends these implied directories as\nreal directories in the file list, even if a path element is really a\nsymlink on the sending side.  This prevents some really unexpected behaviors\nwhen copying the full path of a file that you didn't realize had a symlink\nin its path.  If you want to duplicate a server-side symlink, include both\nthe symlink via its path, and referent directory via its real path.  If\nyou're dealing with an older rsync on the sending side, you may need to use\nthe\n--no-implied-dirs\noption.\nIt is also possible to limit the amount of path information that is sent as\nimplied directories for each path you specify.  With a modern rsync on the\nsending side (beginning with 2.6.7), you can insert a dot and a slash into\nthe source path, like this:\nrsync -avR /foo/./bar/baz.c remote:/tmp/\nThat would create /tmp/bar/baz.c on the remote machine. (Note that the dot\nmust be followed by a slash, so \"/foo/.\" would not be abbreviated.) For\nolder rsync versions, you would need to use a chdir to limit the source\npath.  For example, when pushing files:\n(cd /foo; rsync -avR bar/baz.c remote:/tmp/)\n(Note that the parens put the two commands into a sub-shell, so that the\n\"cd\" command doesn't remain in effect for future commands.) If you're\npulling files from an older rsync, use this idiom (but only for a\nnon-daemon transfer):\nrsync -avR --rsync-path=\"cd /foo; rsync\" \\\nremote:bar/baz.c /tmp/\n--no-implied-dirs\nThis option affects the default behavior of the\n--relative\noption.  When\nit is specified, the attributes of the implied directories from the source\nnames are not included in the transfer.  This means that the corresponding\npath elements on the destination system are left unchanged if they exist,\nand any missing implied directories are created with default attributes.\nThis even allows these implied path elements to have big differences, such\nas being a symlink to a directory on the receiving side.\nFor instance, if a command-line arg or a files-from entry told rsync to\ntransfer the file \"path/foo/file\", the directories \"path\" and \"path/foo\"\nare implied when\n--relative\nis used.  If \"path/foo\" is a symlink to \"bar\"\non the destination system, the receiving rsync would ordinarily delete\n\"path/foo\", recreate it as a directory, and receive the file into the new\ndirectory.  With\n--no-implied-dirs\n, the receiving rsync updates\n\"path/foo/file\" using the existing path elements, which means that the file\nends up being created in \"path/bar\".  Another way to accomplish this link\npreservation is to use the\n--keep-dirlinks\noption (which will also affect\nsymlinks to directories in the rest of the transfer).\nWhen pulling files from an rsync older than 3.0.0, you may need to use this\noption if the sending side has a symlink in the path you request and you\nwish the implied directories to be transferred as normal directories.\n--backup\n,\n-b\nWith this option, preexisting destination files are renamed as each file is\ntransferred or deleted.  You can control where the backup file goes and\nwhat (if any) suffix gets appended using the\n--backup-dir\nand\n--suffix\noptions.\nIf you don't specify\n--backup-dir\n:\nthe\n--omit-dir-times\noption will be forced on\nthe use of\n--delete\n(without\n--delete-excluded\n),\ncauses rsync to add a \"protect\"\nfilter-rule\nfor the\nbackup suffix to the end of all your existing filters that looks like\nthis:\n-f \"P *~\"\n.  This rule prevents previously backed-up files from\nbeing deleted.\nNote that if you are supplying your own filter rules, you may need to\nmanually insert your own exclude/protect rule somewhere higher up in the\nlist so that it has a high enough priority to be effective (e.g. if your\nrules specify a trailing inclusion/exclusion of\n*\n, the auto-added rule\nwould never be reached).\n--backup-dir=DIR\nThis implies the\n--backup\noption, and tells rsync to store all\nbackups in the specified directory on the receiving side.  This can be used\nfor incremental backups.  You can additionally specify a backup suffix\nusing the\n--suffix\noption (otherwise the files backed up in the\nspecified directory will keep their original filenames).\nNote that if you specify a relative path, the backup directory will be\nrelative to the destination directory, so you probably want to specify\neither an absolute path or a path that starts with \"../\".  If an rsync\ndaemon is the receiver, the backup dir cannot go outside the module's path\nhierarchy, so take extra care not to delete it or copy into it.\n--suffix=SUFFIX\nThis option allows you to override the default backup suffix used with the\n--backup\n(\n-b\n) option.  The default suffix is a\n~\nif no\n--backup-dir\nwas specified, otherwise it is an empty string.\n--update\n,\n-u\nThis forces rsync to skip any files which exist on the destination and have\na modified time that is newer than the source file. (If an existing\ndestination file has a modification time equal to the source file's, it\nwill be updated if the sizes are different.)\nNote that this does not affect the copying of dirs, symlinks, or other\nspecial files.  Also, a difference of file format between the sender and\nreceiver is always considered to be important enough for an update, no\nmatter what date is on the objects.  In other words, if the source has a\ndirectory where the destination has a file, the transfer would occur\nregardless of the timestamps.\nThis option is a\nTRANSFER RULE\n, so don't expect any\nexclude side effects.\nA caution for those that choose to combine\n--inplace\nwith\n--update\n: an interrupted transfer will leave behind a partial file on the\nreceiving side that has a very recent modified time, so re-running the\ntransfer will probably\nnot\ncontinue the interrupted file.  As such, it\nis usually best to avoid combining this with\n--inplace\nunless you\nhave implemented manual steps to handle any interrupted in-progress files.\n--inplace\nThis option changes how rsync transfers a file when its data needs to be\nupdated: instead of the default method of creating a new copy of the file\nand moving it into place when it is complete, rsync instead writes the\nupdated data directly to the destination file.\nThis has several effects:\nHard links are not broken.  This means the new data will be visible\nthrough other hard links to the destination file.  Moreover, attempts to\ncopy differing source files onto a multiply-linked destination file will\nresult in a \"tug of war\" with the destination data changing back and\nforth.\nIn-use binaries cannot be updated (either the OS will prevent this from\nhappening, or binaries that attempt to swap-in their data will misbehave\nor crash).\nThe file's data will be in an inconsistent state during the transfer and\nwill be left that way if the transfer is interrupted or if an update\nfails.\nA file that rsync cannot write to cannot be updated.  While a super user\ncan update any file, a normal user needs to be granted write permission\nfor the open of the file for writing to be successful.\nThe efficiency of rsync's delta-transfer algorithm may be reduced if some\ndata in the destination file is overwritten before it can be copied to a\nposition later in the file.  This does not apply if you use\n--backup\n,\nsince rsync is smart enough to use the backup file as the basis file for\nthe transfer.\nWARNING: you should not use this option to update files that are being\naccessed by others, so be careful when choosing to use this for a copy.\nThis option is useful for transferring large files with block-based changes\nor appended data, and also on systems that are disk bound, not network\nbound.  It can also help keep a copy-on-write filesystem snapshot from\ndiverging the entire contents of a file that only has minor changes.\nThe option implies\n--partial\n(since an interrupted transfer does\nnot delete the file), but conflicts with\n--partial-dir\nand\n--delay-updates\n.  Prior to rsync 2.6.4\n--inplace\nwas also\nincompatible with\n--compare-dest\nand\n--link-dest\n.\n--append\nThis special copy mode only works to efficiently update files that are\nknown to be growing larger where any existing content on the receiving side\nis also known to be the same as the content on the sender.  The use of\n--append\ncan be dangerous\nif you aren't 100% sure that all the files\nin the transfer are shared, growing files.  You should thus use filter\nrules to ensure that you weed out any files that do not fit this criteria.\nRsync updates these growing file in-place without verifying any of the\nexisting content in the file (it only verifies the content that it is\nappending).  Rsync skips any files that exist on the receiving side that\nare not shorter than the associated file on the sending side (which means\nthat new files are transferred).  It also skips any files whose size on the\nsending side gets shorter during the send negotiations (rsync warns about a\n\"diminished\" file when this happens).\nThis does not interfere with the updating of a file's non-content\nattributes (e.g.  permissions, ownership, etc.) when the file does not need\nto be transferred, nor does it affect the updating of any directories or\nnon-regular files.\n--append-verify\nThis special copy mode works like\n--append\nexcept that all the\ndata in the file is included in the checksum verification (making it less\nefficient but also potentially safer).  This option\ncan be dangerous\nif\nyou aren't 100% sure that all the files in the transfer are shared, growing\nfiles.  See the\n--append\noption for more details.\nNote: prior to rsync 3.0.0, the\n--append\noption worked like\n--append-verify\n, so if you are interacting with an older rsync (or the\ntransfer is using a protocol prior to 30), specifying either append option\nwill initiate an\n--append-verify\ntransfer.\n--dirs\n,\n-d\nTell the sending side to include any directories that are encountered.\nUnlike\n--recursive\n, a directory's contents are not copied unless\nthe directory name specified is \".\" or ends with a trailing slash (e.g.\n\".\", \"dir/.\", \"dir/\", etc.).  Without this option or the\n--recursive\noption, rsync will skip all directories it encounters\n(and output a message to that effect for each one).  If you specify both\n--dirs\nand\n--recursive\n,\n--recursive\ntakes precedence.\nThe\n--dirs\noption is implied by the\n--files-from\noption or the\n--list-only\noption (including an implied\n--list-only\nusage) if\n--recursive\nwasn't specified (so that directories are\nseen in the listing).  Specify\n--no-dirs\n(or\n--no-d\n) if you want to\nturn this off.\nThere is also a backward-compatibility helper option,\n--old-dirs\n(\n--old-d\n) that tells rsync to use a hack of\n-r --exclude='/*/*'\nto get\nan older rsync to list a single directory without recursing.\n--mkpath\nCreate all missing path components of the destination path.\nBy default, rsync allows only the final component of the destination path\nto not exist, which is an attempt to help you to validate your destination\npath.  With this option, rsync creates all the missing destination-path\ncomponents, just as if\nmkdir -p $DEST_PATH\nhad been run on the receiving\nside.\nWhen specifying a destination path, including a trailing slash ensures that\nthe whole path is treated as directory names to be created, even when the\nfile list has a single item. See the\nCOPYING TO A DIFFERENT NAME\nsection for full details on how rsync decides if a final destination-path\ncomponent should be created as a directory or not.\nIf you would like the newly-created destination dirs to match the dirs on\nthe sending side, you should be using\n--relative\n(\n-R\n) instead\nof\n--mkpath\n.  For instance, the following two commands result in the same\ndestination tree, but only the second command ensures that the\n\"some/extra/path\" components match the dirs on the sending side:\nrsync -ai --mkpath host:some/extra/path/*.c some/extra/path/\nrsync -aiR host:some/extra/path/*.c ./\n--links\n,\n-l\nAdd symlinks to the transferred files instead of noisily ignoring them with\na \"non-regular file\" warning for each symlink encountered.  You can\nalternately silence the warning by specifying\n--info=nonreg0\n.\nThe default handling of symlinks is to recreate each symlink's unchanged\nvalue on the receiving side.\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--copy-links\n,\n-L\nThe sender transforms each symlink encountered in the transfer into the\nreferent item, following the symlink chain to the file or directory that it\nreferences.  If a symlink chain is broken, an error is output and the file\nis dropped from the transfer.\nThis option supersedes any other options that affect symlinks in the\ntransfer, since there are no symlinks left in the transfer.\nThis option does not change the handling of existing symlinks on the\nreceiving side, unlike versions of rsync prior to 2.6.3 which had the\nside-effect of telling the receiving side to also follow symlinks.  A\nmodern rsync won't forward this option to a remote receiver (since only the\nsender needs to know about it), so this caveat should only affect someone\nusing an rsync client older than 2.6.7 (which is when\n-L\nstopped being\nforwarded to the receiver).\nSee the\n--keep-dirlinks\n(\n-K\n) if you need a symlink to a\ndirectory to be treated as a real directory on the receiving side.\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--copy-unsafe-links\nThis tells rsync to copy the referent of symbolic links that point outside\nthe copied tree.  Absolute symlinks are also treated like ordinary files,\nand so are any symlinks in the source path itself when\n--relative\nis used.\nNote that the cut-off point is the top of the transfer, which is the part\nof the path that rsync isn't mentioning in the verbose output.  If you copy\n\"/src/subdir\" to \"/dest/\" then the \"subdir\" directory is a name inside the\ntransfer tree, not the top of the transfer (which is /src) so it is legal\nfor created relative symlinks to refer to other names inside the /src and\n/dest directories.  If you instead copy \"/src/subdir/\" (with a trailing\nslash) to \"/dest/subdir\" that would not allow symlinks to any files outside\nof \"subdir\".\nNote that safe symlinks are only copied if\n--links\nwas also\nspecified or implied. The\n--copy-unsafe-links\noption has no extra effect\nwhen combined with\n--copy-links\n.\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--safe-links\nThis tells the receiving rsync to ignore any symbolic links in the transfer\nwhich point outside the copied tree.  All absolute symlinks are also\nignored.\nSince this ignoring is happening on the receiving side, it will still be\neffective even when the sending side has munged symlinks (when it is using\n--munge-links\n). It also affects deletions, since the file being\npresent in the transfer prevents any matching file on the receiver from\nbeing deleted when the symlink is deemed to be unsafe and is skipped.\nThis option must be combined with\n--links\n(or\n--archive\n) to have any symlinks in the transfer to conditionally\nignore. Its effect is superseded by\n--copy-unsafe-links\n.\nUsing this option in conjunction with\n--relative\nmay give\nunexpected results.\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--munge-links\nThis option affects just one side of the transfer and tells rsync to munge\nsymlink values when it is receiving files or unmunge symlink values when it\nis sending files.  The munged values make the symlinks unusable on disk but\nallows the original contents of the symlinks to be recovered.\nThe server-side rsync often enables this option without the client's\nknowledge, such as in an rsync daemon's configuration file or by an option\ngiven to the rrsync (restricted rsync) script.  When specified on the\nclient side, specify the option normally if it is the client side that\nhas/needs the munged symlinks, or use\n-M--munge-links\nto give the option\nto the server when it has/needs the munged symlinks.  Note that on a local\ntransfer, the client is the sender, so specifying the option directly\nunmunges symlinks while specifying it as a remote option munges symlinks.\nThis option has no effect when sent to a daemon via\n--remote-option\nbecause the daemon configures whether it wants munged symlinks via its\n\"\nmunge symlinks\n\" parameter.\nThe symlink value is munged/unmunged once it is in the transfer, so any\noption that transforms symlinks into non-symlinks occurs prior to the\nmunging/unmunging\nexcept\nfor\n--safe-links\n, which is a choice\nthat the receiver makes, so it bases its decision on the munged/unmunged\nvalue.  This does mean that if a receiver has munging enabled, that using\n--safe-links\nwill cause all symlinks to be ignored (since they\nare all absolute).\nThe method that rsync uses to munge the symlinks is to prefix each one's\nvalue with the string \"/rsyncd-munged/\".  This prevents the links from\nbeing used as long as the directory does not exist.  When this option is\nenabled, rsync will refuse to run if that path is a directory or a symlink\nto a directory (though it only checks at startup).  See also the\n\"munge-symlinks\" python script in the support directory of the source code\nfor a way to munge/unmunge one or more symlinks in-place.\n--copy-dirlinks\n,\n-k\nThis option causes the sending side to treat a symlink to a directory as\nthough it were a real directory.  This is useful if you don't want symlinks\nto non-directories to be affected, as they would be using\n--copy-links\n.\nWithout this option, if the sending side has replaced a directory with a\nsymlink to a directory, the receiving side will delete anything that is in\nthe way of the new symlink, including a directory hierarchy (as long as\n--force\nor\n--delete\nis in effect).\nSee also\n--keep-dirlinks\nfor an analogous option for the\nreceiving side.\n--copy-dirlinks\napplies to all symlinks to directories in the source.  If\nyou want to follow only a few specified symlinks, a trick you can use is to\npass them as additional source args with a trailing slash, using\n--relative\nto make the paths match up right.  For example:\nrsync -r --relative src/./ src/./follow-me/ dest/\nThis works because rsync calls\nlstat\n(2) on the source arg as given, and\nthe trailing slash makes\nlstat\n(2) follow the symlink, giving rise to a\ndirectory in the file-list which overrides the symlink found during the\nscan of \"src/./\".\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--keep-dirlinks\n,\n-K\nThis option causes the receiving side to treat a symlink to a directory as\nthough it were a real directory, but only if it matches a real directory\nfrom the sender.  Without this option, the receiver's symlink would be\ndeleted and replaced with a real directory.\nFor example, suppose you transfer a directory \"foo\" that contains a file\n\"file\", but \"foo\" is a symlink to directory \"bar\" on the receiver.  Without\n--keep-dirlinks\n, the receiver deletes symlink \"foo\", recreates it as a\ndirectory, and receives the file into the new directory.  With\n--keep-dirlinks\n, the receiver keeps the symlink and \"file\" ends up in\n\"bar\".\nOne note of caution: if you use\n--keep-dirlinks\n, you must trust all the\nsymlinks in the copy or enable the\n--munge-links\noption on the\nreceiving side!  If it is possible for an untrusted user to create their\nown symlink to any real directory, the user could then (on a subsequent\ncopy) replace the symlink with a real directory and affect the content of\nwhatever directory the symlink references.  For backup copies, you are\nbetter off using something like a bind mount instead of a symlink to modify\nyour receiving hierarchy.\nSee also\n--copy-dirlinks\nfor an analogous option for the sending\nside.\nSee the\nSYMBOLIC LINKS\nsection for multi-option info.\n--hard-links\n,\n-H\nThis tells rsync to look for hard-linked files in the source and link\ntogether the corresponding files on the destination.  Without this option,\nhard-linked files in the source are treated as though they were separate\nfiles.\nThis option does NOT necessarily ensure that the pattern of hard links on\nthe destination exactly matches that on the source.  Cases in which the\ndestination may end up with extra hard links include the following:\nIf the destination contains extraneous hard-links (more linking than what\nis present in the source file list), the copying algorithm will not break\nthem explicitly.  However, if one or more of the paths have content\ndifferences, the normal file-update process will break those extra links\n(unless you are using the\n--inplace\noption).\nIf you specify a\n--link-dest\ndirectory that contains hard\nlinks, the linking of the destination files against the\n--link-dest\nfiles can cause some paths in the destination to\nbecome linked together due to the\n--link-dest\nassociations.\nNote that rsync can only detect hard links between files that are inside\nthe transfer set.  If rsync updates a file that has extra hard-link\nconnections to files outside the transfer, that linkage will be broken.  If\nyou are tempted to use the\n--inplace\noption to avoid this breakage, be\nvery careful that you know how your files are being updated so that you are\ncertain that no unintended changes happen due to lingering hard links (and\nsee the\n--inplace\noption for more caveats).\nIf incremental recursion is active (see\n--inc-recursive\n), rsync\nmay transfer a missing hard-linked file before it finds that another link\nfor that contents exists elsewhere in the hierarchy.  This does not affect\nthe accuracy of the transfer (i.e. which files are hard-linked together),\njust its efficiency (i.e. copying the data for a new, early copy of a\nhard-linked file that could have been found later in the transfer in\nanother member of the hard-linked set of files).  One way to avoid this\ninefficiency is to disable incremental recursion using the\n--no-inc-recursive\noption.\n--perms\n,\n-p\nThis option causes the receiving rsync to set the destination permissions\nto be the same as the source permissions. (See also the\n--chmod\noption for a way to modify what rsync considers to be the source\npermissions.)\nWhen this option is\noff\n, permissions are set as follows:\nExisting files (including updated files) retain their existing\npermissions, though the\n--executability\noption might change\njust the execute permission for the file.\nNew files get their \"normal\" permission bits set to the source file's\npermissions masked with the receiving directory's default permissions\n(either the receiving process's umask, or the permissions specified via\nthe destination directory's default ACL), and their special permission\nbits disabled except in the case where a new directory inherits a setgid\nbit from its parent directory.\nThus, when\n--perms\nand\n--executability\nare both disabled, rsync's\nbehavior is the same as that of other file-copy utilities, such as\ncp\n(1)\nand\ntar\n(1).\nIn summary: to give destination files (both old and new) the source\npermissions, use\n--perms\n.  To give new files the destination-default\npermissions (while leaving existing files unchanged), make sure that the\n--perms\noption is off and use\n--chmod=ugo=rwX\n(which ensures\nthat all non-masked bits get enabled).  If you'd care to make this latter\nbehavior easier to type, you could define a popt alias for it, such as\nputting this line in the file\n~/.popt\n(the following defines the\n-Z\noption, and includes\n--no-g\nto use the default group of the destination\ndir):\nrsync alias -Z --no-p --no-g --chmod=ugo=rwX\nYou could then use this new option in a command such as this one:\nrsync -avZ src/ dest/\n(Caveat: make sure that\n-a\ndoes not follow\n-Z\n, or it will re-enable the\ntwo\n--no-*\noptions mentioned above.)\nThe preservation of the destination's setgid bit on newly-created\ndirectories when\n--perms\nis off was added in rsync 2.6.7.  Older rsync\nversions erroneously preserved the three special permission bits for\nnewly-created files when\n--perms\nwas off, while overriding the\ndestination's setgid bit setting on a newly-created directory.  Default ACL\nobservance was added to the ACL patch for rsync 2.6.7, so older (or\nnon-ACL-enabled) rsyncs use the umask even if default ACLs are present.\n(Keep in mind that it is the version of the receiving rsync that affects\nthese behaviors.)\n--executability\n,\n-E\nThis option causes rsync to preserve the executability (or\nnon-executability) of regular files when\n--perms\nis not enabled.\nA regular file is considered to be executable if at least one 'x' is turned\non in its permissions.  When an existing destination file's executability\ndiffers from that of the corresponding source file, rsync modifies the\ndestination file's permissions as follows:\nTo make a file non-executable, rsync turns off all its 'x' permissions.\nTo make a file executable, rsync turns on each 'x' permission that has a\ncorresponding 'r' permission enabled.\nIf\n--perms\nis enabled, this option is ignored.\n--acls\n,\n-A\nThis option causes rsync to update the destination ACLs to be the same as\nthe source ACLs.  The option also implies\n--perms\n.\nThe source and destination systems must have compatible ACL entries for\nthis option to work properly.  See the\n--fake-super\noption for a\nway to backup and restore ACLs that are not compatible.\n--xattrs\n,\n-X\nThis option causes rsync to update the destination extended attributes to\nbe the same as the source ones.\nFor systems that support extended-attribute namespaces, a copy being done\nby a super-user copies all namespaces except system.*.  A normal user only\ncopies the user.* namespace.  To be able to backup and restore non-user\nnamespaces as a normal user, see the\n--fake-super\noption.\nThe above name filtering can be overridden by using one or more filter\noptions with the\nx\nmodifier.  When you specify an xattr-affecting\nfilter rule, rsync requires that you do your own system/user filtering, as\nwell as any additional filtering for what xattr names are copied and what\nnames are allowed to be deleted.  For example, to skip the system\nnamespace, you could specify:\n--filter='-x system.*'\nTo skip all namespaces except the user namespace, you could specify a\nnegated-user match:\n--filter='-x! user.*'\nTo prevent any attributes from being deleted, you could specify a\nreceiver-only rule that excludes all names:\n--filter='-xr *'\nNote that the\n-X\noption does not copy rsync's special xattr values (e.g.\nthose used by\n--fake-super\n) unless you repeat the option (e.g.\n-XX\n).\nThis \"copy all xattrs\" mode cannot be used with\n--fake-super\n.\n--chmod=CHMOD\nThis option tells rsync to apply one or more comma-separated \"chmod\" modes\nto the permission of the files in the transfer.  The resulting value is\ntreated as though it were the permissions that the sending side supplied\nfor the file, which means that this option can seem to have no effect on\nexisting files if\n--perms\nis not enabled.\nIn addition to the normal parsing rules specified in the\nchmod\n(1)\nmanpage, you can specify an item that should only apply to a directory by\nprefixing it with a 'D', or specify an item that should only apply to a\nfile by prefixing it with a 'F'.  For example, the following will ensure\nthat all directories get marked set-gid, that no files are other-writable,\nthat both are user-writable and group-writable, and that both have\nconsistent executability across all bits:\n--chmod=Dg+s,ug+w,Fo-w,+X\nUsing octal mode numbers is also allowed:\n--chmod=D2775,F664\nIt is also legal to specify multiple\n--chmod\noptions, as each additional\noption is just appended to the list of changes to make.\nSee the\n--perms\nand\n--executability\noptions for how the\nresulting permission value can be applied to the files in the transfer.\n--owner\n,\n-o\nThis option causes rsync to set the owner of the destination file to be the\nsame as the source file, but only if the receiving rsync is being run as\nthe super-user (see also the\n--super\nand\n--fake-super\noptions).  Without this option, the owner of new and/or transferred files\nare set to the invoking user on the receiving side.\nThe preservation of ownership will associate matching names by default, but\nmay fall back to using the ID number in some circumstances (see also the\n--numeric-ids\noption for a full discussion).\n--group\n,\n-g\nThis option causes rsync to set the group of the destination file to be the\nsame as the source file.  If the receiving program is not running as the\nsuper-user (or if\n--no-super\nwas specified), only groups that the\ninvoking user on the receiving side is a member of will be preserved.\nWithout this option, the group is set to the default group of the invoking\nuser on the receiving side.\nThe preservation of group information will associate matching names by\ndefault, but may fall back to using the ID number in some circumstances\n(see also the\n--numeric-ids\noption for a full discussion).\n--devices\nThis option causes rsync to transfer character and block device files to\nthe remote system to recreate these devices.  If the receiving rsync is not\nbeing run as the super-user, rsync silently skips creating the device files\n(see also the\n--super\nand\n--fake-super\noptions).\nBy default, rsync generates a \"non-regular file\" warning for each device\nfile encountered when this option is not set.  You can silence the warning\nby specifying\n--info=nonreg0\n.\n--specials\nThis option causes rsync to transfer special files, such as named sockets\nand fifos.  If the receiving rsync is not being run as the super-user,\nrsync silently skips creating the special files (see also the\n--super\nand\n--fake-super\noptions).\nBy default, rsync generates a \"non-regular file\" warning for each special\nfile encountered when this option is not set.  You can silence the warning\nby specifying\n--info=nonreg0\n.\n-D\nThe\n-D\noption is equivalent to \"\n--devices\n--specials\n\".\n--copy-devices\nThis tells rsync to treat a device on the sending side as a regular file,\nallowing it to be copied to a normal destination file (or another device\nif\n--write-devices\nwas also specified).\nThis option is refused by default by an rsync daemon.\n--write-devices\nThis tells rsync to treat a device on the receiving side as a regular file,\nallowing the writing of file data into a device.\nThis option implies the\n--inplace\noption.\nBe careful using this, as you should know what devices are present on the\nreceiving side of the transfer, especially when running rsync as root.\nThis option is refused by default by an rsync daemon.\n--times\n,\n-t\nThis tells rsync to transfer modification times along with the files and\nupdate them on the remote system.  Note that if this option is not used,\nthe optimization that excludes files that have not been modified cannot be\neffective; in other words, a missing\n-t\n(or\n-a\n) will cause the\nnext transfer to behave as if it used\n--ignore-times\n(\n-I\n),\ncausing all files to be updated (though rsync's delta-transfer algorithm\nwill make the update fairly efficient if the files haven't actually\nchanged, you're much better off using\n-t\n).\nA modern rsync that is using transfer protocol 30 or 31 conveys a modify\ntime using up to 8-bytes. If rsync is forced to speak an older protocol\n(perhaps due to the remote rsync being older than 3.0.0) a modify time is\nconveyed using 4-bytes. Prior to 3.2.7, these shorter values could convey\na date range of 13-Dec-1901 to 19-Jan-2038.  Beginning with 3.2.7, these\n4-byte values now convey a date range of 1-Jan-1970 to 7-Feb-2106.  If you\nhave files dated older than 1970, make sure your rsync executables are\nupgraded so that the full range of dates can be conveyed.\n--atimes\n,\n-U\nThis tells rsync to set the access (use) times of the destination files to\nthe same value as the source files.\nIf repeated, it also sets the\n--open-noatime\noption, which can help you\nto make the sending and receiving systems have the same access times on the\ntransferred files without needing to run rsync an extra time after a file\nis transferred.\nNote that some older rsync versions (prior to 3.2.0) may have been built\nwith a pre-release\n--atimes\npatch that does not imply\n--open-noatime\nwhen this option is repeated.\n--open-noatime\nThis tells rsync to open files with the O_NOATIME flag (on systems that\nsupport it) to avoid changing the access time of the files that are being\ntransferred.  If your OS does not support the O_NOATIME flag then rsync\nwill silently ignore this option.  Note also that some filesystems are\nmounted to avoid updating the atime on read access even without the\nO_NOATIME flag being set.\n--crtimes\n,\n-N,\nThis tells rsync to set the create times (newness) of the destination\nfiles to the same value as the source files. Your OS & filesystem must\nsupport the setting of arbitrary creation (birth) times for this option\nto be supported.\n--omit-dir-times\n,\n-O\nThis tells rsync to omit directories when it is preserving modification,\naccess, and create times.  If NFS is sharing the directories on the receiving\nside, it is a good idea to use\n-O\n.  This option is inferred if you use\n--backup\nwithout\n--backup-dir\n.\nThis option also has the side-effect of avoiding early creation of missing\nsub-directories when incremental recursion is enabled, as discussed in the\n--inc-recursive\nsection.\n--omit-link-times\n,\n-J\nThis tells rsync to omit symlinks when it is preserving modification,\naccess, and create times.\n--super\nThis tells the receiving side to attempt super-user activities even if the\nreceiving rsync wasn't run by the super-user.  These activities include:\npreserving users via the\n--owner\noption, preserving all groups\n(not just the current user's groups) via the\n--group\noption, and\ncopying devices via the\n--devices\noption.  This is useful for\nsystems that allow such activities without being the super-user, and also\nfor ensuring that you will get errors if the receiving side isn't being run\nas the super-user.  To turn off super-user activities, the super-user can\nuse\n--no-super\n.\n--fake-super\nWhen this option is enabled, rsync simulates super-user activities by\nsaving/restoring the privileged attributes via special extended attributes\nthat are attached to each file (as needed).  This includes the file's owner\nand group (if it is not the default), the file's device info (device &\nspecial files are created as empty text files), and any permission bits\nthat we won't allow to be set on the real file (e.g. the real file gets\nu-s,g-s,o-t for safety) or that would limit the owner's access (since the\nreal super-user can always access/change a file, the files we create can\nalways be accessed/changed by the creating user).  This option also handles\nACLs (if\n--acls\nwas specified) and non-user extended attributes\n(if\n--xattrs\nwas specified).\nThis is a good way to backup data without using a super-user, and to store\nACLs from incompatible systems.\nThe\n--fake-super\noption only affects the side where the option is used.\nTo affect the remote side of a remote-shell connection, use the\n--remote-option\n(\n-M\n) option:\nrsync -av -M--fake-super /src/ host:/dest/\nFor a local copy, this option affects both the source and the destination.\nIf you wish a local copy to enable this option just for the destination\nfiles, specify\n-M--fake-super\n.  If you wish a local copy to enable this\noption just for the source files, combine\n--fake-super\nwith\n-M--super\n.\nThis option is overridden by both\n--super\nand\n--no-super\n.\nSee also the\nfake super\nsetting in the\ndaemon's rsyncd.conf file.\n--sparse\n,\n-S\nTry to handle sparse files efficiently so they take up less space on the\ndestination.  If combined with\n--inplace\nthe file created might\nnot end up with sparse blocks with some combinations of kernel version\nand/or filesystem type.  If\n--whole-file\nis in effect (e.g. for a\nlocal copy) then it will always work because rsync truncates the file prior\nto writing out the updated version.\nNote that versions of rsync older than 3.1.3 will reject the combination of\n--sparse\nand\n--inplace\n.\n--preallocate\nThis tells the receiver to allocate each destination file to its eventual\nsize before writing data to the file.  Rsync will only use the real\nfilesystem-level preallocation support provided by Linux's\nfallocate\n(2)\nsystem call or Cygwin's\nposix_fallocate\n(3), not the slow glibc\nimplementation that writes a null byte into each block.\nWithout this option, larger files may not be entirely contiguous on the\nfilesystem, but with this option rsync will probably copy more slowly.  If\nthe destination is not an extent-supporting filesystem (such as ext4, xfs,\nNTFS, etc.), this option may have no positive effect at all.\nIf combined with\n--sparse\n, the file will only have sparse blocks\n(as opposed to allocated sequences of null bytes) if the kernel version and\nfilesystem type support creating holes in the allocated data.\n--dry-run\n,\n-n\nThis makes rsync perform a trial run that doesn't make any changes (and\nproduces mostly the same output as a real run).  It is most commonly used\nin combination with the\n--verbose\n(\n-v\n) and/or\n--itemize-changes\n(\n-i\n) options to see what an rsync command is\ngoing to do before one actually runs it.\nThe output of\n--itemize-changes\nis supposed to be exactly the\nsame on a dry run and a subsequent real run (barring intentional trickery\nand system call failures); if it isn't, that's a bug.  Other output should\nbe mostly unchanged, but may differ in some areas.  Notably, a dry run does\nnot send the actual data for file transfers, so\n--progress\nhas no\neffect, the \"bytes sent\", \"bytes received\", \"literal data\", and \"matched\ndata\" statistics are too small, and the \"speedup\" value is equivalent to a\nrun where no file transfers were needed.\n--whole-file\n,\n-W\nThis option disables rsync's delta-transfer algorithm, which causes all\ntransferred files to be sent whole.  The transfer may be faster if this\noption is used when the bandwidth between the source and destination\nmachines is higher than the bandwidth to disk (especially when the \"disk\"\nis actually a networked filesystem).  This is the default when both the\nsource and destination are specified as local paths, but only if no\nbatch-writing option is in effect.\n--no-whole-file\n,\n--no-W\nDisable whole-file updating when it is enabled by default for a local\ntransfer.  This usually slows rsync down, but it can be useful if you are\ntrying to minimize the writes to the destination file (if combined with\n--inplace\n) or for testing the checksum-based update algorithm.\nSee also the\n--whole-file\noption.\n--checksum-choice=STR\n,\n--cc=STR\nThis option overrides the checksum algorithms.  If one algorithm name is\nspecified, it is used for both the transfer checksums and (assuming\n--checksum\nis specified) the pre-transfer checksums.  If two\ncomma-separated names are supplied, the first name affects the transfer\nchecksums, and the second name affects the pre-transfer checksums (\n-c\n).\nThe checksum options that you may be able to use are:\nauto\n(the default automatic choice)\nxxh128\nxxh3\nxxh64\n(aka\nxxhash\n)\nmd5\nmd4\nsha1\nnone\nRun\nrsync --version\nto see the default checksum list compiled into your\nversion (which may differ from the list above).\nIf \"none\" is specified for the first (or only) name, the\n--whole-file\noption is forced on and no checksum verification is performed on the\ntransferred data.  If \"none\" is specified for the second (or only) name,\nthe\n--checksum\noption cannot be used.\nThe \"auto\" option is the default, where rsync bases its algorithm choice on\na negotiation between the client and the server as follows:\nWhen both sides of the transfer are at least 3.2.0, rsync chooses the first\nalgorithm in the client's list of choices that is also in the server's list\nof choices.  If no common checksum choice is found, rsync exits with\nan error.  If the remote rsync is too old to support checksum negotiation,\na value is chosen based on the protocol version (which chooses between MD5\nand various flavors of MD4 based on protocol age).\nThe default order can be customized by setting the environment variable\nRSYNC_CHECKSUM_LIST\nto a space-separated list of acceptable checksum\nnames.  If the string contains a \"\n&\n\" character, it is separated into the\n\"client string & server string\", otherwise the same string applies to both.\nIf the string (or string portion) contains no non-whitespace characters,\nthe default checksum list is used.  This method does not allow you to\nspecify the transfer checksum separately from the pre-transfer checksum,\nand it discards \"auto\" and all unknown checksum names.  A list with only\ninvalid names results in a failed negotiation.\nThe use of the\n--checksum-choice\noption overrides this environment list.\n--one-file-system\n,\n-x\nThis tells rsync to avoid crossing a filesystem boundary when recursing.\nThis does not limit the user's ability to specify items to copy from\nmultiple filesystems, just rsync's recursion through the hierarchy of each\ndirectory that the user specified, and also the analogous recursion on the\nreceiving side during deletion.  Also keep in mind that rsync treats a\n\"bind\" mount to the same device as being on the same filesystem.\nIf this option is repeated, rsync omits all mount-point directories from\nthe copy.  Otherwise, it includes an empty directory at each mount-point it\nencounters (using the attributes of the mounted directory because those of\nthe underlying mount-point directory are inaccessible).\nIf rsync has been told to collapse symlinks (via\n--copy-links\nor\n--copy-unsafe-links\n), a symlink to a directory on another device\nis treated like a mount-point.  Symlinks to non-directories are unaffected\nby this option.\n--ignore-non-existing\n,\n--existing\nThis tells rsync to skip creating files (including directories) that do not\nexist yet on the destination.  If this option is combined with the\n--ignore-existing\noption, no files will be updated (which can be\nuseful if all you want to do is delete extraneous files).\nThis option is a\nTRANSFER RULE\n, so don't expect any\nexclude side effects.\n--ignore-existing\nThis tells rsync to skip updating files that already exist on the\ndestination (this does\nnot\nignore existing directories, or nothing would\nget done).  See also\n--ignore-non-existing\n.\nThis option is a\nTRANSFER RULE\n, so don't expect any\nexclude side effects.\nThis option can be useful for those doing backups using the\n--link-dest\noption when they need to continue a backup run that\ngot interrupted.  Since a\n--link-dest\nrun is copied into a new\ndirectory hierarchy (when it is used properly), using [\n--ignore-existing\nwill ensure that the already-handled files don't get tweaked (which avoids\na change in permissions on the hard-linked files).  This does mean that\nthis option is only looking at the existing files in the destination\nhierarchy itself.\nWhen\n--info=skip2\nis used rsync will output \"FILENAME exists\n(INFO)\" messages where the INFO indicates one of \"type change\", \"sum\nchange\" (requires\n-c\n), \"file change\" (based on the quick check),\n\"attr change\", or \"uptodate\".  Using\n--info=skip1\n(which is also\nimplied by 2\n-v\noptions) outputs the exists message without the\nINFO suffix.\n--remove-source-files\nThis tells rsync to remove from the sending side the files (meaning\nnon-directories) that are a part of the transfer and have been successfully\nduplicated on the receiving side.\nNote that you should only use this option on source files that are\nquiescent.  If you are using this to move files that show up in a\nparticular directory over to another host, make sure that the finished\nfiles get renamed into the source directory, not directly written into it,\nso that rsync can't possibly transfer a file that is not yet fully written.\nIf you can't first write the files into a different directory, you should\nuse a naming idiom that lets rsync avoid transferring files that are not\nyet finished (e.g. name the file \"foo.new\" when it is written, rename it to\n\"foo\" when it is done, and then use the option\n--exclude='*.new'\nfor the rsync transfer).\nStarting with 3.1.0, rsync will skip the sender-side removal (and output an\nerror) if the file's size or modify time has not stayed unchanged.\nStarting with 3.2.6, a local rsync copy will ensure that the sender does\nnot remove a file the receiver just verified, such as when the user\naccidentally makes the source and destination directory the same path.\n--delete\nThis tells rsync to delete extraneous files from the receiving side (ones\nthat aren't on the sending side), but only for the directories that are\nbeing synchronized.  You must have asked rsync to send the whole directory\n(e.g. \"\ndir\n\" or \"\ndir/\n\") without using a wildcard for the directory's\ncontents (e.g. \"\ndir/*\n\") since the wildcard is expanded by the shell and\nrsync thus gets a request to transfer individual files, not the files'\nparent directory.  Files that are excluded from the transfer are also\nexcluded from being deleted unless you use the\n--delete-excluded\noption or mark the rules as only matching on the sending side (see the\ninclude/exclude modifiers in the\nFILTER RULES\nsection).\nPrior to rsync 2.6.7, this option would have no effect unless\n--recursive\nwas enabled.  Beginning with 2.6.7, deletions will\nalso occur when\n--dirs\n(\n-d\n) is enabled, but only for\ndirectories whose contents are being copied.\nThis option can be dangerous if used incorrectly! It is a very good idea to\nfirst try a run using the\n--dry-run\n(\n-n\n) option to see what\nfiles are going to be deleted.\nIf the sending side detects any I/O errors, then the deletion of any files\nat the destination will be automatically disabled.  This is to prevent\ntemporary filesystem failures (such as NFS errors) on the sending side from\ncausing a massive deletion of files on the destination.  You can override\nthis with the\n--ignore-errors\noption.\nThe\n--delete\noption may be combined with one of the -⁠-⁠delete-⁠WHEN options\nwithout conflict, as well as\n--delete-excluded\n.  However, if none\nof the\n--delete-WHEN\noptions are specified, rsync will choose the\n--delete-during\nalgorithm when talking to rsync 3.0.0 or newer,\nor the\n--delete-before\nalgorithm when talking to an older rsync.\nSee also\n--delete-delay\nand\n--delete-after\n.\n--delete-before\nRequest that the file-deletions on the receiving side be done before the\ntransfer starts.  See\n--delete\n(which is implied) for more\ndetails on file-deletion.\nDeleting before the transfer is helpful if the filesystem is tight for\nspace and removing extraneous files would help to make the transfer\npossible.  However, it does introduce a delay before the start of the\ntransfer, and this delay might cause the transfer to timeout (if\n--timeout\nwas specified).  It also forces rsync to use the old,\nnon-incremental recursion algorithm that requires rsync to scan all the\nfiles in the transfer into memory at once (see\n--recursive\n).\n--delete-during\n,\n--del\nRequest that the file-deletions on the receiving side be done incrementally\nas the transfer happens.  The per-directory delete scan is done right\nbefore each directory is checked for updates, so it behaves like a more\nefficient\n--delete-before\n, including doing the deletions prior to\nany per-directory filter files being updated.  This option was first added\nin rsync version 2.6.4.  See\n--delete\n(which is implied) for more\ndetails on file-deletion.\n--delete-delay\nRequest that the file-deletions on the receiving side be computed during\nthe transfer (like\n--delete-during\n), and then removed after the\ntransfer completes.  This is useful when combined with\n--delay-updates\nand/or\n--fuzzy\n, and is more efficient\nthan using\n--delete-after\n(but can behave differently, since\n--delete-after\ncomputes the deletions in a separate pass after\nall updates are done).  If the number of removed files overflows an\ninternal buffer, a temporary file will be created on the receiving side to\nhold the names (it is removed while open, so you shouldn't see it during\nthe transfer).  If the creation of the temporary file fails, rsync will try\nto fall back to using\n--delete-after\n(which it cannot do if\n--recursive\nis doing an incremental scan).  See\n--delete\n(which is implied) for more details on file-deletion.\n--delete-after\nRequest that the file-deletions on the receiving side be done after the\ntransfer has completed.  This is useful if you are sending new\nper-directory merge files as a part of the transfer and you want their\nexclusions to take effect for the delete phase of the current transfer.  It\nalso forces rsync to use the old, non-incremental recursion algorithm that\nrequires rsync to scan all the files in the transfer into memory at once\n(see\n--recursive\n). See\n--delete\n(which is implied) for\nmore details on file-deletion.\nSee also the\n--delete-delay\noption that might be a faster choice\nfor those that just want the deletions to occur at the end of the transfer.\n--delete-excluded\nThis option turns any unqualified exclude/include rules into server-side\nrules that do not affect the receiver's deletions.\nBy default, an exclude or include has both a server-side effect (to \"hide\"\nand \"show\" files when building the server's file list) and a receiver-side\neffect (to \"protect\" and \"risk\" files when deletions are occurring).  Any\nrule that has no modifier to specify what sides it is executed on will be\ninstead treated as if it were a server-side rule only, avoiding any\n\"protect\" effects of the rules.\nA rule can still apply to both sides even with this option specified if the\nrule is given both the sender & receiver modifier letters (e.g.,\n-f'-sr foo'\n).  Receiver-side protect/risk rules can also be explicitly specified\nto limit the deletions.  This saves you from having to edit a bunch of\n-f'- foo'\nrules into\n-f'-s foo'\n(aka\n-f'H foo'\n) rules (not to mention\nthe corresponding includes).\nSee the\nFILTER RULES\nsection for more information.  See\n--delete\n(which is implied) for more details on deletion.\n--ignore-missing-args\nWhen rsync is first processing the explicitly requested source files (e.g.\ncommand-line arguments or\n--files-from\nentries), it is normally\nan error if the file cannot be found.  This option suppresses that error,\nand does not try to transfer the file.  This does not affect subsequent\nvanished-file errors if a file was initially found to be present and later\nis no longer there.\n--delete-missing-args\nThis option takes the behavior of the (implied)\n--ignore-missing-args\noption a step farther: each missing arg\nwill become a deletion request of the corresponding destination file on the\nreceiving side (should it exist).  If the destination file is a non-empty\ndirectory, it will only be successfully deleted if\n--force\nor\n--delete\nare in effect.  Other than that, this option is\nindependent of any other type of delete processing.\nThe missing source files are represented by special file-list entries which\ndisplay as a \"\n*missing\n\" entry in the\n--list-only\noutput.\n--ignore-errors\nTells\n--delete\nto go ahead and delete files even when there are\nI/O errors.\n--force\nThis option tells rsync to delete a non-empty directory when it is to be\nreplaced by a non-directory.  This is only relevant if deletions are not\nactive (see\n--delete\nfor details).\nNote for older rsync versions:\n--force\nused to still be required when\nusing\n--delete-after\n, and it used to be non-functional unless the\n--recursive\noption was also enabled.\n--max-delete=NUM\nThis tells rsync not to delete more than NUM files or directories.  If that\nlimit is exceeded, all further deletions are skipped through the end of the\ntransfer.  At the end, rsync outputs a warning (including a count of the\nskipped deletions) and exits with an error code of 25 (unless some more\nimportant error condition also occurred).\nBeginning with version 3.0.0, you may specify\n--max-delete=0\nto be warned\nabout any extraneous files in the destination without removing any of them.\nOlder clients interpreted this as \"unlimited\", so if you don't know what\nversion the client is, you can use the less obvious\n--max-delete=-1\nas a\nbackward-compatible way to specify that no deletions be allowed (though\nreally old versions didn't warn when the limit was exceeded).\n--max-size=SIZE\nThis tells rsync to avoid transferring any file that is larger than the\nspecified SIZE.  A numeric value can be suffixed with a string to indicate\nthe numeric units or left unqualified to specify bytes.  Feel free to use a\nfractional value along with the units, such as\n--max-size=1.5m\n.\nThis option is a\nTRANSFER RULE\n, so don't expect any\nexclude side effects.\nThe first letter of a units string can be\nB\n(bytes),\nK\n(kilo),\nM\n(mega),\nG\n(giga),\nT\n(tera), or\nP\n(peta).  If the string is a single\nchar or has \"ib\" added to it (e.g. \"G\" or \"GiB\") then the units are\nmultiples of 1024.  If you use a two-letter suffix that ends with a \"B\"\n(e.g. \"kb\") then you get units that are multiples of 1000.  The string's\nletters can be any mix of upper and lower-case that you want to use.\nFinally, if the string ends with either \"+1\" or \"-⁠1\", it is offset by one\nbyte in the indicated direction.  The largest possible value is usually\n8192P-1\n.\nExamples:\n--max-size=1.5mb-1\nis 1499999 bytes, and\n--max-size=2g+1\nis\n2147483649 bytes.\nNote that rsync versions prior to 3.1.0 did not allow\n--max-size=0\n.\n--min-size=SIZE\nThis tells rsync to avoid transferring any file that is smaller than the\nspecified SIZE, which can help in not transferring small, junk files.  See\nthe\n--max-size\noption for a description of SIZE and other info.\nNote that rsync versions prior to 3.1.0 did not allow\n--min-size=0\n.\n--max-alloc=SIZE\nBy default rsync limits an individual malloc/realloc to about 1GB in size.\nFor most people this limit works just fine and prevents a protocol error\ncausing rsync to request massive amounts of memory.  However, if you have\nmany millions of files in a transfer, a large amount of server memory, and\nyou don't want to split up your transfer into multiple parts, you can\nincrease the per-allocation limit to something larger and rsync will\nconsume more memory.\nKeep in mind that this is not a limit on the total size of allocated\nmemory.  It is a sanity-check value for each individual allocation.\nSee the\n--max-size\noption for a description of how SIZE can be\nspecified.  The default suffix if none is given is bytes.\nBeginning in 3.2.7, a value of 0 is an easy way to specify SIZE_MAX (the\nlargest limit possible).\nYou can set a default value using the environment variable\nRSYNC_MAX_ALLOC\nusing the same SIZE values as supported by this\noption.  If the remote rsync doesn't understand the\n--max-alloc\noption,\nyou can override an environmental value by specifying\n--max-alloc=1g\n,\nwhich will make rsync avoid sending the option to the remote side (because\n\"1G\" is the default).\n--block-size=SIZE\n,\n-B\nThis forces the block size used in rsync's delta-transfer algorithm to a\nfixed value.  It is normally selected based on the size of each file being\nupdated.  See the technical report for details.\nBeginning in 3.2.3 the SIZE can be specified with a suffix as detailed in\nthe\n--max-size\noption.  Older versions only accepted a byte count.\n--rsh=COMMAND\n,\n-e\nThis option allows you to choose an alternative remote shell program to use\nfor communication between the local and remote copies of rsync.  Typically,\nrsync is configured to use ssh by default, but you may prefer to use rsh on\na local network.\nIf this option is used with\n[user@]host::module/path\n, then the remote\nshell\nCOMMAND\nwill be used to run an rsync daemon on the remote host, and\nall data will be transmitted through that remote shell connection, rather\nthan through a direct socket connection to a running rsync daemon on the\nremote host.  See the\nUSING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL\nCONNECTION\nsection above.\nBeginning with rsync 3.2.0, the\nRSYNC_PORT\nenvironment variable will\nbe set when a daemon connection is being made via a remote-shell\nconnection.  It is set to 0 if the default daemon port is being assumed, or\nit is set to the value of the rsync port that was specified via either the\n--port\noption or a non-empty port value in an\nrsync://\nURL.\nThis allows the script to discern if a non-default port is being requested,\nallowing for things such as an SSL or stunnel helper script to connect to a\ndefault or alternate port.\nCommand-line arguments are permitted in COMMAND provided that COMMAND is\npresented to rsync as a single argument.  You must use spaces (not tabs or\nother whitespace) to separate the command and args from each other, and you\ncan use single- and/or double-quotes to preserve spaces in an argument (but\nnot backslashes).  Note that doubling a single-quote inside a single-quoted\nstring gives you a single-quote; likewise for double-quotes (though you\nneed to pay attention to which quotes your shell is parsing and which\nquotes rsync is parsing).  Some examples:\n-e 'ssh -p 2234'\n-e 'ssh -o \"ProxyCommand nohup ssh firewall nc -w1 %h %p\"'\n(Note that ssh users can alternately customize site-specific connect\noptions in their .ssh/config file.)\nYou can also choose the remote shell program using the\nRSYNC_RSH\nenvironment variable, which accepts the same range of values as\n-e\n.\nSee also the\n--blocking-io\noption which is affected by this\noption.\n--rsync-path=PROGRAM\nUse this to specify what program is to be run on the remote machine to\nstart-up rsync.  Often used when rsync is not in the default remote-shell's\npath (e.g.\n--rsync-path=/usr/local/bin/rsync\n).  Note that PROGRAM is run\nwith the help of a shell, so it can be any program, script, or command\nsequence you'd care to run, so long as it does not corrupt the standard-in\n& standard-out that rsync is using to communicate.\nOne tricky example is to set a different default directory on the remote\nmachine for use with the\n--relative\noption.  For instance:\nrsync -avR --rsync-path=\"cd /a/b && rsync\" host:c/d /e/\n--remote-option=OPTION\n,\n-M\nThis option is used for more advanced situations where you want certain\neffects to be limited to one side of the transfer only.  For instance, if\nyou want to pass\n--log-file=FILE\nand\n--fake-super\nto\nthe remote system, specify it like this:\nrsync -av -M --log-file=foo -M--fake-super src/ dest/\nIf you want to have an option affect only the local side of a transfer when\nit normally affects both sides, send its negation to the remote side.  Like\nthis:\nrsync -av -x -M--no-x src/ dest/\nBe cautious using this, as it is possible to toggle an option that will\ncause rsync to have a different idea about what data to expect next over\nthe socket, and that will make it fail in a cryptic fashion.\nNote that you should use a separate\n-M\noption for each remote option you\nwant to pass.  On older rsync versions, the presence of any spaces in the\nremote-option arg could cause it to be split into separate remote args, but\nthis requires the use of\n--old-args\nin a modern rsync.\nWhen performing a local transfer, the \"local\" side is the sender and the\n\"remote\" side is the receiver.\nNote some versions of the popt option-parsing library have a bug in them\nthat prevents you from using an adjacent arg with an equal in it next to a\nshort option letter (e.g.\n-M--log-file=/tmp/foo\n).  If this bug affects\nyour version of popt, you can use the version of popt that is included with\nrsync.\n--cvs-exclude\n,\n-C\nThis is a useful shorthand for excluding a broad range of files that you\noften don't want to transfer between systems.  It uses a similar algorithm\nto CVS to determine if a file should be ignored.\nThe exclude list is initialized to exclude the following items (these\ninitial items are marked as perishable -⁠-⁠ see the\nFILTER RULES\nsection):\nRCS\nSCCS\nCVS\nCVS.adm\nRCSLOG\ncvslog.*\ntags\nTAGS\n.make.state\n.nse_depinfo\n*~\n#*\n.#*\n,*\n_$*\n*$\n*.old\n*.bak\n*.BAK\n*.orig\n*.rej\n.del-*\n*.a\n*.olb\n*.o\n*.obj\n*.so\n*.exe\n*.Z\n*.elc\n*.ln\ncore\n.svn/\n.git/\n.hg/\n.bzr/\nthen, files listed in a $HOME/.cvsignore are added to the list and any\nfiles listed in the CVSIGNORE environment variable (all cvsignore names are\ndelimited by whitespace).\nFinally, any file is ignored if it is in the same directory as a .cvsignore\nfile and matches one of the patterns listed therein.  Unlike rsync's\nfilter/exclude files, these patterns are split on whitespace.  See the\ncvs\n(1) manual for more information.\nIf you're combining\n-C\nwith your own\n--filter\nrules, you should\nnote that these CVS excludes are appended at the end of your own rules,\nregardless of where the\n-C\nwas placed on the command-line.  This makes\nthem a lower priority than any rules you specified explicitly.  If you want\nto control where these CVS excludes get inserted into your filter rules,\nyou should omit the\n-C\nas a command-line option and use a combination of\n--filter=:C\nand\n--filter=-C\n(either on your\ncommand-line or by putting the \":C\" and \"-⁠C\" rules into a filter file with\nyour other rules).  The first option turns on the per-directory scanning\nfor the .cvsignore file.  The second option does a one-time import of the\nCVS excludes mentioned above.\n--filter=RULE\n,\n-f\nThis option allows you to add rules to selectively exclude certain files\nfrom the list of files to be transferred.  This is most useful in\ncombination with a recursive transfer.\nYou may use as many\n--filter\noptions on the command line as you like to\nbuild up the list of files to exclude.  If the filter contains whitespace,\nbe sure to quote it so that the shell gives the rule to rsync as a single\nargument.  The text below also mentions that you can use an underscore to\nreplace the space that separates a rule from its arg.\nSee the\nFILTER RULES\nsection for detailed information on this option.\n-F\nThe\n-F\noption is a shorthand for adding two\n--filter\nrules to\nyour command.  The first time it is used is a shorthand for this rule:\n--filter='dir-merge /.rsync-filter'\nThis tells rsync to look for per-directory .rsync-filter files that have\nbeen sprinkled through the hierarchy and use their rules to filter the\nfiles in the transfer.  If\n-F\nis repeated, it is a shorthand for this\nrule:\n--filter='exclude .rsync-filter'\nThis filters out the .rsync-filter files themselves from the transfer.\nSee the\nFILTER RULES\nsection for detailed information on how these\noptions work.\n--exclude=PATTERN\nThis option is a simplified form of the\n--filter\noption that\nspecifies an exclude rule and does not allow the full rule-parsing syntax\nof normal filter rules.  This is equivalent to specifying\n-f'- PATTERN'\n.\nSee the\nFILTER RULES\nsection for detailed information on this option.\n--exclude-from=FILE\nThis option is related to the\n--exclude\noption, but it specifies\na FILE that contains exclude patterns (one per line).  Blank lines in the\nfile are ignored, as are whole-line comments that start with '\n;\n' or '\n#\n'\n(filename rules that contain those characters are unaffected).\nIf a line begins with \"\n-\n\" (dash, space) or \"\n+\n\" (plus, space), then\nthe type of rule is being explicitly specified as an exclude or an include\n(respectively).  Any rules without such a prefix are taken to be an exclude.\nIf a line consists of just \"\n!\n\", then the current filter rules are cleared\nbefore adding any further rules.\nIf\nFILE\nis '\n-\n', the list will be read from standard input.\n--include=PATTERN\nThis option is a simplified form of the\n--filter\noption that\nspecifies an include rule and does not allow the full rule-parsing syntax\nof normal filter rules.  This is equivalent to specifying\n-f'+ PATTERN'\n.\nSee the\nFILTER RULES\nsection for detailed information on this option.\n--include-from=FILE\nThis option is related to the\n--include\noption, but it specifies\na FILE that contains include patterns (one per line).  Blank lines in the\nfile are ignored, as are whole-line comments that start with '\n;\n' or '\n#\n'\n(filename rules that contain those characters are unaffected).\nIf a line begins with \"\n-\n\" (dash, space) or \"\n+\n\" (plus, space), then\nthe type of rule is being explicitly specified as an exclude or an include\n(respectively).  Any rules without such a prefix are taken to be an include.\nIf a line consists of just \"\n!\n\", then the current filter rules are cleared\nbefore adding any further rules.\nIf\nFILE\nis '\n-\n', the list will be read from standard input.\n--files-from=FILE\nUsing this option allows you to specify the exact list of files to transfer\n(as read from the specified FILE or '\n-\n' for standard input).  It also\ntweaks the default behavior of rsync to make transferring just the\nspecified files and directories easier:\nThe\n--relative\n(\n-R\n) option is implied, which preserves the\npath information that is specified for each item in the file (use\n--no-relative\nor\n--no-R\nif you want to turn that off).\nThe\n--dirs\n(\n-d\n) option is implied, which will create\ndirectories specified in the list on the destination rather than noisily\nskipping them (use\n--no-dirs\nor\n--no-d\nif you want to turn that off).\nThe\n--archive\n(\n-a\n) option's behavior does not imply\n--recursive\n(\n-r\n), so specify it explicitly, if you want it.\nThese side-effects change the default state of rsync, so the position of\nthe\n--files-from\noption on the command-line has no bearing on how other\noptions are parsed (e.g.\n-a\nworks the same before or after\n--files-from\n, as does\n--no-R\nand all other options).\nThe filenames that are read from the FILE are all relative to the source\ndir -⁠-⁠ any leading slashes are removed and no \"..\" references are allowed\nto go higher than the source dir.  For example, take this command:\nrsync -a --files-from=/tmp/foo /usr remote:/backup\nIf /tmp/foo contains the string \"bin\" (or even \"/bin\"), the /usr/bin\ndirectory will be created as /backup/bin on the remote host.  If it\ncontains \"bin/\" (note the trailing slash), the immediate contents of the\ndirectory would also be sent (without needing to be explicitly mentioned in\nthe file -⁠-⁠ this began in version 2.6.4).  In both cases, if the\n-r\noption was enabled, that dir's entire hierarchy would also be\ntransferred (keep in mind that\n-r\nneeds to be specified\nexplicitly with\n--files-from\n, since it is not implied by\n-a\n.\nAlso note that the effect of the (enabled by default)\n-r\noption\nis to duplicate only the path info that is read from the file -⁠-⁠ it does\nnot force the duplication of the source-spec path (/usr in this case).\nIn addition, the\n--files-from\nfile can be read from the remote host\ninstead of the local host if you specify a \"host:\" in front of the file\n(the host must match one end of the transfer).  As a short-cut, you can\nspecify just a prefix of \":\" to mean \"use the remote end of the transfer\".\nFor example:\nrsync -a --files-from=:/path/file-list src:/ /tmp/copy\nThis would copy all the files specified in the /path/file-list file that\nwas located on the remote \"src\" host.\nIf the\n--iconv\nand\n--secluded-args\noptions are specified\nand the\n--files-from\nfilenames are being sent from one host to another,\nthe filenames will be translated from the sending host's charset to the\nreceiving host's charset.\nNOTE: sorting the list of files in the\n--files-from\ninput helps rsync to\nbe more efficient, as it will avoid re-visiting the path elements that are\nshared between adjacent entries.  If the input is not sorted, some path\nelements (implied directories) may end up being scanned multiple times, and\nrsync will eventually unduplicate them after they get turned into file-list\nelements.\n--from0\n,\n-0\nThis tells rsync that the rules/filenames it reads from a file are\nterminated by a null ('\\0') character, not a NL, CR, or CR+LF.  This\naffects\n--exclude-from\n,\n--include-from\n,\n--files-from\n, and any merged files specified in a\n--filter\nrule.  It does not affect\n--cvs-exclude\n(since\nall names read from a .cvsignore file are split on whitespace).\n--old-args\nThis option tells rsync to stop trying to protect the arg values on the\nremote side from unintended word-splitting or other misinterpretation.\nIt also allows the client to treat an empty arg as a \".\" instead of\ngenerating an error.\nThe default in a modern rsync is for \"shell-active\" characters (including\nspaces) to be backslash-escaped in the args that are sent to the remote\nshell.  The wildcard characters\n*\n,\n?\n,\n[\n, &\n]\nare not escaped in\nfilename args (allowing them to expand into multiple filenames) while being\nprotected in option args, such as\n--usermap\n.\nIf you have a script that wants to use old-style arg splitting in its\nfilenames, specify this option once.  If the remote shell has a problem\nwith any backslash escapes at all, specify this option twice.\nYou may also control this setting via the\nRSYNC_OLD_ARGS\nenvironment\nvariable.  If it has the value \"1\", rsync will default to a single-option\nsetting.  If it has the value \"2\" (or more), rsync will default to a\nrepeated-option setting.  If it is \"0\", you'll get the default escaping\nbehavior.  The environment is always overridden by manually specified\npositive or negative options (the negative is\n--no-old-args\n).\nNote that this option also disables the extra safety check added in 3.2.5\nthat ensures that a remote sender isn't including extra top-level items in\nthe file-list that you didn't request.  This side-effect is necessary\nbecause we can't know for sure what names to expect when the remote shell\nis interpreting the args.\nThis option conflicts with the\n--secluded-args\noption.\n--secluded-args\n,\n-s\nThis option sends all filenames and most options to the remote rsync via\nthe protocol (not the remote shell command line) which avoids letting the\nremote shell modify them.  Wildcards are expanded on the remote host by\nrsync instead of a shell.\nThis is similar to the default backslash-escaping of args that was added\nin 3.2.4 (see\n--old-args\n) in that it prevents things like space\nsplitting and unwanted special-character side-effects. However, it has the\ndrawbacks of being incompatible with older rsync versions (prior to 3.0.0)\nand of being refused by restricted shells that want to be able to inspect\nall the option values for safety.\nThis option is useful for those times that you need the argument's\ncharacter set to be converted for the remote host, if the remote shell is\nincompatible with the default backslash-escpaing method, or there is some\nother reason that you want the majority of the options and arguments to\nbypass the command-line of the remote shell.\nIf you combine this option with\n--iconv\n, the args related to the\nremote side will be translated from the local to the remote character-set.\nThe translation happens before wild-cards are expanded.  See also the\n--files-from\noption.\nYou may also control this setting via the\nRSYNC_PROTECT_ARGS\nenvironment variable.  If it has a non-zero value, this setting will be\nenabled by default, otherwise it will be disabled by default.  Either state\nis overridden by a manually specified positive or negative version of this\noption (note that\n--no-s\nand\n--no-secluded-args\nare the negative\nversions).  This environment variable is also superseded by a non-zero\nRSYNC_OLD_ARGS\nexport.\nThis option conflicts with the\n--old-args\noption.\nThis option used to be called\n--protect-args\n(before 3.2.6) and that\nolder name can still be used (though specifying it as\n-s\nis always the\neasiest and most compatible choice).\n--trust-sender\nThis option disables two extra validation checks that a local client\nperforms on the file list generated by a remote sender.  This option should\nonly be used if you trust the sender to not put something malicious in the\nfile list (something that could possibly be done via a modified rsync, a\nmodified shell, or some other similar manipulation).\nNormally, the rsync client (as of version 3.2.5) runs two extra validation\nchecks when pulling files from a remote rsync:\nIt verifies that additional arg items didn't get added at the top of the\ntransfer.\nIt verifies that none of the items in the file list are names that should\nhave been excluded (if filter rules were specified).\nNote that various options can turn off one or both of these checks if the\noption interferes with the validation.  For instance:\nUsing a per-directory filter file reads filter rules that only the server\nknows about, so the filter checking is disabled.\nUsing the\n--old-args\noption allows the sender to manipulate the\nrequested args, so the arg checking is disabled.\nReading the files-from list from the server side means that the client\ndoesn't know the arg list, so the arg checking is disabled.\nUsing\n--read-batch\ndisables both checks since the batch file's\ncontents will have been verified when it was created.\nThis option may help an under-powered client server if the extra pattern\nmatching is slowing things down on a huge transfer.  It can also be used to\nwork around a currently-unknown bug in the verification logic for a transfer\nfrom a trusted sender.\nWhen using this option it is a good idea to specify a dedicated destination\ndirectory, as discussed in the\nMULTI-HOST SECURITY\nsection.\n--copy-as=USER[:GROUP]\nThis option instructs rsync to use the USER and (if specified after a\ncolon) the GROUP for the copy operations.  This only works if the user that\nis running rsync has the ability to change users.  If the group is not\nspecified then the user's default groups are used.\nThis option can help to reduce the risk of an rsync being run as root into\nor out of a directory that might have live changes happening to it and you\nwant to make sure that root-level read or write actions of system files are\nnot possible.  While you could alternatively run all of rsync as the\nspecified user, sometimes you need the root-level host-access credentials\nto be used, so this allows rsync to drop root for the copying part of the\noperation after the remote-shell or daemon connection is established.\nThe option only affects one side of the transfer unless the transfer is\nlocal, in which case it affects both sides.  Use the\n--remote-option\nto affect the remote side, such as\n-M--copy-as=joe\n.  For a local transfer, the lsh (or lsh.sh) support file\nprovides a local-shell helper script that can be used to allow a\n\"localhost:\" or \"lh:\" host-spec to be specified without needing to setup\nany remote shells, allowing you to specify remote options that affect the\nside of the transfer that is using the host-spec (and using hostname \"lh\"\navoids the overriding of the remote directory to the user's home dir).\nFor example, the following rsync writes the local files as user \"joe\":\nsudo rsync -aiv --copy-as=joe host1:backups/joe/ /home/joe/\nThis makes all files owned by user \"joe\", limits the groups to those that\nare available to that user, and makes it impossible for the joe user to do\na timed exploit of the path to induce a change to a file that the joe user\nhas no permissions to change.\nThe following command does a local copy into the \"dest/\" dir as user \"joe\"\n(assuming you've installed support/lsh into a dir on your $PATH):\nsudo rsync -aive lsh -M--copy-as=joe src/ lh:dest/\n--temp-dir=DIR\n,\n-T\nThis option instructs rsync to use DIR as a scratch directory when creating\ntemporary copies of the files transferred on the receiving side.  The\ndefault behavior is to create each temporary file in the same directory as\nthe associated destination file.  Beginning with rsync 3.1.1, the temp-file\nnames inside the specified DIR will not be prefixed with an extra dot\n(though they will still have a random suffix added).\nThis option is most often used when the receiving disk partition does not\nhave enough free space to hold a copy of the largest file in the transfer.\nIn this case (i.e. when the scratch directory is on a different disk\npartition), rsync will not be able to rename each received temporary file\nover the top of the associated destination file, but instead must copy it\ninto place.  Rsync does this by copying the file over the top of the\ndestination file, which means that the destination file will contain\ntruncated data during this copy.  If this were not done this way (even if\nthe destination file were first removed, the data locally copied to a\ntemporary file in the destination directory, and then renamed into place)\nit would be possible for the old file to continue taking up disk space (if\nsomeone had it open), and thus there might not be enough room to fit the\nnew version on the disk at the same time.\nIf you are using this option for reasons other than a shortage of disk\nspace, you may wish to combine it with the\n--delay-updates\noption, which will ensure that all copied files get put into subdirectories\nin the destination hierarchy, awaiting the end of the transfer.  If you\ndon't have enough room to duplicate all the arriving files on the\ndestination partition, another way to tell rsync that you aren't overly\nconcerned about disk space is to use the\n--partial-dir\noption\nwith a relative path; because this tells rsync that it is OK to stash off a\ncopy of a single file in a subdir in the destination hierarchy, rsync will\nuse the partial-dir as a staging area to bring over the copied file, and\nthen rename it into place from there. (Specifying a\n--partial-dir\nwith an absolute path does not have this side-effect.)\n--fuzzy\n,\n-y\nThis option tells rsync that it should look for a basis file for any\ndestination file that is missing.  The current algorithm looks in the same\ndirectory as the destination file for either a file that has an identical\nsize and modified-time, or a similarly-named file.  If found, rsync uses\nthe fuzzy basis file to try to speed up the transfer.\nIf the option is repeated, the fuzzy scan will also be done in any matching\nalternate destination directories that are specified via\n--compare-dest\n,\n--copy-dest\n, or\n--link-dest\n.\nNote that the use of the\n--delete\noption might get rid of any\npotential fuzzy-match files, so either use\n--delete-after\nor\nspecify some filename exclusions if you need to prevent this.\n--compare-dest=DIR\nThis option instructs rsync to use\nDIR\non the destination machine as an\nadditional hierarchy to compare destination files against doing transfers\n(if the files are missing in the destination directory).  If a file is\nfound in\nDIR\nthat is identical to the sender's file, the file will NOT be\ntransferred to the destination directory.  This is useful for creating a\nsparse backup of just files that have changed from an earlier backup.  This\noption is typically used to copy into an empty (or newly created)\ndirectory.\nBeginning in version 2.6.4, multiple\n--compare-dest\ndirectories may be\nprovided, which will cause rsync to search the list in the order specified\nfor an exact match.  If a match is found that differs only in attributes, a\nlocal copy is made and the attributes updated.  If a match is not found, a\nbasis file from one of the\nDIRs\nwill be selected to try to speed up the\ntransfer.\nIf\nDIR\nis a relative path, it is relative to the destination directory.\nSee also\n--copy-dest\nand\n--link-dest\n.\nNOTE: beginning with version 3.1.0, rsync will remove a file from a\nnon-empty destination hierarchy if an exact match is found in one of the\ncompare-dest hierarchies (making the end result more closely match a fresh\ncopy).\n--copy-dest=DIR\nThis option behaves like\n--compare-dest\n, but rsync will also copy\nunchanged files found in\nDIR\nto the destination directory using a local\ncopy.  This is useful for doing transfers to a new destination while\nleaving existing files intact, and then doing a flash-cutover when all\nfiles have been successfully transferred.\nMultiple\n--copy-dest\ndirectories may be provided, which will cause rsync\nto search the list in the order specified for an unchanged file.  If a\nmatch is not found, a basis file from one of the\nDIRs\nwill be selected to\ntry to speed up the transfer.\nIf\nDIR\nis a relative path, it is relative to the destination directory.\nSee also\n--compare-dest\nand\n--link-dest\n.\n--link-dest=DIR\nThis option behaves like\n--copy-dest\n, but unchanged files are\nhard linked from\nDIR\nto the destination directory.  The files must be\nidentical in all preserved attributes (e.g. permissions, possibly\nownership) in order for the files to be linked together.  An example:\nrsync -av --link-dest=$PWD/prior_dir host:src_dir/ new_dir/\nIf files aren't linking, double-check their attributes.  Also check if\nsome attributes are getting forced outside of rsync's control, such a mount\noption that squishes root to a single user, or mounts a removable drive\nwith generic ownership (such as OS X's \"Ignore ownership on this volume\"\noption).\nBeginning in version 2.6.4, multiple\n--link-dest\ndirectories may be\nprovided, which will cause rsync to search the list in the order specified\nfor an exact match (there is a limit of 20 such directories).  If a match\nis found that differs only in attributes, a local copy is made and the\nattributes updated.  If a match is not found, a basis file from one of the\nDIRs\nwill be selected to try to speed up the transfer.\nThis option works best when copying into an empty destination hierarchy, as\nexisting files may get their attributes tweaked, and that can affect\nalternate destination files via hard-links.  Also, itemizing of changes can\nget a bit muddled.  Note that prior to version 3.1.0, an\nalternate-directory exact match would never be found (nor linked into the\ndestination) when a destination file already exists.\nNote that if you combine this option with\n--ignore-times\n, rsync will not\nlink any files together because it only links identical files together as a\nsubstitute for transferring the file, never as an additional check after\nthe file is updated.\nIf\nDIR\nis a relative path, it is relative to the destination directory.\nSee also\n--compare-dest\nand\n--copy-dest\n.\nNote that rsync versions prior to 2.6.1 had a bug that could prevent\n--link-dest\nfrom working properly for a non-super-user when\n--owner\n(\n-o\n) was specified (or implied).  You can work-around\nthis bug by avoiding the\n-o\noption (or using\n--no-o\n) when sending to an\nold rsync.\n--compress\n,\n-z\nWith this option, rsync compresses the file data as it is sent to the\ndestination machine, which reduces the amount of data being transmitted -⁠-⁠\nsomething that is useful over a slow connection.\nRsync supports multiple compression methods and will choose one for you\nunless you force the choice using the\n--compress-choice\n(\n--zc\n)\noption.\nRun\nrsync --version\nto see the default compress list compiled into your\nversion.\nWhen both sides of the transfer are at least 3.2.0, rsync chooses the first\nalgorithm in the client's list of choices that is also in the server's list\nof choices.  If no common compress choice is found, rsync exits with\nan error.  If the remote rsync is too old to support checksum negotiation,\nits list is assumed to be \"zlib\".\nThe default order can be customized by setting the environment variable\nRSYNC_COMPRESS_LIST\nto a space-separated list of acceptable\ncompression names.  If the string contains a \"\n&\n\" character, it is\nseparated into the \"client string & server string\", otherwise the same\nstring applies to both.  If the string (or string portion) contains no\nnon-whitespace characters, the default compress list is used.  Any unknown\ncompression names are discarded from the list, but a list with only invalid\nnames results in a failed negotiation.\nThere are some older rsync versions that were configured to reject a\n-z\noption and require the use of\n-zz\nbecause their compression library was\nnot compatible with the default zlib compression method.  You can usually\nignore this weirdness unless the rsync server complains and tells you to\nspecify\n-zz\n.\n--compress-choice=STR\n,\n--zc=STR\nThis option can be used to override the automatic negotiation of the\ncompression algorithm that occurs when\n--compress\nis used.  The\noption implies\n--compress\nunless \"none\" was specified, which\ninstead implies\n--no-compress\n.\nThe compression options that you may be able to use are:\nzstd\nlz4\nzlibx\nzlib\nnone\nRun\nrsync --version\nto see the default compress list compiled into your\nversion (which may differ from the list above).\nNote that if you see an error about an option named\n--old-compress\nor\n--new-compress\n, this is rsync trying to send the\n--compress-choice=zlib\nor\n--compress-choice=zlibx\noption in a backward-compatible manner that\nmore rsync versions understand.  This error indicates that the older rsync\nversion on the server will not allow you to force the compression type.\nNote that the \"zlibx\" compression algorithm is just the \"zlib\" algorithm\nwith matched data excluded from the compression stream (to try to make it\nmore compatible with an external zlib implementation).\n--compress-level=NUM\n,\n--zl=NUM\nExplicitly set the compression level to use (see\n--compress\n,\n-z\n) instead of letting it default.  The\n--compress\noption is\nimplied as long as the level chosen is not a \"don't compress\" level for the\ncompression algorithm that is in effect (e.g. zlib compression treats level\n0 as \"off\").\nThe level values vary depending on the checksum in effect.  Because rsync\nwill negotiate a checksum choice by default (when the remote rsync is new\nenough), it can be good to combine this option with a\n--compress-choice\n(\n--zc\n) option unless you're sure of the\nchoice in effect.  For example:\nrsync -aiv --zc=zstd --zl=22 host:src/ dest/\nFor zlib & zlibx compression the valid values are from 1 to 9 with 6 being\nthe default.  Specifying\n--zl=0\nturns compression off, and specifying\n--zl=-1\nchooses the default level of 6.\nFor zstd compression the valid values are from -⁠131072 to 22 with 3 being\nthe default. Specifying 0 chooses the default of 3.\nFor lz4 compression there are no levels, so the value is always 0.\nIf you specify a too-large or too-small value, the number is silently\nlimited to a valid value.  This allows you to specify something like\n--zl=999999999\nand be assured that you'll end up with the maximum\ncompression level no matter what algorithm was chosen.\nIf you want to know the compression level that is in effect, specify\n--debug=nstr\nto see the \"negotiated string\" results.  This will\nreport something like \"\nClient compress: zstd (level 3)\n\" (along with the\nchecksum choice in effect).\n--skip-compress=LIST\nNOTE:\nno compression method currently supports per-file compression\nchanges, so this option has no effect.\nOverride the list of file suffixes that will be compressed as little as\npossible.  Rsync sets the compression level on a per-file basis based on\nthe file's suffix.  If the compression algorithm has an \"off\" level, then\nno compression occurs for those files.  Other algorithms that support\nchanging the streaming level on-the-fly will have the level minimized to\nreduces the CPU usage as much as possible for a matching file.\nThe\nLIST\nshould be one or more file suffixes (without the dot) separated\nby slashes (\n/\n).  You may specify an empty string to indicate that no files\nshould be skipped.\nSimple character-class matching is supported: each must consist of a list\nof letters inside the square brackets (e.g. no special classes, such as\n\"[:alpha:]\", are supported, and '-⁠' has no special meaning).\nThe characters asterisk (\n*\n) and question-mark (\n?\n) have no special meaning.\nHere's an example that specifies 6 suffixes to skip (since 1 of the 5 rules\nmatches 2 suffixes):\n--skip-compress=gz/jpg/mp[34]/7z/bz2\nThe default file suffixes in the skip-compress list in this version of\nrsync are:\n3g2\n3gp\n7z\naac\nace\napk\navi\nbz2\ndeb\ndmg\near\nf4v\nflac\nflv\ngpg\ngz\niso\njar\njpeg\njpg\nlrz\nlz\nlz4\nlzma\nlzo\nm1a\nm1v\nm2a\nm2ts\nm2v\nm4a\nm4b\nm4p\nm4r\nm4v\nmka\nmkv\nmov\nmp1\nmp2\nmp3\nmp4\nmpa\nmpeg\nmpg\nmpv\nmts\nodb\nodf\nodg\nodi\nodm\nodp\nods\nodt\noga\nogg\nogm\nogv\nogx\nopus\notg\noth\notp\nots\nott\noxt\npng\nqt\nrar\nrpm\nrz\nrzip\nspx\nsquashfs\nsxc\nsxd\nsxg\nsxm\nsxw\nsz\ntbz\ntbz2\ntgz\ntlz\nts\ntxz\ntzo\nvob\nwar\nwebm\nwebp\nxz\nz\nzip\nzst\nThis list will be replaced by your\n--skip-compress\nlist in all but one\nsituation: a copy from a daemon rsync will add your skipped suffixes to its\nlist of non-compressing files (and its list may be configured to a\ndifferent default).\n--numeric-ids\nWith this option rsync will transfer numeric group and user IDs rather than\nusing user and group names and mapping them at both ends.\nBy default rsync will use the username and groupname to determine what\nownership to give files.  The special uid 0 and the special group 0 are\nnever mapped via user/group names even if the\n--numeric-ids\noption is not\nspecified.\nIf a user or group has no name on the source system or it has no match on\nthe destination system, then the numeric ID from the source system is used\ninstead.  See also the\nuse chroot\nsetting\nin the rsyncd.conf manpage for some comments on how the chroot setting\naffects rsync's ability to look up the names of the users and groups and\nwhat you can do about it.\n--usermap=STRING\n,\n--groupmap=STRING\nThese options allow you to specify users and groups that should be mapped\nto other values by the receiving side.  The\nSTRING\nis one or more\nFROM\n:\nTO\npairs of values separated by commas.  Any matching\nFROM\nvalue from the sender is replaced with a\nTO\nvalue from the receiver.\nYou may specify usernames or user IDs for the\nFROM\nand\nTO\nvalues,\nand the\nFROM\nvalue may also be a wild-card string, which will be\nmatched against the sender's names (wild-cards do NOT match against ID\nnumbers, though see below for why a '\n*\n' matches everything).  You may\ninstead specify a range of ID numbers via an inclusive range: LOW-HIGH.\nFor example:\n--usermap=0-99:nobody,wayne:admin,*:normal --groupmap=usr:1,1:usr\nThe first match in the list is the one that is used.  You should specify\nall your user mappings using a single\n--usermap\noption, and/or all your\ngroup mappings using a single\n--groupmap\noption.\nNote that the sender's name for the 0 user and group are not transmitted to\nthe receiver, so you should either match these values using a 0, or use the\nnames in effect on the receiving side (typically \"root\").  All other\nFROM\nnames match those in use on the sending side.  All\nTO\nnames\nmatch those in use on the receiving side.\nAny IDs that do not have a name on the sending side are treated as having\nan empty name for the purpose of matching.  This allows them to be matched\nvia a \"\n*\n\" or using an empty name.  For instance:\n--usermap=:nobody --groupmap=*:nobody\nWhen the\n--numeric-ids\noption is used, the sender does not send any\nnames, so all the IDs are treated as having an empty name.  This means that\nyou will need to specify numeric\nFROM\nvalues if you want to map these\nnameless IDs to different values.\nFor the\n--usermap\noption to work, the receiver will need to be running as\na super-user (see also the\n--super\nand\n--fake-super\noptions).  For the\n--groupmap\noption to work, the receiver will need to\nhave permissions to set that group.\nStarting with rsync 3.2.4, the\n--usermap\noption implies the\n--owner\n(\n-o\n) option while the\n--groupmap\noption implies the\n--group\n(\n-g\n) option (since rsync needs to have those options\nenabled for the mapping options to work).\nAn older rsync client may need to use\n-s\nto avoid a complaint\nabout wildcard characters, but a modern rsync handles this automatically.\n--chown=USER:GROUP\nThis option forces all files to be owned by USER with group GROUP.  This is\na simpler interface than using\n--usermap\n&\n--groupmap\ndirectly, but it is implemented using those options internally so they\ncannot be mixed.  If either the USER or GROUP is empty, no mapping for the\nomitted user/group will occur.  If GROUP is empty, the trailing colon may\nbe omitted, but if USER is empty, a leading colon must be supplied.\nIf you specify \"\n--chown=foo:bar\n\", this is exactly the same as specifying\n\"\n--usermap=*:foo --groupmap=*:bar\n\", only easier (and with the same\nimplied\n--owner\nand/or\n--group\noptions).\nAn older rsync client may need to use\n-s\nto avoid a complaint\nabout wildcard characters, but a modern rsync handles this automatically.\n--timeout=SECONDS\nThis option allows you to set a maximum I/O timeout in seconds.  If no data\nis transferred for the specified time then rsync will exit.  The default is\n0, which means no timeout.\n--contimeout=SECONDS\nThis option allows you to set the amount of time that rsync will wait for\nits connection to an rsync daemon to succeed.  If the timeout is reached,\nrsync exits with an error.\n--address=ADDRESS\nBy default rsync will bind to the wildcard address when connecting to an\nrsync daemon.  The\n--address\noption allows you to specify a specific IP\naddress (or hostname) to bind to.\nSee also\nthe daemon version of the\n--address\noption\n.\n--port=PORT\nThis specifies an alternate TCP port number to use rather than the default\nof 873.  This is only needed if you are using the double-colon (::) syntax\nto connect with an rsync daemon (since the URL syntax has a way to specify\nthe port as a part of the URL).\nSee also\nthe daemon version of the\n--port\noption\n.\n--sockopts=OPTIONS\nThis option can provide endless fun for people who like to tune their\nsystems to the utmost degree.  You can set all sorts of socket options\nwhich may make transfers faster (or slower!).  Read the manpage for the\nsetsockopt()\nsystem call for details on some of the options you may be\nable to set.  By default no special socket options are set.  This only\naffects direct socket connections to a remote rsync daemon.\nSee also\nthe daemon version of the\n--sockopts\noption\n.\n--blocking-io\nThis tells rsync to use blocking I/O when launching a remote shell\ntransport.  If the remote shell is either rsh or remsh, rsync defaults to\nusing blocking I/O, otherwise it defaults to using non-blocking I/O. (Note\nthat ssh prefers non-blocking I/O.)\n--outbuf=MODE\nThis sets the output buffering mode.  The mode can be None (aka\nUnbuffered), Line, or Block (aka Full).  You may specify as little as a\nsingle letter for the mode, and use upper or lower case.\nThe main use of this option is to change Full buffering to Line buffering\nwhen rsync's output is going to a file or pipe.\n--itemize-changes\n,\n-i\nRequests a simple itemized list of the changes that are being made to each\nfile, including attribute changes.  This is exactly the same as specifying\n--out-format='%i %n%L'\n.  If you repeat the option, unchanged\nfiles will also be output, but only if the receiving rsync is at least\nversion 2.6.7 (you can use\n-vv\nwith older versions of rsync, but that\nalso turns on the output of other verbose messages).\nThe \"%i\" escape has a cryptic output that is 11 letters long.  The general\nformat is like the string\nYXcstpoguax\n, where\nY\nis replaced by the type\nof update being done,\nX\nis replaced by the file-type, and the other\nletters represent attributes that may be output if they are being modified.\nThe update types that replace the\nY\nare as follows:\nA\n<\nmeans that a file is being transferred to the remote host (sent).\nA\n>\nmeans that a file is being transferred to the local host\n(received).\nA\nc\nmeans that a local change/creation is occurring for the item (such\nas the creation of a directory or the changing of a symlink, etc.).\nA\nh\nmeans that the item is a hard link to another item (requires\n--hard-links\n).\nA\n.\nmeans that the item is not being updated (though it might have\nattributes that are being modified).\nA\n*\nmeans that the rest of the itemized-output area contains a message\n(e.g. \"deleting\").\nThe file-types that replace the\nX\nare:\nf\nfor a file, a\nd\nfor a\ndirectory, an\nL\nfor a symlink, a\nD\nfor a device, and a\nS\nfor a\nspecial file (e.g. named sockets and fifos).\nThe other letters in the string indicate if some attributes of the file\nhave changed, as follows:\n\"\n.\n\" -⁠ the attribute is unchanged.\n\"\n+\n\" -⁠ the file is newly created.\n\"\n\" -⁠ all the attributes are unchanged (all dots turn to spaces).\n\"\n?\n\" -⁠ the change is unknown (when the remote rsync is old).\nA letter indicates an attribute is being updated.\nThe attribute that is associated with each letter is as follows:\nA\nc\nmeans either that a regular file has a different checksum (requires\n--checksum\n) or that a symlink, device, or special file has a\nchanged value.  Note that if you are sending files to an rsync prior to\n3.0.1, this change flag will be present only for checksum-differing\nregular files.\nA\ns\nmeans the size of a regular file is different and will be updated\nby the file transfer.\nA\nt\nmeans the modification time is different and is being updated to\nthe sender's value (requires\n--times\n).  An alternate value of\nT\nmeans that the modification time will be set to the transfer time,\nwhich happens when a file/symlink/device is updated without\n--times\nand when a symlink is changed and the receiver can't\nset its time. (Note: when using an rsync 3.0.0 client, you might see the\ns\nflag combined with\nt\ninstead of the proper\nT\nflag for this\ntime-setting failure.)\nA\np\nmeans the permissions are different and are being updated to the\nsender's value (requires\n--perms\n).\nAn\no\nmeans the owner is different and is being updated to the sender's\nvalue (requires\n--owner\nand super-user privileges).\nA\ng\nmeans the group is different and is being updated to the sender's\nvalue (requires\n--group\nand the authority to set the group).\nA\nu\n|\nn\n|\nb\nindicates the following information:\nu\nmeans the access (use) time is different and is being updated to\nthe sender's value (requires\n--atimes\n)\nn\nmeans the create time (newness) is different and is being updated\nto the sender's value (requires\n--crtimes\n)\nb\nmeans that both the access and create times are being updated\nThe\na\nmeans that the ACL information is being changed.\nThe\nx\nmeans that the extended attribute information is being changed.\nOne other output is possible: when deleting files, the \"%i\" will output the\nstring \"\n*deleting\n\" for each item that is being removed (assuming that you\nare talking to a recent enough rsync that it logs deletions instead of\noutputting them as a verbose message).\n--out-format=FORMAT\nThis allows you to specify exactly what the rsync client outputs to the\nuser on a per-update basis.  The format is a text string containing\nembedded single-character escape sequences prefixed with a percent (%)\ncharacter.  A default format of \"%n%L\" is assumed if either\n--info=name\nor\n-v\nis specified (this tells you just the\nname of the file and, if the item is a link, where it points).  For a full\nlist of the possible escape characters, see the\nlog format\nsetting in the rsyncd.conf manpage.\nSpecifying the\n--out-format\noption implies the\n--info=name\noption, which will mention each file, dir, etc. that gets updated in a\nsignificant way (a transferred file, a recreated symlink/device, or a\ntouched directory).  In addition, if the itemize-changes escape (%i) is\nincluded in the string (e.g. if the\n--itemize-changes\noption was\nused), the logging of names increases to mention any item that is changed\nin any way (as long as the receiving side is at least 2.6.4).  See the\n--itemize-changes\noption for a description of the output of \"%i\".\nRsync will output the out-format string prior to a file's transfer unless\none of the transfer-statistic escapes is requested, in which case the\nlogging is done at the end of the file's transfer.  When this late logging\nis in effect and\n--progress\nis also specified, rsync will also\noutput the name of the file being transferred prior to its progress\ninformation (followed, of course, by the out-format output).\n--log-file=FILE\nThis option causes rsync to log what it is doing to a file.  This is\nsimilar to the logging that a daemon does, but can be requested for the\nclient side and/or the server side of a non-daemon transfer.  If specified\nas a client option, transfer logging will be enabled with a default format\nof \"%i %n%L\".  See the\n--log-file-format\noption if you wish to\noverride this.\nHere's an example command that requests the remote side to log what is\nhappening:\nrsync -av --remote-option=--log-file=/tmp/rlog src/ dest/\nThis is very useful if you need to debug why a connection is closing\nunexpectedly.\nSee also\nthe daemon version of the\n--log-file\noption\n.\n--log-file-format=FORMAT\nThis allows you to specify exactly what per-update logging is put into the\nfile specified by the\n--log-file\noption (which must also be\nspecified for this option to have any effect).  If you specify an empty\nstring, updated files will not be mentioned in the log file.  For a list of\nthe possible escape characters, see the\nlog format\nsetting in the rsyncd.conf manpage.\nThe default FORMAT used if\n--log-file\nis specified and this\noption is not is '%i %n%L'.\nSee also\nthe daemon version of the\n--log-file-format\noption\n.\n--stats\nThis tells rsync to print a verbose set of statistics on the file transfer,\nallowing you to tell how effective rsync's delta-transfer algorithm is for\nyour data.  This option is equivalent to\n--info=stats2\nif\ncombined with 0 or 1\n-v\noptions, or\n--info=stats3\nif\ncombined with 2 or more\n-v\noptions.\nThe current statistics are as follows:\nNumber of files\nis the count of all \"files\" (in the generic sense),\nwhich includes directories, symlinks, etc.  The total count will be\nfollowed by a list of counts by filetype (if the total is non-zero).  For\nexample: \"(reg: 5, dir: 3, link: 2, dev: 1, special: 1)\" lists the totals\nfor regular files, directories, symlinks, devices, and special files.  If\nany of value is 0, it is completely omitted from the list.\nNumber of created files\nis the count of how many \"files\" (generic\nsense) were created (as opposed to updated).  The total count will be\nfollowed by a list of counts by filetype (if the total is non-zero).\nNumber of deleted files\nis the count of how many \"files\" (generic\nsense) were deleted.  The total count will be\nfollowed by a list of counts by filetype (if the total is non-zero).\nNote that this line is only output if deletions are in effect, and only\nif protocol 31 is being used (the default for rsync 3.1.x).\nNumber of regular files transferred\nis the count of normal files that\nwere updated via rsync's delta-transfer algorithm, which does not include\ndirs, symlinks, etc.  Note that rsync 3.1.0 added the word \"regular\" into\nthis heading.\nTotal file size\nis the total sum of all file sizes in the transfer.\nThis does not count any size for directories or special files, but does\ninclude the size of symlinks.\nTotal transferred file size\nis the total sum of all files sizes for\njust the transferred files.\nLiteral data\nis how much unmatched file-update data we had to send to\nthe receiver for it to recreate the updated files.\nMatched data\nis how much data the receiver got locally when recreating\nthe updated files.\nFile list size\nis how big the file-list data was when the sender sent\nit to the receiver.  This is smaller than the in-memory size for the file\nlist due to some compressing of duplicated data when rsync sends the\nlist.\nFile list generation time\nis the number of seconds that the sender\nspent creating the file list.  This requires a modern rsync on the\nsending side for this to be present.\nFile list transfer time\nis the number of seconds that the sender spent\nsending the file list to the receiver.\nTotal bytes sent\nis the count of all the bytes that rsync sent from the\nclient side to the server side.\nTotal bytes received\nis the count of all non-message bytes that rsync\nreceived by the client side from the server side. \"Non-message\" bytes\nmeans that we don't count the bytes for a verbose message that the server\nsent to us, which makes the stats more consistent.\n--8-bit-output\n,\n-8\nThis tells rsync to leave all high-bit characters unescaped in the output\ninstead of trying to test them to see if they're valid in the current\nlocale and escaping the invalid ones.  All control characters (but never\ntabs) are always escaped, regardless of this option's setting.\nThe escape idiom that started in 2.6.7 is to output a literal backslash\n(\n\\\n) and a hash (\n#\n), followed by exactly 3 octal digits.  For example, a\nnewline would output as \"\n\\#012\n\".  A literal backslash that is in a\nfilename is not escaped unless it is followed by a hash and 3 digits (0-9).\n--human-readable\n,\n-h\nOutput numbers in a more human-readable format.  There are 3 possible levels:\noutput numbers with a separator between each set of 3 digits (either a\ncomma or a period, depending on if the decimal point is represented by a\nperiod or a comma).\noutput numbers in units of 1000 (with a character suffix for larger\nunits -⁠-⁠ see below).\noutput numbers in units of 1024.\nThe default is human-readable level 1.  Each\n-h\noption increases the\nlevel by one.  You can take the level down to 0 (to output numbers as pure\ndigits) by specifying the\n--no-human-readable\n(\n--no-h\n) option.\nThe unit letters that are appended in levels 2 and 3 are:\nK\n(kilo),\nM\n(mega),\nG\n(giga),\nT\n(tera), or\nP\n(peta).  For example, a 1234567-byte\nfile would output as 1.23M in level-2 (assuming that a period is your local\ndecimal point).\nBackward compatibility note: versions of rsync prior to 3.1.0 do not\nsupport human-readable level 1, and they default to level 0.  Thus,\nspecifying one or two\n-h\noptions will behave in a comparable manner in\nold and new versions as long as you didn't specify a\n--no-h\noption prior\nto one or more\n-h\noptions.  See the\n--list-only\noption for one\ndifference.\n--partial\nBy default, rsync will delete any partially transferred file if the\ntransfer is interrupted.  In some circumstances it is more desirable to\nkeep partially transferred files.  Using the\n--partial\noption tells rsync\nto keep the partial file which should make a subsequent transfer of the\nrest of the file much faster.\n--partial-dir=DIR\nThis option modifies the behavior of the\n--partial\noption while\nalso implying that it be enabled.  This enhanced partial-file method puts\nany partially transferred files into the specified\nDIR\ninstead of writing\nthe partial file out to the destination file.  On the next transfer, rsync\nwill use a file found in this dir as data to speed up the resumption of the\ntransfer and then delete it after it has served its purpose.\nNote that if\n--whole-file\nis specified (or implied), any\npartial-dir files that are found for a file that is being updated will\nsimply be removed (since rsync is sending files without using rsync's\ndelta-transfer algorithm).\nRsync will create the\nDIR\nif it is missing, but just the last dir -⁠-⁠ not\nthe whole path.  This makes it easy to use a relative path (such as\n\"\n--partial-dir=.rsync-partial\n\") to have rsync create the\npartial-directory in the destination file's directory when it is needed,\nand then remove it again when the partial file is deleted.  Note that this\ndirectory removal is only done for a relative pathname, as it is expected\nthat an absolute path is to a directory that is reserved for partial-dir\nwork.\nIf the partial-dir value is not an absolute path, rsync will add an exclude\nrule at the end of all your existing excludes.  This will prevent the\nsending of any partial-dir files that may exist on the sending side, and\nwill also prevent the untimely deletion of partial-dir items on the\nreceiving side.  An example: the above\n--partial-dir\noption would add the\nequivalent of this \"perishable\" exclude at the end of any other filter\nrules:\n-f '-p .rsync-partial/'\nIf you are supplying your own exclude rules, you may need to add your own\nexclude/hide/protect rule for the partial-dir because:\nthe auto-added rule may be ineffective at the end of your other rules, or\nyou may wish to override rsync's exclude choice.\nFor instance, if you want to make rsync clean-up any left-over partial-dirs\nthat may be lying around, you should specify\n--delete-after\nand\nadd a \"risk\" filter rule, e.g.\n-f 'R .rsync-partial/'\n. Avoid using\n--delete-before\nor\n--delete-during\nunless you don't\nneed rsync to use any of the left-over partial-dir data during the current\nrun.\nIMPORTANT: the\n--partial-dir\nshould not be writable by other users or it\nis a security risk!  E.g. AVOID \"/tmp\"!\nYou can also set the partial-dir value the\nRSYNC_PARTIAL_DIR\nenvironment variable.  Setting this in the environment does not force\n--partial\nto be enabled, but rather it affects where partial\nfiles go when\n--partial\nis specified.  For instance, instead of\nusing\n--partial-dir=.rsync-tmp\nalong with\n--progress\n, you could\nset\nRSYNC_PARTIAL_DIR=.rsync-tmp\nin your environment and then use\nthe\n-P\noption to turn on the use of the .rsync-tmp dir for\npartial transfers.  The only times that the\n--partial\noption does\nnot look for this environment value are:\nwhen\n--inplace\nwas specified (since\n--inplace\nconflicts with\n--partial-dir\n), and\nwhen\n--delay-updates\nwas specified (see below).\nWhen a modern rsync resumes the transfer of a file in the partial-dir, that\npartial file is now updated in-place instead of creating yet another\ntmp-file copy (so it maxes out at dest + tmp instead of dest + partial +\ntmp).  This requires both ends of the transfer to be at least version\n3.2.0.\nFor the purposes of the daemon-config's \"\nrefuse options\n\" setting,\n--partial-dir\ndoes\nnot\nimply\n--partial\n.  This is so that a\nrefusal of the\n--partial\noption can be used to disallow the\noverwriting of destination files with a partial transfer, while still\nallowing the safer idiom provided by\n--partial-dir\n.\n--delay-updates\nThis option puts the temporary file from each updated file into a holding\ndirectory until the end of the transfer, at which time all the files are\nrenamed into place in rapid succession.  This attempts to make the updating\nof the files a little more atomic.  By default the files are placed into a\ndirectory named\n.~tmp~\nin each file's destination directory, but if\nyou've specified the\n--partial-dir\noption, that directory will be\nused instead.  See the comments in the\n--partial-dir\nsection for\na discussion of how this\n.~tmp~\ndir will be excluded from the transfer,\nand what you can do if you want rsync to cleanup old\n.~tmp~\ndirs that\nmight be lying around.  Conflicts with\n--inplace\nand\n--append\n.\nThis option implies\n--no-inc-recursive\nsince it needs the full\nfile list in memory in order to be able to iterate over it at the end.\nThis option uses more memory on the receiving side (one bit per file\ntransferred) and also requires enough free disk space on the receiving side\nto hold an additional copy of all the updated files.  Note also that you\nshould not use an absolute path to\n--partial-dir\nunless:\nthere is no chance of any of the files in the transfer having the same\nname (since all the updated files will be put into a single directory if\nthe path is absolute), and\nthere are no mount points in the hierarchy (since the delayed updates\nwill fail if they can't be renamed into place).\nSee also the \"atomic-rsync\" python script in the \"support\" subdir for an\nupdate algorithm that is even more atomic (it uses\n--link-dest\nand a parallel hierarchy of files).\n--prune-empty-dirs\n,\n-m\nThis option tells the receiving rsync to get rid of empty directories from\nthe file-list, including nested directories that have no non-directory\nchildren.  This is useful for avoiding the creation of a bunch of useless\ndirectories when the sending rsync is recursively scanning a hierarchy of\nfiles using include/exclude/filter rules.\nThis option can still leave empty directories on the receiving side if you\nmake use of\nTRANSFER_RULES\n.\nBecause the file-list is actually being pruned, this option also affects\nwhat directories get deleted when a delete is active.  However, keep in\nmind that excluded files and directories can prevent existing items from\nbeing deleted due to an exclude both hiding source files and protecting\ndestination files.  See the perishable filter-rule option for how to avoid\nthis.\nYou can prevent the pruning of certain empty directories from the file-list\nby using a global \"protect\" filter.  For instance, this option would ensure\nthat the directory \"emptydir\" was kept in the file-list:\n--filter 'protect emptydir/'\nHere's an example that copies all .pdf files in a hierarchy, only creating\nthe necessary destination directories to hold the .pdf files, and ensures\nthat any superfluous files and directories in the destination are removed\n(note the hide filter of non-directories being used instead of an exclude):\nrsync -avm --del --include='*.pdf' -f 'hide,! */' src/ dest\nIf you didn't want to remove superfluous destination files, the more\ntime-honored options of\n--include='*/' --exclude='*'\nwould work\nfine in place of the hide-filter (if that is more natural to you).\n--progress\nThis option tells rsync to print information showing the progress of the\ntransfer.  This gives a bored user something to watch.  With a modern rsync\nthis is the same as specifying\n--info=flist2,name,progress\n, but\nany user-supplied settings for those info flags takes precedence (e.g.\n--info=flist0 --progress\n).\nWhile rsync is transferring a regular file, it updates a progress line that\nlooks like this:\n782448  63%  110.64kB/s    0:00:04\nIn this example, the receiver has reconstructed 782448 bytes or 63% of the\nsender's file, which is being reconstructed at a rate of 110.64 kilobytes\nper second, and the transfer will finish in 4 seconds if the current rate\nis maintained until the end.\nThese statistics can be misleading if rsync's delta-transfer algorithm is\nin use.  For example, if the sender's file consists of the basis file\nfollowed by additional data, the reported rate will probably drop\ndramatically when the receiver gets to the literal data, and the transfer\nwill probably take much longer to finish than the receiver estimated as it\nwas finishing the matched part of the file.\nWhen the file transfer finishes, rsync replaces the progress line with a\nsummary line that looks like this:\n1,238,099 100%  146.38kB/s    0:00:08  (xfr#5, to-chk=169/396)\nIn this example, the file was 1,238,099 bytes long in total, the average\nrate of transfer for the whole file was 146.38 kilobytes per second over\nthe 8 seconds that it took to complete, it was the 5th transfer of a\nregular file during the current rsync session, and there are 169 more files\nfor the receiver to check (to see if they are up-to-date or not) remaining\nout of the 396 total files in the file-list.\nIn an incremental recursion scan, rsync won't know the total number of\nfiles in the file-list until it reaches the ends of the scan, but since it\nstarts to transfer files during the scan, it will display a line with the\ntext \"ir-chk\" (for incremental recursion check) instead of \"to-chk\" until\nthe point that it knows the full size of the list, at which point it will\nswitch to using \"to-chk\".  Thus, seeing \"ir-chk\" lets you know that the\ntotal count of files in the file list is still going to increase (and each\ntime it does, the count of files left to check will increase by the number\nof the files added to the list).\n-P\nThe\n-P\noption is equivalent to \"\n--partial\n--progress\n\".  Its purpose is to make it much easier to specify\nthese two options for a long transfer that may be interrupted.\nThere is also a\n--info=progress2\noption that outputs statistics\nbased on the whole transfer, rather than individual files.  Use this flag\nwithout outputting a filename (e.g. avoid\n-v\nor specify\n--info=name0\n) if you want to see how the transfer is doing\nwithout scrolling the screen with a lot of names. (You don't need to\nspecify the\n--progress\noption in order to use\n--info=progress2\n.)\nFinally, you can get an instant progress report by sending rsync a signal\nof either SIGINFO or SIGVTALRM.  On BSD systems, a SIGINFO is generated by\ntyping a Ctrl+T (Linux doesn't currently support a SIGINFO signal).  When\nthe client-side process receives one of those signals, it sets a flag to\noutput a single progress report which is output when the current file\ntransfer finishes (so it may take a little time if a big file is being\nhandled when the signal arrives).  A filename is output (if needed)\nfollowed by the\n--info=progress2\nformat of progress info.  If you\ndon't know which of the 3 rsync processes is the client process, it's OK to\nsignal all of them (since the non-client processes ignore the signal).\nCAUTION: sending SIGVTALRM to an older rsync (pre-3.2.0) will kill it.\n--password-file=FILE\nThis option allows you to provide a password for accessing an rsync daemon\nvia a file or via standard input if\nFILE\nis\n-\n.  The file should\ncontain just the password on the first line (all other lines are ignored).\nRsync will exit with an error if\nFILE\nis world readable or if a\nroot-run rsync command finds a non-root-owned file.\nThis option does not supply a password to a remote shell transport such as\nssh; to learn how to do that, consult the remote shell's documentation.\nWhen accessing an rsync daemon using a remote shell as the transport, this\noption only comes into effect after the remote shell finishes its\nauthentication (i.e. if you have also specified a password in the daemon's\nconfig file).\n--early-input=FILE\nThis option allows rsync to send up to 5K of data to the \"early exec\"\nscript on its stdin.  One possible use of this data is to give the script a\nsecret that can be used to mount an encrypted filesystem (which you should\nunmount in the the \"post-xfer exec\" script).\nThe daemon must be at least version 3.2.1.\n--list-only\nThis option will cause the source files to be listed instead of\ntransferred.  This option is inferred if there is a single source arg and\nno destination specified, so its main uses are:\nto turn a copy command that includes a destination arg into a\nfile-listing command, or\nto be able to specify more than one source arg.  Note: be sure to\ninclude the destination.\nCAUTION: keep in mind that a source arg with a wild-card is expanded by the\nshell into multiple args, so it is never safe to try to specify a single\nwild-card arg to try to infer this option. A safe example is:\nrsync -av --list-only foo* dest/\nThis option always uses an output format that looks similar to this:\ndrwxrwxr-x          4,096 2022/09/30 12:53:11 support\n-rw-rw-r--             80 2005/01/11 10:37:37 support/Makefile\nThe only option that affects this output style is (as of 3.1.0) the\n--human-readable\n(\n-h\n) option.  The default is to output sizes\nas byte counts with digit separators (in a 14-character-width column).\nSpecifying at least one\n-h\noption makes the sizes output with unit\nsuffixes.  If you want old-style bytecount sizes without digit separators\n(and an 11-character-width column) use\n--no-h\n.\nCompatibility note: when requesting a remote listing of files from an rsync\nthat is version 2.6.3 or older, you may encounter an error if you ask for a\nnon-recursive listing.  This is because a file listing implies the\n--dirs\noption w/o\n--recursive\n, and older rsyncs don't\nhave that option.  To avoid this problem, either specify the\n--no-dirs\noption (if you don't need to expand a directory's content), or turn on\nrecursion and exclude the content of subdirectories:\n-r --exclude='/*/*'\n.\n--bwlimit=RATE\nThis option allows you to specify the maximum transfer rate for the data\nsent over the socket, specified in units per second.  The RATE value can be\nsuffixed with a string to indicate a size multiplier, and may be a\nfractional value (e.g.\n--bwlimit=1.5m\n).  If no suffix is specified, the\nvalue will be assumed to be in units of 1024 bytes (as if \"K\" or \"KiB\" had\nbeen appended).  See the\n--max-size\noption for a description of\nall the available suffixes.  A value of 0 specifies no limit.\nFor backward-compatibility reasons, the rate limit will be rounded to the\nnearest KiB unit, so no rate smaller than 1024 bytes per second is\npossible.\nRsync writes data over the socket in blocks, and this option both limits\nthe size of the blocks that rsync writes, and tries to keep the average\ntransfer rate at the requested limit.  Some burstiness may be seen where\nrsync writes out a block of data and then sleeps to bring the average rate\ninto compliance.\nDue to the internal buffering of data, the\n--progress\noption may\nnot be an accurate reflection on how fast the data is being sent.  This is\nbecause some files can show up as being rapidly sent when the data is\nquickly buffered, while other can show up as very slow when the flushing of\nthe output buffer occurs.  This may be fixed in a future version.\nSee also\nthe daemon version of the\n--bwlimit\noption\n.\n--stop-after=MINS\n, (\n--time-limit=MINS\n)\nThis option tells rsync to stop copying when the specified number of\nminutes has elapsed.\nFor maximal flexibility, rsync does not communicate this option to the\nremote rsync since it is usually enough that one side of the connection\nquits as specified.  This allows the option's use even when only one side\nof the connection supports it.  You can tell the remote side about the time\nlimit using\n--remote-option\n(\n-M\n), should the need arise.\nThe\n--time-limit\nversion of this option is deprecated.\n--stop-at=y-m-dTh:m\nThis option tells rsync to stop copying when the specified point in time\nhas been reached. The date & time can be fully specified in a numeric\nformat of year-month-dayThour:minute (e.g. 2000-12-31T23:59) in the local\ntimezone.  You may choose to separate the date numbers using slashes\ninstead of dashes.\nThe value can also be abbreviated in a variety of ways, such as specifying\na 2-digit year and/or leaving off various values.  In all cases, the value\nwill be taken to be the next possible point in time where the supplied\ninformation matches.  If the value specifies the current time or a past\ntime, rsync exits with an error.\nFor example, \"1-30\" specifies the next January 30th (at midnight local\ntime), \"14:00\" specifies the next 2 P.M., \"1\" specifies the next 1st of the\nmonth at midnight, \"31\" specifies the next month where we can stop on its\n31st day, and \":59\" specifies the next 59th minute after the hour.\nFor maximal flexibility, rsync does not communicate this option to the\nremote rsync since it is usually enough that one side of the connection\nquits as specified.  This allows the option's use even when only one side\nof the connection supports it.  You can tell the remote side about the time\nlimit using\n--remote-option\n(\n-M\n), should the need arise.  Do\nkeep in mind that the remote host may have a different default timezone\nthan your local host.\n--fsync\nCause the receiving side to fsync each finished file.  This may slow down\nthe transfer, but can help to provide peace of mind when updating critical\nfiles.\n--write-batch=FILE\nRecord a file that can later be applied to another identical destination\nwith\n--read-batch\n.  See the \"BATCH MODE\" section for details, and\nalso the\n--only-write-batch\noption.\nThis option overrides the negotiated checksum & compress lists and always\nnegotiates a choice based on old-school md5/md4/zlib choices.  If you want\na more modern choice, use the\n--checksum-choice\n(\n--cc\n) and/or\n--compress-choice\n(\n--zc\n) options.\n--only-write-batch=FILE\nWorks like\n--write-batch\n, except that no updates are made on the\ndestination system when creating the batch.  This lets you transport the\nchanges to the destination system via some other means and then apply the\nchanges via\n--read-batch\n.\nNote that you can feel free to write the batch directly to some portable\nmedia: if this media fills to capacity before the end of the transfer, you\ncan just apply that partial transfer to the destination and repeat the\nwhole process to get the rest of the changes (as long as you don't mind a\npartially updated destination system while the multi-update cycle is\nhappening).\nAlso note that you only save bandwidth when pushing changes to a remote\nsystem because this allows the batched data to be diverted from the sender\ninto the batch file without having to flow over the wire to the receiver\n(when pulling, the sender is remote, and thus can't write the batch).\n--read-batch=FILE\nApply all of the changes stored in FILE, a file previously generated by\n--write-batch\n.  If\nFILE\nis\n-\n, the batch data will be read\nfrom standard input. See the \"BATCH MODE\" section for details.\n--protocol=NUM\nForce an older protocol version to be used.  This is useful for creating a\nbatch file that is compatible with an older version of rsync.  For\ninstance, if rsync 2.6.4 is being used with the\n--write-batch\noption, but rsync 2.6.3 is what will be used to run the\n--read-batch\noption, you should use \"-⁠-⁠protocol=28\" when creating\nthe batch file to force the older protocol version to be used in the batch\nfile (assuming you can't upgrade the rsync on the reading system).\n--iconv=CONVERT_SPEC\nRsync can convert filenames between character sets using this option.\nUsing a CONVERT_SPEC of \".\" tells rsync to look up the default\ncharacter-set via the locale setting.  Alternately, you can fully specify\nwhat conversion to do by giving a local and a remote charset separated by a\ncomma in the order\n--iconv=LOCAL,REMOTE\n, e.g.\n--iconv=utf8,iso88591\n.\nThis order ensures that the option will stay the same whether you're\npushing or pulling files.  Finally, you can specify either\n--no-iconv\nor\na CONVERT_SPEC of \"-⁠\" to turn off any conversion.  The default setting of\nthis option is site-specific, and can also be affected via the\nRSYNC_ICONV\nenvironment variable.\nFor a list of what charset names your local iconv library supports, you can\nrun \"\niconv --list\n\".\nIf you specify the\n--secluded-args\n(\n-s\n) option, rsync will\ntranslate the filenames you specify on the command-line that are being sent\nto the remote host.  See also the\n--files-from\noption.\nNote that rsync does not do any conversion of names in filter files\n(including include/exclude files).  It is up to you to ensure that you're\nspecifying matching rules that can match on both sides of the transfer.\nFor instance, you can specify extra include/exclude rules if there are\nfilename differences on the two sides that need to be accounted for.\nWhen you pass an\n--iconv\noption to an rsync daemon that allows it, the\ndaemon uses the charset specified in its \"charset\" configuration parameter\nregardless of the remote charset you actually pass.  Thus, you may feel\nfree to specify just the local charset for a daemon transfer (e.g.\n--iconv=utf8\n).\n--ipv4\n,\n-4\nor\n--ipv6\n,\n-6\nTells rsync to prefer IPv4/IPv6 when creating sockets or running ssh.  This\naffects sockets that rsync has direct control over, such as the outgoing\nsocket when directly contacting an rsync daemon, as well as the forwarding\nof the\n-4\nor\n-6\noption to ssh when rsync can deduce that ssh is being\nused as the remote shell.  For other remote shells you'll need to specify\nthe \"\n--rsh SHELL -4\n\" option directly (or whatever IPv4/IPv6 hint options\nit uses).\nSee also\nthe daemon version of these options\n.\nIf rsync was compiled without support for IPv6, the\n--ipv6\noption will\nhave no effect.  The\nrsync --version\noutput will contain \"\nno IPv6\n\" if\nis the case.\n--checksum-seed=NUM\nSet the checksum seed to the integer NUM.  This 4 byte checksum seed is\nincluded in each block and MD4 file checksum calculation (the more modern\nMD5 file checksums don't use a seed).  By default the checksum seed is\ngenerated by the server and defaults to the current\ntime\n().  This\noption is used to set a specific checksum seed, which is useful for\napplications that want repeatable block checksums, or in the case where the\nuser wants a more random checksum seed.  Setting NUM to 0 causes rsync to\nuse the default of\ntime\n() for checksum seed.\nDAEMON OPTIONS\nThe options allowed when starting an rsync daemon are as follows:\n--daemon\nThis tells rsync that it is to run as a daemon.  The daemon you start\nrunning may be accessed using an rsync client using the\nhost::module\nor\nrsync://host/module/\nsyntax.\nIf standard input is a socket then rsync will assume that it is being run\nvia inetd, otherwise it will detach from the current terminal and become a\nbackground daemon.  The daemon will read the config file (rsyncd.conf) on\neach connect made by a client and respond to requests accordingly.\nSee the\nrsyncd.conf\n(5)\nmanpage for more details.\n--address=ADDRESS\nBy default rsync will bind to the wildcard address when run as a daemon\nwith the\n--daemon\noption.  The\n--address\noption allows you to specify a\nspecific IP address (or hostname) to bind to.  This makes virtual hosting\npossible in conjunction with the\n--config\noption.\nSee also the\naddress\nglobal option in the\nrsyncd.conf manpage and the\nclient version of the\n--address\noption\n.\n--bwlimit=RATE\nThis option allows you to specify the maximum transfer rate for the data\nthe daemon sends over the socket.  The client can still specify a smaller\n--bwlimit\nvalue, but no larger value will be allowed.\nSee the\nclient version of the\n--bwlimit\noption\nfor some\nextra details.\n--config=FILE\nThis specifies an alternate config file than the default.  This is only\nrelevant when\n--daemon\nis specified.  The default is\n/etc/rsyncd.conf unless the daemon is running over a remote shell program\nand the remote user is not the super-user; in that case the default is\nrsyncd.conf in the current directory (typically $HOME).\n--dparam=OVERRIDE\n,\n-M\nThis option can be used to set a daemon-config parameter when starting up\nrsync in daemon mode.  It is equivalent to adding the parameter at the end\nof the global settings prior to the first module's definition.  The\nparameter names can be specified without spaces, if you so desire.  For\ninstance:\nrsync --daemon -M pidfile=/path/rsync.pid\n--no-detach\nWhen running as a daemon, this option instructs rsync to not detach itself\nand become a background process.  This option is required when running as a\nservice on Cygwin, and may also be useful when rsync is supervised by a\nprogram such as\ndaemontools\nor AIX's\nSystem Resource Controller\n.\n--no-detach\nis also recommended when rsync is run under a debugger.  This\noption has no effect if rsync is run from inetd or sshd.\n--port=PORT\nThis specifies an alternate TCP port number for the daemon to listen on\nrather than the default of 873.\nSee also\nthe client version of the\n--port\noption\nand the\nport\nglobal setting in the rsyncd.conf manpage.\n--log-file=FILE\nThis option tells the rsync daemon to use the given log-file name instead\nof using the \"\nlog file\n\" setting in the config file.\nSee also\nthe client version of the\n--log-file\noption\n.\n--log-file-format=FORMAT\nThis option tells the rsync daemon to use the given FORMAT string instead\nof using the \"\nlog format\n\" setting in the config file.  It also enables\n\"\ntransfer logging\n\" unless the string is empty, in which case transfer\nlogging is turned off.\nSee also\nthe client version of the\n--log-file-format\noption\n.\n--sockopts\nThis overrides the\nsocket options\nsetting in the rsyncd.conf file and has the same syntax.\nSee also\nthe client version of the\n--sockopts\noption\n.\n--verbose\n,\n-v\nThis option increases the amount of information the daemon logs during its\nstartup phase.  After the client connects, the daemon's verbosity level\nwill be controlled by the options that the client used and the\n\"\nmax verbosity\n\" setting in the module's config section.\nSee also\nthe client version of the\n--verbose\noption\n.\n--ipv4\n,\n-4\nor\n--ipv6\n,\n-6\nTells rsync to prefer IPv4/IPv6 when creating the incoming sockets that the\nrsync daemon will use to listen for connections.  One of these options may\nbe required in older versions of Linux to work around an IPv6 bug in the\nkernel (if you see an \"address already in use\" error when nothing else is\nusing the port, try specifying\n--ipv6\nor\n--ipv4\nwhen starting the\ndaemon).\nSee also\nthe client version of these options\n.\nIf rsync was compiled without support for IPv6, the\n--ipv6\noption will\nhave no effect.  The\nrsync --version\noutput will contain \"\nno IPv6\n\" if\nis the case.\n--help\n,\n-h\nWhen specified after\n--daemon\n, print a short help page describing the\noptions available for starting an rsync daemon.\nFILTER RULES\nThe filter rules allow for custom control of several aspects of how files are\nhandled:\nControl which files the sending side puts into the file list that describes\nthe transfer hierarchy\nControl which files the receiving side protects from deletion when the file\nis not in the sender's file list\nControl which extended attribute names are skipped when copying xattrs\nThe rules are either directly specified via option arguments or they can be\nread in from one or more files.  The filter-rule files can even be a part of\nthe hierarchy of files being copied, affecting different parts of the tree in\ndifferent ways.\nSIMPLE INCLUDE/EXCLUDE RULES\nWe will first cover the basics of how include & exclude rules affect what files\nare transferred, ignoring any deletion side-effects.  Filter rules mainly\naffect the contents of directories that rsync is \"recursing\" into, but they can\nalso affect a top-level item in the transfer that was specified as a argument.\nThe default for any unmatched file/dir is for it to be included in the\ntransfer, which puts the file/dir into the sender's file list.  The use of an\nexclude rule causes one or more matching files/dirs to be left out of the\nsender's file list.  An include rule can be used to limit the effect of an\nexclude rule that is matching too many files.\nThe order of the rules is important because the first rule that matches is the\none that takes effect.  Thus, if an early rule excludes a file, no include rule\nthat comes after it can have any effect. This means that you must place any\ninclude overrides somewhere prior to the exclude that it is intended to limit.\nWhen a directory is excluded, all its contents and sub-contents are also\nexcluded.  The sender doesn't scan through any of it at all, which can save a\nlot of time when skipping large unneeded sub-trees.\nIt is also important to understand that the include/exclude rules are applied\nto every file and directory that the sender is recursing into. Thus, if you\nwant a particular deep file to be included, you have to make sure that none of\nthe directories that must be traversed on the way down to that file are\nexcluded or else the file will never be discovered to be included. As an\nexample, if the directory \"\na/path\n\" was given as a transfer argument and you\nwant to ensure that the file \"\na/path/down/deep/wanted.txt\n\" is a part of the\ntransfer, then the sender must not exclude the directories \"\na/path\n\",\n\"\na/path/down\n\", or \"\na/path/down/deep\n\" as it makes it way scanning through\nthe file tree.\nWhen you are working on the rules, it can be helpful to ask rsync to tell you\nwhat is being excluded/included and why.  Specifying\n--debug=FILTER\nor (when\npulling files)\n-M--debug=FILTER\nturns on level 1 of the FILTER debug\ninformation that will output a message any time that a file or directory is\nincluded or excluded and which rule it matched.  Beginning in 3.2.4 it will\nalso warn if a filter rule has trailing whitespace, since an exclude of \"foo \"\n(with a trailing space) will not exclude a file named \"foo\".\nExclude and include rules can specify wildcard\nPATTERN MATCHING RULES\n(similar to shell wildcards) that allow you to match things like a file suffix\nor a portion of a filename.\nA rule can be limited to only affecting a directory by putting a trailing slash\nonto the filename.\nSIMPLE INCLUDE/EXCLUDE EXAMPLE\nWith the following file tree created on the sending side:\nmkdir x/\ntouch x/file.txt\nmkdir x/y/\ntouch x/y/file.txt\ntouch x/y/zzz.txt\nmkdir x/z/\ntouch x/z/file.txt\nThen the following rsync command will transfer the file \"\nx/y/file.txt\n\" and\nthe directories needed to hold it, resulting in the path \"\n/tmp/x/y/file.txt\n\"\nexisting on the remote host:\nrsync -ai -f'+ x/' -f'+ x/y/' -f'+ x/y/file.txt' -f'- *' x host:/tmp/\nAside: this copy could also have been accomplished using the\n-R\noption (though the 2 commands behave differently if deletions are enabled):\nrsync -aiR x/y/file.txt host:/tmp/\nThe following command does not need an include of the \"x\" directory because it\nis not a part of the transfer (note the trailing slash).  Running this command\nwould copy just \"\n/tmp/x/file.txt\n\" because the \"y\" and \"z\" dirs get excluded:\nrsync -ai -f'+ file.txt' -f'- *' x/ host:/tmp/x/\nThis command would omit the zzz.txt file while copying \"x\" and everything else\nit contains:\nrsync -ai -f'- zzz.txt' x host:/tmp/\nFILTER RULES WHEN DELETING\nBy default the include & exclude filter rules affect both the sender\n(as it creates its file list)\nand the receiver (as it creates its file lists for calculating deletions).  If\nno delete option is in effect, the receiver skips creating the delete-related\nfile lists.  This two-sided default can be manually overridden so that you are\nonly specifying sender rules or receiver rules, as described in the\nFILTER\nRULES IN DEPTH\nsection.\nWhen deleting, an exclude protects a file from being removed on the receiving\nside while an include overrides that protection (putting the file at risk of\ndeletion). The default is for a file to be at risk -⁠-⁠ its safety depends on it\nmatching a corresponding file from the sender.\nAn example of the two-sided exclude effect can be illustrated by the copying of\na C development directory between 2 systems.  When doing a touch-up copy, you\nmight want to skip copying the built executable and the\n.o\nfiles (sender\nhide) so that the receiving side can build their own and not lose any object\nfiles that are already correct (receiver protect).  For instance:\nrsync -ai --del -f'- *.o' -f'- cmd' src host:/dest/\nNote that using\n-f'-p *.o'\nis even better than\n-f'- *.o'\nif there is a\nchance that the directory structure may have changed.  The \"p\" modifier is\ndiscussed in\nFILTER RULE MODIFIERS\n.\nOne final note, if your shell doesn't mind unexpanded wildcards, you could\nsimplify the typing of the filter options by using an underscore in place of\nthe space and leaving off the quotes.  For instance,\n-f -_*.o -f -_cmd\n(and\nsimilar) could be used instead of the filter options above.\nFILTER RULES IN DEPTH\nRsync supports old-style include/exclude rules and new-style filter rules.  The\nolder rules are specified using\n--include\nand\n--exclude\nas\nwell as the\n--include-from\nand\n--exclude-from\n. These are\nlimited in behavior but they don't require a \"-⁠\" or \"+\" prefix.  An old-style\nexclude rule is turned into a \"\n- name\n\" filter rule (with no modifiers) and an\nold-style include rule is turned into a \"\n+ name\n\" filter rule (with no\nmodifiers).\nRsync builds an ordered list of filter rules as specified on the command-line\nand/or read-in from files.  New style filter rules have the following syntax:\nRULE [PATTERN_OR_FILENAME]\nRULE,MODIFIERS [PATTERN_OR_FILENAME]\nYou have your choice of using either short or long RULE names, as described\nbelow.  If you use a short-named rule, the ',' separating the RULE from the\nMODIFIERS is optional.  The PATTERN or FILENAME that follows (when present)\nmust come after either a single space or an underscore (_). Any additional\nspaces and/or underscores are considered to be a part of the pattern name.\nHere are the available rule prefixes:\nexclude, '-'\nspecifies an exclude pattern that (by default) is both a\nhide\nand a\nprotect\n.\ninclude, '+'\nspecifies an include pattern that (by default) is both a\nshow\nand a\nrisk\n.\nmerge, '.'\nspecifies a merge-file on the client side to read for more\nrules.\ndir-merge, ':'\nspecifies a per-directory merge-file.  Using this kind of\nfilter rule requires that you trust the sending side's filter checking, so\nit has the side-effect mentioned under the\n--trust-sender\noption.\nhide, 'H'\nspecifies a pattern for hiding files from the transfer.\nEquivalent to a sender-only exclude, so\n-f'H foo'\ncould also be specified\nas\n-f'-s foo'\n.\nshow, 'S'\nfiles that match the pattern are not hidden. Equivalent to a\nsender-only include, so\n-f'S foo'\ncould also be specified as\n-f'+s foo'\n.\nprotect, 'P'\nspecifies a pattern for protecting files from deletion.\nEquivalent to a receiver-only exclude, so\n-f'P foo'\ncould also be\nspecified as\n-f'-r foo'\n.\nrisk, 'R'\nfiles that match the pattern are not protected. Equivalent to a\nreceiver-only include, so\n-f'R foo'\ncould also be specified as\n-f'+r foo'\n.\nclear, '!'\nclears the current include/exclude list (takes no arg)\nWhen rules are being read from a file (using merge or dir-merge), empty lines\nare ignored, as are whole-line comments that start with a '\n#\n' (filename rules\nthat contain a hash character are unaffected).\nNote also that the\n--filter\n,\n--include\n, and\n--exclude\noptions take one rule/pattern each.  To add multiple ones,\nyou can repeat the options on the command-line, use the merge-file syntax of\nthe\n--filter\noption, or the\n--include-from\n/\n--exclude-from\noptions.\nPATTERN MATCHING RULES\nMost of the rules mentioned above take an argument that specifies what the rule\nshould match.  If rsync is recursing through a directory hierarchy, keep in\nmind that each pattern is matched against the name of every directory in the\ndescent path as rsync finds the filenames to send.\nThe matching rules for the pattern argument take several forms:\nIf a pattern contains a\n/\n(not counting a trailing slash) or a \"\n**\n\"\n(which can match a slash), then the pattern is matched against the full\npathname, including any leading directories within the transfer.  If the\npattern doesn't contain a (non-trailing)\n/\nor a \"\n**\n\", then it is matched\nonly against the final component of the filename or pathname. For example,\nfoo\nmeans that the final path component must be \"foo\" while\nfoo/bar\nwould\nmatch the last 2 elements of the path (as long as both elements are within\nthe transfer).\nA pattern that ends with a\n/\nonly matches a directory, not a regular file,\nsymlink, or device.\nA pattern that starts with a\n/\nis anchored to the start of the transfer\npath instead of the end.  For example,\n/foo/**\nor\n/foo/bar/**\nmatch only\nleading elements in the path.  If the rule is read from a per-directory\nfilter file, the transfer path being matched will begin at the level of the\nfilter file instead of the top of the transfer.  See the section on\nANCHORING INCLUDE/EXCLUDE PATTERNS\nfor a full discussion of how to\nspecify a pattern that matches at the root of the transfer.\nRsync chooses between doing a simple string match and wildcard matching by\nchecking if the pattern contains one of these three wildcard characters: '\n*\n',\n'\n?\n', and '\n[\n' :\na '\n?\n' matches any single character except a slash (\n/\n).\na '\n*\n' matches zero or more non-slash characters.\na '\n**\n' matches zero or more characters, including slashes.\na '\n[\n' introduces a character class, such as\n[a-z]\nor\n[[:alpha:]]\n, that\nmust match one character.\na trailing\n***\nin the pattern is a shorthand that allows you to match a\ndirectory and all its contents using a single rule.  For example, specifying\n\"\ndir_name/***\n\" will match both the \"dir_name\" directory (as if \"\ndir_name/\n\"\nhad been specified) and everything in the directory (as if \"\ndir_name/**\n\"\nhad been specified).\na backslash can be used to escape a wildcard character, but it is only\ninterpreted as an escape character if at least one wildcard character is\npresent in the match pattern. For instance, the pattern \"\nfoo\\bar\n\" matches\nthat single backslash literally, while the pattern \"\nfoo\\bar*\n\" would need to\nbe changed to \"\nfoo\\\\bar*\n\" to avoid the \"\n\\b\n\" becoming just \"b\".\nHere are some examples of exclude/include matching:\nOption\n-f'- *.o'\nwould exclude all filenames ending with\n.o\nOption\n-f'- /foo'\nwould exclude a file (or directory) named foo in the\ntransfer-root directory\nOption\n-f'- foo/'\nwould exclude any directory named foo\nOption\n-f'- foo/*/bar'\nwould exclude any file/dir named bar which is at two\nlevels below a directory named foo (if foo is in the transfer)\nOption\n-f'- /foo/**/bar'\nwould exclude any file/dir named bar that was two\nor more levels below a top-level directory named foo (note that /foo/bar is\nnot\nexcluded by this)\nOptions\n-f'+ */' -f'+ *.c' -f'- *'\nwould include all directories and .c\nsource files but nothing else\nOptions\n-f'+ foo/' -f'+ foo/bar.c' -f'- *'\nwould include only the foo\ndirectory and foo/bar.c (the foo directory must be explicitly included or it\nwould be excluded by the \"\n- *\n\")\nFILTER RULE MODIFIERS\nThe following modifiers are accepted after an include (+) or exclude (-⁠) rule:\nA\n/\nspecifies that the include/exclude rule should be matched against the\nabsolute pathname of the current item.  For example,\n-f'-/ /etc/passwd'\nwould exclude the passwd file any time the transfer was sending files from\nthe \"/etc\" directory, and \"-⁠/ subdir/foo\" would always exclude \"foo\" when it\nis in a dir named \"subdir\", even if \"foo\" is at the root of the current\ntransfer.\nA\n!\nspecifies that the include/exclude should take effect if the pattern\nfails to match.  For instance,\n-f'-! */'\nwould exclude all non-directories.\nA\nC\nis used to indicate that all the global CVS-exclude rules should be\ninserted as excludes in place of the \"-⁠C\".  No arg should follow.\nAn\ns\nis used to indicate that the rule applies to the sending side.  When a\nrule affects the sending side, it affects what files are put into the\nsender's file list.  The default is for a rule to affect both sides unless\n--delete-excluded\nwas specified, in which case default rules become\nsender-side only.  See also the hide (H) and show (S) rules, which are an\nalternate way to specify sending-side includes/excludes.\nAn\nr\nis used to indicate that the rule applies to the receiving side.  When\na rule affects the receiving side, it prevents files from being deleted.  See\nthe\ns\nmodifier for more info.  See also the protect (P) and risk (R) rules,\nwhich are an alternate way to specify receiver-side includes/excludes.\nA\np\nindicates that a rule is perishable, meaning that it is ignored in\ndirectories that are being deleted.  For instance, the\n--cvs-exclude\n(\n-C\n) option's default rules that exclude things\nlike \"CVS\" and \"\n*.o\n\" are marked as perishable, and will not prevent a\ndirectory that was removed on the source from being deleted on the\ndestination.\nAn\nx\nindicates that a rule affects xattr names in xattr copy/delete\noperations (and is thus ignored when matching file/dir names).  If no\nxattr-matching rules are specified, a default xattr filtering rule is used\n(see the\n--xattrs\noption).\nMERGE-FILE FILTER RULES\nYou can merge whole files into your filter rules by specifying either a merge\n(.) or a dir-merge (:) filter rule (as introduced in the\nFILTER RULES\nsection above).\nThere are two kinds of merged files -⁠-⁠ single-instance ('.') and per-directory\n(':').  A single-instance merge file is read one time, and its rules are\nincorporated into the filter list in the place of the \".\" rule.  For\nper-directory merge files, rsync will scan every directory that it traverses\nfor the named file, merging its contents when the file exists into the current\nlist of inherited rules.  These per-directory rule files must be created on the\nsending side because it is the sending side that is being scanned for the\navailable files to transfer.  These rule files may also need to be transferred\nto the receiving side if you want them to affect what files don't get deleted\n(see\nPER-DIRECTORY RULES AND DELETE\nbelow).\nSome examples:\nmerge /etc/rsync/default.rules\n. /etc/rsync/default.rules\ndir-merge .per-dir-filter\ndir-merge,n- .non-inherited-per-dir-excludes\n:n- .non-inherited-per-dir-excludes\nThe following modifiers are accepted after a merge or dir-merge rule:\nA\n-\nspecifies that the file should consist of only exclude patterns, with\nno other rule-parsing except for in-file comments.\nA\n+\nspecifies that the file should consist of only include patterns, with\nno other rule-parsing except for in-file comments.\nA\nC\nis a way to specify that the file should be read in a CVS-compatible\nmanner.  This turns on 'n', 'w', and '-⁠', but also allows the list-clearing\ntoken (!) to be specified.  If no filename is provided, \".cvsignore\" is\nassumed.\nA\ne\nwill exclude the merge-file name from the transfer; e.g.  \"dir-merge,e\n.rules\" is like \"dir-merge .rules\" and \"-⁠ .rules\".\nAn\nn\nspecifies that the rules are not inherited by subdirectories.\nA\nw\nspecifies that the rules are word-split on whitespace instead of the\nnormal line-splitting.  This also turns off comments.  Note: the space that\nseparates the prefix from the rule is treated specially, so \"-⁠ foo + bar\" is\nparsed as two rules (assuming that prefix-parsing wasn't also disabled).\nYou may also specify any of the modifiers for the \"+\" or \"-⁠\" rules (above) in\norder to have the rules that are read in from the file default to having that\nmodifier set (except for the\n!\nmodifier, which would not be useful).  For\ninstance, \"merge,-⁠/ .excl\" would treat the contents of .excl as absolute-path\nexcludes, while \"dir-merge,s .filt\" and \":sC\" would each make all their\nper-directory rules apply only on the sending side.  If the merge rule\nspecifies sides to affect (via the\ns\nor\nr\nmodifier or both), then the\nrules in the file must not specify sides (via a modifier or a rule prefix\nsuch as\nhide\n).\nPer-directory rules are inherited in all subdirectories of the directory where\nthe merge-file was found unless the 'n' modifier was used.  Each subdirectory's\nrules are prefixed to the inherited per-directory rules from its parents, which\ngives the newest rules a higher priority than the inherited rules.  The entire\nset of dir-merge rules are grouped together in the spot where the merge-file\nwas specified, so it is possible to override dir-merge rules via a rule that\ngot specified earlier in the list of global rules.  When the list-clearing rule\n(\"!\") is read from a per-directory file, it only clears the inherited rules for\nthe current merge file.\nAnother way to prevent a single rule from a dir-merge file from being inherited\nis to anchor it with a leading slash.  Anchored rules in a per-directory\nmerge-file are relative to the merge-file's directory, so a pattern \"/foo\"\nwould only match the file \"foo\" in the directory where the dir-merge filter\nfile was found.\nHere's an example filter file which you'd specify via\n--filter=\". file\":\nmerge /home/user/.global-filter\n- *.gz\ndir-merge .rules\n+ *.[ch]\n- *.o\n- foo*\nThis will merge the contents of the /home/user/.global-filter file at the start\nof the list and also turns the \".rules\" filename into a per-directory filter\nfile.  All rules read in prior to the start of the directory scan follow the\nglobal anchoring rules (i.e. a leading slash matches at the root of the\ntransfer).\nIf a per-directory merge-file is specified with a path that is a parent\ndirectory of the first transfer directory, rsync will scan all the parent dirs\nfrom that starting point to the transfer directory for the indicated\nper-directory file.  For instance, here is a common filter (see\n-F\n):\n--filter=': /.rsync-filter'\nThat rule tells rsync to scan for the file .rsync-filter in all directories\nfrom the root down through the parent directory of the transfer prior to the\nstart of the normal directory scan of the file in the directories that are sent\nas a part of the transfer. (Note: for an rsync daemon, the root is always the\nsame as the module's \"path\".)\nSome examples of this pre-scanning for per-directory files:\nrsync -avF /src/path/ /dest/dir\nrsync -av --filter=': ../../.rsync-filter' /src/path/ /dest/dir\nrsync -av --filter=': .rsync-filter' /src/path/ /dest/dir\nThe first two commands above will look for \".rsync-filter\" in \"/\" and \"/src\"\nbefore the normal scan begins looking for the file in \"/src/path\" and its\nsubdirectories.  The last command avoids the parent-dir scan and only looks for\nthe \".rsync-filter\" files in each directory that is a part of the transfer.\nIf you want to include the contents of a \".cvsignore\" in your patterns, you\nshould use the rule \":C\", which creates a dir-merge of the .cvsignore file, but\nparsed in a CVS-compatible manner.  You can use this to affect where the\n--cvs-exclude\n(\n-C\n) option's inclusion of the per-directory\n.cvsignore file gets placed into your rules by putting the \":C\" wherever you\nlike in your filter rules.  Without this, rsync would add the dir-merge rule\nfor the .cvsignore file at the end of all your other rules (giving it a lower\npriority than your command-line rules).  For example:\ncat <<EOT | rsync -avC --filter='. -' a/ b\n+ foo.o\n:C\n- *.old\nEOT\nrsync -avC --include=foo.o -f :C --exclude='*.old' a/ b\nBoth of the above rsync commands are identical.  Each one will merge all the\nper-directory .cvsignore rules in the middle of the list rather than at the\nend.  This allows their dir-specific rules to supersede the rules that follow\nthe :C instead of being subservient to all your rules.  To affect the other CVS\nexclude rules (i.e. the default list of exclusions, the contents of\n$HOME/.cvsignore, and the value of $CVSIGNORE) you should omit the\n-C\ncommand-line option and instead insert a \"-⁠C\" rule into your filter rules; e.g.\n\"\n--filter=-C\n\".\nLIST-CLEARING FILTER RULE\nYou can clear the current include/exclude list by using the \"!\" filter rule (as\nintroduced in the\nFILTER RULES\nsection above).  The \"current\" list is either\nthe global list of rules (if the rule is encountered while parsing the filter\noptions) or a set of per-directory rules (which are inherited in their own\nsub-list, so a subdirectory can use this to clear out the parent's rules).\nANCHORING INCLUDE/EXCLUDE PATTERNS\nAs mentioned earlier, global include/exclude patterns are anchored at the \"root\nof the transfer\" (as opposed to per-directory patterns, which are anchored at\nthe merge-file's directory).  If you think of the transfer as a subtree of\nnames that are being sent from sender to receiver, the transfer-root is where\nthe tree starts to be duplicated in the destination directory.  This root\ngoverns where patterns that start with a / match.\nBecause the matching is relative to the transfer-root, changing the trailing\nslash on a source path or changing your use of the\n--relative\noption\naffects the path you need to use in your matching (in addition to changing how\nmuch of the file tree is duplicated on the destination host).  The following\nexamples demonstrate this.\nLet's say that we want to match two source files, one with an absolute\npath of \"/home/me/foo/bar\", and one with a path of \"/home/you/bar/baz\".\nHere is how the various command choices differ for a 2-source transfer:\nExample cmd: rsync -a /home/me /home/you /dest\n+/- pattern: /me/foo/bar\n+/- pattern: /you/bar/baz\nTarget file: /dest/me/foo/bar\nTarget file: /dest/you/bar/baz\nExample cmd: rsync -a /home/me/ /home/you/ /dest\n+/- pattern: /foo/bar               (note missing \"me\")\n+/- pattern: /bar/baz               (note missing \"you\")\nTarget file: /dest/foo/bar\nTarget file: /dest/bar/baz\nExample cmd: rsync -a --relative /home/me/ /home/you /dest\n+/- pattern: /home/me/foo/bar       (note full path)\n+/- pattern: /home/you/bar/baz      (ditto)\nTarget file: /dest/home/me/foo/bar\nTarget file: /dest/home/you/bar/baz\nExample cmd: cd /home; rsync -a --relative me/foo you/ /dest\n+/- pattern: /me/foo/bar      (starts at specified path)\n+/- pattern: /you/bar/baz     (ditto)\nTarget file: /dest/me/foo/bar\nTarget file: /dest/you/bar/baz\nThe easiest way to see what name you should filter is to just look at the\noutput when using\n--verbose\nand put a / in front of the name (use the\n--dry-run\noption if you're not yet ready to copy any files).\nPER-DIRECTORY RULES AND DELETE\nWithout a delete option, per-directory rules are only relevant on the sending\nside, so you can feel free to exclude the merge files themselves without\naffecting the transfer.  To make this easy, the 'e' modifier adds this exclude\nfor you, as seen in these two equivalent commands:\nrsync -av --filter=': .excl' --exclude=.excl host:src/dir /dest\nrsync -av --filter=':e .excl' host:src/dir /dest\nHowever, if you want to do a delete on the receiving side AND you want some\nfiles to be excluded from being deleted, you'll need to be sure that the\nreceiving side knows what files to exclude.  The easiest way is to include the\nper-directory merge files in the transfer and use\n--delete-after\n,\nbecause this ensures that the receiving side gets all the same exclude rules as\nthe sending side before it tries to delete anything:\nrsync -avF --delete-after host:src/dir /dest\nHowever, if the merge files are not a part of the transfer, you'll need to\neither specify some global exclude rules (i.e. specified on the command line),\nor you'll need to maintain your own per-directory merge files on the receiving\nside.  An example of the first is this (assume that the remote .rules files\nexclude themselves):\nrsync -av --filter=': .rules' --filter='. /my/extra.rules'\n--delete host:src/dir /dest\nIn the above example the extra.rules file can affect both sides of the\ntransfer, but (on the sending side) the rules are subservient to the rules\nmerged from the .rules files because they were specified after the\nper-directory merge rule.\nIn one final example, the remote side is excluding the .rsync-filter files from\nthe transfer, but we want to use our own .rsync-filter files to control what\ngets deleted on the receiving side.  To do this we must specifically exclude\nthe per-directory merge files (so that they don't get deleted) and then put\nrules into the local files to control what else should not get deleted.  Like\none of these commands:\nrsync -av --filter=':e /.rsync-filter' --delete \\\nhost:src/dir /dest\nrsync -avFF --delete host:src/dir /dest\nTRANSFER RULES\nIn addition to the\nFILTER RULES\nthat affect the recursive file scans that\ngenerate the file list on the sending and (when deleting) receiving sides,\nthere are transfer rules. These rules affect which files the generator decides\nneed to be transferred without the side effects of an exclude filter rule.\nTransfer rules affect only files and never directories.\nBecause a transfer rule does not affect what goes into the sender's (and\nreceiver's) file list, it cannot have any effect on which files get deleted on\nthe receiving side.  For example, if the file \"foo\" is present in the sender's\nlist but its size is such that it is omitted due to a transfer rule, the\nreceiving side does not request the file.  However, its presence in the file\nlist means that a delete pass will not remove a matching file named \"foo\" on\nthe receiving side.  On the other hand, a server-side exclude (hide) of the\nfile \"foo\" leaves the file out of the server's file list, and absent a\nreceiver-side exclude (protect) the receiver will remove a matching file named\n\"foo\" if deletions are requested.\nGiven that the files are still in the sender's file list, the\n--prune-empty-dirs\noption will not judge a directory as being empty\neven if it contains only files that the transfer rules omitted.\nSimilarly, a transfer rule does not have any extra effect on which files are\ndeleted on the receiving side, so setting a maximum file size for the transfer\ndoes not prevent big files from being deleted.\nExamples of transfer rules include the default \"quick check\" algorithm (which\ncompares size & modify time), the\n--update\noption, the\n--max-size\noption, the\n--ignore-non-existing\noption, and a\nfew others.\nBATCH MODE\nBatch mode can be used to apply the same set of updates to many identical\nsystems.  Suppose one has a tree which is replicated on a number of hosts.  Now\nsuppose some changes have been made to this source tree and those changes need\nto be propagated to the other hosts.  In order to do this using batch mode,\nrsync is run with the write-batch option to apply the changes made to the\nsource tree to one of the destination trees.  The write-batch option causes the\nrsync client to store in a \"batch file\" all the information needed to repeat\nthis operation against other, identical destination trees.\nGenerating the batch file once saves having to perform the file status,\nchecksum, and data block generation more than once when updating multiple\ndestination trees.  Multicast transport protocols can be used to transfer the\nbatch update files in parallel to many hosts at once, instead of sending the\nsame data to every host individually.\nTo apply the recorded changes to another destination tree, run rsync with the\nread-batch option, specifying the name of the same batch file, and the\ndestination tree.  Rsync updates the destination tree using the information\nstored in the batch file.\nFor your convenience, a script file is also created when the write-batch option\nis used: it will be named the same as the batch file with \".sh\" appended.  This\nscript file contains a command-line suitable for updating a destination tree\nusing the associated batch file.  It can be executed using a Bourne (or\nBourne-like) shell, optionally passing in an alternate destination tree\npathname which is then used instead of the original destination path.  This is\nuseful when the destination tree path on the current host differs from the one\nused to create the batch file.\nExamples:\n$ rsync --write-batch=foo -a host:/source/dir/ /adest/dir/\n$ scp foo* remote:\n$ ssh remote ./foo.sh /bdest/dir/\n$ rsync --write-batch=foo -a /source/dir/ /adest/dir/\n$ ssh remote rsync --read-batch=- -a /bdest/dir/ <foo\nIn these examples, rsync is used to update /adest/dir/ from /source/dir/ and\nthe information to repeat this operation is stored in \"foo\" and \"foo.sh\".  The\nhost \"remote\" is then updated with the batched data going into the directory\n/bdest/dir.  The differences between the two examples reveals some of the\nflexibility you have in how you deal with batches:\nThe first example shows that the initial copy doesn't have to be local -⁠-⁠ you\ncan push or pull data to/from a remote host using either the remote-shell\nsyntax or rsync daemon syntax, as desired.\nThe first example uses the created \"foo.sh\" file to get the right rsync\noptions when running the read-batch command on the remote host.\nThe second example reads the batch data via standard input so that the batch\nfile doesn't need to be copied to the remote machine first.  This example\navoids the foo.sh script because it needed to use a modified\n--read-batch\noption, but you could edit the script file if you\nwished to make use of it (just be sure that no other option is trying to use\nstandard input, such as the\n--exclude-from=-\noption).\nCaveats:\nThe read-batch option expects the destination tree that it is updating to be\nidentical to the destination tree that was used to create the batch update\nfileset.  When a difference between the destination trees is encountered the\nupdate might be discarded with a warning (if the file appears to be up-to-date\nalready) or the file-update may be attempted and then, if the file fails to\nverify, the update discarded with an error.  This means that it should be safe\nto re-run a read-batch operation if the command got interrupted.  If you wish\nto force the batched-update to always be attempted regardless of the file's\nsize and date, use the\n-I\noption (when reading the batch).  If an\nerror occurs, the destination tree will probably be in a partially updated\nstate.  In that case, rsync can be used in its regular (non-batch) mode of\noperation to fix up the destination tree.\nThe rsync version used on all destinations must be at least as new as the one\nused to generate the batch file.  Rsync will die with an error if the protocol\nversion in the batch file is too new for the batch-reading rsync to handle.\nSee also the\n--protocol\noption for a way to have the creating rsync\ngenerate a batch file that an older rsync can understand.  (Note that batch\nfiles changed format in version 2.6.3, so mixing versions older than that with\nnewer versions will not work.)\nWhen reading a batch file, rsync will force the value of certain options to\nmatch the data in the batch file if you didn't set them to the same as the\nbatch-writing command.  Other options can (and should) be changed.  For\ninstance\n--write-batch\nchanges to\n--read-batch\n,\n--files-from\nis dropped, and the\n--filter\n/\n--include\n/\n--exclude\noptions are not needed unless one of\nthe\n--delete\noptions is specified.\nThe code that creates the BATCH.sh file transforms any filter/include/exclude\noptions into a single list that is appended as a \"here\" document to the shell\nscript file.  An advanced user can use this to modify the exclude list if a\nchange in what gets deleted by\n--delete\nis desired.  A normal user\ncan ignore this detail and just use the shell script as an easy way to run the\nappropriate\n--read-batch\ncommand for the batched data.\nThe original batch mode in rsync was based on \"rsync+\", but the latest\nversion uses a new implementation.\nSYMBOLIC LINKS\nThree basic behaviors are possible when rsync encounters a symbolic\nlink in the source directory.\nBy default, symbolic links are not transferred at all.  A message \"skipping\nnon-regular\" file is emitted for any symlinks that exist.\nIf\n--links\nis specified, then symlinks are added to the transfer\n(instead of being noisily ignored), and the default handling is to recreate\nthem with the same target on the destination.  Note that\n--archive\nimplies\n--links\n.\nIf\n--copy-links\nis specified, then symlinks are \"collapsed\" by\ncopying their referent, rather than the symlink.\nRsync can also distinguish \"safe\" and \"unsafe\" symbolic links.  An example\nwhere this might be used is a web site mirror that wishes to ensure that the\nrsync module that is copied does not include symbolic links to\n/etc/passwd\nin\nthe public section of the site.  Using\n--copy-unsafe-links\nwill cause\nany links to be copied as the file they point to on the destination.  Using\n--safe-links\nwill cause unsafe links to be omitted by the receiver.\n(Note that you must specify or imply\n--links\nfor\n--safe-links\nto have any effect.)\nSymbolic links are considered unsafe if they are absolute symlinks (start with\n/\n), empty, or if they contain enough \"..\" components to ascend from the top\nof the transfer.\nHere's a summary of how the symlink options are interpreted.  The list is in\norder of precedence, so if your combination of options isn't mentioned, use the\nfirst line that is a complete subset of your options:\n--copy-links\nTurn all symlinks into normal files and directories\n(leaving no symlinks in the transfer for any other options to affect).\n--copy-dirlinks\nTurn just symlinks to directories into real\ndirectories, leaving all other symlinks to be handled as described below.\n--links --copy-unsafe-links\nTurn all unsafe symlinks\ninto files and create all safe symlinks.\n--copy-unsafe-links\nTurn all unsafe symlinks into files, noisily\nskip all safe symlinks.\n--links --safe-links\nThe receiver skips creating\nunsafe symlinks found in the transfer and creates the safe ones.\n--links\nCreate all symlinks.\nFor the effect of\n--munge-links\n, see the discussion in that option's\nsection.\nNote that the\n--keep-dirlinks\noption does not effect symlinks in the\ntransfer but instead affects how rsync treats a symlink to a directory that\nalready exists on the receiving side.  See that option's section for a warning.\nDIAGNOSTICS\nRsync occasionally produces error messages that may seem a little cryptic.  The\none that seems to cause the most confusion is \"protocol version mismatch -⁠-⁠ is\nyour shell clean?\".\nThis message is usually caused by your startup scripts or remote shell facility\nproducing unwanted garbage on the stream that rsync is using for its transport.\nThe way to diagnose this problem is to run your remote shell like this:\nssh remotehost /bin/true > out.dat\nthen look at out.dat.  If everything is working correctly then out.dat should\nbe a zero length file.  If you are getting the above error from rsync then you\nwill probably find that out.dat contains some text or data.  Look at the\ncontents and try to work out what is producing it.  The most common cause is\nincorrectly configured shell startup scripts (such as .cshrc or .profile) that\ncontain output statements for non-interactive logins.\nIf you are having trouble debugging filter patterns, then try specifying the\n-vv\noption.  At this level of verbosity rsync will show why each individual\nfile is included or excluded.\nEXIT VALUES\n0\n-⁠ Success\n1\n-⁠ Syntax or usage error\n2\n-⁠ Protocol incompatibility\n3\n-⁠ Errors selecting input/output files, dirs\n4\n-⁠ Requested action not supported. Either:\nan attempt was made to manipulate 64-bit files on a platform that cannot support them\nan option was specified that is supported by the client and not by the server\n5\n-⁠ Error starting client-server protocol\n6\n-⁠ Daemon unable to append to log-file\n10\n-⁠ Error in socket I/O\n11\n-⁠ Error in file I/O\n12\n-⁠ Error in rsync protocol data stream\n13\n-⁠ Errors with program diagnostics\n14\n-⁠ Error in IPC code\n20\n-⁠ Received SIGUSR1 or SIGINT\n21\n-⁠ Some error returned by\nwaitpid()\n22\n-⁠ Error allocating core memory buffers\n23\n-⁠ Partial transfer due to error\n24\n-⁠ Partial transfer due to vanished source files\n25\n-⁠ The -⁠-⁠max-⁠delete limit stopped deletions\n30\n-⁠ Timeout in data send/receive\n35\n-⁠ Timeout waiting for daemon connection\nENVIRONMENT VARIABLES\nCVSIGNORE\nThe CVSIGNORE environment variable supplements any ignore patterns in\n.cvsignore files.  See the\n--cvs-exclude\noption for more details.\nRSYNC_ICONV\nSpecify a default\n--iconv\nsetting using this environment\nvariable. First supported in 3.0.0.\nRSYNC_OLD_ARGS\nSpecify a \"1\" if you want the\n--old-args\noption to be enabled by\ndefault, a \"2\" (or more) if you want it to be enabled in the\nrepeated-option state, or a \"0\" to make sure that it is disabled by\ndefault. When this environment variable is set to a non-zero value, it\nsupersedes the\nRSYNC_PROTECT_ARGS\nvariable.\nThis variable is ignored if\n--old-args\n,\n--no-old-args\n, or\n--secluded-args\nis specified on the command line.\nFirst supported in 3.2.4.\nRSYNC_PROTECT_ARGS\nSpecify a non-zero numeric value if you want the\n--secluded-args\noption to be enabled by default, or a zero value to make sure that it is\ndisabled by default.\nThis variable is ignored if\n--secluded-args\n,\n--no-secluded-args\n,\nor\n--old-args\nis specified on the command line.\nFirst supported in 3.1.0.  Starting in 3.2.4, this variable is ignored if\nRSYNC_OLD_ARGS\nis set to a non-zero value.\nRSYNC_RSH\nThis environment variable allows you to override the default shell used as\nthe transport for rsync.  Command line options are permitted after the\ncommand name, just as in the\n--rsh\n(\n-e\n) option.\nRSYNC_PROXY\nThis environment variable allows you to redirect your rsync\nclient to use a web proxy when connecting to an rsync daemon.  You should\nset\nRSYNC_PROXY\nto a hostname:port pair.\nRSYNC_PASSWORD\nThis environment variable allows you to set the password for an rsync\ndaemon\nconnection, which avoids the password prompt.  Note that this\ndoes\nnot\nsupply a password to a remote shell transport such as ssh\n(consult its documentation for how to do that).\nUSER\nor\nLOGNAME\nThe USER or LOGNAME environment variables are used to determine the default\nusername sent to an rsync daemon.  If neither is set, the username defaults\nto \"nobody\".  If both are set,\nUSER\ntakes precedence.\nRSYNC_PARTIAL_DIR\nThis environment variable specifies the directory to use for a\n--partial\ntransfer without implying that partial transfers be\nenabled.  See the\n--partial-dir\noption for full details.\nRSYNC_COMPRESS_LIST\nThis environment variable allows you to customize the negotiation of the\ncompression algorithm by specifying an alternate order or a reduced list of\nnames.  Use the command\nrsync --version\nto see the available compression\nnames.  See the\n--compress\noption for full details.\nRSYNC_CHECKSUM_LIST\nThis environment variable allows you to customize the negotiation of the\nchecksum algorithm by specifying an alternate order or a reduced list of\nnames.  Use the command\nrsync --version\nto see the available checksum\nnames.  See the\n--checksum-choice\noption for full details.\nRSYNC_MAX_ALLOC\nThis environment variable sets an allocation maximum as if you had used the\n--max-alloc\noption.\nRSYNC_PORT\nThis environment variable is not read by rsync, but is instead set in\nits sub-environment when rsync is running the remote shell in combination\nwith a daemon connection.  This allows a script such as\nrsync-ssl\nto be able to know the port number that the user\nspecified on the command line.\nHOME\nThis environment variable is used to find the user's default .cvsignore\nfile.\nRSYNC_CONNECT_PROG\nThis environment variable is mainly used in debug setups to set the program\nto use when making a daemon connection.  See\nCONNECTING TO AN RSYNC\nDAEMON\nfor full details.\nRSYNC_SHELL\nThis environment variable is mainly used in debug setups to set the program\nto use to run the program specified by\nRSYNC_CONNECT_PROG\n.  See\nCONNECTING TO AN RSYNC DAEMON\nfor full details.\nFILES\n/etc/rsyncd.conf or rsyncd.conf\nSEE ALSO\nrsync-ssl\n(1)\n,\nrsyncd.conf\n(5)\n,\nrrsync\n(1)\nBUGS\nTimes are transferred as *nix time_t values.\nWhen transferring to FAT filesystems rsync may re-sync unmodified files.  See\nthe comments on the\n--modify-window\noption.\nFile permissions, devices, etc. are transferred as native numerical values.\nSee also the comments on the\n--delete\noption.\nPlease report bugs! See the web site at\nhttps://rsync.samba.org/\n.\nVERSION\nThis manpage is current for version 3.4.1 of rsync.\nINTERNAL OPTIONS\nThe options\n--server\nand\n--sender\nare used internally by rsync, and should\nnever be typed by a user under normal circumstances.  Some awareness of these\noptions may be needed in certain scenarios, such as when setting up a login\nthat can only run an rsync command.  For instance, the support directory of the\nrsync distribution has an example script named rrsync (for restricted rsync)\nthat can be used with a restricted ssh login.\nCREDITS\nRsync is distributed under the GNU General Public License.  See the file\nCOPYING\nfor details.\nAn rsync web site is available at\nhttps://rsync.samba.org/\n.  The site\nincludes an FAQ-O-Matic which may cover questions unanswered by this manual\npage.\nThe rsync github project is\nhttps://github.com/RsyncProject/rsync\n.\nWe would be delighted to hear from you if you like this program.  Please\ncontact the mailing-list at\nrsync@lists.samba.org\n.\nThis program uses the excellent zlib compression library written by Jean-loup\nGailly and Mark Adler.\nTHANKS\nSpecial thanks go out to: John Van Essen, Matt McCutchen, Wesley W. Terpstra,\nDavid Dykstra, Jos Backus, Sebastian Krahmer, Martin Pool, and our\ngone-but-not-forgotten compadre, J.W. Schultz.\nThanks also to Richard Brent, Brendan Mackay, Bill Waite, Stephen Rothwell and\nDavid Bell.  I've probably missed some people, my apologies if I have.\nAUTHOR\nRsync was originally written by Andrew Tridgell and Paul Mackerras.  Many\npeople from around the world have helped to maintain and improve it.\nMailing lists for support and development are available at\nhttps://lists.samba.org/\n.\n15 Jan 2025", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://download.samba.org/pub/rsync/rsync.1"}}
{"text": "Borg Documentation — Borg - Deduplicating Archiver 1.4.2.post3 documentation\nNavigation\nnext\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nBorg Documentation\nBorg 1.4.2.post3\nInstallation\nQuick Start\nUsage\nDeployment\nFrequently asked questions\nSupport\nImportant notes\nUpgrade Notes\nChange Log\nInternals\nDevelopment\nAuthors\nLicense\nDocs\nBorg Documentation\nBorg Documentation\n¶\nMore screencasts:\ninstallation\n,\nadvanced usage\nWhat is BorgBackup?\n¶\nBorgBackup (short: Borg) is a deduplicating backup program.\nOptionally, it supports compression and authenticated encryption.\nThe main goal of Borg is to provide an efficient and secure way to backup data.\nThe data deduplication technique used makes Borg suitable for daily backups\nsince only changes are stored.\nThe authenticated encryption technique makes it suitable for backups to not\nfully trusted targets.\nSee the\ninstallation manual\nor, if you have already\ndownloaded Borg,\ndocs/installation.rst\nto get started with Borg.\nThere is also an\noffline documentation\navailable, in multiple formats.\nMain features\n¶\nSpace efficient storage\nDeduplication based on content-defined chunking is used to reduce the number\nof bytes stored: each file is split into a number of variable length chunks\nand only chunks that have never been seen before are added to the repository.\nA chunk is considered duplicate if its id_hash value is identical.\nA cryptographically strong hash or MAC function is used as id_hash, e.g.\n(hmac-)sha256.\nTo deduplicate, all the chunks in the same repository are considered, no\nmatter whether they come from different machines, from previous backups,\nfrom the same backup or even from the same single file.\nCompared to other deduplication approaches, this method does NOT depend on:\nfile/directory names staying the same: So you can move your stuff around\nwithout killing the deduplication, even between machines sharing a repo.\ncomplete files or time stamps staying the same: If a big file changes a\nlittle, only a few new chunks need to be stored - this is great for VMs or\nraw disks.\nThe absolute position of a data chunk inside a file: Stuff may get shifted\nand will still be found by the deduplication algorithm.\nSpeed\nperformance-critical code (chunking, compression, encryption) is\nimplemented in C/Cython\nlocal caching of files/chunks index data\nquick detection of unmodified files\nData encryption\nAll data can be protected using 256-bit AES encryption, data integrity and\nauthenticity is verified using HMAC-SHA256. Data is encrypted client-side.\nObfuscation\nOptionally, Borg can actively obfuscate, e.g., the size of files/chunks to\nmake fingerprinting attacks more difficult.\nCompression\nAll data can be optionally compressed:\nlz4 (super fast, low compression)\nzstd (wide range from high speed and low compression to high compression\nand lower speed)\nzlib (medium speed and compression)\nlzma (low speed, high compression)\nOff-site backups\nBorg can store data on any remote host accessible over SSH. If Borg is\ninstalled on the remote host, significant performance gains can be achieved\ncompared to using a network file system (sshfs, NFS, …).\nBackups mountable as file systems\nBackup archives are mountable as user-space file systems for easy interactive\nbackup examination and restores (e.g., by using a regular file manager).\nEasy installation on multiple platforms\nWe offer single-file binaries that do not require installing anything -\nyou can just run them on these platforms:\nLinux\nmacOS\nFreeBSD\nOpenBSD and NetBSD (no xattrs/ACLs support or binaries yet)\nCygwin (experimental, no binaries yet)\nWindows Subsystem for Linux (WSL) on Windows 10/11 (experimental)\nFree and Open Source Software\nsecurity and functionality can be audited independently\nlicensed under the BSD (3-clause) license, see\nLicense\nfor the\ncomplete license\nEasy to use\n¶\nInitialize a new backup repository (see\nborg\ninit\n--help\nfor encryption options):\n$ borg init -e repokey /path/to/repo\nCreate a backup archive:\n$ borg create /path/to/repo::Saturday1 ~/Documents\nNow doing another backup, just to show off the great deduplication:\n$ borg create -v --stats /path/to/repo::Saturday2 ~/Documents\n-----------------------------------------------------------------------------\nArchive name: Saturday2\nArchive fingerprint: 622b7c53c...\nTime (start): Sat, 2016-02-27 14:48:13\nTime (end):   Sat, 2016-02-27 14:48:14\nDuration: 0.88 seconds\nNumber of files: 163\n-----------------------------------------------------------------------------\nOriginal size      Compressed size    Deduplicated size\nThis archive:        6.85 MB              6.85 MB             30.79 kB  <-- !\nAll archives:       13.69 MB             13.71 MB              6.88 MB\nUnique chunks         Total chunks\nChunk index:             167                  330\n-----------------------------------------------------------------------------\nFor a graphical frontend, refer to our complementary project\nBorgWeb\n.\nHelping, donations and bounties, becoming a Patron\n¶\nYour help is always welcome!\nSpread the word, give feedback, help with documentation, testing or development.\nYou can also give monetary support to the project, see there for details:\nhttps://www.borgbackup.org/support/fund.html\nLinks\n¶\nMain website\nReleases\n,\nPyPI packages\nand\nChangelog\nOffline documentation\nGitHub\nand\nIssue tracker\n.\nWeb chat (IRC)\nand\nMailing list\nLicense\nSecurity contact\nCompatibility notes\n¶\nEXPECT THAT WE WILL BREAK COMPATIBILITY REPEATEDLY WHEN MAJOR RELEASE NUMBER\nCHANGES (like when going from 0.x.y to 1.0.0 or from 1.x.y to 2.0.0).\nNOT RELEASED DEVELOPMENT VERSIONS HAVE UNKNOWN COMPATIBILITY PROPERTIES.\nTHIS IS SOFTWARE IN DEVELOPMENT, DECIDE YOURSELF WHETHER IT FITS YOUR NEEDS.\nSecurity issues should be reported to the\nSecurity contact\n(or\nsee\ndocs/support.rst\nin the source distribution).\nInstallation\nDistribution Package\nStandalone Binary\nFrom Source\nQuick Start\nA step-by-step example\nArchives and repositories\nImportant note about free space\nImportant note about permissions\nImportant note about files changing during the backup process\nAutomating backups\nPitfalls with shell variables and environment variables\nPassphrase notes\nBackup compression\nRepository encryption\nRemote repositories\nRestoring a backup\nUsage\nGeneral\nborg init\nborg create\nborg extract\nborg check\nborg rename\nborg list\nborg diff\nborg delete\nborg prune\nborg compact\nborg info\nborg version\nborg mount\nborg umount\nborg key change-passphrase\nborg key export\nborg key import\nborg upgrade\nborg recreate\nborg import-tar\nborg export-tar\nborg serve\nborg config\nborg with-lock\nborg break-lock\nborg benchmark crud\nMiscellaneous Help\nDebugging Facilities\nAdditional Notes\nDeployment\nCentral repository server with Ansible or Salt\nHosting repositories\nAutomated backups to a local hard drive\nBacking up entire disk images\nBacking up in pull mode\nBacking up using a non-root user\nFrequently asked questions\nUsage & Limitations\nSecurity\nCommon issues\nMiscellaneous\nMigrating from Attic\nSupport\nSupport and Services\nSecurity\nVerifying signed releases\nImportant notes\nPre-1.2.5 archives spoofing vulnerability (CVE-2023-36811)\nPre-1.1.11 potential index corruption / data loss issue\nPre-1.1.4 potential data corruption issue\nPre-1.0.9 manifest spoofing vulnerability (CVE-2016-10099)\nPre-1.0.9 potential data loss\nPre-1.0.4 potential repo corruption\nUpgrade Notes\nborg 1.2.x to 1.4.x\nborg 1.1.x to 1.2.x\nChange Log\nVersion 1.4.2 (2025-10-31)\nVersion 1.4.1 (2025-04-19)\nVersion 1.4.0 (2024-07-03)\nVersion 1.4.0rc1 (2024-05-26)\nVersion 1.4.0b2 (2024-03-31)\nVersion 1.4.0b1 (2024-01-21)\nVersion 1.4.0a1 (2024-01-01)\nVersion 1.2.7 (2023-12-02)\nVersion 1.2.6 (2023-08-31)\nVersion 1.2.5 (2023-08-30)\nVersion 1.2.4 (2023-03-24)\nVersion 1.2.3 (2022-12-24)\nVersion 1.2.2 (2022-08-20)\nVersion 1.2.1 (2022-06-06)\nVersion 1.2.0 (2022-02-22 22:02:22 :-)\nVersion 1.2.0rc1 (2022-02-05)\nVersion 1.2.0b4 (2022-01-23)\nVersion 1.2.0b3 (2021-05-12)\nVersion 1.2.0b2 (2021-02-06)\nVersion 1.2.0b1 (2020-12-06)\nVersion 1.2.0a9 (2020-10-05)\nVersion 1.2.0a8 (2020-04-22)\nVersion 1.2.0a7 (2019-09-07)\nVersion 1.2.0a6 (2019-04-22)\nVersion 1.2.0a5 (2019-03-21)\nVersion 1.2.0a4 (2019-03-11)\nVersion 1.2.0a3 (2019-02-26)\nVersion 1.2.0a2 and earlier (2019-02-24)\nVersion 1.1.18 (2022-06-05)\nVersion 1.1.17 (2021-07-12)\nVersion 1.1.16 (2021-03-23)\nVersion 1.1.15 (2020-12-25)\nVersion 1.1.14 (2020-10-07)\nVersion 1.1.13 (2020-06-06)\nVersion 1.1.12 (2020-06-06)\nVersion 1.1.11 (2020-03-08)\nVersion 1.1.10 (2019-05-16)\nVersion 1.1.9 (2019-02-10)\nVersion 1.1.8 (2018-12-09)\nVersion 1.1.7 (2018-08-11)\nVersion 1.1.6 (2018-06-11)\nVersion 1.1.5 (2018-04-01)\nVersion 1.1.4 (2017-12-31)\nVersion 1.1.3 (2017-11-27)\nVersion 1.1.2 (2017-11-05)\nVersion 1.1.1 (2017-10-22)\nVersion 1.1.0 (2017-10-07)\nVersion 1.1.0rc4 (2017-10-01)\nVersion 1.1.0rc3 (2017-09-10)\nVersion 1.1.0rc2 (2017-08-28)\nVersion 1.1.0rc1 (2017-07-24)\nVersion 1.1.0b6 (2017-06-18)\nVersion 1.1.0b5 (2017-04-30)\nVersion 1.1.0b4 (2017-03-27)\nVersion 1.1.0b3 (2017-01-15)\nVersion 1.1.0b2 (2016-10-01)\nVersion 1.1.0b1 (2016-08-28)\nVersion 1.0.13 (2019-02-15)\nVersion 1.0.12 (2018-04-08)\nVersion 1.0.11 (2017-07-21)\nVersion 1.0.11rc1 (2017-06-27)\nVersion 1.0.10 (2017-02-13)\nVersion 1.0.10rc1 (2017-01-29)\nVersion 1.0.9 (2016-12-20)\nVersion 1.0.9rc1 (2016-11-27)\nVersion 1.0.8 (2016-10-29)\nVersion 1.0.8rc1 (2016-10-17)\nVersion 1.0.7 (2016-08-19)\nVersion 1.0.7rc2 (2016-08-13)\nVersion 1.0.7rc1 (2016-08-05)\nVersion 1.0.6 (2016-07-12)\nVersion 1.0.6rc1 (2016-07-10)\nVersion 1.0.5 (2016-07-07)\nVersion 1.0.4 (2016-07-07)\nVersion 1.0.3 (2016-05-20)\nVersion 1.0.2 (2016-04-16)\nVersion 1.0.1 (2016-04-08)\nVersion 1.0.0 (2016-03-05)\nVersion 1.0.0rc2 (2016-02-28)\nVersion 1.0.0rc1 (2016-02-07)\nVersion 0.30.0 (2016-01-23)\nVersion 0.29.0 (2015-12-13)\nVersion 0.28.2 (2015-11-15)\nVersion 0.28.1 (2015-11-08)\nVersion 0.28.0 (2015-11-08)\nVersion 0.27.0 (2015-10-07)\nVersion 0.26.1 (2015-09-28)\nVersion 0.26.0 (2015-09-19)\nVersion 0.25.0 (2015-08-29)\nVersion 0.24.0 (2015-08-09)\nVersion 0.23.0 (2015-06-11)\nAttic Changelog\nInternals\nSecurity\nData structures and file formats\nAll about JSON: How to develop frontends\nDevelopment\nContributions\nBranching model\nCode and issues\nStyle guide\nContinuous Integration\nOutput and Logging\nBuilding a development environment\nRunning the tests\nRunning the tests (using the pypi package)\nAdding a compression algorithm\nDocumentation\nUsing Vagrant\nCreating standalone binaries\nCreating a new release\nAuthors\nBorg authors (“The Borg Collective”)\nAttic authors\nBLAKE2\nSlicing CRC32\nFolding CRC32\nxxHash\nLicense\nInstallation\nNavigation\nnext\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nBorg Documentation\n© Copyright 2010-2014 Jonas Borgström, 2015-2025 The Borg Collective (see AUTHORS file). Created using\nSphinx\n.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://borgbackup.readthedocs.io/en/stable/"}}
{"text": "Quick Start — Borg - Deduplicating Archiver 1.4.2.post3 documentation\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nQuick Start\nBorg 1.4.2.post3\nInstallation\nQuick Start\nA step-by-step example\nArchives and repositories\nImportant note about free space\nImportant note about permissions\nImportant note about files changing during the backup process\nAutomating backups\nPitfalls with shell variables and environment variables\nPassphrase notes\nBackup compression\nRepository encryption\nRemote repositories\nRestoring a backup\nUsage\nDeployment\nFrequently asked questions\nSupport\nImportant notes\nUpgrade Notes\nChange Log\nInternals\nDevelopment\nAuthors\nLicense\nDocs\nQuick Start\nQuick Start\n¶\nThis chapter will get you started with Borg and covers\nvarious use cases.\nA step-by-step example\n¶\nBefore a backup can be made a repository has to be initialized:\n$\nborg\ninit\n--encryption\n=\nrepokey\n/path/to/repo\nBackup the\n~/src\nand\n~/Documents\ndirectories into an archive called\nMonday\n:\n$\nborg\ncreate\n/path/to/repo::Monday\n~/src\n~/Documents\nThe next day create a new archive called\nTuesday\n:\n$\nborg\ncreate\n--stats\n/path/to/repo::Tuesday\n~/src\n~/Documents\nThis backup will be a lot quicker and a lot smaller since only new never\nbefore seen data is stored. The\n--stats\noption causes Borg to\noutput statistics about the newly created archive such as the amount of unique\ndata (not shared with other archives):\n------------------------------------------------------------------------------\nArchive\nname:\nTuesday\nArchive\nfingerprint:\nbd31004d58f51ea06ff735d2e5ac49376901b21d58035f8fb05dbf866566e3c2\nTime\n(\nstart\n)\n:\nTue,\n2016\n-02-16\n18\n:15:11\nTime\n(\nend\n)\n:\nTue,\n2016\n-02-16\n18\n:15:11\nDuration:\n0\n.19\nseconds\nNumber\nof\nfiles:\n127\n------------------------------------------------------------------------------\nOriginal\nsize\nCompressed\nsize\nDeduplicated\nsize\nThis\narchive:\n4\n.16\nMB\n4\n.17\nMB\n26\n.78\nkB\nAll\narchives:\n8\n.33\nMB\n8\n.34\nMB\n4\n.19\nMB\nUnique\nchunks\nTotal\nchunks\nChunk\nindex:\n132\n261\n------------------------------------------------------------------------------\nList all archives in the repository:\n$\nborg\nlist\n/path/to/repo\nMonday\nMon,\n2016\n-02-15\n19\n:14:44\nTuesday\nTue,\n2016\n-02-16\n19\n:15:11\nList the contents of the\nMonday\narchive:\n$\nborg\nlist\n/path/to/repo::Monday\ndrwxr-xr-x\nuser\ngroup\n0\nMon,\n2016\n-02-15\n18\n:22:30\nhome/user/Documents\n-rw-r--r--\nuser\ngroup\n7961\nMon,\n2016\n-02-15\n18\n:22:30\nhome/user/Documents/Important.doc\n...\nRestore the\nMonday\narchive by extracting the files relative to the current directory:\n$\nborg\nextract\n/path/to/repo::Monday\nDelete the\nMonday\narchive (please note that this does\nnot\nfree repo disk space):\n$\nborg\ndelete\n/path/to/repo::Monday\nRecover disk space by compacting the segment files in the repo:\n$\nborg\ncompact\n/path/to/repo\nNote\nBorg is quiet by default (it works on WARNING log level).\nYou can use options like\n--progress\nor\n--list\nto get specific\nreports during command execution.  You can also add the\n-v\n(or\n--verbose\nor\n--info\n) option to adjust the log level to INFO to\nget other informational messages.\nArchives and repositories\n¶\nA\nBorg archive\nis the result of a single backup (\nborg\ncreate\n). An archive\nstores a snapshot of the data of the files “inside” it. One can later extract or\nmount an archive to restore from a backup.\nRepositories\nare file system directories acting as self-contained stores of archives.\nRepositories can be accessed locally via path or remotely via SSH. Under the hood,\nrepositories contain data blocks and a manifest tracking which blocks are in each\narchive. If some data hasn’t changed from one backup to another, Borg can simply\nreference an already uploaded data chunk (deduplication).\nImportant note about free space\n¶\nBefore you start creating backups, please make sure that there is\nalways\na good amount of free space on the filesystem that has your backup repository\n(and also on ~/.cache). A few GB should suffice for most hard-drive sized\nrepositories. See also\nIndexes / Caches memory usage\n.\nBorg doesn’t use space reserved for root on repository disks (even when run as root),\non file systems which do not support this mechanism (e.g., XFS) we recommend reserving\nsome space in Borg itself just to be safe by adjusting the\nadditional_free_space\nsetting (a good starting point is\n2G\n):\nborg\nconfig\n/path/to/repo\nadditional_free_space\n2G\nIf Borg runs out of disk space, it tries to free as much space as it\ncan while aborting the current operation safely, which allows the user to free more space\nby deleting/pruning archives. This mechanism is not bullet-proof in some\ncircumstances\n[\n1\n]\n.\nIf you\nreally\nrun out of disk space, it can be hard or impossible to free space,\nbecause Borg needs free space to operate — even to delete backup\narchives.\nYou can use some monitoring process or just include the free space information\nin your backup log files (you check them regularly anyway, right?).\nAlso helpful:\ncreate a big file as a “space reserve”, that you can delete to free space\nif you use LVM: use an LV + a file system that you can resize later and have\nsome unallocated PEs you can add to the LV.\nconsider using quotas\nuse\nprune\nand\ncompact\nregularly\n[\n1\n]\nThis fail-safe can fail in these circumstances:\nThe underlying file system does not support statvfs(2), or returns incorrect\ndata, or the repository does not reside on a single file system\nOther tasks fill the disk simultaneously\nHard quotas (which may not be reflected in statvfs(2))\nImportant note about permissions\n¶\nTo avoid permissions issues (in your Borg repository or Borg cache),\nalways\naccess the repository using the same user account\n.\nIf you want to back up files of other users or the operating system, running\nBorg as root likely will be required (otherwise you’d get\nPermission denied\nerrors).\nIf you only back up your own files, you neither need nor want to run Borg as\nroot, just run it as your normal user.\nFor a local repository just always use the same user to invoke Borg.\nFor a remote repository: always use e.g.\nborg\n@\nremote_host\n. You can use this\nfrom different local users; the remote user running Borg and accessing the\nrepo will always be\nborg\n.\nIf you need to access a local repository from different users, you can use the\nsame method by using SSH to\nborg\n@\nlocalhost\n.\nImportant note about files changing during the backup process\n¶\nBorg does not do anything about the internal consistency of the data\nit backs up.  It just reads and backs up each file in whatever state\nthat file is when Borg gets to it.  On an active system, this can lead\nto two kinds of inconsistency:\nBy the time Borg backs up a file, it might have changed since the backup process was initiated\nA file could change while Borg is backing it up, making the file internally inconsistent\nIf you have a set of files and want to ensure that they are backed up\nin a specific or consistent state, you must take steps to prevent\nchanges to those files during the backup process.  There are a few\ncommon techniques to achieve this.\nAvoid running any programs that might change the files.\nSnapshot files, filesystems, container storage volumes, or logical volumes.\nLVM or ZFS might be useful here.\nDump databases or stop the database servers.\nShut down virtual machines before backing up their images.\nShut down containers before backing up their storage volumes.\nFor some systems Borg might work well enough without these\nprecautions.  If you are simply backing up the files on a system that\nisn’t very active (e.g. in a typical home directory), Borg usually\nworks well enough without further care for consistency.  Log files and\ncaches might not be in a perfect state, but this is rarely a problem.\nFor databases, virtual machines, and containers, there are specific\ntechniques for backing them up that do not simply use Borg to backup\nthe underlying filesystem.  For databases, check your database\ndocumentation for techniques that will save the database state between\ntransactions.  For virtual machines, consider running the backup on\nthe VM itself or mounting the filesystem while the VM is shut down.\nFor Docker containers, perhaps docker’s “save” command can help.\nAutomating backups\n¶\nThe following example script is meant to be run daily by the\nroot\nuser on\ndifferent local machines. It backs up a machine’s important files (but not the\ncomplete operating system) to a repository\n~/backup/main\non a remote server.\nSome files which aren’t necessarily needed in this backup are excluded. See\nborg help patterns\non how to add more exclude options.\nAfter the backup this script also uses the\nborg prune\nsubcommand to keep\nonly a certain number of old archives and deletes the others.\nFinally, it uses the\nborg compact\nsubcommand to remove deleted objects\nfrom the segment files in the repository to preserve disk space.\nBefore running, make sure that the repository is initialized as documented in\nRemote repositories\nand that the script has the correct permissions to be executable\nby the root user, but not executable or readable by anyone else, i.e. root:root 0700.\nYou can use this script as a starting point and modify it where it’s necessary to fit\nyour setup.\nDo not forget to test your created backups to make sure everything you need is being\nbacked up and that the\nprune\ncommand is keeping and deleting the correct backups.\n#!/bin/sh\n# Setting this, so the repo does not need to be given on the commandline:\nexport\nBORG_REPO\n=\nssh://username@example.com:2022/~/backup/main\n# See the section \"Passphrase notes\" for more infos.\nexport\nBORG_PASSPHRASE\n=\n'XYZl0ngandsecurepa_55_phrasea&&123'\n# some helpers and error handling:\ninfo\n()\n{\nprintf\n\"\\n%s %s\\n\\n\"\n\"\n$(\ndate\n)\n\"\n\"\n$*\n\"\n>\n&\n2\n;\n}\ntrap\n'echo $( date ) Backup interrupted >&2; exit 2'\nINT\nTERM\ninfo\n\"Starting backup\"\n# Backup the most important directories into an archive named after\n# the machine this script is currently running on:\nborg\ncreate\n\\\n--verbose\n\\\n--filter\nAME\n\\\n--list\n\\\n--stats\n\\\n--show-rc\n\\\n--compression\nlz4\n\\\n--exclude-caches\n\\\n--exclude\n'home/*/.cache/*'\n\\\n--exclude\n'var/tmp/*'\n\\\n\\\n::\n'{hostname}-{now}'\n\\\n/etc\n\\\n/home\n\\\n/root\n\\\n/var\nbackup_exit\n=\n$?\ninfo\n\"Pruning repository\"\n# Use the `prune` subcommand to maintain 7 daily, 4 weekly and 6 monthly\n# archives of THIS machine. The '{hostname}-*' matching is very important to\n# limit prune's operation to this machine's archives and not apply to\n# other machines' archives also:\nborg\nprune\n\\\n--list\n\\\n--glob-archives\n'{hostname}-*'\n\\\n--show-rc\n\\\n--keep-daily\n7\n\\\n--keep-weekly\n4\n\\\n--keep-monthly\n6\nprune_exit\n=\n$?\n# actually free repo disk space by compacting segments\ninfo\n\"Compacting repository\"\nborg\ncompact\ncompact_exit\n=\n$?\n# use highest exit code as global exit code\nglobal_exit\n=\n$((\nbackup_exit\n>\nprune_exit\n?\nbackup_exit\n:\nprune_exit\n))\nglobal_exit\n=\n$((\ncompact_exit\n>\nglobal_exit\n?\ncompact_exit\n:\nglobal_exit\n))\nif\n[\n${\nglobal_exit\n}\n-eq\n0\n]\n;\nthen\ninfo\n\"Backup, Prune, and Compact finished successfully\"\nelif\n[\n${\nglobal_exit\n}\n-eq\n1\n]\n;\nthen\ninfo\n\"Backup, Prune, and/or Compact finished with warnings\"\nelse\ninfo\n\"Backup, Prune, and/or Compact finished with errors\"\nfi\nexit\n${\nglobal_exit\n}\nPitfalls with shell variables and environment variables\n¶\nThis applies to all environment variables you want Borg to see, not just\nBORG_PASSPHRASE\n. The short explanation is: always\nexport\nyour variable,\nand use single quotes if you’re unsure of the details of your shell’s expansion\nbehavior. E.g.:\nexport\nBORG_PASSPHRASE\n=\n'complicated & long'\nThis is because\nexport\nexposes variables to subprocesses, which Borg may be\none of. More on\nexport\ncan be found in the “ENVIRONMENT” section of the\nbash(1) man page.\nBeware of how\nsudo\ninteracts with environment variables. For example, you\nmay be surprised that the following\nexport\nhas no effect on your command:\nexport\nBORG_PASSPHRASE\n=\n'complicated & long'\nsudo\n./yourborgwrapper.sh\n# still prompts for password\nFor more information, refer to the sudo(8) man page and\nenv_keep\nin\nthe sudoers(5) man page.\nTip\nTo debug what your borg process is actually seeing, find its PID\n(\nps\naux|grep\nborg\n) and then look into\n/proc/<PID>/environ\n.\nPassphrase notes\n¶\nIf you use encryption (or authentication), Borg will interactively ask you\nfor a passphrase to encrypt/decrypt the keyfile / repokey.\nA passphrase should be a single line of text, a trailing linefeed will be\nstripped.\nFor your own safety, you maybe want to avoid empty passphrases as well\nextremely long passphrase (much more than 256 bits of entropy).\nAlso avoid passphrases containing non-ASCII characters.\nBorg is technically able to process all unicode text, but you might get into\ntrouble reproducing the same encoded utf-8 bytes or with keyboard layouts,\nso better just avoid non-ASCII stuff.\nIf you want to automate, you can alternatively supply the passphrase\ndirectly or indirectly using some environment variables.\nYou can directly give a passphrase:\n# use this passphrase (use safe permissions on the script!):\nexport\nBORG_PASSPHRASE\n=\n'my super secret passphrase'\nOr ask an external program to supply the passphrase:\n# use the \"pass\" password manager to get the passphrase:\nexport\nBORG_PASSCOMMAND\n=\n'pass show backup'\n# use GPG to get the passphrase contained in a gpg-encrypted file:\nexport\nBORG_PASSCOMMAND\n=\n'gpg --decrypt borg-passphrase.gpg'\nOr read the passphrase from an open file descriptor:\nexport\nBORG_PASSPHRASE_FD\n=\n42\nUsing hardware crypto devices (like Nitrokey, Yubikey and others) is not\ndirectly supported by borg, but you can use these indirectly.\nE.g. if your crypto device supports GPG and borg calls\ngpg\nvia\nBORG_PASSCOMMAND\n, it should just work.\nBackup compression\n¶\nThe default is lz4 (very fast, but low compression ratio), but other methods are\nsupported for different situations. Compression not only helps you save disk space,\nbut will especially speed up remote backups since less data needs to be transferred.\nzstd is a modern compression algorithm which can be parametrized to anything between\nN=1 for highest speed (and relatively low compression) to N=22 for highest compression\n(and lower speed):\n$\nborg\ncreate\n--compression\nzstd,N\n/path/to/repo::arch\n~\nIf you have a fast repo storage and you want minimum CPU usage you can disable\ncompression:\n$\nborg\ncreate\n--compression\nnone\n/path/to/repo::arch\n~\nYou can also use zlib and lzma instead of zstd, although zstd usually provides the\nthe best compression for a given resource consumption. You may want to use these\nalgorithms if you need compatibility to older borg versions (< 1.1.4) that\ndid not yet offer zstd. Please see\nborg help compression\nfor all options.\nAn interesting alternative is\nauto\n, which first checks with lz4 whether a chunk is\ncompressible (that check is very fast), and only if it is, compresses it with the\nspecified algorithm:\n$\nborg\ncreate\n--compression\nauto,zstd,7\n/path/to/repo::arch\n~\nYou’ll need to experiment a bit to find the best compression for your use case.\nKeep an eye on CPU load and throughput.\nRepository encryption\n¶\nYou can choose the repository encryption mode at repository creation time:\n$\nborg\ninit\n--encryption\n=\nMODE\nPATH\nFor a list of available encryption MODEs and their descriptions, please refer\nto\nborg init\n.\nIf you use encryption, all data is encrypted on the client before being written\nto the repository.\nThis means that an attacker who manages to compromise the host containing an\nencrypted repository will not be able to access any of the data, even while the\nbackup is being made.\nKey material is stored in encrypted form and can be only decrypted by providing\nthe correct passphrase.\nFor automated backups the passphrase can be specified using the\nBORG_PASSPHRASE\nenvironment variable.\nNote\nBe careful about how you set that environment, see\nthis note about password environments\nfor more information.\nWarning\nThe repository data is totally inaccessible without the key\nand the key passphrase.\nMake a backup copy of the key file (\nkeyfile\nmode) or repo config\nfile (\nrepokey\nmode) and keep it at a safe place, so you still have\nthe key in case it gets corrupted or lost. Also keep your passphrase\nat a safe place. You can make backups using\nborg key export\nsubcommand.\nIf you want to print a backup of your key to paper use the\n--paper\noption of this command and print the result, or print this\ntemplate\nif you need a version with QR-Code.\nA backup inside of the backup that is encrypted with that key/passphrase\nwon’t help you with that, of course.\nIn case you lose your repository and the security information, but have an\nolder copy of it to restore from, don’t use that later for creating new\nbackups – you would run into security issues (reuse of nonce counter\nvalues). It is better to initialize a new Borg repository. See also:\nMy repository is corrupt, how can I restore from an older copy of it?\nRemote repositories\n¶\nBorg can initialize and access repositories on remote hosts if the\nhost is accessible using SSH.  This is fastest and easiest when Borg\nis installed on the remote host, in which case the following syntax is used:\n$\nborg\ninit\nuser@hostname:/path/to/repo\nNote: Please see the usage chapter for a full documentation of repo URLs. Also\nsee\nSSH Configuration\nfor recommended settings to avoid disconnects and hangs.\nRemote operations over SSH can be automated with SSH keys. You can restrict the\nuse of the SSH keypair by prepending a forced command to the SSH public key in\nthe remote server’s\nauthorized_keys\nfile. This example will start Borg\nin server mode and limit it to a specific filesystem path:\ncommand\n=\n\"borg serve --restrict-to-path /path/to/repo\"\n,restrict\nssh-rsa\nAAAAB3\n[\n...\n]\nIf it is not possible to install Borg on the remote host,\nit is still possible to use the remote host to store a repository by\nmounting the remote filesystem, for example, using sshfs:\n$\nsshfs\nuser@hostname:/path/to\n/path/to\n$\nborg\ninit\n/path/to/repo\n$\nfusermount\n-u\n/path/to\nYou can also use other remote filesystems in a similar way. Just be careful,\nnot all filesystems out there are really stable and working good enough to\nbe acceptable for backup usage.\nRestoring a backup\n¶\nPlease note that we are only describing the most basic commands and options\nhere - please refer to the command reference to see more.\nFor restoring, you usually want to work\non the same machine as the same user\nthat was also used to create the backups of the wanted files. Doing it like\nthat avoids quite some issues:\nno confusion relating to paths\nsame mapping of user/group names to user/group IDs\nno permission issues\nyou likely already have a working borg setup there,\nmaybe including a environment variable for the key passphrase (for encrypted repos),\nmaybe including a keyfile for the repo (not needed for repokey mode),\nmaybe including a ssh key for the repo server (not needed for locally mounted repos),\nmaybe including a valid borg cache for that repo (quicker than cache rebuild).\nThe\nuser\nmight be:\nroot (if full backups, backups including system stuff or multiple\nusers’ files were made)\nsome specific user using sudo to execute borg as root\nsome specific user (if backups of that user’s files were made)\nA borg\nbackup repository\ncan be either:\nin a local directory (like e.g. a locally mounted USB disk)\non a remote backup server machine that is reachable via ssh (client/server)\nIf the repository is encrypted, you will also need the\nkey\nand the\npassphrase\n(which is protecting the key).\nThe\nkey\ncan be located:\nin the repository (\nrepokey\nmode).\nEasy, this will usually “just work”.\nin the home directory of the user who did the backup (\nkeyfile\nmode).\nThis may cause a bit more effort:\nif you have just lost that home directory and you first need to restore the\nborg key (e.g. from the separate backup you have made of it or from another\nuser or machine accessing the same repository).\nif you first must find out the correct machine / user / home directory\n(where the borg client was run to make the backups).\nThe\npassphrase\nfor the key has been either:\nentered interactively at backup time\n(not practical if backup is automated / unattended).\nacquired via some environment variable driven mechanism in the backup script\n(look there for BORG_PASSPHRASE, BORG_PASSCOMMAND, etc. and just do it like\nthat).\nThere are\n2 ways to restore\nfiles from a borg backup repository:\nborg mount\n- use this if:\nyou don’t precisely know what files you want to restore\nyou don’t know which archive contains the files (in the state) you want\nyou need to look into files / directories before deciding what you want\nyou need a relatively low volume of data restored\nyou don’t care for restoring stuff that the FUSE mount is not implementing yet\n(like special fs flags, ACLs)\nyou have a client with good resources (RAM, CPU, temp. disk space)\nyou want to rather use some filemanager to restore (copy) files than borg\nextract shell commands\nborg extract\n- use this if:\nyou precisely know what you want (repo, archive, path)\nyou need a high volume of files restored (best speed)\nyou want a as-complete-as-it-gets reproduction of file metadata\n(like special fs flags, ACLs)\nyou have a client with low resources (RAM, CPU, temp. disk space)\nExample with\nborg mount\n:\n# open a new, separate terminal (this terminal will be blocked until umount)\n# now we find out the archive names we have in the repo:\nborg\nlist\n/mnt/backup/borg_repo\n# mount one archive from a borg repo:\nborg\nmount\n/mnt/backup/borg_repo::myserver-system-2019-08-11\n/mnt/borg\n# alternatively, mount all archives from a borg repo (slower):\nborg\nmount\n/mnt/backup/borg_repo\n/mnt/borg\n# it may take a while until you will see stuff in /mnt/borg.\n# now use another terminal or file browser and look into /mnt/borg.\n# when finished, umount to unlock the repo and unblock the terminal:\nborg\numount\n/mnt/borg\nExample with\nborg extract\n:\n# borg extract always extracts into current directory and that directory\n# should be empty (borg does not support transforming a non-empty dir to\n# the state as present in your backup archive).\nmkdir\nborg_restore\ncd\nborg_restore\n# now we find out the archive names we have in the repo:\nborg\nlist\n/mnt/backup/borg_repo\n# we could find out the archive contents, esp. the path layout:\nborg\nlist\n/mnt/backup/borg_repo::myserver-system-2019-08-11\n# we extract only some specific path (note: no leading / !):\nborg\nextract\n/mnt/backup/borg_repo::myserver-system-2019-08-11\npath/to/extract\n# alternatively, we could fully extract the archive:\nborg\nextract\n/mnt/backup/borg_repo::myserver-system-2019-08-11\n# now move the files to the correct place...\nDifference when using a\nremote borg backup server\n:\nIt is basically all the same as with the local repository, but you need to\nrefer to the repo using a\nssh://\nURL.\nIn the given example,\nborg\nis the user name used to log into the machine\nbackup.example.org\nwhich runs ssh on port\n2222\nand has the borg repo\nin\n/path/to/repo\n.\nInstead of giving a FQDN or a hostname, you can also give an IP address.\nAs usual, you either need a password to log in or the backup server might\nhave authentication set up via ssh\nauthorized_keys\n(which is likely the\ncase if unattended, automated backups were done).\nborg\nmount\nssh://borg@backup.example.org:2222/path/to/repo\n/mnt/borg\n# or\nborg\nextract\nssh://borg@backup.example.org:2222/path/to/repo\nInstallation\nUsage\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nQuick Start\n© Copyright 2010-2014 Jonas Borgström, 2015-2025 The Borg Collective (see AUTHORS file). Created using\nSphinx\n.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://borgbackup.readthedocs.io/en/stable/quickstart.html"}}
{"text": "General — Borg - Deduplicating Archiver 1.4.2.post3 documentation\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nGeneral\nBorg 1.4.2.post3\nInstallation\nQuick Start\nUsage\nGeneral\nPositional Arguments and Options: Order matters\nRepository URLs\nRepository / Archive Locations\nLogging\nReturn codes\nEnvironment Variables\nFile systems\nUnits\nDate and Time\nResource Usage\nSupport for file metadata\nCommon options\nExamples\nborg init\nborg create\nborg extract\nborg check\nborg rename\nborg list\nborg diff\nborg delete\nborg prune\nborg compact\nborg info\nborg version\nborg mount\nborg umount\nborg key change-passphrase\nborg key export\nborg key import\nborg upgrade\nborg recreate\nborg import-tar\nborg export-tar\nborg serve\nborg config\nborg with-lock\nborg break-lock\nborg benchmark crud\nMiscellaneous Help\nDebugging Facilities\nAdditional Notes\nDeployment\nFrequently asked questions\nSupport\nImportant notes\nUpgrade Notes\nChange Log\nInternals\nDevelopment\nAuthors\nLicense\nDocs\nUsage\nGeneral\nGeneral\n¶\nBorg consists of a number of commands. Each command accepts\na number of arguments and options and interprets various environment variables.\nThe following sections will describe each command in detail.\nCommands, options, parameters, paths and such are\nset\nin\nfixed-width\n.\nOption values are\nunderlined\n. Borg has few options accepting a fixed set\nof values (e.g.\n--encryption\nof\nborg init\n).\nExperimental features are marked with red stripes on the sides, like this paragraph.\nExperimental features are not stable, which means that they may be changed in incompatible\nways or even removed entirely without prior notice in following releases.\nPositional Arguments and Options: Order matters\n¶\nBorg only supports taking options (\n-s\nand\n--progress\nin the example)\nto the left or right of all positional arguments (\nrepo::archive\nand\npath\nin the example), but not in between them:\nborg\ncreate\n-\ns\n--\nprogress\nrepo\n::\narchive\npath\n# good and preferred\nborg\ncreate\nrepo\n::\narchive\npath\n-\ns\n--\nprogress\n# also works\nborg\ncreate\n-\ns\nrepo\n::\narchive\npath\n--\nprogress\n# works, but ugly\nborg\ncreate\nrepo\n::\narchive\n-\ns\n--\nprogress\npath\n# BAD\nThis is due to a problem in the argparse module:\nhttps://bugs.python.org/issue15112\nRepository URLs\n¶\nLocal filesystem\n(or locally mounted network filesystem):\n/path/to/repo\n- filesystem path to repo directory, absolute path\npath/to/repo\n- filesystem path to repo directory, relative path\nAlso, stuff like\n~/path/to/repo\nor\n~other/path/to/repo\nworks (this is\nexpanded by your shell).\nNote: you may also prepend a\nfile://\nto a filesystem path to get URL style.\nRemote repositories\naccessed via ssh\nuser\n@\nhost\n:\nssh://user@host:port/path/to/repo\n- remote repo, absolute path, port can be given\nuser@host:/path/to/repo\n- remote repo, absolute path, deprecated syntax\nRemote repositories with relative paths, URL style syntax with port\n:\nssh://user@host:port/./path/to/repo\n- path relative to current directory\nssh://user@host:port/~/path/to/repo\n- path relative to user’s home directory\nssh://user@host:port/~other/path/to/repo\n- path relative to other’s home directory (deprecated)\nRemote repositories with relative paths, deprecated SCP style syntax\n:\nuser@host:path/to/repo\n- path relative to current directory\nuser@host:~/path/to/repo\n- path relative to user’s home directory\nuser@host:~other/path/to/repo\n- path relative to other’s home directory\nNote: giving\nuser@host:/./path/to/repo\nor\nuser@host:/~/path/to/repo\nor\nuser@host:/~other/path/to/repo\nis also supported, but not required here.\nIf you frequently need the same repo URL, it is a good idea to set the\nBORG_REPO\nenvironment variable to set a default for the repo URL:\nexport\nBORG_REPO\n=\n'ssh://user@host:port/path/to/repo'\nThen just leave away the repo URL if only a repo URL is needed and you want\nto use the default - it will be read from BORG_REPO then.\nUse\n::\nsyntax to give the repo URL when syntax requires giving a positional\nargument for the repo (e.g.\nborg\nmount\n::\n/mnt\n).\nRepository / Archive Locations\n¶\nMany commands want either a repository (just give the repo URL, see above) or\nan archive location, which is a repo URL followed by\n::archive_name\n.\nArchive names must not contain the\n/\n(slash) character. For simplicity,\nmaybe also avoid blanks or other characters that have special meaning on the\nshell or in a filesystem (borg mount will use the archive name as directory\nname).\nIf you have set BORG_REPO (see above) and an archive location is needed, use\n::archive_name\n- the repo URL part is then read from BORG_REPO.\nLogging\n¶\nBorg writes all log output to stderr by default. But please note that something\nshowing up on stderr does\nnot\nindicate an error condition just because it is\non stderr. Please check the log levels of the messages and the return code of\nborg for determining error, warning or success conditions.\nIf you want to capture the log output to a file, just redirect it:\nborg\ncreate\nrepo\n::\narchive\nmyfiles\n2\n>>\nlogfile\nCustom logging configurations can be implemented via BORG_LOGGING_CONF.\nThe log level of the builtin logging configuration defaults to WARNING.\nThis is because we want Borg to be mostly silent and only output\nwarnings, errors and critical messages, unless output has been requested\nby supplying an option that implies output (e.g.\n--list\nor\n--progress\n).\nLog levels: DEBUG < INFO < WARNING < ERROR < CRITICAL\nUse\n--debug\nto set DEBUG log level -\nto get debug, info, warning, error and critical level output.\nUse\n--info\n(or\n-v\nor\n--verbose\n) to set INFO log level -\nto get info, warning, error and critical level output.\nUse\n--warning\n(default) to set WARNING log level -\nto get warning, error and critical level output.\nUse\n--error\nto set ERROR log level -\nto get error and critical level output.\nUse\n--critical\nto set CRITICAL log level -\nto get critical level output.\nWhile you can set misc. log levels, do not expect that every command will\ngive different output on different log levels - it’s just a possibility.\nWarning\nOptions\n--critical\nand\n--error\nare provided for completeness,\ntheir usage is not recommended as you might miss important information.\nReturn codes\n¶\nBorg can exit with the following return codes (rc):\nReturn code\nMeaning\n0\nsuccess (logged as INFO)\n1\ngeneric warning (operation reached its normal end, but there were warnings --\nyou should check the log, logged as WARNING)\n2\ngeneric error (like a fatal error, a local or remote exception, the operation\ndid not reach its normal end, logged as ERROR)\n3..99\nspecific error (enabled by BORG_EXIT_CODES=modern)\n100..127\nspecific warning (enabled by BORG_EXIT_CODES=modern)\n128+N\nkilled by signal N (e.g. 137 == kill -9)\nIf you use\n--show-rc\n, the return code is also logged at the indicated\nlevel as the last log entry.\nThe modern exit codes (return codes, “rc”) are documented there:\nMessage IDs\nEnvironment Variables\n¶\nBorg uses some environment variables for automation:\nGeneral:\nBORG_REPO\nWhen set, use the value to give the default repository location. If a command needs an archive\nparameter, you can abbreviate as\n::archive\n. If a command needs a repository parameter, you\ncan either leave it away or abbreviate as\n::\n, if a positional parameter is required.\nBORG_PASSPHRASE\nWhen set, use the value to answer the passphrase question for encrypted repositories.\nIt is used when a passphrase is needed to access an encrypted repo as well as when a new\npassphrase should be initially set when initializing an encrypted repo.\nSee also BORG_NEW_PASSPHRASE.\nBORG_PASSCOMMAND\nWhen set, use the standard output of the command (trailing newlines are stripped) to answer the\npassphrase question for encrypted repositories.\nIt is used when a passphrase is needed to access an encrypted repo as well as when a new\npassphrase should be initially set when initializing an encrypted repo. Note that the command\nis executed without a shell. So variables, like\n$HOME\nwill work, but\n~\nwon’t.\nIf BORG_PASSPHRASE is also set, it takes precedence.\nSee also BORG_NEW_PASSPHRASE.\nBORG_PASSPHRASE_FD\nWhen set, specifies a file descriptor to read a passphrase\nfrom. Programs starting borg may choose to open an anonymous pipe\nand use it to pass a passphrase. This is safer than passing via\nBORG_PASSPHRASE, because on some systems (e.g. Linux) environment\ncan be examined by other processes.\nIf BORG_PASSPHRASE or BORG_PASSCOMMAND are also set, they take precedence.\nBORG_NEW_PASSPHRASE\nWhen set, use the value to answer the passphrase question when a\nnew\npassphrase is asked for.\nThis variable is checked first. If it is not set, BORG_PASSPHRASE and BORG_PASSCOMMAND will also\nbe checked.\nMain usecase for this is to fully automate\nborg\nchange-passphrase\n.\nBORG_DISPLAY_PASSPHRASE\nWhen set, use the value to answer the “display the passphrase for verification” question when defining a new passphrase for encrypted repositories.\nBORG_EXIT_CODES\nWhen set to “modern”, the borg process will return more specific exit codes (rc).\nDefault is “legacy” and returns rc 2 for all errors, 1 for all warnings, 0 for success.\nBORG_HOST_ID\nBorg usually computes a host id from the FQDN plus the results of\nuuid.getnode()\n(which usually returns\na unique id based on the MAC address of the network interface. Except if that MAC happens to be all-zero - in\nthat case it returns a random value, which is not what we want (because it kills automatic stale lock removal).\nSo, if you have a all-zero MAC address or other reasons to better externally control the host id, just set this\nenvironment variable to a unique value. If all your FQDNs are unique, you can just use the FQDN. If not,\nuse\nfqdn\n@\nuniqueid\n.\nBORG_LOGGING_CONF\nWhen set, use the given filename as\nINI\n-style logging configuration.\nA basic example conf can be found at\ndocs/misc/logging.conf\n.\nBORG_RSH\nWhen set, use this command instead of\nssh\n. This can be used to specify ssh options, such as\na custom identity file\nssh\n-i\n/path/to/private/key\n. See\nman\nssh\nfor other options. Using\nthe\n--rsh\nCMD\ncommandline option overrides the environment variable.\nBORG_REMOTE_PATH\nWhen set, use the given path as borg executable on the remote (defaults to “borg” if unset).\nUsing\n--remote-path\nPATH\ncommandline option overrides the environment variable.\nBORG_FILES_CACHE_SUFFIX\nWhen set to a value at least one character long, instructs borg to use a specifically named\n(based on the suffix) alternative files cache. This can be used to avoid loading and saving\ncache entries for backup sources other than the current sources.\nBORG_FILES_CACHE_TTL\nWhen set to a numeric value, this determines the maximum “time to live” for the files cache\nentries (default: 20). The files cache is used to quickly determine whether a file is unchanged.\nThe FAQ explains this more detailed in:\nIt always chunks all my files, even unchanged ones!\nBORG_USE_CHUNKS_ARCHIVE\nWhen set to no (default: yes), the\nchunks.archive.d\nfolder will not be used. This reduces\ndisk space usage but slows down cache resyncs.\nBORG_SHOW_SYSINFO\nWhen set to no (default: yes), system information (like OS, Python version, …) in\nexceptions is not shown.\nPlease only use for good reasons as it makes issues harder to analyze.\nBORG_MSGPACK_VERSION_CHECK\nControls whether Borg checks the\nmsgpack\nversion.\nThe default is\nyes\n(strict check). Set to\nno\nto disable the version check and\nallow any installed\nmsgpack\nversion. Use this at your own risk; malfunctioning or\nincompatible\nmsgpack\nversions may cause subtle bugs or repository data corruption.\nBORG_FUSE_IMPL\nChoose the lowlevel FUSE implementation borg shall use for\nborg\nmount\n.\nThis is a comma-separated list of implementation names, they are tried in the\ngiven order, e.g.:\npyfuse3,llfuse\n: default, first try to load pyfuse3, then try to load llfuse.\nllfuse,pyfuse3\n: first try to load llfuse, then try to load pyfuse3.\npyfuse3\n: only try to load pyfuse3\nllfuse\n: only try to load llfuse\nnone\n: do not try to load an implementation\nBORG_SELFTEST\nThis can be used to influence borg’s builtin self-tests. The default is to execute the tests\nat the beginning of each borg command invocation.\nBORG_SELFTEST=disabled can be used to switch off the tests and rather save some time.\nDisabling is not recommended for normal borg users, but large scale borg storage providers can\nuse this to optimize production servers after at least doing a one-time test borg (with\nselftests not disabled) when installing or upgrading machines / OS / borg.\nBORG_WORKAROUNDS\nA list of comma separated strings that trigger workarounds in borg,\ne.g. to work around bugs in other software.\nCurrently known strings are:\nbasesyncfile\nUse the more simple BaseSyncFile code to avoid issues with sync_file_range.\nYou might need this to run borg on WSL (Windows Subsystem for Linux) or\nin systemd.nspawn containers on some architectures (e.g. ARM).\nUsing this does not affect data safety, but might result in a more bursty\nwrite to disk behaviour (not continuously streaming to disk).\nretry_erofs\nRetry opening a file without O_NOATIME if opening a file with O_NOATIME\ncaused EROFS. You will need this to make archives from volume shadow copies\nin WSL1 (Windows Subsystem for Linux 1).\nauthenticated_no_key\nWork around a lost passphrase or key for an\nauthenticated\nmode repository\n(these are only authenticated, but not encrypted).\nIf the key is missing in the repository config, add\nkey\n=\nanything\nthere.\nThis workaround is\nonly\nfor emergencies and\nonly\nto extract data\nfrom an affected repository (read-only access):\nBORG_WORKAROUNDS\n=\nauthenticated_no_key\nborg\nextract\nrepo\n::\narchive\nAfter you have extracted all data you need, you MUST delete the repository:\nBORG_WORKAROUNDS\n=\nauthenticated_no_key\nborg\ndelete\nrepo\nNow you can init a fresh repo. Make sure you do not use the workaround any more.\nignore_invalid_archive_tam\nWork around invalid archive TAMs created by borg < 1.2.5, see\n#7791\n.\nThis workaround likely needs to get used only once when following the upgrade\ninstructions for CVE-2023-36811, see\nPre-1.2.5 archives spoofing vulnerability (CVE-2023-36811)\n.\nIn normal production operations, this workaround should never be used.\nSome automatic “answerers” (if set, they automatically answer confirmation questions):\nBORG_UNKNOWN_UNENCRYPTED_REPO_ACCESS_IS_OK=no (or =yes)\nFor “Warning: Attempting to access a previously unknown unencrypted repository”\nBORG_RELOCATED_REPO_ACCESS_IS_OK=no (or =yes)\nFor “Warning: The repository at location … was previously located at …”\nBORG_CHECK_I_KNOW_WHAT_I_AM_DOING=NO (or =YES)\nFor “This is a potentially dangerous function…” (check --repair)\nBORG_DELETE_I_KNOW_WHAT_I_AM_DOING=NO (or =YES)\nFor “You requested to completely DELETE the repository\nincluding\nall archives it contains:”\nNote: answers are case sensitive. setting an invalid answer value might either give the default\nanswer or ask you interactively, depending on whether retries are allowed (they by default are\nallowed). So please test your scripts interactively before making them a non-interactive script.\nDirectories and files:\nBORG_BASE_DIR\nDefaults to\n$HOME\nor\n~$USER\nor\n~\n(in that order).\nIf you want to move all borg-specific folders to a custom path at once, all you need to do is\nto modify\nBORG_BASE_DIR\n: the other paths for cache, config etc. will adapt accordingly\n(assuming you didn’t set them to a different custom value).\nBORG_CACHE_DIR\nDefaults to\n$BORG_BASE_DIR/.cache/borg\n. If\nBORG_BASE_DIR\nis not explicitly set while\nXDG env var\nXDG_CACHE_HOME\nis set, then\n$XDG_CACHE_HOME/borg\nis being used instead.\nThis directory contains the local cache and might need a lot\nof space for dealing with big repositories. Make sure you’re aware of the associated\nsecurity aspects of the cache location:\nDo I need to take security precautions regarding the cache?\nBORG_CONFIG_DIR\nDefaults to\n$BORG_BASE_DIR/.config/borg\n. If\nBORG_BASE_DIR\nis not explicitly set while\nXDG env var\nXDG_CONFIG_HOME\nis set, then\n$XDG_CONFIG_HOME/borg\nis being used instead.\nThis directory contains all borg configuration directories, see the FAQ\nfor a security advisory about the data in this directory:\nHow important is the $HOME/.config/borg directory?\nBORG_SECURITY_DIR\nDefaults to\n$BORG_CONFIG_DIR/security\n.\nThis directory contains information borg uses to track its usage of NONCES (“numbers used\nonce” - usually in encryption context) and other security relevant data.\nBORG_KEYS_DIR\nDefaults to\n$BORG_CONFIG_DIR/keys\n.\nThis directory contains keys for encrypted repositories.\nBORG_KEY_FILE\nWhen set, use the given path as repository key file. Please note that this is only\nfor rather special applications that externally fully manage the key files:\nthis setting only applies to the keyfile modes (not to the repokey modes).\nusing a full, absolute path to the key file is recommended.\nall directories in the given path must exist.\nthis setting forces borg to use the key file at the given location.\nthe key file must either exist (for most commands) or will be created (\nborg\ninit\n).\nyou need to give a different path for different repositories.\nyou need to point to the correct key file matching the repository the command will operate on.\nTMPDIR\nThis is where temporary files are stored (might need a lot of temporary space for some\noperations), see\ntempfile\nfor details.\nBuilding:\nBORG_OPENSSL_PREFIX\nAdds given OpenSSL header file directory to the default locations (setup.py).\nBORG_LIBLZ4_PREFIX\nAdds given prefix directory to the default locations. If a ‘include/lz4.h’ is found Borg\nwill be linked against the system liblz4 instead of a bundled implementation. (setup.py)\nBORG_LIBZSTD_PREFIX\nAdds given prefix directory to the default locations. If a ‘include/zstd.h’ is found Borg\nwill be linked against the system libzstd instead of a bundled implementation. (setup.py)\nPlease note:\nBe very careful when using the “yes” sayers, the warnings with prompt exist for your / your data’s security/safety.\nAlso be very careful when putting your passphrase into a script, make sure it has appropriate file permissions (e.g.\nmode 600, root:root).\nFile systems\n¶\nWe strongly recommend against using Borg (or any other database-like\nsoftware) on non-journaling file systems like FAT, since it is not\npossible to assume any consistency in case of power failures (or a\nsudden disconnect of an external drive or similar failures).\nWhile Borg uses a data store that is resilient against these failures\nwhen used on journaling file systems, it is not possible to guarantee\nthis with some hardware -- independent of the software used. We don’t\nknow a list of affected hardware.\nIf you are suspicious whether your Borg repository is still consistent\nand readable after one of the failures mentioned above occurred, run\nborg\ncheck\n--verify-data\nto make sure it is consistent.\nRequirements for Borg repository file systems\nLong file names\nAt least three directory levels with short names\nTypically, file sizes up to a few hundred MB.\nLarge repositories may require large files (>2 GB).\nUp to 1000 files per directory.\nrename(2) / MoveFile(Ex) should work as specified, i.e. on the same file system\nit should be a move (not a copy) operation, and in case of a directory\nit should fail if the destination exists and is not an empty directory,\nsince this is used for locking.\nHardlinks are needed for\nborg upgrade\n(if\n--inplace\noption is not used).\nAlso hardlinks are used for more safe and secure file updating (e.g. of the repo\nconfig file), but the code tries to work also if hardlinks are not supported.\nUnits\n¶\nTo display quantities, Borg takes care of respecting the\nusual conventions of scale. Disk sizes are displayed in\ndecimal\n, using powers of ten (so\nkB\nmeans 1000 bytes). For memory usage,\nbinary prefixes\nare used, and are\nindicated using the\nIEC binary prefixes\n,\nusing powers of two (so\nKiB\nmeans 1024 bytes).\nDate and Time\n¶\nWe format date and time conforming to ISO-8601, that is: YYYY-MM-DD and\nHH:MM:SS (24h clock).\nFor more information about that, see:\nhttps://xkcd.com/1179/\nUnless otherwise noted, we display local date and time.\nInternally, we store and process date and time as UTC.\nResource Usage\n¶\nBorg might use a lot of resources depending on the size of the data set it is dealing with.\nIf one uses Borg in a client/server way (with a ssh: repository),\nthe resource usage occurs in part on the client and in another part on the\nserver.\nIf one uses Borg as a single process (with a filesystem repo),\nall the resource usage occurs in that one process, so just add up client +\nserver to get the approximate resource usage.\nCPU client:\nborg create:\ndoes chunking, hashing, compression, crypto (high CPU usage)\nchunks cache sync:\nquite heavy on CPU, doing lots of hashtable operations.\nborg extract:\ncrypto, decompression (medium to high CPU usage)\nborg check:\nsimilar to extract, but depends on options given.\nborg prune / borg delete archive:\nlow to medium CPU usage\nborg delete repo:\ndone on the server\nIt won’t go beyond 100% of 1 core as the code is currently single-threaded.\nEspecially higher zlib and lzma compression levels use significant amounts\nof CPU cycles. Crypto might be cheap on the CPU (if hardware accelerated) or\nexpensive (if not).\nCPU server:\nIt usually doesn’t need much CPU, it just deals with the key/value store\n(repository) and uses the repository index for that.\nborg check: the repository check computes the checksums of all chunks\n(medium CPU usage)\nborg delete repo: low CPU usage\nCPU (only for client/server operation):\nWhen using borg in a client/server way with a\nssh:-type\nrepo, the ssh\nprocesses used for the transport layer will need some CPU on the client and\non the server due to the crypto they are doing - esp. if you are pumping\nbig amounts of data.\nMemory (RAM) client:\nThe chunks index and the files index are read into memory for performance\nreasons. Might need big amounts of memory (see below).\nCompression, esp. lzma compression with high levels might need substantial\namounts of memory.\nMemory (RAM) server:\nThe server process will load the repository index into memory. Might need\nconsiderable amounts of memory, but less than on the client (see below).\nChunks index (client only):\nProportional to the amount of data chunks in your repo. Lots of chunks\nin your repo imply a big chunks index.\nIt is possible to tweak the chunker params (see create options).\nFiles index (client only):\nProportional to the amount of files in your last backups. Can be switched\noff (see create options), but next backup might be much slower if you do.\nThe speed benefit of using the files cache is proportional to file size.\nRepository index (server only):\nProportional to the amount of data chunks in your repo. Lots of chunks\nin your repo imply a big repository index.\nIt is possible to tweak the chunker params (see create options) to\ninfluence the amount of chunks being created.\nTemporary files (client):\nReading data and metadata from a FUSE mounted repository will consume up to\nthe size of all deduplicated, small chunks in the repository. Big chunks\nwon’t be locally cached.\nTemporary files (server):\nA non-trivial amount of data will be stored on the remote temp directory\nfor each client that connects to it. For some remotes, this can fill the\ndefault temporary directory at /tmp. This can be remediated by ensuring the\n$TMPDIR, $TEMP, or $TMP environment variable is properly set for the sshd\nprocess.\nFor some OSes, this can be done just by setting the correct value in the\n.bashrc (or equivalent login config file for other shells), however in\nother cases it may be necessary to first enable\nPermitUserEnvironment\nyes\nin your\nsshd_config\nfile, then add\nenvironment=\"TMPDIR=/my/big/tmpdir\"\nat the start of the public key to be used in the\nauthorized_hosts\nfile.\nCache files (client only):\nContains the chunks index and files index (plus a collection of single-\narchive chunk indexes which might need huge amounts of disk space,\ndepending on archive count and size - see FAQ about how to reduce).\nNetwork (only for client/server operation):\nIf your repository is remote, all deduplicated (and optionally compressed/\nencrypted) data of course has to go over the connection (\nssh://\nrepo url).\nIf you use a locally mounted network filesystem, additionally some copy\noperations used for transaction support also go over the connection. If\nyou backup multiple sources to one target repository, additional traffic\nhappens for cache resynchronization.\nSupport for file metadata\n¶\nBesides regular file and directory structures, Borg can preserve\nsymlinks (stored as symlink, the symlink is not followed)\nspecial files:\ncharacter and block device files (restored via mknod)\nFIFOs (“named pipes”)\nspecial file\ncontents\ncan be backed up in\n--read-special\nmode.\nBy default the metadata to create them with mknod(2), mkfifo(2) etc. is stored.\nhardlinked regular files, devices, FIFOs (considering all items in the same archive)\ntimestamps in nanosecond precision: mtime, atime, ctime\nother timestamps: birthtime (on platforms supporting it)\npermissions:\nIDs of owning user and owning group\nnames of owning user and owning group (if the IDs can be resolved)\nUnix Mode/Permissions (u/g/o permissions, suid, sgid, sticky)\nOn some platforms additional features are supported:\nPlatform\nACLs\n[\n5\n]\nxattr\n[\n6\n]\nFlags\n[\n7\n]\nLinux\nYes\nYes\nYes\n[\n1\n]\nmacOS\nYes\nYes\nYes (all)\nFreeBSD\nYes\nYes\nYes (all)\nOpenBSD\nn/a\nn/a\nYes (all)\nNetBSD\nn/a\nNo\n[\n2\n]\nYes (all)\nSolaris and derivatives\nNo\n[\n3\n]\nNo\n[\n3\n]\nn/a\nWindows (cygwin)\nNo\n[\n4\n]\nNo\nNo\nOther Unix-like operating systems may work as well, but have not been tested at all.\nNote that most of the platform-dependent features also depend on the file system.\nFor example, ntfs-3g on Linux isn’t able to convey NTFS ACLs.\n[\n1\n]\n(\n1\n,\n2\n)\nOnly “nodump”, “immutable”, “compressed” and “append” are supported.\nFeature request\n#618\nfor more flags.\n[\n2\n]\nFeature request\n#1332\n[\n3\n]\n(\n1\n,\n2\n)\nFeature request\n#1337\n[\n4\n]\nCygwin tries to map NTFS ACLs to permissions with varying degrees of success.\n[\n5\n]\nThe native access control list mechanism of the OS. This normally limits access to\nnon-native ACLs. For example, NTFS ACLs aren’t completely accessible on Linux with ntfs-3g.\n[\n6\n]\nextended attributes; key-value pairs attached to a file, mainly used by the OS.\nThis includes resource forks on Mac OS X.\n[\n7\n]\naka\nBSD flags\n. The Linux set of flags\n[\n1\n]\nis portable across platforms.\nThe BSDs define additional flags.\nIn case you are interested in more details (like formulas), please see\nInternals\n. For details on the available JSON output, refer to\nAll about JSON: How to develop frontends\n.\nCommon options\n¶\nAll Borg commands share these options:\n-h\n,\n--help\nshow this help message and exit\n--critical\nwork on log level CRITICAL\n--error\nwork on log level ERROR\n--warning\nwork on log level WARNING (default)\n--info\n,\n-v\n,\n--verbose\nwork on log level INFO\n--debug\nenable debug output, work on log level DEBUG\n--debug-topic\nTOPIC\nenable TOPIC debugging (can be specified multiple times). The logger path is borg.debug.<TOPIC> if TOPIC is not fully qualified.\n-p\n,\n--progress\nshow progress information\n--iec\nformat using IEC units (1KiB = 1024B)\n--log-json\nOutput one JSON object per log line instead of formatted text.\n--lock-wait\nSECONDS\nwait at most SECONDS for acquiring a repository/cache lock (default: 1).\n--bypass-lock\nBypass locking mechanism\n--show-version\nshow/log the borg version\n--show-rc\nshow/log the return code (rc)\n--umask\nM\nset umask to M (local only, default: 0077)\n--remote-path\nPATH\nuse PATH as borg executable on the remote (default: “borg”)\n--remote-ratelimit\nRATE\ndeprecated, use\n--upload-ratelimit\ninstead\n--upload-ratelimit\nRATE\nset network upload rate limit in kiByte/s (default: 0=unlimited)\n--remote-buffer\nUPLOAD_BUFFER\ndeprecated, use\n--upload-buffer\ninstead\n--upload-buffer\nUPLOAD_BUFFER\nset network upload buffer size in MiB. (default: 0=no buffer)\n--consider-part-files\ntreat part files like normal files (e.g. to list/extract them)\n--debug-profile\nFILE\nWrite execution profile in Borg format into FILE. For local use a Python-compatible file can be generated by suffixing FILE with “.pyprof”.\n--rsh\nRSH\nUse this command to connect to the ‘borg serve’ process (default: ‘ssh’)\nOption\n--bypass-lock\nallows you to access the repository while bypassing\nBorg’s locking mechanism. This is necessary if your repository is on a read-only\nstorage where you don’t have write permissions or capabilities and therefore\ncannot create a lock. Examples are repositories stored on a Blu-ray disc or a\nread-only network storage. Avoid this option if you are able to use locks, as\nthat is the safer way; see the warning below.\nWarning\nIf you do use\n--bypass-lock\n, you are responsible for ensuring that no other\nBorg instances have write access to the repository. Otherwise, you might\nexperience errors and read broken data if changes to that repository are\nbeing made at the same time.\nExamples\n¶\n# Create an archive and log: borg version, files list, return code\n$ borg create --show-version --list --show-rc /path/to/repo::my-files files\nUsage\nborg init\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nGeneral\n© Copyright 2010-2014 Jonas Borgström, 2015-2025 The Borg Collective (see AUTHORS file). Created using\nSphinx\n.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://borgbackup.readthedocs.io/en/stable/usage/general.html"}}
{"text": "borg create — Borg - Deduplicating Archiver 1.4.2.post3 documentation\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nborg create\nBorg 1.4.2.post3\nInstallation\nQuick Start\nUsage\nGeneral\nborg init\nborg create\nborg extract\nborg check\nborg rename\nborg list\nborg diff\nborg delete\nborg prune\nborg compact\nborg info\nborg version\nborg mount\nborg umount\nborg key change-passphrase\nborg key export\nborg key import\nborg upgrade\nborg recreate\nborg import-tar\nborg export-tar\nborg serve\nborg config\nborg with-lock\nborg break-lock\nborg benchmark crud\nMiscellaneous Help\nDebugging Facilities\nAdditional Notes\nDeployment\nFrequently asked questions\nSupport\nImportant notes\nUpgrade Notes\nChange Log\nInternals\nDevelopment\nAuthors\nLicense\nDocs\nUsage\nborg create\nborg create\n¶\nborg [common options] create [options] ARCHIVE [PATH...]\npositional arguments\nARCHIVE\nname of archive to create (must be also a valid directory name)\nPATH\npaths to archive\noptions\n-n\n,\n--dry-run\ndo not create a backup archive\n-s\n,\n--stats\nprint statistics for the created archive\n--list\noutput verbose list of items (files, dirs, …)\n--filter\nSTATUSCHARS\nonly display items with the given status characters (see description)\n--json\noutput stats as JSON. Implies\n--stats\n.\n--no-cache-sync\nexperimental: do not synchronize the cache. Implies not using the files cache.\n--stdin-name\nNAME\nuse NAME in archive for stdin data (default: ‘stdin’)\n--stdin-user\nUSER\nset user USER in archive for stdin data (default: ‘root’)\n--stdin-group\nGROUP\nset group GROUP in archive for stdin data (default: ‘wheel’)\n--stdin-mode\nM\nset mode to M in archive for stdin data (default: 0660)\n--content-from-command\ninterpret PATH as command and store its stdout. See also section Reading from stdin below.\n--paths-from-stdin\nread DELIM-separated list of paths to backup from stdin. All control is external: it will back up all files given - no more, no less.\n--paths-from-command\ninterpret PATH as command and treat its output as\n--paths-from-stdin\n--paths-delimiter\nDELIM\nset path delimiter for\n--paths-from-stdin\nand\n--paths-from-command\n(default:\n\\n\n)\nCommon options\nInclude/Exclude options\n-e\nPATTERN\n,\n--exclude\nPATTERN\nexclude paths matching PATTERN\n--exclude-from\nEXCLUDEFILE\nread exclude patterns from EXCLUDEFILE, one per line\n--pattern\nPATTERN\ninclude/exclude paths matching PATTERN\n--patterns-from\nPATTERNFILE\nread include/exclude patterns from PATTERNFILE, one per line\n--exclude-caches\nexclude directories that contain a CACHEDIR.TAG file (\nhttp://www.bford.info/cachedir/spec.html\n)\n--exclude-if-present\nNAME\nexclude directories that are tagged by containing a filesystem object with the given NAME\n--keep-exclude-tags\nif tag objects are specified with\n--exclude-if-present\n, don’t omit the tag objects themselves from the backup archive\n--exclude-nodump\nexclude files flagged NODUMP\nFilesystem options\n-x\n,\n--one-file-system\nstay in the same file system and do not store mount points of other file systems - this might behave different from your expectations, see the description below.\n--numeric-owner\ndeprecated, use\n--numeric-ids\ninstead\n--numeric-ids\nonly store numeric user and group identifiers\n--noatime\ndo not store atime into archive\n--atime\ndo store atime into archive\n--noctime\ndo not store ctime into archive\n--nobirthtime\ndo not store birthtime (creation date) into archive\n--nobsdflags\ndeprecated, use\n--noflags\ninstead\n--noflags\ndo not read and store flags (e.g. NODUMP, IMMUTABLE) into archive\n--noacls\ndo not read and store ACLs into archive\n--noxattrs\ndo not read and store xattrs into archive\n--sparse\ndetect sparse holes in input (supported only by fixed chunker)\n--files-cache\nMODE\noperate files cache in MODE. default: ctime,size,inode\n--files-changed\nMODE\nspecify how to detect if a file has changed during backup (ctime, mtime, disabled). default: ctime\n--read-special\nopen and read block and char device files as well as FIFOs as if they were regular files. Also follows symlinks pointing to these kinds of files.\nArchive options\n--comment\nCOMMENT\nadd a comment text to the archive\n--timestamp\nTIMESTAMP\nmanually specify the archive creation date/time (UTC, yyyy-mm-ddThh:mm:ss format). Alternatively, give a reference file/directory.\n-c\nSECONDS\n,\n--checkpoint-interval\nSECONDS\nwrite checkpoint every SECONDS seconds (Default: 1800)\n--chunker-params\nPARAMS\nspecify the chunker parameters (ALGO, CHUNK_MIN_EXP, CHUNK_MAX_EXP, HASH_MASK_BITS, HASH_WINDOW_SIZE). default: buzhash,19,23,21,4095\n-C\nCOMPRESSION\n,\n--compression\nCOMPRESSION\nselect compression algorithm, see the output of the “borg help compression” command for details.\nDescription\n¶\nThis command creates a backup archive containing all files found while recursively\ntraversing all paths specified. Paths are added to the archive as they are given,\nwhich means that if relative paths are desired, the command has to be run from the correct\ndirectory.\nThe slashdot hack in paths (recursion roots) is triggered by using\n/./\n:\n/this/gets/stripped/./this/gets/archived\nmeans to process that filesystem object, but\nstrip the prefix on the left side of\n./\nfrom the archived items (in this case,\nthis/gets/archived\nwill be the path in the archived item).\nWhen giving ‘-’ as a path, Borg will read data from standard input and create a\nfile ‘stdin’ in the created archive from that data. In some cases, it is more\nappropriate to use\n--content-from-command\n. See section “Reading from stdin”\nbelow for details.\nThe archive will consume almost no disk space for files or parts of files that\nhave already been stored in other archives.\nThe archive name needs to be unique. It must not end in ‘.checkpoint’ or\n‘.checkpoint.N’ (with N being a number), because these names are used for\ncheckpoints and treated in special ways.\nIn the archive name, you may use the following placeholders:\n{now}, {utcnow}, {fqdn}, {hostname}, {user} and some others.\nBackup speed is increased by not reprocessing files that are already part of\nexisting archives and weren’t modified. The detection of unmodified files is\ndone by comparing multiple file metadata values with previous values kept in\nthe files cache.\nThis comparison can operate in different modes as given by\n--files-cache\n:\nctime,size,inode (default)\nmtime,size,inode (default behavior of borg versions older than 1.1.0rc4)\nctime,size (ignore the inode number)\nmtime,size (ignore the inode number)\nrechunk,ctime (all files are considered modified - rechunk, cache ctime)\nrechunk,mtime (all files are considered modified - rechunk, cache mtime)\ndisabled (disable the files cache, all files considered modified - rechunk)\ninode number: better safety, but often unstable on network file systems\nNormally, detecting file modifications will take inode information into\nconsideration to improve the reliability of file change detection.\nThis is problematic for files located on SSHFS and similar network file\nsystems which do not provide stable inode numbers; such files will always\nbe considered modified. You can use modes without\ninode\nin this case to\nimprove performance, but the reliability of change detection might be reduced.\nctime vs. mtime: safety vs. speed\nctime is a rather safe way to detect changes to a file (metadata and contents)\nas it cannot be set from user space. However, a metadata-only change will already\nupdate the ctime, so there might be some unnecessary chunking/hashing even\nwithout content changes. Some file systems do not support ctime (change time).\nFor example, doing a chown or chmod to a file will change its ctime.\nmtime usually works and only updates if file contents were changed. But mtime\ncan be arbitrarily set from user space, e.g., to set mtime back to the same value\nit had before a content change happened. This can be used maliciously as well as\nwell-meant, but in both cases mtime-based cache modes can be problematic.\nThe\n--files-changed\noption controls how Borg detects if a file has changed during backup:\nctime (default): Use ctime to detect changes. This is the safest option.\nmtime: Use mtime to detect changes.\ndisabled: Disable the “file has changed while we backed it up” detection completely.\nThis is not recommended unless you know what you’re doing, as it could lead to\ninconsistent backups if files change during the backup process.\nThe mount points of file systems or file system snapshots should be the same for every\ncreation of a new archive to ensure fast operation. This is because the file cache that\nis used to determine changed files quickly uses absolute file names.\nIf this is not possible, consider creating a bind mount to a stable location.\nThe\n--progress\noption shows (from left to right) Original, Compressed and Deduplicated\n(O, C and D, respectively), then the number of files (N) processed so far, followed by\nthe currently processed path.\nWhen using\n--stats\n, you will get some statistics about how much data was\nadded - the “This Archive” deduplicated size there is most interesting as that is\nhow much your repository will grow. Please note that the “All archives” stats refer to\nthe state after creation. Also, the\n--stats\nand\n--dry-run\noptions are mutually\nexclusive because the data is not actually compressed and deduplicated during a dry run.\nFor more help on include/exclude patterns, see the\nborg help patterns\ncommand output.\nFor more help on placeholders, see the\nborg help placeholders\ncommand output.\nThe\n--exclude\npatterns are not like tar. In tar\n--exclude\n.bundler/gems will\nexclude foo/.bundler/gems. In borg it will not, you need to use\n--exclude\n‘*/.bundler/gems’ to get the same effect.\nIn addition to using\n--exclude\npatterns, it is possible to use\n--exclude-if-present\nto specify the name of a filesystem object (e.g. a file\nor folder name) which, when contained within another folder, will prevent the\ncontaining folder from being backed up.  By default, the containing folder and\nall of its contents will be omitted from the backup.  If, however, you wish to\nonly include the objects specified by\n--exclude-if-present\nin your backup,\nand not include any other contents of the containing folder, this can be enabled\nthrough using the\n--keep-exclude-tags\noption.\nThe\n-x\nor\n--one-file-system\noption excludes directories that are mount points (and everything in them).\nIt detects mount points by comparing the device number from the output of\nstat()\nof the directory and its\nparent directory. Specifically, it excludes directories for which\nstat()\nreports a device number different\nfrom the device number of their parent.\nIn general: be aware that there are directories with device numbers different from their parent, which the kernel\ndoes not consider mount points, and vice versa.\nLinux examples for this are bind mounts (possibly same device number, but always a mount point) and all\nsubvolumes of a Btrfs file system (different device numbers from the parent but not necessarily mount points).\nmacOS examples are the APFS mounts of a typical macOS installation.\nTherefore, when using\n--one-file-system\n, you should double-check that the backup works as intended.\nItem flags\n¶\n--list\noutputs a list of all files, directories and other\nfile system items it considered (no matter whether they had content changes\nor not). For each item, it prefixes a single-letter flag that indicates type\nand/or status of the item.\nIf you are interested only in a subset of that output, you can give e.g.\n--filter=AME\nand it will only show regular files with A, M or E status (see\nbelow).\nA uppercase character represents the status of a regular file relative to the\n“files” cache (not relative to the repo -- this is an issue if the files cache\nis not used). Metadata is stored in any case and for ‘A’ and ‘M’ also new data\nchunks are stored. For ‘U’ all data chunks refer to already existing chunks.\n‘A’ = regular file, added (see also\nI am seeing ‘A’ (added) status for an unchanged file!?\nin the FAQ)\n‘M’ = regular file, modified\n‘U’ = regular file, unchanged\n‘C’ = regular file, it changed while we backed it up\n‘E’ = regular file, an error happened while accessing/reading\nthis\nfile\nA lowercase character means a file type other than a regular file,\nborg usually just stores their metadata:\n‘d’ = directory\n‘b’ = block device\n‘c’ = char device\n‘h’ = regular file, hardlink (to already seen inodes)\n‘s’ = symlink\n‘f’ = fifo\nOther flags used include:\n‘i’ = backup data was read from standard input (stdin)\n‘-’ = dry run, item was\nnot\nbacked up\n‘x’ = excluded, item was\nnot\nbacked up\n‘?’ = missing status code (if you see this, please file a bug report!)\nReading backup data from stdin\n¶\nThere are two methods to read from stdin. Either specify\n-\nas path and\npipe directly to borg:\nbackup\n-\nvm\n--\nid\nmyvm\n--\nstdout\n|\nborg\ncreate\nREPO\n::\nARCHIVE\n-\nOr use\n--content-from-command\nto have Borg manage the execution of the\ncommand and piping. If you do so, the first PATH argument is interpreted\nas command to execute and any further arguments are treated as arguments\nto the command:\nborg\ncreate\n--\ncontent\n-\nfrom\n-\ncommand\nREPO\n::\nARCHIVE\n--\nbackup\n-\nvm\n--\nid\nmyvm\n--\nstdout\n--\nis used to ensure\n--id\nand\n--stdout\nare\nnot\nconsidered\narguments to\nborg\nbut rather\nbackup-vm\n.\nThe difference between the two approaches is that piping to borg creates an\narchive even if the command piping to borg exits with a failure. In this case,\none can end up with truncated output being backed up\n. Using\n--content-from-command\n, in contrast, borg is guaranteed to fail without\ncreating an archive should the command fail. The command is considered failed\nwhen it returned a non-zero exit code.\nReading from stdin yields just a stream of data without file metadata\nassociated with it, and the files cache is not needed at all. So it is\nsafe to disable it via\n--files-cache\ndisabled\nand speed up backup\ncreation a bit.\nBy default, the content read from stdin is stored in a file called ‘stdin’.\nUse\n--stdin-name\nto change the name.\nFeeding all file paths from externally\n¶\nUsually, you give a starting path (recursion root) to borg and then borg\nautomatically recurses, finds and backs up all fs objects contained in\nthere (optionally considering include/exclude rules).\nIf you need more control and you want to give every single fs object path\nto borg (maybe implementing your own recursion or your own rules), you can use\n--paths-from-stdin\nor\n--paths-from-command\n(with the latter, borg will\nfail to create an archive should the command fail).\nBorg supports paths with the slashdot hack to strip path prefixes here also.\nSo, be careful not to unintentionally trigger that.\nExamples\n¶\n# Backup ~/Documents into an archive named \"my-documents\"\n$ borg create /path/to/repo::my-documents ~/Documents\n# same, but list all files as we process them\n$ borg create --list /path/to/repo::my-documents ~/Documents\n# Backup /mnt/disk/docs, but strip path prefix using the slashdot hack\n$ borg create /path/to/repo::docs /mnt/disk/./docs\n# Backup ~/Documents and ~/src but exclude pyc files\n$ borg create /path/to/repo::my-files \\\n~/Documents                       \\\n~/src                             \\\n--exclude '*.pyc'\n# Backup home directories excluding image thumbnails (i.e. only\n# /home/<one directory>/.thumbnails is excluded, not /home/*/*/.thumbnails etc.)\n$ borg create /path/to/repo::my-files /home \\\n--exclude 'sh:home/*/.thumbnails'\n# Backup the root filesystem into an archive named \"root-YYYY-MM-DD\"\n# use zlib compression (good, but slow) - default is lz4 (fast, low compression ratio)\n$ borg create -C zlib,6 --one-file-system /path/to/repo::root-{now:%Y-%m-%d} /\n# Backup onto a remote host (\"push\" style) via ssh to port 2222,\n# logging in as user \"borg\" and storing into /path/to/repo\n$ borg create ssh://borg@backup.example.org:2222/path/to/repo::{fqdn}-root-{now} /\n# Backup a remote host locally (\"pull\" style) using sshfs\n$ mkdir sshfs-mount\n$ sshfs root@example.com:/ sshfs-mount\n$ cd sshfs-mount\n$ borg create /path/to/repo::example.com-root-{now:%Y-%m-%d} .\n$ cd ..\n$ fusermount -u sshfs-mount\n# Make a big effort in fine granular deduplication (big chunk management\n# overhead, needs a lot of RAM and disk space, see formula in internals\n# docs - same parameters as borg < 1.0 or attic):\n$ borg create --chunker-params buzhash,10,23,16,4095 /path/to/repo::small /smallstuff\n# Backup a raw device (must not be active/in use/mounted at that time)\n$ borg create --read-special --chunker-params fixed,4194304 /path/to/repo::my-sdx /dev/sdX\n# Backup a sparse disk image (must not be active/in use/mounted at that time)\n$ borg create --sparse --chunker-params fixed,4194304 /path/to/repo::my-disk my-disk.raw\n# No compression (none)\n$ borg create --compression none /path/to/repo::arch ~\n# Super fast, low compression (lz4, default)\n$ borg create /path/to/repo::arch ~\n# Less fast, higher compression (zlib, N = 0..9)\n$ borg create --compression zlib,N /path/to/repo::arch ~\n# Even slower, even higher compression (lzma, N = 0..9)\n$ borg create --compression lzma,N /path/to/repo::arch ~\n# Only compress compressible data with lzma,N (N = 0..9)\n$ borg create --compression auto,lzma,N /path/to/repo::arch ~\n# Use short hostname, user name and current time in archive name\n$ borg create /path/to/repo::{hostname}-{user}-{now} ~\n# Similar, use the same datetime format that is default as of borg 1.1\n$ borg create /path/to/repo::{hostname}-{user}-{now:%Y-%m-%dT%H:%M:%S} ~\n# As above, but add nanoseconds\n$ borg create /path/to/repo::{hostname}-{user}-{now:%Y-%m-%dT%H:%M:%S.%f} ~\n# Backing up relative paths by moving into the correct directory first\n$ cd /home/user/Documents\n# The root directory of the archive will be \"projectA\"\n$ borg create /path/to/repo::daily-projectA-{now:%Y-%m-%d} projectA\n# Use external command to determine files to archive\n# Use --paths-from-stdin with find to only backup files less than 1MB in size\n$ find ~ -size -1000k | borg create --paths-from-stdin /path/to/repo::small-files-only\n# Use --paths-from-command with find to only backup files from a given user\n$ borg create --paths-from-command /path/to/repo::joes-files -- find /srv/samba/shared -user joe\n# Use --paths-from-stdin with --paths-delimiter (for example, for filenames with newlines in them)\n$ find ~ -size -1000k -print0 | borg create \\\n--paths-from-stdin \\\n--paths-delimiter \"\\0\" \\\n/path/to/repo::smallfiles-handle-newline\nborg init\nborg extract\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nborg create\n© Copyright 2010-2014 Jonas Borgström, 2015-2025 The Borg Collective (see AUTHORS file). Created using\nSphinx\n.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://borgbackup.readthedocs.io/en/stable/usage/create.html"}}
{"text": "borg prune — Borg - Deduplicating Archiver 1.4.2.post3 documentation\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nborg prune\nBorg 1.4.2.post3\nInstallation\nQuick Start\nUsage\nGeneral\nborg init\nborg create\nborg extract\nborg check\nborg rename\nborg list\nborg diff\nborg delete\nborg prune\nborg compact\nborg info\nborg version\nborg mount\nborg umount\nborg key change-passphrase\nborg key export\nborg key import\nborg upgrade\nborg recreate\nborg import-tar\nborg export-tar\nborg serve\nborg config\nborg with-lock\nborg break-lock\nborg benchmark crud\nMiscellaneous Help\nDebugging Facilities\nAdditional Notes\nDeployment\nFrequently asked questions\nSupport\nImportant notes\nUpgrade Notes\nChange Log\nInternals\nDevelopment\nAuthors\nLicense\nDocs\nUsage\nborg prune\nborg prune\n¶\nborg [common options] prune [options] [REPOSITORY]\npositional arguments\nREPOSITORY\nrepository to prune\noptions\n-n\n,\n--dry-run\ndo not change repository\n--force\nforce pruning of corrupted archives, use\n--force\n--force\nin case\n--force\ndoes not work.\n-s\n,\n--stats\nprint statistics for the deleted archive\n--list\noutput verbose list of archives it keeps/prunes\n--keep-within\nINTERVAL\nkeep all archives within this time interval\n--keep-last\n,\n--keep-secondly\nnumber of secondly archives to keep\n--keep-minutely\nnumber of minutely archives to keep\n-H\n,\n--keep-hourly\nnumber of hourly archives to keep\n-d\n,\n--keep-daily\nnumber of daily archives to keep\n-w\n,\n--keep-weekly\nnumber of weekly archives to keep\n-m\n,\n--keep-monthly\nnumber of monthly archives to keep\n--keep-13weekly\nnumber of quarterly archives to keep (13 week strategy)\n--keep-3monthly\nnumber of quarterly archives to keep (3 month strategy)\n-y\n,\n--keep-yearly\nnumber of yearly archives to keep\n--save-space\nwork slower, but using less space\n-c\nSECONDS\n,\n--checkpoint-interval\nSECONDS\nwrite checkpoint every SECONDS seconds (Default: 1800)\nCommon options\nArchive filters\n— Archive filters can be applied to repository targets.\n-P\nPREFIX\n,\n--prefix\nPREFIX\nonly consider archive names starting with this prefix. (deprecated)\n-a\nGLOB\n,\n--glob-archives\nGLOB\nonly consider archive names matching the glob. sh: rules apply (without actually using the sh: prefix), see “borg help patterns”.\nDescription\n¶\nThe prune command prunes a repository by deleting all archives not matching\nany of the specified retention options.\nImportant: Repository disk space is\nnot\nfreed until you run\nborg\ncompact\n.\nThis command is normally used by automated backup scripts wanting to keep a\ncertain number of historic backups. This retention policy is commonly referred to as\nGFS\n(Grandfather-father-son) backup rotation scheme.\nAlso, prune automatically removes checkpoint archives (incomplete archives left\nbehind by interrupted backup runs) except if the checkpoint is the latest\narchive (and thus still needed). Checkpoint archives are not considered when\ncomparing archive counts against the retention limits (\n--keep-X\n).\nIf a prefix is set with -P, then only archives that start with the prefix are\nconsidered for deletion and only those archives count towards the totals\nspecified by the rules.\nOtherwise,\nall\narchives in the repository are candidates for deletion!\nThere is no automatic distinction between archives representing different\ncontents. These need to be distinguished by specifying matching prefixes.\nIf you have multiple sequences of archives with different data sets (e.g.\nfrom different machines) in one shared repository, use one prune call per\ndata set that matches only the respective archives using the -P option.\nThe\n--keep-within\noption takes an argument of the form “<int><char>”,\nwhere char is “H”, “d”, “w”, “m”, “y”. For example,\n--keep-within\n2d\nmeans\nto keep all archives that were created within the past 48 hours.\n“1m” is taken to mean “31d”. The archives kept with this option do not\ncount towards the totals specified by any other options.\nA good procedure is to thin out more and more the older your backups get.\nAs an example,\n--keep-daily\n7\nmeans to keep the latest backup on each day,\nup to 7 most recent days with backups (days without backups do not count).\nThe rules are applied from secondly to yearly, and backups selected by previous\nrules do not count towards those of later rules. The time that each backup\nstarts is used for pruning purposes. Dates and times are interpreted in\nthe local time zone, and weeks go from Monday to Sunday. Specifying a\nnegative number of archives to keep means that there is no limit. As of Borg\n1.2.0, Borg will retain the oldest archive if any of the secondly, minutely,\nhourly, daily, weekly, monthly, quarterly, or yearly rules was not otherwise\nable to meet its retention target. This enables the first chronological archive\nto continue aging until it is replaced by a newer archive that meets the\nretention criteria.\nThe\n--keep-13weekly\nand\n--keep-3monthly\nrules are two different\nstrategies for keeping archives every quarter year.\nThe\n--keep-last\nN\noption is doing the same as\n--keep-secondly\nN\n(and it will\nkeep the last N archives under the assumption that you do not create more than one\nbackup archive in the same second).\nWhen using\n--stats\n, you will get some statistics about how much data was\ndeleted - the “Deleted data” deduplicated size there is most interesting as\nthat is how much your repository will shrink.\nPlease note that the “All archives” stats refer to the state after pruning.\nExamples\n¶\nBe careful: prune is a potentially dangerous command; it will remove backup\narchives.\nBy default, prune applies to\nall archives in the repository\nunless you\nrestrict its operation to a subset of the archives using\n--glob-archives\n.\nWhen using\n--glob-archives\n, be careful to choose a good matching pattern —\nfor example, do not use “foo*” if you do not also want to match “foobar”.\nIt is strongly recommended to always run\nprune\n-v\n--list\n--dry-run\n...\nfirst, so you can see what it would do without actually doing anything.\n# Keep 7 end-of-day and 4 additional end-of-week archives.\n# Do a dry-run without actually deleting anything.\n$ borg prune -v --list --dry-run --keep-daily=7 --keep-weekly=4 /path/to/repo\n# Same as above but only apply to archive names starting with the hostname\n# of the machine followed by a \"-\" character:\n$ borg prune -v --list --keep-daily=7 --keep-weekly=4 --glob-archives='{hostname}-*' /path/to/repo\n# Actually free disk space:\n$ borg compact /path/to/repo\n# Keep 7 end-of-day, 4 additional end-of-week archives,\n# and an end-of-month archive for every month:\n$ borg prune -v --list --keep-daily=7 --keep-weekly=4 --keep-monthly=-1 /path/to/repo\n# Keep all backups in the last 10 days, 4 additional end-of-week archives,\n# and an end-of-month archive for every month:\n$ borg prune -v --list --keep-within=10d --keep-weekly=4 --keep-monthly=-1 /path/to/repo\nThere is also a visual example of pruning in\ndocs/misc/prune-example.txt\n:\nborg prune visualized\n=====================\nAssume it is 2016-01-01, today's backup has not yet been made, you have\ncreated at least one backup on each day in 2015 except on 2015-12-19 (no\nbackup made on that day), and you started backing up with borg on\n2015-01-01.\nThis is what borg prune --keep-daily 14 --keep-monthly 6 --keep-yearly 1\nwould keep.\nBackups kept by the --keep-daily rule are marked by a \"d\" to the right,\nbackups kept by the --keep-monthly rule are marked by a \"m\" to the right,\nand backups kept by the --keep-yearly rule are marked by a \"y\" to the\nright.\nCalendar view\n-------------\n2015\nJanuary               February               March\nMo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su\n1y 2  3  4                     1                     1\n5  6  7  8  9 10 11   2  3  4  5  6  7  8   2  3  4  5  6  7  8\n12 13 14 15 16 17 18   9 10 11 12 13 14 15   9 10 11 12 13 14 15\n19 20 21 22 23 24 25  16 17 18 19 20 21 22  16 17 18 19 20 21 22\n26 27 28 29 30 31     23 24 25 26 27 28     23 24 25 26 27 28 29\n30 31\nApril                  May                   June\nMo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su\n1  2  3  4  5               1  2  3   1  2  3  4  5  6  7\n6  7  8  9 10 11 12   4  5  6  7  8  9 10   8  9 10 11 12 13 14\n13 14 15 16 17 18 19  11 12 13 14 15 16 17  15 16 17 18 19 20 21\n20 21 22 23 24 25 26  18 19 20 21 22 23 24  22 23 24 25 26 27 28\n27 28 29 30           25 26 27 28 29 30 31  29 30m\nJuly                 August              September\nMo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su\n1  2  3  4  5                  1  2      1  2  3  4  5  6\n6  7  8  9 10 11 12   3  4  5  6  7  8  9   7  8  9 10 11 12 13\n13 14 15 16 17 18 19  10 11 12 13 14 15 16  14 15 16 17 18 19 20\n20 21 22 23 24 25 26  17 18 19 20 21 22 23  21 22 23 24 25 26 27\n27 28 29 30 31m       24 25 26 27 28 29 30  28 29 30m\n31m\nOctober               November              December\nMo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su  Mo Tu We Th Fr Sa Su\n1  2  3  4                     1      1  2  3  4  5  6\n5  6  7  8  9 10 11   2  3  4  5  6  7  8   7  8  9 10 11 12 13\n12 13 14 15 16 17 18   9 10 11 12 13 14 15  14 15 16 17d18d19 20d\n19 20 21 22 23 24 25  16 17 18 19 20 21 22  21d22d23d24d25d26d27d\n26 27 28 29 30 31m    23 24 25 26 27 28 29  28d29d30d31d\n30m\nList view\n---------\n--keep-daily 14     --keep-monthly 6     --keep-yearly 1\n----------------------------------------------------------------\n1. 2015-12-31       (2015-12-31 kept     (2015-12-31 kept\n2. 2015-12-30        by daily rule)       by daily rule)\n3. 2015-12-29       1. 2015-11-30        1. 2015-01-01 (oldest)\n4. 2015-12-28       2. 2015-10-31\n5. 2015-12-27       3. 2015-09-30\n6. 2015-12-26       4. 2015-08-31\n7. 2015-12-25       5. 2015-07-31\n8. 2015-12-24       6. 2015-06-30\n9. 2015-12-23\n10. 2015-12-22\n11. 2015-12-21\n12. 2015-12-20\n(no backup made on 2015-12-19)\n13. 2015-12-18\n14. 2015-12-17\nNotes\n-----\n2015-12-31 is kept due to the --keep-daily 14 rule (because it is applied\nfirst), not due to the --keep-monthly or --keep-yearly rule.\nThe --keep-yearly 1 rule does not consider the December 31st backup because it\nhas already been kept due to the daily rule. There are no backups available\nfrom previous years, so the --keep-yearly target of 1 backup is not satisfied.\nBecause of this, the 2015-01-01 archive (the oldest archive available) is kept.\nThe --keep-monthly 6 rule keeps Nov, Oct, Sep, Aug, Jul and Jun. December is\nnot considered for this rule, because that backup was already kept because of\nthe daily rule.\n2015-12-17 is kept to satisfy the --keep-daily 14 rule - because no backup was\nmade on 2015-12-19. If a backup had been made on that day, it would not keep\nthe one from 2015-12-17.\nWe did not include weekly, hourly, minutely or secondly rules to keep this\nexample simple. They all work in basically the same way.\nThe weekly rule is easy to understand roughly, but hard to understand in all\ndetails. If interested, read \"ISO 8601:2000 standard week-based year\".\nThe 13weekly and 3monthly rules are two different strategies for keeping one\nevery quarter of a year. There are `multiple ways` to define a quarter-year;\nborg prune recognizes two:\n* --keep-13weekly keeps one backup every 13 weeks using ISO 8601:2000's\ndefinition of the week-based year. January 4th is always included in the\nfirst week of a year, and January 1st to 3rd may be in week 52 or 53 of the\nprevious year. Week 53 is also in the fourth quarter of the year.\n* --keep-3monthly keeps one backup every 3 months. January 1st to\nMarch 31, April 1st to June 30th, July 1st to September 30th, and October 1st\nto December 31st form the quarters.\nIf the subtleties of the definition of a quarter year don't matter to you, a\nshort summary of behavior is:\n* --keep-13weekly favors keeping backups at the beginning of Jan, Apr, July,\nand Oct.\n* --keep-3monthly favors keeping backups at the end of Dec, Mar, Jun, and Sept.\n* Both strategies will have some overlap in which backups are kept.\n* The differences are negligible unless backups considered for deletion were\ncreated weekly or more frequently.\n.. _multiple ways: https://en.wikipedia.org/wiki/Calendar_year#Quarter_year\nborg delete\nborg compact\nNavigation\nnext\nprevious\n|\nBorg - Deduplicating Archiver 1.4.2.post3 documentation\n»\nUsage\n»\nborg prune\n© Copyright 2010-2014 Jonas Borgström, 2015-2025 The Borg Collective (see AUTHORS file). Created using\nSphinx\n.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://borgbackup.readthedocs.io/en/stable/usage/prune.html"}}
{"text": "Restic Documentation — restic 0.18.1\ndocumentation\nRestic Documentation\nEdit on GitHub\nRestic Documentation\n\nIntroduction\nQuickstart Guide\nInstallation\nPackages\nOfficial Binaries\nDocker Container\nFrom Source\nAutocompletion\nPreparing a new repository\nLocal\nSFTP\nREST Server\nAmazon S3\nMinio Server\nS3-compatible Storage\nWasabi\nAlibaba Cloud (Aliyun) Object Storage System (OSS)\nOpenStack Swift\nBackblaze B2\nMicrosoft Azure Blob Storage\nGoogle Cloud Storage\nOther Services via rclone\nPassword prompt on Windows\nGroup accessible repositories\nRepositories with empty password\nBacking up\nFile change detection\nSkip creating snapshots if unchanged\nDry Runs\nExcluding Files\nIncluding Files\nComparing Snapshots\nBacking up special items and metadata\nReading data from a command\nReading data from stdin\nTags for backup\nScheduling backups\nSpace requirements\nExit status codes\nEnvironment Variables\nWorking with repositories\nListing all snapshots\nListing files in a snapshot\nCopying snapshots between repositories\nRemoving files from snapshots\nModifying metadata of snapshots\nChecking integrity and consistency\nUpgrading the repository format version\nTuning Backup Parameters\nDisabling Backup Progress Estimation\nBackend Connections\nCPU Usage\nCompression\nData Verification\nFile Read Concurrency\nPack Size\nFeature Flags\nRestoring from backup\nRestoring from a snapshot\nRestore using mount\nPrinting files to stdout\nRemoving backup snapshots\nRemove a single snapshot\nRemoving snapshots according to a policy\nCustomize pruning\nRecovering from “no free space” errors\nEncryption\nManage repository keys\nScripting\nCheck if a repository is already initialized\nExit codes\nJSON output\nTroubleshooting\n1. Find out what is damaged\n2. Backup the repository\n3. Repair the index\n4. Run all backups (optional)\n5. Remove missing data from snapshots\n6. Check the repository again\nExamples\nSetting up restic with Amazon S3\nBacking up your system without running restic as root\nParticipating\nDebug Logs\nDebugging\nContributing\nSecurity\nCompatibility\nBuilding documentation\nReferences\nDesign\nLocal Cache\nREST Backend\nTalks\nFAQ\nWill restic resume an interrupted backup?\nrestic\ncheck\nreports packs that aren’t referenced in any index, is my repository broken?\nI ran a\nrestic\ncommand but it is not working as intended, what do I do now?\nHow can I specify encryption passwords automatically?\nHow to prioritize restic’s IO and CPU time\nCreating new repository on a Synology NAS via sftp fails\nWhy does restic perform so poorly on Windows?\nHow do I choose a strong password?\nRestic backup command fails to find a valid file in Windows\nWhat can I do in case of “request timeout” errors?\nAre “cold storages” supported?\nManual\nUsage help\nManage tags\nUnder the hood\nScripting\nTemporary files\nCaching\nDeveloper Information\nReproducible Builds\nBuilding the Official Binaries\nVerifying SLSA Provenance for GHCR Docker Images\nVerifying the Official Binaries\nPrepare a New Release", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://restic.readthedocs.io/en/stable/"}}
{"text": "Introduction — restic 0.18.1\ndocumentation\nIntroduction\nEdit on GitHub\nIntroduction\n\nRestic is a fast and secure backup program. In the following sections, we will\npresent typical workflows, starting with installing, preparing a new\nrepository, and making the first backup.\nQuickstart Guide\n\nTo get started with a local repository, first define some environment variables:\nexport RESTIC_REPOSITORY=/srv/restic-repo\nexport RESTIC_PASSWORD=some-strong-password\nInitialize the repository (first time only):\nrestic init\nCreate your first backup:\nrestic backup ~/work\nYou can list all the snapshots you created with:\nrestic snapshots\nYou can restore a backup by noting the snapshot ID you want and running:\nrestic restore --target /tmp/restore-work your-snapshot-ID\nIt is a good idea to periodically check your repository’s metadata:\nrestic check\n#\nor\nfull\ndata:\nrestic check --read-data\nFor more details continue reading the next sections.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://restic.readthedocs.io/en/stable/010_introduction.html"}}
{"text": "Preparing a new repository — restic 0.18.1\ndocumentation\nPreparing a new repository\nEdit on GitHub\nPreparing a new repository\n\nThe place where your backups will be saved is called a “repository”. This is\nsimply a directory containing a set of subdirectories and files created by\nrestic to store your backups, some corresponding metadata and encryption keys.\nTo access the repository, a password (also called a key) must be specified. A\nrepository can hold multiple keys that can all be used to access the repository.\nThis chapter explains how to create (“init”) such a repository. The repository\ncan be stored locally, or on some remote server or service. We’ll first cover\nusing a local repository; the remaining sections of this chapter cover all the\nother options. You can skip to the next chapter once you’ve read the relevant\nsection here.\nFor automated backups, restic supports specifying the repository location in the\nenvironment variable\nRESTIC_REPOSITORY\n. Restic can also read the repository\nlocation from a file specified via the\n--repository-file\noption or the\nenvironment variable\nRESTIC_REPOSITORY_FILE\n.\nFor automating the supply of the repository password to restic, several options\nexist:\nSetting the environment variable\nRESTIC_PASSWORD\nSpecifying the path to a file with the password via the option\n--password-file\nor the environment variable\nRESTIC_PASSWORD_FILE\nConfiguring a program to be called when the password is needed via the\noption\n--password-command\nor the environment variable\nRESTIC_PASSWORD_COMMAND\nThe\ninit\ncommand has an option called\n--repository-version\nwhich can\nbe used to explicitly set the version of the new repository. By default, the\ncurrent stable version is used (see table below). The alias\nlatest\nwill\nalways resolve to the latest repository version. Have a look at the\ndesign\ndocumentation\nfor more details.\nThe below table shows which restic version is required to use a certain\nrepository version, as well as notable features introduced in the various\nversions.\nRepository version\nRequired restic version\nMajor new features\nComment\n1\nAny\n2\n0.14.0 or newer\nCompression support\nCurrent default\nLocal\n\nIn order to create a repository at\n/srv/restic-repo\n, run the following\ncommand and enter the same password twice:\n$\nrestic\ninit\n--repo\n/srv/restic-repo\nenter password for new repository:\nenter password again:\ncreated restic repository 085b3c76b9 at /srv/restic-repo\nPlease note that knowledge of your password is required to access the repository.\nLosing your password means that your data is irrecoverably lost.\nWarning\nRemembering your password is important! If you lose it, you won’t be\nable to access data stored in the repository.\nWarning\nOn Linux, storing the backup repository on a CIFS (SMB) share or backing up\ndata from a CIFS share is not recommended due to compatibility issues in\nolder Linux kernels. Either use another backend or set the environment\nvariable\nGODEBUG\nto\nasyncpreemptoff=1\n. Refer to GitHub issue\n#2659\nfor further explanations.\nSFTP\n\nIn order to backup data via SFTP, you must first set up a server with\nSSH and let it know your public key. Passwordless login is important\nsince automatic backups are not possible if the server prompts for\ncredentials.\nOnce the server is configured, the setup of the SFTP repository can\nsimply be achieved by changing the URL scheme in the\ninit\ncommand:\n$\nrestic\n-r\nsftp:user@host:/srv/restic-repo\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository f1c6108821 at sftp:user@host:/srv/restic-repo\nPlease note that knowledge of your password is required to access the repository.\nLosing your password means that your data is irrecoverably lost.\nYou can also specify a relative (read: no slash (\n/\n) character at the\nbeginning) directory, in this case the dir is relative to the remote\nuser’s home directory.\nAlso, if the SFTP server is enforcing domain-confined users, you can\nspecify the user this way:\nuser@domain@host\n.\nNote\nPlease be aware that SFTP servers do not expand the tilde character\n(\n~\n) normally used as an alias for a user’s home directory. If you\nwant to specify a path relative to the user’s home directory, pass a\nrelative path to the SFTP backend.\nIf you need to specify a port number or IPv6 address, you’ll need to use\nURL syntax. E.g., the repository\n/srv/restic-repo\non\n[::1]\n(localhost)\nat port 2222 with username\nuser\ncan be specified as\nsftp\n:\n//\nuser\n@\n[::\n1\n]:\n2222\n//\nsrv\n/\nrestic\n-\nrepo\nNote the double slash: the first slash separates the connection settings from\nthe path, while the second is the start of the path. To specify a relative\npath, use one slash.\nAlternatively, you can create an entry in the\nssh\nconfiguration file,\nusually located in your home directory at\n~/.ssh/config\nor in\n/etc/ssh/ssh_config\n:\nHost\nfoo\nUser\nbar\nPort\n2222\nThen use the specified host name\nfoo\nnormally (you don’t need to\nspecify the user name in this case):\n$ restic -r sftp:foo:/srv/restic-repo init\nYou can also add an entry with a special host name which does not exist,\njust for use with restic, and use the\nHostname\noption to set the\nreal host name:\nHost\nrestic\n-\nbackup\n-\nhost\nHostname\nfoo\nUser\nbar\nPort\n2222\nThen use it in the backend specification:\n$ restic -r sftp:restic-backup-host:/srv/restic-repo init\nLast, if you’d like to use an entirely different program to create the\nSFTP connection, you can specify the command to be run with the option\n-o\nsftp.command=\"foobar\"\n. Alternatively,\n-o\nsftp.args\nallows\nsetting the arguments passed to the default SSH command (ignored when\nsftp.command\nis set)\nNote\nPlease be aware that SFTP servers close connections when no data is\nreceived by the client. This can happen when restic is processing huge\namounts of unchanged data. To avoid this issue add the following lines\nto the client’s .ssh/config file:\nServerAliveInterval\n60\nServerAliveCountMax\n240\nREST Server\n\nIn order to backup data to the remote server via HTTP or HTTPS protocol,\nyou must first set up a remote\nREST\nserver\ninstance. Once the\nserver is configured, accessing it is achieved by changing the URL\nscheme like this:\n$\nrestic\n-r\nrest:http://host:8000/\ninit\nDepending on your REST server setup, you can use HTTPS protocol,\nunix socket, password protection, multiple repositories or any\ncombination of those features. The TCP/IP port is also configurable.\nHere are some more examples:\n$\nrestic\n-r\nrest:https://host:8000/\ninit\n$\nrestic\n-r\nrest:https://user:pass@host:8000/\ninit\n$\nrestic\n-r\nrest:https://user:pass@host:8000/my_backup_repo/\ninit\n$\nrestic\n-r\nrest:http+unix:///tmp/rest.socket:/my_backup_repo/\ninit\nThe server username and password can be specified using environment\nvariables as well:\n$\nexport\nRESTIC_REST_USERNAME\n=\n<MY_REST_SERVER_USERNAME>\n$\nexport\nRESTIC_REST_PASSWORD\n=\n<MY_REST_SERVER_PASSWORD>\nIf you use TLS, restic will use the system’s CA certificates to verify the\nserver certificate. When the verification fails, restic refuses to proceed and\nexits with an error. If you have your own self-signed certificate, or a custom\nCA certificate should be used for verification, you can pass restic the\ncertificate filename via the\n--cacert\noption. It will then verify that the\nserver’s certificate is contained in the file passed to this option, or signed\nby a CA certificate in the file. In this case, the system CA certificates are\nnot considered at all.\nREST server uses exactly the same directory structure as local backend,\nso you should be able to access it both locally and via HTTP, even\nsimultaneously.\nAmazon S3\n\nRestic can backup data to any Amazon S3 bucket. However, in this case,\nchanging the URL scheme is not enough since Amazon uses special security\ncredentials to sign HTTP requests. By consequence, you must first setup\nthe following environment variables with the credentials you obtained\nwhile creating the bucket.\n$\nexport\nAWS_ACCESS_KEY_ID\n=\n<MY_ACCESS_KEY>\n$\nexport\nAWS_SECRET_ACCESS_KEY\n=\n<MY_SECRET_ACCESS_KEY>\nWhen using temporary credentials make sure to include the session token via\nthe environment variable\nAWS_SESSION_TOKEN\n.\nYou can then easily initialize a repository that uses your Amazon S3 as\na backend. Make sure to use the endpoint for the correct region. The example\nuses\nus-east-1\n. If the bucket does not exist it will be created in that region:\n$\nrestic\n-r\ns3:s3.us-east-1.amazonaws.com/bucket_name\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository eefee03bbd at s3:s3.us-east-1.amazonaws.com/bucket_name\nPlease note that knowledge of your password is required to access the repository.\nLosing your password means that your data is irrecoverably lost.\nUntil version 0.8.0, restic used a default prefix of\nrestic\n, so the files\nin the bucket were placed in a directory named\nrestic\n. If you want to\naccess a repository created with an older version of restic, specify the path\nafter the bucket name like this:\n$\nrestic\n-r\ns3:s3.us-east-1.amazonaws.com/bucket_name/restic\n[\n...\n]\nNote\nrestic expects\npath-style URLs\nlike for example\ns3.us-west-2.amazonaws.com/bucket_name\nfor Amazon S3.\nVirtual-hosted–style URLs like\nbucket_name.s3.us-west-2.amazonaws.com\n,\nwhere the bucket name is part of the hostname are not supported. These must\nbe converted to path-style URLs instead, for example\ns3.us-west-2.amazonaws.com/bucket_name\n.\nSee below for configuration options for S3-compatible storage from other providers.\nMinio Server\n\nMinio\nis an Open Source Object Storage,\nwritten in Go and compatible with Amazon S3 API.\nDownload and Install\nMinio Download\n.\nYou can also refer to\nMinio Docs\nfor step by step guidance\non installation and getting started on Minio Client and Minio Server.\nYou must first setup the following environment variables with the\ncredentials of your Minio Server.\n$\nexport\nAWS_ACCESS_KEY_ID\n=\n<YOUR-MINIO-ACCESS-KEY-ID>\n$\nexport\nAWS_SECRET_ACCESS_KEY\n=\n<YOUR-MINIO-SECRET-ACCESS-KEY>\nNow you can easily initialize restic to use Minio server as a backend with\nthis command.\n$\nrestic\n-r\ns3:http://localhost:9000/restic\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository 6ad29560f5 at s3:http://localhost:9000/restic\nPlease note that knowledge of your password is required to access\nthe repository. Losing your password means that your data is irrecoverably lost.\nS3-compatible Storage\n\nFor an S3-compatible storage service that is not Amazon, you can specify the URL to the server\nlike this:\ns3:https://server:port/bucket_name\n.\nYou must also set credentials for authentication to the service.\n$\nexport\nAWS_ACCESS_KEY_ID\n=\n<YOUR-ACCESS-KEY-ID>\n$\nexport\nAWS_SECRET_ACCESS_KEY\n=\n<YOUR-SECRET-ACCESS-KEY>\n$\nrestic\n-r\ns3:https://server:port/bucket_name\ninit\nIf needed, you can manually specify the region to use by either setting the\nenvironment variable\nAWS_DEFAULT_REGION\nor calling restic with an option\nparameter like\n-o\ns3.region=\"us-east-1\"\n. If the region is not specified,\nthe default region\nus-east-1\nis used.\nTo select between path-style and virtual-hosted access, the extended option\n-o\ns3.bucket-lookup=auto\ncan be used. It supports the following values:\nauto\n: Default behavior. Uses\ndns\nfor Amazon and Google endpoints. Uses\npath\nfor all other endpoints\ndns\n: Use virtual-hosted-style bucket access\npath\n: Use path-style bucket access\nCertain S3-compatible servers do not properly implement the\nListObjectsV2\nAPI,\nmost notably Ceph versions before v14.2.5. On these backends, as a temporary\nworkaround, you can provide the\n-o\ns3.list-objects-v1=true\noption to use the\nolder\nListObjects\nAPI instead. This option may be removed in future versions\nof restic.\nWasabi\n\nS3 storage from\nWasabi\ncan be used as follows.\nDetermine the correct Wasabi service URL for your bucket\nhere\n.\nSet environment variables with the necessary account credentials\n$\nexport\nAWS_ACCESS_KEY_ID\n=\n<YOUR-WASABI-ACCESS-KEY-ID>\n$\nexport\nAWS_SECRET_ACCESS_KEY\n=\n<YOUR-WASABI-SECRET-ACCESS-KEY>\n$\nrestic\n-r\ns3:https://<WASABI-SERVICE-URL>/<WASABI-BUCKET-NAME>\ninit\nAlibaba Cloud (Aliyun) Object Storage System (OSS)\n\nS3 storage from\nAlibaba OSS\ncan be used as follows.\nDetermine the correct\nAlibaba OSS region endpoint\n- this will be something like\noss-eu-west-1.aliyuncs.com\nYou will need the region name too - this will be something like\noss-eu-west-1\nSet environment variables with the necessary account credentials\n$\nexport\nAWS_ACCESS_KEY_ID\n=\n<YOUR-OSS-ACCESS-KEY-ID>\n$\nexport\nAWS_SECRET_ACCESS_KEY\n=\n<YOUR-OSS-SECRET-ACCESS-KEY>\n$\nrestic\n-o\ns3.bucket-lookup\n=\ndns\n-o\ns3.region\n=\n<OSS-REGION>\n-r\ns3:https://<OSS-ENDPOINT>/<OSS-BUCKET-NAME>\ninit\nOpenStack Swift\n\nRestic can backup data to an OpenStack Swift container. Because Swift supports\nvarious authentication methods, credentials are passed through environment\nvariables. In order to help integration with existing OpenStack installations,\nthe naming convention of those variables follows the official Python Swift client:\n#\nFor\nkeystone\nv1\nauthentication\n$\nexport\nST_AUTH\n=\n<MY_AUTH_URL>\n$\nexport\nST_USER\n=\n<MY_USER_NAME>\n$\nexport\nST_KEY\n=\n<MY_USER_PASSWORD>\n#\nFor\nkeystone\nv2\nauthentication\n(\nsome\nvariables\nare\noptional\n)\n$\nexport\nOS_AUTH_URL\n=\n<MY_AUTH_URL>\n$\nexport\nOS_REGION_NAME\n=\n<MY_REGION_NAME>\n$\nexport\nOS_USERNAME\n=\n<MY_USERNAME>\n$\nexport\nOS_PASSWORD\n=\n<MY_PASSWORD>\n$\nexport\nOS_TENANT_ID\n=\n<MY_TENANT_ID>\n$\nexport\nOS_TENANT_NAME\n=\n<MY_TENANT_NAME>\n#\nFor\nkeystone\nv3\nauthentication\n(\nsome\nvariables\nare\noptional\n)\n$\nexport\nOS_AUTH_URL\n=\n<MY_AUTH_URL>\n$\nexport\nOS_REGION_NAME\n=\n<MY_REGION_NAME>\n$\nexport\nOS_USERNAME\n=\n<MY_USERNAME>\n$\nexport\nOS_USER_ID\n=\n<MY_USER_ID>\n$\nexport\nOS_PASSWORD\n=\n<MY_PASSWORD>\n$\nexport\nOS_USER_DOMAIN_NAME\n=\n<MY_DOMAIN_NAME>\n$\nexport\nOS_USER_DOMAIN_ID\n=\n<MY_DOMAIN_ID>\n$\nexport\nOS_PROJECT_NAME\n=\n<MY_PROJECT_NAME>\n$\nexport\nOS_PROJECT_DOMAIN_NAME\n=\n<MY_PROJECT_DOMAIN_NAME>\n$\nexport\nOS_PROJECT_DOMAIN_ID\n=\n<MY_PROJECT_DOMAIN_ID>\n$\nexport\nOS_TRUST_ID\n=\n<MY_TRUST_ID>\n#\nFor\nkeystone\nv3\napplication\ncredential\nauthentication\n(\napplication\ncredential\nid\n)\n$\nexport\nOS_AUTH_URL\n=\n<MY_AUTH_URL>\n$\nexport\nOS_APPLICATION_CREDENTIAL_ID\n=\n<MY_APPLICATION_CREDENTIAL_ID>\n$\nexport\nOS_APPLICATION_CREDENTIAL_SECRET\n=\n<MY_APPLICATION_CREDENTIAL_SECRET>\n#\nFor\nkeystone\nv3\napplication\ncredential\nauthentication\n(\napplication\ncredential\nname\n)\n$\nexport\nOS_AUTH_URL\n=\n<MY_AUTH_URL>\n$\nexport\nOS_USERNAME\n=\n<MY_USERNAME>\n$\nexport\nOS_USER_DOMAIN_NAME\n=\n<MY_DOMAIN_NAME>\n$\nexport\nOS_APPLICATION_CREDENTIAL_NAME\n=\n<MY_APPLICATION_CREDENTIAL_NAME>\n$\nexport\nOS_APPLICATION_CREDENTIAL_SECRET\n=\n<MY_APPLICATION_CREDENTIAL_SECRET>\n#\nFor\nauthentication\nbased\non\ntokens\n$\nexport\nOS_STORAGE_URL\n=\n<MY_STORAGE_URL>\n$\nexport\nOS_AUTH_TOKEN\n=\n<MY_AUTH_TOKEN>\nRestic should be compatible with an\nOpenStack RC file\nin most cases.\nOnce environment variables are set up, a new repository can be created. The\nname of the Swift container and optional path can be specified. If\nthe container does not exist, it will be created automatically:\n$\nrestic\n-r\nswift:container_name:/path\ninit\n# path is optional\nenter password for new repository:\nenter password again:\ncreated restic repository eefee03bbd at swift:container_name:/path\nPlease note that knowledge of your password is required to access the repository.\nLosing your password means that your data is irrecoverably lost.\nThe policy of the new container created by restic can be changed using environment variable:\n$\nexport\nSWIFT_DEFAULT_CONTAINER_POLICY\n=\n<MY_CONTAINER_POLICY>\nBackblaze B2\n\nWarning\nDue to issues with error handling in the current B2 library that restic uses,\nthe recommended way to utilize Backblaze B2 is by using its S3-compatible API.\nFollow the documentation to\ngenerate S3-compatible access keys\nand then\nsetup restic as described at\nAmazon S3\n. This is expected to work better\nthan using the Backblaze B2 backend directly.\nDifferent from the B2 backend, restic’s S3 backend will only hide no longer\nnecessary files. By default, Backblaze B2 retains all of the different versions of the\nfiles and “hides” the older versions. Thus, to free space occupied by hidden files,\nit is\nrecommended\nto use the B2 lifecycle “Keep only the last version of the file”.\nThe previous version of the file is “hidden” for one day and then deleted automatically\nby B2. More details at the\nBackblaze documentation\n.\nRestic can backup data to any Backblaze B2 bucket. You need to first setup the\nfollowing environment variables with the credentials you can find in the\ndashboard on the “Buckets” page when signed into your B2 account:\n$\nexport\nB2_ACCOUNT_ID\n=\n<MY_APPLICATION_KEY_ID>\n$\nexport\nB2_ACCOUNT_KEY\n=\n<MY_APPLICATION_KEY>\nTo get application keys, a user can go to the App Keys section of the Backblaze\naccount portal.  You must create a master application key first.  From there, you\ncan generate a standard Application Key.  Please note that the Application Key\nshould be treated like a password and will only appear once.  If an Application\nKey is forgotten, you must generate a new one.\nFor more information on application keys, refer to the\nBackblaze documentation\n.\nNote\nAs of version 0.9.2, restic supports both master and non-master\napplication keys\n. If using a non-master application key, ensure that it is created with at least\nread and write\naccess to the B2 bucket. On earlier versions of restic, a master application key is required.\nYou can then initialize a repository stored at Backblaze B2. If the\nbucket does not exist yet and the credentials you passed to restic have the\nprivilege to create buckets, it will be created automatically:\n$\nrestic\n-r\nb2:bucketname:path/to/repo\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository eefee03bbd at b2:bucketname:path/to/repo\nPlease note that knowledge of your password is required to access the repository.\nLosing your password means that your data is irrecoverably lost.\nNote that the bucket name must be unique across all of B2.\nThe number of concurrent connections to the B2 service can be set with the\n-o\nb2.connections=10\nswitch. By default, at most five parallel connections are\nestablished.\nMicrosoft Azure Blob Storage\n\nYou can also store backups on Microsoft Azure Blob Storage. Export the Azure\nBlob Storage account name:\n$\nexport\nAZURE_ACCOUNT_NAME\n=\n<ACCOUNT_NAME>\nFor authentication export one of the following variables:\n#\nFor\nstorage\naccount\nkey\n$\nexport\nAZURE_ACCOUNT_KEY\n=\n<SECRET_KEY>\n#\nFor\nSAS\n$\nexport\nAZURE_ACCOUNT_SAS\n=\n<SAS_TOKEN>\nFor authentication using\naz\nlogin\nensure the user has\nthe minimum permissions of the role assignment\nStorage\nBlob\nData\nContributor\non Azure RBAC\nfor the storage account.\n$\naz\nlogin\nAlternatively, if run on Azure, restic will automatically use service accounts configured\nvia the standard environment variables or Workload / Managed Identities.\nTo enforce the use of the Azure CLI credential when other credentials are present, set the following environment variable:\n$\nexport\nAZURE_FORCE_CLI_CREDENTIAL\n=\ntrue\nRestic will by default use Azure’s global domain\ncore.windows.net\nas endpoint suffix.\nYou can specify other suffixes as follows:\n$\nexport\nAZURE_ENDPOINT_SUFFIX\n=\n<ENDPOINT_SUFFIX>\nAfterwards you can initialize a repository in a container called\nfoo\nin the\nroot path like this:\n$\nrestic\n-r\nazure:foo:/\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository a934bac191 at azure:foo:/\n[...]\nThe number of concurrent connections to the Azure Blob Storage service can be set with the\n-o\nazure.connections=10\nswitch. By default, at most five parallel connections are\nestablished.\nThe access tier of the blobs uploaded to the Azure Blob Storage service can be set with the\n-o\nazure.access-tier=Cool\nswitch. The allowed values are\nHot\n,\nCool\nor\nCold\n.\nIf unspecified, the default is inferred from the default configured on the storage account.\nGoogle Cloud Storage\n\nNote\nGoogle Cloud Storage is not the same service as Google Drive - to use\nthe latter, please see\nOther Services via rclone\nfor instructions on using\nthe rclone backend.\nRestic supports Google Cloud Storage as a backend and connects via a\nservice account\n.\nFor normal restic operation, the service account must have the\nstorage.objects.{create,delete,get,list}\npermissions for the bucket. These\nare included in the “Storage Object Admin” role.\nrestic\ninit\ncan create the repository bucket. Doing so requires the\nstorage.buckets.create\npermission (“Storage Admin” role). If the bucket\nalready exists, that permission is unnecessary.\nTo use the Google Cloud Storage backend, first\ncreate a service account key\nand download the JSON credentials file.\nSecond, find the Google Project ID that you can see in the Google Cloud\nPlatform console at the “Storage/Settings” menu. Export the path to the JSON\nkey file and the project ID as follows:\n$\nexport\nGOOGLE_PROJECT_ID\n=\n123123123123\n$\nexport\nGOOGLE_APPLICATION_CREDENTIALS\n=\n$HOME\n/.config/gs-secret-restic-key.json\nRestic uses  Google’s client library to generate\ndefault authentication material\n,\nwhich means if you’re running in Google Container Engine or are otherwise\nlocated on an instance with default service accounts then these should work out of\nthe box.\nAlternatively, you can specify an existing access token directly:\n$\nexport\nGOOGLE_ACCESS_TOKEN\n=\nya29.a0AfH6SMC78...\nIf\nGOOGLE_ACCESS_TOKEN\nis set all other authentication mechanisms are\ndisabled. The access token must have at least the\nhttps://www.googleapis.com/auth/devstorage.read_write\nscope. Keep in mind\nthat access tokens are short-lived (usually one hour), so they are not suitable\nif creating a backup takes longer than that, for instance.\nOnce authenticated, you can use the\ngs:\nbackend type to create a new\nrepository in the bucket\nfoo\nat the root path:\n$\nrestic\n-r\ngs:foo:/\ninit\nenter password for new repository:\nenter password again:\ncreated restic repository bde47d6254 at gs:foo/\n[...]\nThe number of concurrent connections to the GCS service can be set with the\n-o\ngs.connections=10\nswitch. By default, at most five parallel connections are\nestablished.\nThe region, where a bucket should be created, can be specified with the\n-o\ngs.region=us\nswitch. By default, the region is set to\nus\n.\nOther Services via rclone\n\nThe program\nrclone\ncan be used to access many other different services and\nstore data there. First, you need to install and\nconfigure\nrclone.  The\ngeneral backend specification format is\nrclone:<remote>:<path>\n, the\n<remote>:<path>\ncomponent will be directly passed to rclone. When you\nconfigure a remote named\nfoo\n, you can then call restic as follows to\ninitiate a new repository in the path\nbar\nin the remote\nfoo\n:\n$\nrestic\n-r\nrclone:foo:bar\ninit\nRestic takes care of starting and stopping rclone.\nNote\nIf you get an error message saying “cannot implicitly run relative\nexecutable rclone found in current directory”, this means that an\nrclone executable was found in the current directory. For security\nreasons restic will not run this implicitly, instead you have to\nuse the\n-o\nrclone.program=./rclone\nextended option to override\nthis security check and explicitly tell restic to use the executable.\nAs a more concrete example, suppose you have configured a remote named\nb2prod\nfor Backblaze B2 with rclone, with a bucket called\nyggdrasil\n.\nYou can then use rclone to list files in the bucket like this:\n$\nrclone\nls\nb2prod:yggdrasil\nIn order to create a new repository in the root directory of the bucket, call\nrestic like this:\n$\nrestic\n-r\nrclone:b2prod:yggdrasil\ninit\nIf you want to use the path\nfoo/bar/baz\nin the bucket instead, pass this to\nrestic:\n$\nrestic\n-r\nrclone:b2prod:yggdrasil/foo/bar/baz\ninit\nListing the files of an empty repository directly with rclone should return a\nlisting similar to the following:\n$\nrclone\nls\nb2prod:yggdrasil/foo/bar/baz\n155 bar/baz/config\n448 bar/baz/keys/4bf9c78049de689d73a56ed0546f83b8416795295cda12ec7fb9465af3900b44\nRclone can be\nconfigured with environment variables\n, so for instance\nconfiguring a bandwidth limit for rclone can be achieved by setting the\nRCLONE_BWLIMIT\nenvironment variable:\n$\nexport\nRCLONE_BWLIMIT\n=\n1M\nFor debugging rclone, you can set the environment variable\nRCLONE_VERBOSE=2\n.\nThe rclone backend has three additional options:\n-o\nrclone.program\nspecifies the path to rclone, the default value is just\nrclone\n-o\nrclone.args\nallows setting the arguments passed to rclone, by default this is\nserve\nrestic\n--stdio\n--b2-hard-delete\n-o\nrclone.timeout\nspecifies timeout for waiting on repository opening, the default value is\n1m\nThe reason for the\n--b2-hard-delete\nparameters can be found in the corresponding GitHub\nissue #1657\n.\nIn order to start rclone, restic will build a list of arguments by joining the\nfollowing lists (in this order):\nrclone.program\n,\nrclone.args\nand as the\nlast parameter the value that follows the\nrclone:\nprefix of the repository\nspecification.\nSo, calling restic like this\n$\nrestic\n-o\nrclone.program\n=\n\"/path/to/rclone\"\n\\\n-o\nrclone.args\n=\n\"serve restic --stdio --bwlimit 1M --b2-hard-delete --verbose\"\n\\\n-r\nrclone:b2:foo/bar\nruns rclone as follows:\n$\n/path/to/rclone\nserve\nrestic\n--stdio\n--bwlimit\n1M\n--b2-hard-delete\n--verbose\nb2:foo/bar\nManually setting\nrclone.program\nalso allows running a remote instance of\nrclone e.g. via SSH on a server, for example:\n$\nrestic\n-o\nrclone.program\n=\n\"ssh user@remotehost rclone\"\n-r\nrclone:b2:foo/bar\nWith these options, restic works with local files. It uses rclone and\ncredentials stored on\nremotehost\nto communicate with B2. All data (except\ncredentials) is encrypted/decrypted locally, then sent/received via\nremotehost\nto/from B2.\nA more advanced version of this setup forbids specific hosts from removing\nfiles in a repository. See the\nblog post by Simon Ruderich\nfor details and the documentation for the\nforget\ncommand to learn about\nimportant security considerations.\nThe rclone command may also be hard-coded in the SSH configuration or the\nuser’s public key, in this case it may be sufficient to just start the SSH\nconnection (and it’s irrelevant what’s passed after\nrclone:\nin the\nrepository specification):\n$\nrestic\n-o\nrclone.program\n=\n\"ssh user@host\"\n-r\nrclone:x\nPassword prompt on Windows\n\nAt the moment, restic only supports the default Windows console\ninteraction. If you use emulation environments like\nMSYS2\nor\nCygwin\n, which use terminals like\nMintty\nor\nrxvt\n, you may get a password error.\nYou can workaround this by using a special tool called\nwinpty\n(look\nhere\nand\nhere\nfor detail information).\nOn MSYS2, you can install\nwinpty\nas follows:\n$\npacman\n-S\nwinpty\n$\nwinpty\nrestic\n-r\n/srv/restic-repo\ninit\nGroup accessible repositories\n\nSince restic version 0.14 local and SFTP repositories can be made\naccessible to members of a system group. To control this we have to change\nthe group permissions of the top-level\nconfig\nfile and restic will use\nthis as a hint to determine what permissions to apply to newly created\nfiles. By default\nrestic\ninit\nsets repositories up to be group\ninaccessible.\nIn order to give group members read-only access we simply add the read\npermission bit to all repository files with\nchmod\n:\n$\nchmod\n-R\ng+r\n/srv/restic-repo\nThis serves two purposes: 1) it sets the read permission bit on the\nrepository config file triggering restic’s logic to create new files as\ngroup accessible and 2) it actually allows the group read access to the\nfiles.\nNote\nBy default files on Unix systems are created with a user’s\nprimary group as defined by the gid (group id) field in\n/etc/passwd\n. See\npasswd(5)\n.\nFor read-write access things are a bit more complicated. When users other\nthan the repository creator add new files in the repository they will be\ngroup-owned by this user’s primary group by default, not that of the\noriginal repository owner, meaning the original creator wouldn’t have\naccess to these files. That’s hardly what you’d want.\nTo make this work we can employ the help of the\nsetgid\npermission bit\navailable on Linux and most other Unix systems. This permission bit makes\nnewly created directories inherit both the group owner (gid) and setgid bit\nfrom the parent directory. Setting this bit requires root but since it\npropagates down to any new directories we only have to do this privileged\nsetup once:\n#\nfind\n/srv/restic-repo\n-type\nd\n-exec\nchmod\ng+s\n'{}'\n\\;\n$\nchmod\n-R\ng+rw\n/srv/restic-repo\nThis sets the\nsetgid\nbit on all existing directories in the repository\nand then grants read/write permissions for group access.\nNote\nTo manage who has access to the repository you can use\nusermod\non Linux systems, to change which group controls\nrepository access\nchgrp\n-R\nis your friend.\nRepositories with empty password\n\nRestic by default refuses to create or operate on repositories that use an\nempty password. Since restic 0.17.0, the option\n--insecure-no-password\nallows\ndisabling this check. Restic will not prompt for a password when using this option.\nSpecifying\n--insecure-no-password\nwhile also passing a password to restic\nvia a CLI option or via environment variable results in an error.\nFor security reasons, the option must always be specified when operating on\nrepositories with an empty password. For example to create a new repository\nwith an empty password, use the following command.\nrestic init --insecure-no-password\nThe\ninit\nand\ncopy\ncommands also support the option\n--from-insecure-no-password\nwhich applies to the source repository. The\nkey\nadd\nand\nkey\npasswd\ncommands\ninclude the\n--new-insecure-no-password\noption to add or set an empty password.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://restic.readthedocs.io/en/stable/030_preparing_a_new_repo.html"}}
{"text": "Backing up — restic 0.18.1\ndocumentation\nBacking up\nEdit on GitHub\nBacking up\n\nNow we’re ready to backup some data. The contents of a directory at a\nspecific point in time is called a “snapshot” in restic. Run the\nfollowing command and enter the repository password you chose above\nagain:\n$\nrestic\n-r\n/srv/restic-repo\n--verbose\nbackup\n~/work\nopen repository\nenter password for repository:\nrepository a14e5863 opened (version 2, compression level auto)\nload index files\nstart scan on [/home/user/work]\nstart backup on [/home/user/work]\nscan finished in 1.837s: 5307 files, 1.720 GiB\nFiles:        5307 new,     0 changed,     0 unmodified\nDirs:         1867 new,     0 changed,     0 unmodified\nAdded to the repository: 1.200 GiB (1.103 GiB stored)\nprocessed 5307 files, 1.720 GiB in 0:12\nsnapshot 40dc1520 saved\nAs you can see, restic created a backup of the directory and was pretty\nfast! The specific snapshot just created is identified by a sequence of\nhexadecimal characters,\n40dc1520\nin this case.\nYou can see that restic tells us it processed 1.720 GiB of data, this is the\nsize of the files and directories in\n~/work\non the local file system. It\nalso tells us that only 1.200 GiB was added to the repository. This means that\nsome of the data was duplicate and restic was able to efficiently reduce it.\nThe data compression also managed to compress the data down to 1.103 GiB.\nIf you don’t pass the\n--verbose\noption, restic will print less data. You’ll\nstill get a nice live status display. Be aware that the live status shows the\nprocessed files and not the transferred data. Transferred volume might be lower\n(due to de-duplication) or higher.\nOn Windows, the\n--use-fs-snapshot\noption will use Windows’ Volume Shadow Copy\nService (VSS) when creating backups. Restic will transparently create a VSS\nsnapshot for each volume that contains files to backup. Files are read from the\nVSS snapshot instead of the regular filesystem. This allows to backup files that are\nexclusively locked by another process during the backup.\nYou can use the following extended options to change the VSS behavior:\n-o\nvss.timeout\nspecifies timeout for VSS snapshot creation, default value being 120 seconds\n-o\nvss.exclude-all-mount-points\ndisable auto snapshotting of all volume mount points\n-o\nvss.exclude-volumes\nallows excluding specific volumes or volume mount points from snapshotting\n-o\nvss.provider\nspecifies VSS provider used for snapshotting\nFor example a 2.5 minutes timeout with snapshotting of mount points disabled can be specified as:\n-o vss.timeout=2m30s -o vss.exclude-all-mount-points=true\nand excluding drive\nd:\\\n, mount point\nc:\\mnt\nand volume\n\\\\?\\Volume{04ce0545-3391-11e0-ba2f-806e6f6e6963}\\\nas:\n-o vss.exclude-volumes=\"d:;c:\\mnt\\;\\\\?\\volume{04ce0545-3391-11e0-ba2f-806e6f6e6963}\"\nVSS provider can be specified by GUID:\n-o vss.provider={3f900f90-00e9-440e-873a-96ca5eb079e5}\nor by name:\n-o vss.provider=\"Hyper-V IC Software Shadow Copy Provider\"\nAlso,\nMS\ncan be used as alias for\nMicrosoft\nSoftware\nShadow\nCopy\nprovider\n1.0\n.\nBy default VSS ignores Outlook OST files. This is not a restriction of restic\nbut the default Windows VSS configuration. The files not to snapshot are\nconfigured in the Windows registry under the following key:\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\BackupRestore\\FilesNotToSnapshot\nFor more details refer the official Windows documentation e.g. the article\nRegistry\nKeys\nand\nValues\nfor\nBackup\nand\nRestore\n.\nIf you run the backup command again, restic will create another snapshot of\nyour data, but this time it’s even faster and no new data was added to the\nrepository (since all data is already there). This is de-duplication at work!\n$\nrestic\n-r\n/srv/restic-repo\n--verbose\nbackup\n~/work\nopen repository\nenter password for repository:\nrepository a14e5863 opened (version 2, compression level auto)\nload index files\nusing parent snapshot 40dc1520\nstart scan on [/home/user/work]\nstart backup on [/home/user/work]\nscan finished in 1.881s: 5307 files, 1.720 GiB\nFiles:           0 new,     0 changed,  5307 unmodified\nDirs:            0 new,     0 changed,  1867 unmodified\nAdded to the repository: 0 B   (0 B   stored)\nprocessed 5307 files, 1.720 GiB in 0:03\nsnapshot 79766175 saved\nYou can even backup individual files in the same repository (not passing\n--verbose\nmeans less output):\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n~/work.txt\nenter password for repository:\nsnapshot 249d0210 saved\nIf you’re interested in what restic does, pass\n--verbose\ntwice (or\n--verbose=2\n) to display detailed information about each file and directory\nrestic encounters:\n$\necho\n'more data foo bar'\n>>\n~/work.txt\n$\nrestic\n-r\n/srv/restic-repo\n--verbose\n--verbose\nbackup\n~/work.txt\nopen repository\nenter password for repository:\nlock repository\nload index files\nusing parent snapshot f3f8d56b\nstart scan\nstart backup\nscan finished in 2.115s\nmodified  /home/user/work.txt, saved in 0.007s (22 B added)\nmodified  /home/user/, saved in 0.008s (0 B added, 378 B metadata)\nmodified  /home/, saved in 0.009s (0 B added, 375 B metadata)\nprocessed 22 B in 0:02\nFiles:           0 new,     1 changed,     0 unmodified\nDirs:            0 new,     2 changed,     0 unmodified\nData Blobs:      1 new\nTree Blobs:      3 new\nAdded:      1.116 KiB\nsnapshot 8dc503fc saved\nIn fact several hosts may use the same repository to backup directories\nand files leading to a greater de-duplication.\nNow is a good time to run\nrestic\ncheck\nto verify that all data\nis properly stored in the repository. You should run this command regularly\nto make sure the internal structure of the repository is free of errors.\nFile change detection\n\nWhen restic encounters a file that has already been backed up, whether in the\ncurrent backup or a previous one, it makes sure the file’s content is only\nstored once in the repository. To do so, it normally has to scan the entire\ncontent of the file. Because this can be very expensive, restic also uses a\nchange detection rule based on file metadata to determine whether a file is\nlikely unchanged since a previous backup. If it is, the file is not scanned\nagain.\nThe previous backup snapshot, called “parent” snapshot in restic terminology,\nis determined as follows. By default restic groups snapshots by hostname and\nbackup paths, and then selects the latest snapshot in the group that matches\nthe current backup. You can change the selection criteria using the\n--group-by\noption, which defaults to\nhost,paths\n. To select the latest\nsnapshot with the same paths independent of the hostname, use\npaths\n. Or,\nto only consider the hostname and tags, use\nhost,tags\n. Alternatively, it\nis possible to manually specify a specific parent snapshot using the\n--parent\noption. Finally, note that one would normally set the\n--group-by\noption for the\nforget\ncommand to the same value.\nChange detection is only performed for regular files (not special files,\nsymlinks or directories) that have the exact same path as they did in a\nprevious backup of the same location.  If a file or one of its containing\ndirectories was renamed, it is considered a different file and its entire\ncontents will be scanned again.\nMetadata changes (permissions, ownership, etc.) are always included in the\nbackup, even if file contents are considered unchanged.\nOn\nUnix\n(including Linux and Mac), given that a file lives at the same\nlocation as a file in a previous backup, the following file metadata\nattributes have to match for its contents to be presumed unchanged:\nModification timestamp (mtime).\nMetadata change timestamp (ctime).\nFile size.\nInode number (internal number used to reference a file in a filesystem).\nThe reason for requiring both mtime and ctime to match is that Unix programs\ncan freely change mtime (and some do). In such cases, a ctime change may be\nthe only hint that a file did change.\nThe following\nrestic\nbackup\ncommand line flags modify the change detection\nrules:\n--force\n: turn off change detection and rescan all files.\n--ignore-ctime\n: require mtime to match, but allow ctime to differ.\n--ignore-inode\n: require mtime to match, but allow inode number\nand ctime to differ.\nThe option\n--ignore-inode\nexists to support FUSE-based filesystems and\npCloud, which do not assign stable inodes to files.\nNote that the device id of the containing mount point is never taken into\naccount. Device numbers are not stable for removable devices and ZFS snapshots.\nIf you want to force a re-scan in such a case, you can change the mountpoint.\nOn\nWindows\n, a file is considered unchanged when its path, size\nand modification time match, and only\n--force\nhas any effect.\nThe other options are recognized but ignored.\nSkip creating snapshots if unchanged\n\nBy default, restic always creates a new snapshot even if nothing has changed\ncompared to the parent snapshot. To omit the creation of a new snapshot in this\ncase, specify the\n--skip-if-unchanged\noption.\nNote that when using absolute paths to specify the backup source, then also\nchanges to the parent folders result in a changed snapshot. For example, a backup\nof\n/home/user/work\nwill create a new snapshot if the metadata of either\n/\n,\n/home\nor\n/home/user\nchange. To avoid this problem run restic from\nthe corresponding folder and use relative paths.\n$\ncd\n/home/user/work\n&&\nrestic\n-r\n/srv/restic-repo\nbackup\n.\n--skip-if-unchanged\nopen repository\nenter password for repository:\nrepository a14e5863 opened (version 2, compression level auto)\nload index files\nusing parent snapshot 40dc1520\nstart scan on [.]\nstart backup on [.]\nscan finished in 1.814s: 5307 files, 1.720 GiB\nFiles:           0 new,     0 changed,  5307 unmodified\nDirs:            0 new,     0 changed,  1867 unmodified\nAdded to the repository: 0 B   (0 B   stored)\nprocessed 5307 files, 1.720 GiB in 0:03\nskipped creating snapshot\nDry Runs\n\nYou can perform a backup in dry run mode to see what would happen without\nmodifying the repository.\n--dry-run\n/\n-n\nReport what would be done, without writing to the repository\nCombined with\n--verbose\n, you can see a list of changes:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n~/work\n--dry-run\n-vv\n|\ngrep\n\"added\"\nmodified  /plan.txt, saved in 0.000s (9.110 KiB added)\nmodified  /archive.tar.gz, saved in 0.140s (25.542 MiB added)\nWould be added to the repository: 25.551 MiB\nExcluding Files\n\nYou can exclude folders and files by specifying exclude patterns, currently\nthe exclude options are:\n--exclude\nSpecified one or more times to exclude one or more items\n--iexclude\nSame as\n--exclude\nbut ignores the case of paths\n--exclude-caches\nSpecified once to exclude a folder’s content if it contains\nthe special CACHEDIR.TAG file\n, but keep\nCACHEDIR.TAG\n.\n--exclude-file\nSpecified one or more times to exclude items listed in a given file\n--iexclude-file\nSame as\nexclude-file\nbut ignores cases like in\n--iexclude\n--exclude-if-present\nfoo\nSpecified one or more times to exclude a folder’s content if it contains a file called\nfoo\n(optionally having a given header, no wildcards for the file name supported)\n--exclude-larger-than\nsize\nSpecified once to exclude files larger than the given size\n--exclude-cloud-files\nSpecified once to exclude online-only cloud files (such as OneDrive Files On-Demand), currently only supported on Windows\nPlease see\nrestic\nhelp\nbackup\nfor more specific information about each exclude option.\nLet’s say we have a file called\nexcludes.txt\nwith the following content:\n# exclude go-files\n*.\ngo\n# exclude foo/x/y/z/bar foo/x/bar foo/bar\nfoo\n/**/\nbar\nIt can be used like this:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n~/work\n--exclude\n=\n\"*.c\"\n--exclude-file\n=\nexcludes.txt\nThis instructs restic to exclude files matching the following criteria:\nAll files matching\n*.c\n(parameter\n--exclude\n)\nAll files matching\n*.go\n(second line in\nexcludes.txt\n)\nAll files and sub-directories named\nbar\nwhich reside somewhere below a directory called\nfoo\n(fourth line in\nexcludes.txt\n)\nPatterns use the syntax of the Go function\nfilepath.Match\nand are tested against the full path of a file/dir to be saved,\neven if restic is passed a relative path to save. Empty lines and lines\nstarting with a\n#\nare ignored.\nEnvironment variables in exclude files are expanded with\nos.ExpandEnv\n, so\n/home/$USER/foo\nwill be\nexpanded to\n/home/bob/foo\nfor the user\nbob\n. To get a literal dollar\nsign, write\n$$\nto the file - this has to be done even when there’s no\nmatching environment variable for the word following a single\n$\n. Note\nthat tilde (\n~\n) is not expanded, instead use the\n$HOME\nor equivalent\nenvironment variable (depending on your operating system).\nPatterns need to match on complete path components. For example, the pattern\nfoo\n:\nmatches\n/dir1/foo/dir2/file\nand\n/dir/foo\ndoes not match\n/dir/foobar\nor\nbarfoo\nA trailing\n/\nis ignored, a leading\n/\nanchors the pattern at the root directory.\nThis means,\n/bin\nmatches\n/bin/bash\nbut does not match\n/usr/bin/restic\n.\nRegular wildcards cannot be used to match over the directory separator\n/\n,\ne.g.\nb*ash\nmatches\n/bin/bash\nbut does not match\n/bin/ash\n. To match\nacross an arbitrary number of subdirectories, use the special\n**\nwildcard.\nThe\n**\nmust be positioned between path separators. The pattern\nfoo/**/bar\nmatches:\n/dir1/foo/dir2/bar/file\n/foo/bar/file\n/tmp/foo/bar\nSpaces in patterns listed in an exclude file can be specified verbatim. That is,\nin order to exclude a file named\nfoo\nbar\nstar.txt\n, put that just as it reads\non one line in the exclude file. Please note that beginning and trailing spaces\nare trimmed - in order to match these, use e.g. a\n*\nat the beginning or end\nof the filename.\nSpaces in patterns listed in the other exclude options (e.g.\n--exclude\non the\ncommand line) are specified in different ways depending on the operating system\nand/or shell. Restic itself does not need any escaping, but your shell may need\nsome escaping in order to pass the name/pattern as a single argument to restic.\nOn most Unixy shells, you can either quote or use backslashes. For example:\n--exclude='foo\nbar\nstar/foo.txt'\n--exclude=\"foo\nbar\nstar/foo.txt\"\n--exclude=foo\\\nbar\\\nstar/foo.txt\nIf a pattern starts with exclamation mark and matches a file that\nwas previously matched by a regular pattern, the match is cancelled.\nIt works similarly to\ngitignore\n, with the same limitation: once a\ndirectory is excluded, it is not possible to include files inside the\ndirectory. Here is a complete example to backup a selection of\ndirectories inside the home directory. It works by excluding any\ndirectory, then selectively add back some of them.\n$HOME/*\n!$HOME/Documents\n!$HOME/code\n!$HOME/.emacs.d\n!$HOME/games\n# [...]\nnode_modules\n*~\n*.o\n*.lo\n*.pyc\nBy specifying the option\n--one-file-system\nyou can instruct restic\nto only backup files from the file systems the initially specified files\nor directories reside on. In other words, it will prevent restic from crossing\nfilesystem boundaries and subvolumes when performing a backup.\nFor example, if you backup\n/\nwith this option and you have external\nmedia mounted under\n/media/usb\nthen restic will not back up\n/media/usb\nat all because this is a different filesystem than\n/\n. Virtual filesystems\nsuch as\n/proc\nare also considered different and thereby excluded when\nusing\n--one-file-system\n:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--one-file-system\n/\nPlease note that this does not prevent you from specifying multiple filesystems\non the command line, e.g:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--one-file-system\n/\n/media/usb\nwill back up both the\n/\nand\n/media/usb\nfilesystems, but will not\ninclude other filesystems like\n/sys\nand\n/proc\n.\nNote\n--one-file-system\nis currently unsupported on Windows, and will\ncause the backup to immediately fail with an error.\nFiles larger than a given size can be excluded using the\n–exclude-larger-than\noption:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n~/work\n--exclude-larger-than\n1M\nThis excludes files in\n~/work\nwhich are larger than 1 MiB from the backup.\nThe default unit for the size value is bytes, so e.g.\n--exclude-larger-than\n2048\nwould exclude files larger than 2048 bytes (2 KiB). To specify other units,\nsuffix the size value with one of\nk\n/\nK\nfor KiB (1024 bytes),\nm\n/\nM\nfor MiB (1024^2 bytes),\ng\n/\nG\nfor GiB (1024^3 bytes) and\nt\n/\nT\nfor TiB (1024^4 bytes), e.g.\n1k\n,\n10K\n,\n20m\n,\n20M\n,\n30g\n,\n30G\n,\n2t\nor\n2T\n).\nIncluding Files\n\nThe options\n--files-from\n,\n--files-from-verbatim\nand\n--files-from-raw\nallow you to give restic a file containing lists of file patterns or paths to\nbe backed up. This is useful e.g. when you want to back up files from many\ndifferent locations, or when you use some other software to generate the list\nof files to back up.\nThe argument passed to\n--files-from\nmust be the name of a text file that\ncontains one\npattern\nper line. The file must be encoded as UTF-8, or UTF-16\nwith a byte-order mark. Leading and trailing whitespace is removed from the\npatterns. Empty lines and lines starting with a\n#\nare ignored and each\npattern is expanded when read, such that special characters in it are expanded\naccording to the syntax described in the documentation of the Go function\nfilepath.Match\n.\nThe argument passed to\n--files-from-verbatim\nmust be the name of a text file\nthat contains one\npath\nper line, e.g. as generated by GNU\nfind\nwith the\n-print\nflag. Unlike\n--files-from\n,\n--files-from-verbatim\ndoes not\nexpand any special characters in the list of paths, does not strip off any\nwhitespace and does not ignore lines starting with a\n#\n. This option simply\nreads and uses each line as-is, although empty lines are still ignored. Use this\noption when you want to backup a list of filenames containing the special\ncharacters that would otherwise be expanded when using\n--files-from\n.\nThe\n--files-from-raw\noption is a variant of\n--files-from-verbatim\nthat\nrequires each line in the file to be terminated by an ASCII NUL character (the\n\\0\nzero byte) instead of a newline, so that it can even handle file paths\ncontaining newlines in their name or are not encoded as UTF-8 (except on\nWindows, where the listed filenames must still be encoded in UTF-8. This option\nis the safest choice when generating the list of filenames from a script (e.g.\nGNU\nfind\nwith the\n-print0\nflag).\nAll three options interpret the argument\n-\nas standard input and will read\nthe list of files/patterns from there instead of a text file.\nIn all cases, paths may be absolute or relative to\nrestic\nbackup\n’s working\ndirectory.\nFor example, maybe you want to backup files which have a name that matches a\ncertain regular expression pattern (uses GNU\nfind\n):\n$\nfind\n/tmp/some_folder\n-regex\nPATTERN\n-print0\n>\n/tmp/files_to_backup\nYou can then use restic to backup the filtered files:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--files-from-raw\n/tmp/files_to_backup\nYou can combine all three options with each other and with the normal file arguments:\n$\nrestic\nbackup\n--files-from\n/tmp/files_to_backup\n/tmp/some_additional_file\n$\nrestic\nbackup\n--files-from\n/tmp/glob-pattern\n--files-from-raw\n/tmp/generated-list\n/tmp/some_additional_file\nComparing Snapshots\n\nRestic has a\ndiff\ncommand which shows the difference between two snapshots\nand displays a small statistic, just pass the command two snapshot IDs:\n$\nrestic\n-r\n/srv/restic-repo\ndiff\n5845b002\n2ab627a6\ncomparing snapshot ea657ce5 to 2ab627a6:\nM    /restic/cmd_diff.go\n+    /restic/foo\nM    /restic/restic\nFiles:           0 new,     0 removed,     2 changed\nDirs:            1 new,     0 removed\nOthers:          0 new,     0 removed\nData Blobs:     14 new,    15 removed\nTree Blobs:      2 new,     1 removed\nAdded:   16.403 MiB\nRemoved: 16.402 MiB\nTo only compare files in specific subfolders, you can use the\n<snapshot>:<subfolder>\nsyntax, where\nsnapshot\nis the ID of a snapshot (or the string\nlatest\n) and\nsubfolder\nis a path within the snapshot. For example, to only compare files in the\n/restic\nfolder, you could use the following command:\n$\nrestic\n-r\n/srv/restic-repo\ndiff\n5845b002:/restic\n2ab627a6:/restic\nBy default, the\ndiff\ncommand only lists differences in file contents.\nThe flag\n--metadata\nshows changes to file metadata, too.\nThe characters left of the file path show what has changed for this file:\n+\nadded\n-\nremoved\nT\nentry type changed\nM\nfile content changed\nU\nmetadata changed\n?\nbitrot detected\nBacking up special items and metadata\n\nSymlinks\nare archived as symlinks,\nrestic\ndoes not follow them.\nWhen you restore, you get the same symlink again, with the same link target\nand the same timestamps.\nIf there is a\nbind-mount\nbelow a directory that is to be saved, restic descends into it.\nDevice files\nare saved and restored as device files. This means that e.g.\n/dev/sda\nis\narchived as a block device file and restored as such. This also means that the content of the\ncorresponding disk is not read, at least not from the device file.\nBy default, restic does not save the access time (atime) for any files or other\nitems, since it is not possible to reliably disable updating the access time by\nrestic itself. This means that for each new backup a lot of metadata is\nwritten, and the next backup needs to write new metadata again. If you really\nwant to save the access time for files and directories, you can pass the\n--with-atime\noption to the\nbackup\ncommand.\nBacking up full security descriptors on Windows is only possible when the user\nhas\nSeBackupPrivilege\nprivilege or is running as admin. This is a restriction\nof Windows not restic.\nIf either of these conditions are not met, only the owner, group and DACL will\nbe backed up.\nNote that\nrestic\ndoes not back up some metadata associated with files. Of\nparticular note are:\nFile creation date on Unix platforms\nInode flags on Unix platforms\nReading data from a command\n\nSometimes, it can be useful to directly save the output of a program, for example,\nmysqldump\nso that the SQL can later be restored. Restic supports this mode\nof operation; just supply the option\n--stdin-from-command\nwhen using the\nbackup\naction, and write the command in place of the files/directories. To prevent\nrestic from interpreting the arguments for the command, make sure to add\n--\nbefore\nthe command starts:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--stdin-from-command\n--\nmysqldump\n--host\nexample\nmydb\n[\n...\n]\nThis command creates a new snapshot based on the standard output of\nmysqldump\n.\nBy default, the command’s standard output is saved in a file named\nstdin\n.\nA different name can be specified with\n--stdin-filename\n:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--stdin-filename\nproduction.sql\n--stdin-from-command\n--\nmysqldump\n--host\nexample\nmydb\n[\n...\n]\nRestic uses the command exit code to determine whether the command succeeded. A\nnon-zero exit code from the command causes restic to cancel the backup. This causes\nrestic to fail with exit code 1. No snapshot will be created in this case.\nReading data from stdin\n\nWarning\nRestic cannot detect if data read from stdin is complete or not. As explained\nbelow, this can cause incomplete backup unless additional checks (outside of\nrestic) are configured. If possible, use\n--stdin-from-command\ninstead.\nAlternatively, restic supports reading arbitrary data directly from the standard\ninput. Use the option\n--stdin\nof the\nbackup\ncommand as  follows:\n#\nWill\nnot\nnotice\nfailures,\nsee\nthe\nwarning\nbelow\n$\ngzip\nbigfile.dat\n|\nrestic\n-r\n/srv/restic-repo\nbackup\n--stdin\nThis creates a new snapshot of the content of\nbigfile.dat\n.\nAs for\n--stdin-from-command\n, the default file name is\nstdin\n; a\ndifferent name can be specified with\n--stdin-filename\n.\nImportant\n: while it is possible to pipe a command output to restic using\n--stdin\n, doing so is discouraged as it will mask errors from the\ncommand, leading to corrupted backups. For example, in the following code\nblock, if\nmysqldump\nfails to connect to the MySQL database, the restic\nbackup will nevertheless succeed in creating an _empty_ backup:\n#\nWill\nnot\nnotice\nfailures,\nread\nthe\nwarning\nabove\n$\nmysqldump\n[\n...\n]\n|\nrestic\n-r\n/srv/restic-repo\nbackup\n--stdin\nA simple solution is to use\n--stdin-from-command\n(see above). If you\nstill need to use the\n--stdin\nflag, you must use the shell option\nset\n-o\npipefail\n(so that a non-zero exit code from one of the programs in the pipe makes the\nwhole chain return a non-zero exit code) and you must check the exit code of\nthe pipe and act accordingly (e.g., remove the last backup). Refer to the\nUse the Unofficial Bash Strict Mode\nfor more details on this.\nTags for backup\n\nSnapshots can have one or more tags, short strings which add identifying\ninformation. Just specify the tags for a snapshot one by one with\n--tag\n:\n$\nrestic\n-r\n/srv/restic-repo\nbackup\n--tag\nprojectX\n--tag\nfoo\n--tag\nbar\n~/work\n[...]\nThe tags can later be used to keep (or forget) snapshots with the\nforget\ncommand. The command\ntag\ncan be used to modify tags on an existing\nsnapshot.\nScheduling backups\n\nRestic does not have a built-in way of scheduling backups, as it’s a tool\nthat runs when executed rather than a daemon. There are plenty of different\nways to schedule backup runs on various different platforms, e.g. systemd\nand cron on Linux/BSD and Task Scheduler in Windows, depending on one’s\nneeds and requirements. If you don’t want to implement your own scheduling,\nyou can use\nresticprofile\n.\nWhen scheduling restic to run recurringly, please make sure to detect already\nrunning instances before starting the backup.\nSpace requirements\n\nRestic currently assumes that your backup repository has sufficient space\nfor the backup operation you are about to perform. This is a realistic\nassumption for many cloud providers, but may not be true when backing up\nto local disks.\nShould you run out of space during the middle of a backup, there will be\nsome additional data in the repository, but the snapshot will never be\ncreated as it would only be written at the very (successful) end of\nthe backup operation.  Previous snapshots will still be there and will still\nwork.\nExit status codes\n\nRestic returns an exit status code after the backup command is run:\n0 when the backup was successful (snapshot with all source files created)\n1 when there was a fatal error (no snapshot created)\n3 when some source files could not be read (incomplete snapshot with remaining files created)\nfurther exit codes are documented in\nExit codes\n.\nFatal errors occur for example when restic is unable to write to the backup destination, when\nthere are network connectivity issues preventing successful communication, or when an invalid\npassword or command line argument is provided. When restic returns this exit status code, one\nshould not expect a snapshot to have been created.\nSource file read errors occur when restic fails to read one or more files or directories that\nit was asked to back up, e.g. due to permission problems. Restic displays the number of source\nfile read errors that occurred while running the backup. If there are errors of this type,\nrestic will still try to complete the backup run with all the other files, and create a\nsnapshot that then contains all but the unreadable files.\nFor use of these exit status codes in scripts and other automation tools, see\nExit codes\n.\nTo manually inspect the exit code in e.g. Linux, run\necho\n$?\n.\nEnvironment Variables\n\nIn addition to command-line options, restic supports passing various options in\nenvironment variables. The following lists these environment variables:\nRESTIC_REPOSITORY_FILE              Name of file containing the repository location (replaces --repository-file)\nRESTIC_REPOSITORY                   Location of repository (replaces -r)\nRESTIC_PASSWORD_FILE                Location of password file (replaces --password-file)\nRESTIC_PASSWORD                     The actual password for the repository\nRESTIC_PASSWORD_COMMAND             Command printing the password for the repository to stdout\nRESTIC_KEY_HINT                     ID of key to try decrypting first, before other keys\nRESTIC_CACERT                       Location(s) of certificate file(s), comma separated if multiple (replaces --cacert)\nRESTIC_TLS_CLIENT_CERT              Location of TLS client certificate and private key (replaces --tls-client-cert)\nRESTIC_CACHE_DIR                    Location of the cache directory\nRESTIC_COMPRESSION                  Compression mode (only available for repository format version 2)\nRESTIC_HOST                         Only consider snapshots for this host / Set the hostname for the snapshot manually (replaces --host)\nRESTIC_PROGRESS_FPS                 Frames per second by which the progress bar is updated\nRESTIC_PACK_SIZE                    Target size for pack files\nRESTIC_READ_CONCURRENCY             Concurrency for file reads\nTMPDIR                              Location for temporary files (except Windows)\nTMP                                 Location for temporary files (only Windows)\nAWS_ACCESS_KEY_ID                   Amazon S3 access key ID\nAWS_SECRET_ACCESS_KEY               Amazon S3 secret access key\nAWS_SESSION_TOKEN                   Amazon S3 temporary session token\nAWS_DEFAULT_REGION                  Amazon S3 default region\nAWS_PROFILE                         Amazon credentials profile (alternative to specifying key and region)\nAWS_SHARED_CREDENTIALS_FILE         Location of the AWS CLI shared credentials file (default: ~/.aws/credentials)\nRESTIC_AWS_ASSUME_ROLE_ARN          Amazon IAM Role ARN to assume using discovered credentials\nRESTIC_AWS_ASSUME_ROLE_SESSION_NAME Session Name to use with the role assumption\nRESTIC_AWS_ASSUME_ROLE_EXTERNAL_ID  External ID to use with the role assumption\nRESTIC_AWS_ASSUME_ROLE_POLICY       Inline Amazion IAM session policy\nRESTIC_AWS_ASSUME_ROLE_REGION       Region to use for IAM calls for the role assumption (default: us-east-1)\nRESTIC_AWS_ASSUME_ROLE_STS_ENDPOINT URL to the STS endpoint (default is determined based on RESTIC_AWS_ASSUME_ROLE_REGION). You generally do not need to set this, advanced use only.\nAZURE_ACCOUNT_NAME                  Account name for Azure\nAZURE_ACCOUNT_KEY                   Account key for Azure\nAZURE_ACCOUNT_SAS                   Shared access signatures (SAS) for Azure\nAZURE_ENDPOINT_SUFFIX               Endpoint suffix for Azure Storage (default: core.windows.net)\nAZURE_FORCE_CLI_CREDENTIAL          Force the use of Azure CLI credentials for authentication\nB2_ACCOUNT_ID                       Account ID or applicationKeyId for Backblaze B2\nB2_ACCOUNT_KEY                      Account Key or applicationKey for Backblaze B2\nGOOGLE_PROJECT_ID                   Project ID for Google Cloud Storage\nGOOGLE_APPLICATION_CREDENTIALS      Application Credentials for Google Cloud Storage (e.g. $HOME/.config/gs-secret-restic-key.json)\nOS_AUTH_URL                         Auth URL for keystone authentication\nOS_REGION_NAME                      Region name for keystone authentication\nOS_USERNAME                         Username for keystone authentication\nOS_USER_ID                          User ID for keystone v3 authentication\nOS_PASSWORD                         Password for keystone authentication\nOS_TENANT_ID                        Tenant ID for keystone v2 authentication\nOS_TENANT_NAME                      Tenant name for keystone v2 authentication\nOS_USER_DOMAIN_NAME                 User domain name for keystone authentication\nOS_USER_DOMAIN_ID                   User domain ID for keystone v3 authentication\nOS_PROJECT_NAME                     Project name for keystone authentication\nOS_PROJECT_DOMAIN_NAME              Project domain name for keystone authentication\nOS_PROJECT_DOMAIN_ID                Project domain ID for keystone v3 authentication\nOS_TRUST_ID                         Trust ID for keystone v3 authentication\nOS_APPLICATION_CREDENTIAL_ID        Application Credential ID (keystone v3)\nOS_APPLICATION_CREDENTIAL_NAME      Application Credential Name (keystone v3)\nOS_APPLICATION_CREDENTIAL_SECRET    Application Credential Secret (keystone v3)\nOS_STORAGE_URL                      Storage URL for token authentication\nOS_AUTH_TOKEN                       Auth token for token authentication\nRCLONE_BWLIMIT                      rclone bandwidth limit\nRESTIC_REST_USERNAME                Restic REST Server username\nRESTIC_REST_PASSWORD                Restic REST Server password\nST_AUTH                             Auth URL for keystone v1 authentication\nST_USER                             Username for keystone v1 authentication\nST_KEY                              Password for keystone v1 authentication\nSee\nCaching\nfor the rules concerning cache locations when\nRESTIC_CACHE_DIR\nis not set.\nThe external programs that restic may execute include\nrclone\n(for rclone\nbackends) and\nssh\n(for the SFTP backend). These may respond to further\nenvironment variables and configuration files; see their respective manuals.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://restic.readthedocs.io/en/stable/040_backup.html"}}
{"text": "Restoring from backup — restic 0.18.1\ndocumentation\nRestoring from backup\nEdit on GitHub\nRestoring from backup\n\nRestoring from a snapshot\n\nRestoring a snapshot is as easy as it sounds, just use the following\ncommand to restore the contents of the latest snapshot to\n/tmp/restore-work\n:\n$\nrestic\n-r\n/srv/restic-repo\nrestore\n79766175\n--target\n/tmp/restore-work\nenter password for repository:\nrestoring <Snapshot of [/home/user/work] at 2015-05-08 21:40:19.884408621 +0200 CEST> to /tmp/restore-work\nUse the word\nlatest\nto restore the last backup. You can also combine\nlatest\nwith the\n--host\nand\n--path\nfilters to choose the last\nbackup for a specific host, path or both.\n$\nrestic\n-r\n/srv/restic-repo\nrestore\nlatest\n--target\n/tmp/restore-art\n--path\n\"/home/art\"\n--host\nluigi\nenter password for repository:\nrestoring <Snapshot of [/home/art] at 2015-05-08 21:45:17.884408621 +0200 CEST> to /tmp/restore-art\nUse\n--exclude\nand\n--include\nto restrict the restore to a subset of\nfiles in the snapshot. For example, to restore a single file:\n$\nrestic\n-r\n/srv/restic-repo\nrestore\n79766175\n--target\n/tmp/restore-work\n--include\n/work/foo\nenter password for repository:\nrestoring <Snapshot of [/home/user/work] at 2015-05-08 21:40:19.884408621 +0200 CEST> to /tmp/restore-work\nThis will restore the file\nfoo\nto\n/tmp/restore-work/work/foo\n.\nTo only restore a specific subfolder, you can use the\n<snapshot>:<subfolder>\nsyntax, where\nsnapshot\nis the ID of a snapshot (or the string\nlatest\n)\nand\nsubfolder\nis a path within the snapshot.\n$\nrestic\n-r\n/srv/restic-repo\nrestore\n79766175\n:/work\n--target\n/tmp/restore-work\n--include\n/foo\nenter password for repository:\nrestoring <Snapshot of [/home/user/work] at 2015-05-08 21:40:19.884408621 +0200 CEST> to /tmp/restore-work\nThis will restore the file\nfoo\nto\n/tmp/restore-work/foo\n.\nYou can use the command\nrestic\nls\nlatest\nor\nrestic\nfind\nfoo\nto find the\npath to the file within the snapshot. This path you can then pass to\n--include\nin verbatim to only restore the single file or directory.\nThere are case insensitive variants of\n--exclude\nand\n--include\ncalled\n--iexclude\nand\n--iinclude\n. These options will behave the same way but\nignore the casing of paths.\nThere are also\n--include-file\n,\n--exclude-file\n,\n--iinclude-file\nand\n--iexclude-file\nflags that read the include and exclude patterns from a file.\nRestoring symbolic links on windows is only possible when the user has\nSeCreateSymbolicLinkPrivilege\nprivilege or is running as admin. This is a\nrestriction of windows not restic.\nRestoring full security descriptors on Windows is only possible when the user has\nSeRestorePrivilege\n,\nSeSecurityPrivilege\nand\nSeTakeOwnershipPrivilege\nprivilege or is running as admin. This is a restriction of Windows not restic.\nIf either of these conditions are not met, only the DACL will be restored.\nBy default, restic does not restore files as sparse. Use\nrestore\n--sparse\nto\nenable the creation of sparse files if supported by the filesystem. Then restic\nwill restore long runs of zero bytes as holes in the corresponding files.\nReading from a hole returns the original zero bytes, but it does not consume\ndisk space. Note that the exact location of the holes can differ from those in\nthe original file, as their location is determined while restoring and is not\nstored explicitly.\nRestoring extended file attributes\n\nBy default, all extended attributes for files are restored.\nUse only\n--exclude-xattr\nor\n--include-xattr\nto control which extended\nattributes are restored for files in the snapshot. For example, to restore\nuser and security namespaced extended attributes for files:\n$\nrestic\n-r\n/srv/restic-repo\nrestore\n79766175\n--target\n/tmp/restore-work\n--include-xattr\nuser.*\n--include-xattr\nsecurity.*\nenter password for repository:\nrestoring <Snapshot of [/home/user/work] at 2015-05-08 21:40:19.884408621 +0200 CEST> to /tmp/restore-work\nRestoring in-place\n\nNote\nRestoring data in-place can leave files in a partially restored state if the\nrestore\noperation is interrupted. To ensure you can revert back to the previous state, create\na current\nbackup\nbefore restoring a different snapshot.\nBy default, the\nrestore\ncommand overwrites already existing files at the target\ndirectory. This behavior can be configured via the\n--overwrite\noption. The following\nvalues are supported:\n--overwrite\nalways\n(default): always overwrites already existing files.\nrestore\nwill verify the existing file content and only restore mismatching parts to minimize\ndownloads. Updates the metadata of all files.\n--overwrite\nif-changed\n: like the previous case, but speeds up the file content check\nby assuming that files with matching size and modification time (mtime) are already up to date.\nIn case of a mismatch, the full file content is verified. Updates the metadata of all files.\n--overwrite\nif-newer\n: only overwrite existing files if the file in the snapshot has a\nnewer modification time (mtime).\n--overwrite\nnever\n: never overwrite existing files.\nDelete files not in snapshot\n\nWhen restoring into a directory that already contains files, it can be useful to remove all\nfiles that do not exist in the snapshot. For this, pass the\n--delete\noption to the\nrestore\ncommand. The command will then\ndelete all files\nfrom the target directory that do not\nexist in the snapshot.\nThe\n--delete\noption also allows overwriting a non-empty directory if the snapshot contains a\nfile with the same name.\nWarning\nAlways use the\n--dry-run\n-vv\noption to verify what would be deleted before running the actual\ncommand.\nWhen specifying\n--include\nor\n--exclude\noptions, only files or directories matched by those\noptions will be deleted. For example, the command\nrestic\n-r\n/srv/restic-repo\nrestore\n79766175:/work\n--target\n/tmp/restore-work\n--include\n/foo\n--delete\nwould only delete files within\n/tmp/restore-work/foo\n.\nWhen using\n--target\n/\n--delete\nthen the\nrestore\ncommand only works if either an\n--include\nor\n--exclude\noption is also specified. This ensures that one cannot accidentally delete\nthe whole system.\nDry run\n\nAs restore operations can take a long time, it can be useful to perform a dry-run to\nsee what would be restored without having to run the full restore operation. The\nrestore command supports the\n--dry-run\noption and prints information about the\nrestored files when specifying\n--verbose=2\n.\n$\nrestic\nrestore\n--target\n/tmp/restore-work\n--dry-run\n--verbose\n=\n2\nlatest\nunchanged /restic/internal/walker/walker.go with size 2.812 KiB\nupdated   /restic/internal/walker/walker_test.go with size 11.143 KiB\nrestored  /restic/restic with size 35.318 MiB\nrestored  /restic\n[...]\nSummary: Restored 9072 files/dirs (153.597 MiB) in 0:00\nFiles with already up to date content are reported as\nunchanged\n. Files whose content\nwas modified are\nupdated\nand files that are new are shown as\nrestored\n. Directories\nand other file types like symlinks are always reported as\nrestored\n.\nTo reliably determine which files would be updated, a dry-run also verifies the content of\nalready existing files according to the specified overwrite behavior. To skip these checks\neither specify\n--overwrite\nnever\nor specify a non-existing\n--target\ndirectory.\nRestore using mount\n\nBrowsing your backup as a regular file system is also very easy. First,\ncreate a mount point such as\n/mnt/restic\nand then use the following\ncommand to serve the repository with FUSE:\n$\nmkdir\n/mnt/restic\n$\nrestic\n-r\n/srv/restic-repo\nmount\n/mnt/restic\nenter password for repository:\nNow serving /srv/restic-repo at /mnt/restic\nUse another terminal or tool to browse the contents of this folder.\nWhen finished, quit with Ctrl-c here or umount the mountpoint.\nMounting repositories via FUSE is only possible on Linux, macOS and FreeBSD.\nOn Linux, the\nfuse\nkernel module needs to be loaded and the\nfusermount\ncommand needs to be in the\nPATH\n. On macOS, you need\nFUSE-T\nor\nFUSE for macOS\n.\nOn FreeBSD, you may need to install FUSE and load the kernel module (\nkldload\nfuse\n).\nRestic supports storage and preservation of hard links. However, since\nhard links exist in the scope of a filesystem by definition, restoring\nhard links from a fuse mount should be done by a program that preserves\nhard links. A program that does so is\nrsync\n, used with the option\n--hard-links\n.\nNote\nrestic\nmount\nis mostly useful if you want to restore just a few\nfiles out of a snapshot, or to check which files are contained in a snapshot.\nTo restore many files or a whole snapshot,\nrestic\nrestore\nis the best\nalternative, often it is\nsignificantly\nfaster.\nPrinting files to stdout\n\nSometimes it’s helpful to print files to stdout so that other programs can read\nthe data directly. This can be achieved by using the\ndump\ncommand, like this:\n$\nrestic\n-r\n/srv/restic-repo\ndump\nlatest\nproduction.sql\n|\nmysql\nIf you have saved multiple different things into the same repo, the\nlatest\nsnapshot may not be the right one. For example, consider the following\nsnapshots in a repository:\n$\nrestic\n-r\n/srv/restic-repo\nsnapshots\nID        Date                 Host        Tags        Directory\n----------------------------------------------------------------------\n562bfc5e  2018-07-14 20:18:01  mopped                  /home/user/file1\nbbacb625  2018-07-14 20:18:07  mopped                  /home/other/work\ne922c858  2018-07-14 20:18:10  mopped                  /home/other/work\n098db9d5  2018-07-14 20:18:13  mopped                  /production.sql\nb62f46ec  2018-07-14 20:18:16  mopped                  /home/user/file1\n1541acae  2018-07-14 20:18:18  mopped                  /home/other/work\n----------------------------------------------------------------------\nHere, restic would resolve\nlatest\nto the snapshot\n1541acae\n, which does\nnot contain the file we’d like to print at all (\nproduction.sql\n).  In this\ncase, you can pass restic the snapshot ID of the snapshot you like to restore:\n$\nrestic\n-r\n/srv/restic-repo\ndump\n098db9d5\nproduction.sql\n|\nmysql\nOr you can pass restic a path that should be used for selecting the latest\nsnapshot. The path must match the patch printed in the “Directory” column,\ne.g.:\n$\nrestic\n-r\n/srv/restic-repo\ndump\n--path\n/production.sql\nlatest\nproduction.sql\n|\nmysql\nIt is also possible to\ndump\nthe contents of a whole folder structure to\nstdout. To retain the information about the files and folders Restic will\noutput the contents in the tar (default) or zip format:\n$\nrestic\n-r\n/srv/restic-repo\ndump\nlatest\n/home/other/work\n>\nrestore.tar\n$\nrestic\n-r\n/srv/restic-repo\ndump\n-a\nzip\nlatest\n/home/other/work\n>\nrestore.zip\nThe folder content is then contained at\n/home/other/work\nwithin the archive.\nTo include the folder content at the root of the archive, you can use the\n<snapshot>:<subfolder>\nsyntax:\n$\nrestic\n-r\n/srv/restic-repo\ndump\nlatest:/home/other/work\n/\n>\nrestore.tar\nIt is also possible to\ndump\nthe contents of a selected snapshot and folder\nstructure to a file using the\n--target\nflag.\n$\nrestic\n-r\n/srv/restic-repo\ndump\nlatest\n/\n--target\n/home/linux.user/output.tar\n-a\ntar", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://restic.readthedocs.io/en/stable/050_restore.html"}}
{"text": "Documentation\nUsage\nRclone is a command line program to manage files on cloud storage.\nAfter\ndownload\nand\ninstall\n, continue\nhere to learn how to use it: Initial\nconfiguration\n,\nwhat the\nbasic syntax\nlooks like, describes the\nvarious\nsubcommands\n, the various\noptions\n,\nand more.\nConfigure\nFirst, you'll need to configure rclone.  As the object storage systems\nhave quite complicated authentication these are kept in a config file.\n(See the\n--config\nentry for how to find the config\nfile and choose its location.)\nThe easiest way to make the config is to run rclone with the config\noption:\nrclone config\nSee the following for detailed instructions for\n1Fichier\nAkamai Netstorage\nAlias\nArchive\nAmazon S3\nBackblaze B2\nBox\nChunker\n- transparently splits large files for other remotes\nCitrix ShareFile\nCompress\nCloudinary\nCombine\nCrypt\n- to encrypt other remotes\nDigitalOcean Spaces\nDigi Storage\nDropbox\nEnterprise File Fabric\nFileLu Cloud Storage\nFiles.com\nFTP\nGofile\nGoogle Cloud Storage\nGoogle Drive\nGoogle Photos\nHasher\n- to handle checksums for other remotes\nHDFS\nHetzner Storage Box\nHiDrive\nHTTP\niCloud Drive\nInternet Archive\nJottacloud\nKoofr\nLinkbox\nMail.ru Cloud\nMega\nMemory\nMicrosoft Azure Blob Storage\nMicrosoft Azure Files Storage\nMicrosoft OneDrive\nOpenStack Swift / Rackspace Cloudfiles / Blomp Cloud Storage / Memset Memstore\nOpenDrive\nOracle Object Storage\nPcloud\nPikPak\nPixeldrain\npremiumize.me\nput.io\nProton Drive\nQingStor\nQuatrix by Maytech\nrsync.net\nSeafile\nSFTP\nSia\nSMB\nStorj\nSugarSync\nUnion\nUloz.to\nUptobox\nWebDAV\nYandex Disk\nZoho WorkDrive\nThe local filesystem\nBasic syntax\nRclone syncs a directory tree from one storage system to another.\nIts syntax is like this\nrclone subcommand [options] <parameters> <parameters...>\nA\nsubcommand\nis an rclone operation required (e.g.\nsync\n,\ncopy\n,\nls\n).\nAn\noption\nis a single letter flag (e.g.\n-v\n) or a group of single\nletter flags (e.g.\n-Pv\n) or a long flag (e.g.\n--progress\n). No\noptions are required. Options can come after the\nsubcommand\nor in\nbetween parameters too or on the end, but only global options can be\nused before the\nsubcommand\n. Anything after a\n--\noption will not be\ninterpreted as an option so if you need to add a parameter which\nstarts with a\n-\nthen put a\n--\non its own first, eg\nrclone lsf -- -directory-starting-with-dash\nA\nparameter\nis usually a file path or\nrclone remote\n,\neg\n/path/to/file\nor\nremote:path/to/file\nbut it can be other things -\nthe\nsubcommand\nhelp will tell you what.\nSource and destination paths are specified by the name you gave the\nstorage system in the config file then the sub path, e.g.\n\"drive:myfolder\" to look at \"myfolder\" in Google drive.\nYou can define as many storage paths as you like in the config file.\nPlease use the\n--interactive\n/\n-i\nflag while\nlearning rclone to avoid accidental data loss.\nSubcommands\nrclone uses a system of subcommands. For example\nrclone ls remote:path # lists a remote\nrclone copy /local/path remote:path # copies /local/path to the remote\nrclone sync --interactive /local/path remote:path # syncs /local/path to the remote\nThe main rclone commands with most used first\nrclone config\n- Enter an interactive configurationsession.\nrclone copy\n- Copy files from source to dest, skipping already copied.\nrclone sync\n- Make source and dest identical, modifying destination only.\nrclone bisync\n-\nBidirectional synchronization\nbetween two paths.\nrclone move\n- Move files from source to dest.\nrclone delete\n- Remove the contents of path.\nrclone purge\n- Remove the path and all of its contents.\nrclone mkdir\n- Make the path if it doesn't already exist.\nrclone rmdir\n- Remove the path.\nrclone rmdirs\n- Remove any empty directories under the path.\nrclone check\n- Check if the files in the source and destination match.\nrclone ls\n- List all the objects in the path with size and path.\nrclone lsd\n- List all directories/containers/buckets in the path.\nrclone lsl\n- List all the objects in the path with size, modification time and path.\nrclone md5sum\n- Produce an md5sum file for all the objects in the path.\nrclone sha1sum\n- Produce a sha1sum file for all the objects in the path.\nrclone size\n- Return the total size and number of objects in remote:path.\nrclone version\n- Show the version number.\nrclone cleanup\n- Clean up the remote if possible.\nrclone dedupe\n- Interactively find duplicate files and delete/rename them.\nrclone authorize\n- Remote authorization.\nrclone cat\n- Concatenate any files and send them to stdout.\nrclone copyto\n- Copy files from source to dest, skipping already copied.\nrclone completion\n- Output shell completion scripts for rclone.\nrclone gendocs\n- Output markdown docs for rclone to the directory supplied.\nrclone listremotes\n- List all the remotes in the config file.\nrclone mount\n- Mount the remote as a mountpoint.\nrclone moveto\n- Move file or directory from source to dest.\nrclone obscure\n- Obscure password for use in the rclone.conf\nrclone cryptcheck\n- Check the integrity of an encrypted remote.\nrclone about\n- Get quota information from the remote.\nSee the\ncommands index\nfor the full list.\nCopying single files\nrclone normally syncs or copies directories.  However, if the source\nremote points to a file, rclone will just copy that file.  The\ndestination remote must point to a directory - rclone will give the\nerror\nFailed to create file system for \"remote:file\": is a file not a directory\nif it isn't.\nFor example, suppose you have a remote with a file in called\ntest.jpg\n, then you could copy just that file like this\nrclone copy remote:test.jpg /tmp/download\nThe file\ntest.jpg\nwill be placed inside\n/tmp/download\n.\nThis is equivalent to specifying\nrclone copy --files-from /tmp/files remote: /tmp/download\nWhere\n/tmp/files\ncontains the single line\ntest.jpg\nIt is recommended to use\ncopy\nwhen copying individual files, not\nsync\n.\nThey have pretty much the same effect but\ncopy\nwill use a lot less\nmemory.\nSyntax of remote paths\nThe syntax of the paths passed to the rclone command are as follows.\n/path/to/dir\nThis refers to the local file system.\nOn Windows\n\\\nmay be used instead of\n/\nin local paths\nonly\n,\nnon local paths must use\n/\n. See\nlocal filesystem\ndocumentation for more about Windows-specific paths.\nThese paths needn't start with a leading\n/\n- if they don't then they\nwill be relative to the current directory.\nremote:path/to/dir\nThis refers to a directory\npath/to/dir\non\nremote:\nas defined in\nthe config file (configured with\nrclone config\n).\nremote:/path/to/dir\nOn most backends this is refers to the same directory as\nremote:path/to/dir\nand that format should be preferred.  On a very\nsmall number of remotes (FTP, SFTP, Dropbox for business) this will\nrefer to a different directory.  On these, paths without a leading\n/\nwill refer to your \"home\" directory and paths with a leading\n/\nwill\nrefer to the root.\n:backend:path/to/dir\nThis is an advanced form for creating remotes on the fly.\nbackend\nshould be the name or prefix of a backend (the\ntype\nin the config\nfile) and all the configuration for the backend should be provided on\nthe command line (or in environment variables).\nHere are some examples:\nrclone lsd --http-url https://pub.rclone.org :http:\nTo list all the directories in the root of\nhttps://pub.rclone.org/\n.\nrclone lsf --http-url https://example.com :http:path/to/dir\nTo list files and directories in\nhttps://example.com/path/to/dir/\nrclone copy --http-url https://example.com :http:path/to/dir /tmp/dir\nTo copy files and directories in\nhttps://example.com/path/to/dir\nto\n/tmp/dir\n.\nrclone copy --sftp-host example.com :sftp:path/to/dir /tmp/dir\nTo copy files and directories from\nexample.com\nin the relative\ndirectory\npath/to/dir\nto\n/tmp/dir\nusing sftp.\nConnection strings\nThe above examples can also be written using a connection string\nsyntax, so instead of providing the arguments as command line\nparameters\n--http-url https://pub.rclone.org\nthey are provided as\npart of the remote specification as a kind of connection string.\nrclone lsd \":http,url='https://pub.rclone.org':\"\nrclone lsf \":http,url='https://example.com':path/to/dir\"\nrclone copy \":http,url='https://example.com':path/to/dir\" /tmp/dir\nrclone copy :sftp,host=example.com:path/to/dir /tmp/dir\nThese can apply to modify existing remotes as well as create new\nremotes with the on the fly syntax. This example is equivalent to\nadding the\n--drive-shared-with-me\nparameter to the remote\ngdrive:\n.\nrclone lsf \"gdrive,shared_with_me:path/to/dir\"\nThe major advantage to using the connection string style syntax is\nthat it only applies to the remote, not to all the remotes of that\ntype of the command line. A common confusion is this attempt to copy a\nfile shared on google drive to the normal drive which\ndoes not\nwork\nbecause the\n--drive-shared-with-me\nflag applies to both the\nsource and the destination.\nrclone copy --drive-shared-with-me gdrive:shared-file.txt gdrive:\nHowever using the connection string syntax, this does work.\nrclone copy \"gdrive,shared_with_me:shared-file.txt\" gdrive:\nNote that the connection string only affects the options of the immediate\nbackend. If for example gdriveCrypt is a crypt based on gdrive, then the\nfollowing command\nwill not work\nas intended, because\nshared_with_me\nis ignored by the crypt backend:\nrclone copy \"gdriveCrypt,shared_with_me:shared-file.txt\" gdriveCrypt:\nThe connection strings have the following syntax\nremote,parameter=value,parameter2=value2:path/to/dir\n:backend,parameter=value,parameter2=value2:path/to/dir\nIf the\nparameter\nhas a\n:\nor\n,\nthen it must be placed in quotes\n\"\nor\n'\n, so\nremote,parameter=\"colon:value\",parameter2=\"comma,value\":path/to/dir\n:backend,parameter='colon:value',parameter2='comma,value':path/to/dir\nIf a quoted value needs to include that quote, then it should be\ndoubled, so\nremote,parameter=\"with\"\"quote\",parameter2='with''quote':path/to/dir\nThis will make\nparameter\nbe\nwith\"quote\nand\nparameter2\nbe\nwith'quote\n.\nIf you leave off the\n=parameter\nthen rclone will substitute\n=true\nwhich works very well with flags. For example, to use s3 configured in\nthe environment you could use:\nrclone lsd :s3,env_auth:\nWhich is equivalent to\nrclone lsd :s3,env_auth=true:\nNote that on the command line you might need to surround these\nconnection strings with\n\"\nor\n'\nto stop the shell interpreting any\nspecial characters within them.\nIf you are a shell master then you'll know which strings are OK and\nwhich aren't, but if you aren't sure then enclose them in\n\"\nand use\n'\nas the inside quote. This syntax works on all OSes.\nrclone copy \":http,url='https://example.com':path/to/dir\" /tmp/dir\nOn Linux/macOS some characters are still interpreted inside\n\"\nstrings in the shell (notably\n\\\nand\n$\nand\n\"\n) so if your strings\ncontain those you can swap the roles of\n\"\nand\n'\nthus. (This syntax\ndoes not work on Windows.)\nrclone copy ':http,url=\"https://example.com\":path/to/dir' /tmp/dir\nYou can use\nrclone config string\nto\nconvert a remote into a connection string.\nConnection strings, config and logging\nIf you supply extra configuration to a backend by command line flag,\nenvironment variable or connection string then rclone will add a\nsuffix based on the hash of the config to the name of the remote, eg\nrclone -vv lsf --s3-chunk-size 20M s3:\nHas the log message\nDEBUG : s3: detected overridden config - adding \"{Srj1p}\" suffix to name\nThis is so rclone can tell the modified remote apart from the\nunmodified remote when caching the backends.\nThis should only be noticeable in the logs.\nThis means that on the fly backends such as\nrclone -vv lsf :s3,env_auth:\nWill get their own names\nDEBUG : :s3: detected overridden config - adding \"{YTu53}\" suffix to name\nValid remote names\nRemote names are case sensitive, and must adhere to the following rules:\nMay contain number, letter,\n_\n,\n-\n,\n.\n,\n+\n,\n@\nand space.\nMay not start with\n-\nor space.\nMay not end with space.\nStarting with rclone version 1.61, any Unicode numbers and letters are allowed,\nwhile in older versions it was limited to plain ASCII (0-9, A-Z, a-z). If you use\nthe same rclone configuration from different shells, which may be configured with\ndifferent character encoding, you must be cautious to use characters that are\npossible to write in all of them. This is mostly a problem on Windows, where\nthe console traditionally uses a non-Unicode character set - defined\nby the so-called \"code page\".\nDo not use single character names on Windows as it creates ambiguity with Windows\ndrives' names, e.g.: remote called\nC\nis indistinguishable from\nC\ndrive. Rclone\nwill always assume that single letter name refers to a drive.\nAdding global configuration to a remote\nIt is possible to add global configuration to the remote configuration which\nwill be applied just before the remote is created.\nThis can be done in two ways. The first is to use\noverride.var = value\nin the\nconfig file or the connection string for a temporary change, and the second is\nto use\nglobal.var = value\nin the config file or connection string for a\npermanent change.\nThis is explained fully below.\noverride.var\nThis is used to override a global variable\njust\nfor the duration of the\nremote creation. It won't affect other remotes even if they are created at the\nsame time.\nThis is very useful for overriding networking config needed for just for that\nremote. For example, say you have a remote which needs\n--no-check-certificate\nas it is running on test infrastructure without a proper certificate. You could\nsupply the\n--no-check-certificate\nflag to rclone, but this will affect\nall\nthe remotes. To make it just affect this remote you use an override. You could\nput this in the config file:\n[remote]\ntype\n=\nXXX\n...\noverride.no_check_certificate\n=\ntrue\nor use it in the connection string\nremote,override.no_check_certificate=true:\n(or just\nremote,override.no_check_certificate:\n).\nNote how the global flag name loses its initial\n--\nand gets\n-\nreplaced with\n_\nand gets an\noverride.\nprefix.\nNot all global variables make sense to be overridden like this as the config is\nonly applied during the remote creation. Here is a non exhaustive list of ones\nwhich might be useful:\nbind_addr\nca_cert\nclient_cert\nclient_key\nconnect_timeout\ndisable_http2\ndisable_http_keep_alives\ndump\nexpect_continue_timeout\nheaders\nhttp_proxy\nlow_level_retries\nmax_connections\nno_check_certificate\nno_gzip\ntimeout\ntraffic_class\nuse_cookies\nuse_server_modtime\nuser_agent\nAn\noverride.var\nwill override all other config methods, but\njust\nfor the\nduration of the creation of the remote.\nglobal.var\nThis is used to set a global variable\nfor everything\n. The global variable is\nset just before the remote is created.\nThis is useful for parameters (eg sync parameters) which can't be set as an\noverride\n. For example, say you have a remote where you would always like to\nuse the\n--checksum\nflag. You could supply the\n--checksum\nflag to rclone on\nevery command line, but instead you could put this in the config file:\n[remote]\ntype\n=\nXXX\n...\nglobal.checksum\n=\ntrue\nor use it in the connection string\nremote,global.checksum=true:\n(or just\nremote,global.checksum:\n). This is equivalent to using the\n--checksum\nflag.\nNote how the global flag name loses its initial\n--\nand gets\n-\nreplaced with\n_\nand gets a\nglobal.\nprefix.\nAny global variable can be set like this and it is exactly equivalent to using\nthe equivalent flag on the command line. This means it will affect all uses of\nrclone.\nIf two remotes set the same global variable then the first one instantiated will\nbe overridden by the second one. A\nglobal.var\nwill override all other config\nmethods when the remote is created.\nQuoting and the shell\nWhen you are typing commands to your computer you are using something\ncalled the command line shell.  This interprets various characters in\nan OS specific way.\nHere are some gotchas which may help users unfamiliar with the shell rules\nLinux / macOS\nIf your names have spaces or shell metacharacters (e.g.\n*\n,\n?\n,\n$\n,\n'\n,\n\"\n, etc.) then you must quote them.  Use single quotes\n'\nby default.\nrclone copy 'Important files?' remote:backup\nIf you want to send a\n'\nyou will need to use\n\"\n, e.g.\nrclone copy \"O'Reilly Reviews\" remote:backup\nThe rules for quoting metacharacters are complicated and if you want\nthe full details you'll have to consult the manual page for your\nshell.\nWindows\nIf your names have spaces in you need to put them in\n\"\n, e.g.\nrclone copy\n\"E:\\folder name\\folder name\\folder name\"\nremote:backup\nIf you are using the root directory on its own then don't quote it\n(see\n#464\nfor why), e.g.\nrclone copy E:\\ remote:backup\nCopying files or directories with\n:\nin the names\nrclone uses\n:\nto mark a remote name.  This is, however, a valid\nfilename component in non-Windows OSes.  The remote name parser will\nonly search for a\n:\nup to the first\n/\nso if you need to act on a\nfile or directory like this then use the full path starting with a\n/\n, or use\n./\nas a current directory prefix.\nSo to sync a directory called\nsync:me\nto a remote called\nremote:\nuse\nrclone sync --interactive ./sync:me remote:path\nor\nrclone sync --interactive /full/path/to/sync:me remote:path\nServer-side copy\nMost remotes (but not all - see\nthe\noverview\n) support server-side copy.\nThis means if you want to copy one folder to another then rclone won't\ndownload all the files and re-upload them; it will instruct the server\nto copy them in place.\nEg\nrclone copy s3:oldbucket s3:newbucket\nWill copy the contents of\noldbucket\nto\nnewbucket\nwithout\ndownloading and re-uploading.\nRemotes which don't support server-side copy\nwill\ndownload and\nre-upload in this case.\nServer-side copies are used with\nsync\nand\ncopy\nand will be\nidentified in the log when using the\n-v\nflag.  The\nmove\ncommand\nmay also use them if remote doesn't support server-side move directly.\nThis is done by issuing a server-side copy then a delete which is much\nquicker than a download and re-upload.\nServer-side copies will only be attempted if the remote names are the\nsame.\nThis can be used when scripting to make aged backups efficiently, e.g.\nrclone sync --interactive remote:current-backup remote:previous-backup\nrclone sync --interactive /path/to/files remote:current-backup\nMetadata support\nMetadata is data about a file (or directory) which isn't the contents\nof the file (or directory). Normally rclone only preserves the\nmodification time and the content (MIME) type where possible.\nRclone supports preserving all the available metadata on files and\ndirectories when using the\n--metadata\nor\n-M\nflag.\nExactly what metadata is supported and what that support means depends\non the backend. Backends that support metadata have a metadata section\nin their docs and are listed in the\nfeatures table\n(Eg\nlocal\n,\ns3\n)\nSome backends don't support metadata, some only support metadata on\nfiles and some support metadata on both files and directories.\nRclone only supports a one-time sync of metadata. This means that\nmetadata will be synced from the source object to the destination\nobject only when the source object has changed and needs to be\nre-uploaded. If the metadata subsequently changes on the source object\nwithout changing the object itself then it won't be synced to the\ndestination object. This is in line with the way rclone syncs\nContent-Type\nwithout the\n--metadata\nflag.\nUsing\n--metadata\nwhen syncing from local to local will preserve file\nattributes such as file mode, owner, extended attributes (not\nWindows).\nNote that arbitrary metadata may be added to objects using the\n--metadata-set key=value\nflag when the object is first uploaded.\nThis flag can be repeated as many times as necessary.\nThe\n--metadata-mapper\nflag can be used to pass the\nname of a program in which can transform metadata when it is being\ncopied from source to destination.\nRclone supports\n--metadata-set\nand\n--metadata-mapper\nwhen doing\nserver-side\nMove\nand server-side\nCopy\n, but not when doing server\nside\nDirMove\n(renaming a directory) as this would involve recursing\ninto the directory. Note that you can disable\nDirMove\nwith\n--disable DirMove\nand rclone will revert back to using\nMove\nfor\neach individual object where\n--metadata-set\nand\n--metadata-mapper\nare supported.\nTypes of metadata\nMetadata is divided into two type. System metadata and User metadata.\nMetadata which the backend uses itself is called system metadata. For\nexample on the local backend the system metadata\nuid\nwill store the\nuser ID of the file when used on a unix based platform.\nArbitrary metadata is called user metadata and this can be set however\nis desired.\nWhen objects are copied from backend to backend, they will attempt to\ninterpret system metadata if it is supplied. Metadata may change from\nbeing user metadata to system metadata as objects are copied between\ndifferent backends. For example copying an object from s3 sets the\ncontent-type\nmetadata. In a backend which understands this (like\nazureblob\n) this will become the Content-Type of the object. In a\nbackend which doesn't understand this (like the\nlocal\nbackend) this\nwill become user metadata. However should the local object be copied\nback to s3, the Content-Type will be set correctly.\nMetadata framework\nRclone implements a metadata framework which can read metadata from an\nobject and write it to the object when (and only when) it is being\nuploaded.\nThis metadata is stored as a dictionary with string keys and string\nvalues.\nThere are some limits on the names of the keys (these may be clarified\nfurther in the future).\nmust be lower case\nmay be\na-z\n0-9\ncontaining\n.\n-\nor\n_\nlength is backend dependent\nEach backend can provide system metadata that it understands. Some\nbackends can also store arbitrary user metadata.\nWhere possible the key names are standardized, so, for example, it is\npossible to copy object metadata from s3 to azureblob for example and\nmetadata will be translated appropriately.\nSome backends have limits on the size of the metadata and rclone will\ngive errors on upload if they are exceeded.\nMetadata preservation\nThe goal of the implementation is to\nPreserve metadata if at all possible\nInterpret metadata if at all possible\nThe consequences of 1 is that you can copy an S3 object to a local\ndisk then back to S3 losslessly. Likewise you can copy a local file\nwith file attributes and xattrs from local disk to s3 and back again\nlosslessly.\nThe consequence of 2 is that you can copy an S3 object with metadata\nto Azureblob (say) and have the metadata appear on the Azureblob\nobject also.\nStandard system metadata\nHere is a table of standard system metadata which, if appropriate, a\nbackend may implement.\nkey\ndescription\nexample\nmode\nFile type and mode: octal, unix style\n0100664\nuid\nUser ID of owner: decimal number\n500\ngid\nGroup ID of owner: decimal number\n500\nrdev\nDevice ID (if special file)  => hexadecimal\n0\natime\nTime of last access:  RFC 3339\n2006-01-02T15:04:05.999999999Z07:00\nmtime\nTime of last modification:  RFC 3339\n2006-01-02T15:04:05.999999999Z07:00\nbtime\nTime of file creation (birth):  RFC 3339\n2006-01-02T15:04:05.999999999Z07:00\nutime\nTime of file upload:  RFC 3339\n2006-01-02T15:04:05.999999999Z07:00\ncache-control\nCache-Control header\nno-cache\ncontent-disposition\nContent-Disposition header\ninline\ncontent-encoding\nContent-Encoding header\ngzip\ncontent-language\nContent-Language header\nen-US\ncontent-type\nContent-Type header\ntext/plain\nThe metadata keys\nmtime\nand\ncontent-type\nwill take precedence if\nsupplied in the metadata over reading the\nContent-Type\nor\nmodification time of the source object.\nHashes are not included in system metadata as there is a well defined\nway of reading those already.\nOptions\nRclone has a number of options to control its behaviour. These are\ndocumented below, and in the\nflags\npage.\nOptions that take parameters can have the values passed in two ways,\n--option=value\nor\n--option value\n. However boolean (true/false)\noptions behave slightly differently to the other options in that\n--boolean\nsets the option to\ntrue\nand the absence of the flag sets\nit to\nfalse\n.  It is also possible to specify\n--boolean=false\nor\n--boolean=true\n.  Note that\n--boolean false\nis not valid - this is\nparsed as\n--boolean\nand the\nfalse\nis parsed as an extra command\nline argument for rclone.\nString values that are recognized as special identifiers, e.g. the\nname of the log level to set with option\n--log-level\n, are case\ninsensitive, e.g.\n--log-level ERROR\nand\n--log-level error\nare\nidentical.\nOptions documented to take a\nstringArray\nparameter accept multiple\nvalues. To pass more than one value, repeat the option; for example:\n--include value1 --include value2\n. Other options may only accept a\nsingle value, and should only be specified once, but where the\nspecified parameter may indicate a list of values separated by space\nor comma. Such options are documented to take a\nCommaSepList\nparameter, if comma separated, and\nSpaceSepList\nif space separated,\nalthough some may also have different parameters such as\nDumpFlags\nor just\nstring\nand the help text explains that this will be\ninterpreted as a list.\nFloating-point values with fractional part must use period (\n.\n)\nas decimal separator, common in English-speaking countries, regardless\nof your configured system locale. Parameter type\nfloat\naccepts decimal\nand hexadecimal floating-point numbers as defined by the Go syntax for\nfloating-point literals\n.\nTime and duration options\nOptions that take a\nTime\nor\nDuration\nparameter must be specified\nas a formatted string describing an absolute or relative time. Note\nthat both\nTime\nand\nDuration\nparameter types can be expressed as\neither absolute or relative time, just with different interpretations,\ne.g. a relative time will be treated as an offset from the current time\nwhen passed as a\nTime\nvalue.\nAn absolute time can be specified as a string in one of the following formats:\nRFC3339 - e.g.\n2006-01-02T15:04:05Z\nor\n2006-01-02T15:04:05+07:00\nISO8601 Date and time, local timezone -\n2006-01-02T15:04:05\nISO8601 Date and time, local timezone -\n2006-01-02 15:04:05\nISO8601 Date -\n2006-01-02\n(YYYY-MM-DD)\nA relative time is a string with a, possibly signed, sequence of decimal\nnumbers, each with optional fraction, and each with a unit suffix. If\nthe string only contains a single number, then the unit suffix is optional\nand will default to seconds, i.e. a plain decimal value will be treated\nas a number of seconds. The following suffixes are valid:\nms\n- Milliseconds\ns\n- Seconds\nm\n- Minutes\nh\n- Hours\nd\n- Days\nw\n- Weeks\nM\n- Months\ny\n- Years\nExamples: \"10\", \"300ms\", \"-1.5h\" or \"2h45m\".\nSize options\nOptions that take a SizeSuffix parameter can be specified as an\ninteger value, which will then be assumed to represent a KiB\nvalue (multiples of 1024 bytes) by default. The interpretation\ncan be changed by appending a suffix:\nB\nfor Byte,\nK\nfor KiB,\nM\nfor MiB,\nG\nfor GiB,\nT\nfor TiB and\nP\nfor PiB. These are\nthe binary units, e.g. 1, 2**10, 2**20, 2**30 respectively.\nSee also\n--human-readable\n.\nMain options\n--backup-dir string\nWhen using\nsync\n,\ncopy\nor\nmove\n, any files which would have been overwritten\nor deleted are moved in their original hierarchy into this directory.\nIf\n--suffix\nis set, then the moved files will have the suffix added\nto them. If there is a file with the same path (after the suffix has\nbeen added) in the directory, then it will be overwritten.\nThe remote in use must support server-side move or copy and you must\nuse the same remote as the destination of the sync. The backup\ndirectory must not overlap the destination directory without it being\nexcluded by a filter rule.\nFor example\nrclone sync --interactive /path/to/local remote:current --backup-dir remote:old\nwill sync\n/path/to/local\nto\nremote:current\n, but for any files\nwhich would have been updated or deleted will be stored in\nremote:old\n.\nIf running rclone from a script you might want to use today's date as\nthe directory name passed to\n--backup-dir\nto store the old files, or\nyou might want to pass\n--suffix\nwith today's date. This can be done\nwith\n--suffix $(date +%F)\nin bash, and\n--suffix $(Get-Date -Format 'yyyy-MM-dd')\nin PowerShell.\nSee\n--compare-dest\nand\n--copy-dest\n.\n--bind string\nLocal address to bind to for outgoing connections.  This can be an\nIPv4 address (1.2.3.4), an IPv6 address (1234::789A) or host name.  If\nthe host name doesn't resolve or resolves to more than one IP address\nit will give an error.\nYou can use\n--bind 0.0.0.0\nto force rclone to use IPv4 addresses and\n--bind ::0\nto force rclone to use IPv6 addresses.\n--bwlimit BwTimetable\nThis option controls the bandwidth limit. For example\n--bwlimit 10M\nwould mean limit the upload and download bandwidth to 10 MiB/s.\nNB\nthis is\nbytes\nper second not\nbits\nper second. To use a\nsingle limit, specify the desired bandwidth in KiB/s, or use a\nsuffix B|K|M|G|T|P. The default is\n0\nwhich means to not limit bandwidth.\nThe upload and download bandwidth can be specified separately, as\n--bwlimit UP:DOWN\n, so\n--bwlimit 10M:100k\nwould mean limit the upload bandwidth to 10 MiB/s and the download\nbandwidth to 100 KiB/s. Either limit can be \"off\" meaning no limit, so\nto just limit the upload bandwidth you would use\n--bwlimit 10M:off\nthis would limit the upload bandwidth to 10 MiB/s but the download\nbandwidth would be unlimited.\nWhen specified as above the bandwidth limits last for the duration of\nrun of the rclone binary.\nIt is also possible to specify a \"timetable\" of limits, which will\ncause certain limits to be applied at certain times. To specify a\ntimetable, format your entries as\nWEEKDAY-HH:MM,BANDWIDTH WEEKDAY-HH:MM,BANDWIDTH...\nwhere:\nWEEKDAY\nis optional element.\nBANDWIDTH\ncan be a single number, e.g.\n100k\nor a pair of numbers\nfor upload:download, e.g.\n10M:1M\n.\nWEEKDAY\ncan be written as the whole word or only using the first 3\ncharacters. It is optional.\nHH:MM\nis an hour from 00:00 to 23:59.\nEntries can be separated by spaces or semicolons.\nNote:\nSemicolons can be used as separators instead of spaces to avoid\nparsing issues in environments like Docker.\nAn example of a typical timetable to avoid link saturation during daytime\nworking hours could be:\nUsing spaces as separators:\n--bwlimit \"08:00,512k 12:00,10M 13:00,512k 18:00,30M 23:00,off\"\nUsing semicolons as separators:\n--bwlimit \"08:00,512k;12:00,10M;13:00,512k;18:00,30M;23:00,off\"\nIn these examples, the transfer bandwidth will be set to 512 KiB/s\nat 8am every day. At noon, it will rise to 10 MiB/s, and drop back\nto 512 KiB/sec at 1pm. At 6pm, the bandwidth limit will be set to\n30 MiB/s, and at 11pm it will be completely disabled (full speed).\nAnything between 11pm and 8am will remain unlimited.\nAn example of timetable with\nWEEKDAY\ncould be:\nUsing spaces as separators:\n--bwlimit \"Mon-00:00,512 Fri-23:59,10M Sat-10:00,1M Sun-20:00,off\"\nUsing semicolons as separators:\n--bwlimit \"Mon-00:00,512;Fri-23:59,10M;Sat-10:00,1M;Sun-20:00,off\"\nIt means that, the transfer bandwidth will be set to 512 KiB/s on\nMonday. It will rise to 10 MiB/s before the end of Friday. At 10:00\non Saturday it will be set to 1 MiB/s. From 20:00 on Sunday it will\nbe unlimited.\nTimeslots without\nWEEKDAY\nare extended to the whole week. So this\nexample:\n--bwlimit \"Mon-00:00,512 12:00,1M Sun-20:00,off\"\nIs equivalent to this:\n--bwlimit \"Mon-00:00,512Mon-12:00,1M Tue-12:00,1M Wed-12:00,1M Thu-12:00,1M Fri-12:00,1M Sat-12:00,1M Sun-12:00,1M Sun-20:00,off\"\nBandwidth limit apply to the data transfer for all backends. For most\nbackends the directory listing bandwidth is also included (exceptions\nbeing the non HTTP backends,\nftp\n,\nsftp\nand\nstorj\n).\nNote that the units are\nByte/s\n, not\nbit/s\n. Typically\nconnections are measured in bit/s - to convert divide by 8. For\nexample, let's say you have a 10 Mbit/s connection and you wish rclone\nto use half of it - 5 Mbit/s. This is 5/8 = 0.625 MiB/s so you would\nuse a\n--bwlimit 0.625M\nparameter for rclone.\nOn Unix systems (Linux, macOS, …) the bandwidth limiter can be toggled by\nsending a\nSIGUSR2\nsignal to rclone. This allows to remove the limitations\nof a long running rclone transfer and to restore it back to the value specified\nwith\n--bwlimit\nquickly when needed. Assuming there is only one rclone instance\nrunning, you can toggle the limiter like this:\nkill -SIGUSR2 $(pidof rclone)\nIf you configure rclone with a\nremote control\nthen you can use\nchange the bwlimit dynamically:\nrclone rc core/bwlimit rate=1M\n--bwlimit-file BwTimetable\nThis option controls per file bandwidth limit. For the options see the\n--bwlimit\nflag.\nFor example use this to allow no transfers to be faster than 1 MiB/s\n--bwlimit-file 1M\nThis can be used in conjunction with\n--bwlimit\n.\nNote that if a schedule is provided the file will use the schedule in\neffect at the start of the transfer.\n--buffer-size SizeSuffix\nUse this sized buffer to speed up file transfers.  Each\n--transfer\nwill use this much memory for buffering.\nWhen using\nmount\nor\ncmount\neach open file descriptor will use this much\nmemory for buffering.\nSee the\nmount\ndocumentation for more details.\nSet to\n0\nto disable the buffering for the minimum memory usage.\nNote that the memory allocation of the buffers is influenced by the\n--use-mmap\nflag.\n--cache-dir string\nSpecify the directory rclone will use for caching, to override\nthe default.\nDefault value is depending on operating system:\nWindows\n%LocalAppData%\\rclone\n, if\nLocalAppData\nis defined.\nmacOS\n$HOME/Library/Caches/rclone\nif\nHOME\nis defined.\nUnix\n$XDG_CACHE_HOME/rclone\nif\nXDG_CACHE_HOME\nis defined, else\n$HOME/.cache/rclone\nif\nHOME\nis defined.\nFallback (on all OS) to\n$TMPDIR/rclone\n, where\nTMPDIR\nis the value\nfrom\n--temp-dir\n.\nYou can use the\nconfig paths\ncommand to see the current value.\nCache directory is heavily used by the\nVFS File Caching\nmount feature, but also by\nserve\n,\nGUI\nand\nother parts of rclone.\n--check-first\nIf this flag is set then in a\nsync\n,\ncopy\nor\nmove\n, rclone\nwill do all the checks to see whether files need to be transferred before\ndoing any of the transfers. Normally rclone would start running\ntransfers as soon as possible.\nThis flag can be useful on IO limited systems where transfers\ninterfere with checking.\nIt can also be useful to ensure perfect ordering when using\n--order-by\n.\nIf both\n--check-first\nand\n--order-by\nare set when doing\nrclone move\nthen rclone will use the transfer thread to delete source files which\ndon't need transferring. This will enable perfect ordering of the\ntransfers and deletes but will cause the transfer stats to have more\nitems in than expected.\nUsing this flag can use more memory as it effectively sets\n--max-backlog\nto infinite. This means that all the info on the\nobjects to transfer is held in memory before the transfers start.\n--checkers int\nOriginally controlling just the number of file checkers to run in parallel,\ne.g. by\nrclone copy\n. Now a fairly universal parallelism control\nused by\nrclone\nin several places.\nNote: checkers do the equality checking of files during a sync.\nFor some storage systems (e.g. S3, Swift, Dropbox) this can take\na significant amount of time so they are run in parallel.\nThe default is to run 8 checkers in parallel. However, in case\nof slow-reacting backends you may need to lower (rather than increase)\nthis default by setting\n--checkers\nto 4 or less threads. This is\nespecially advised if you are experiencing backend server crashes\nduring file checking phase (e.g. on subsequent or top-up backups\nwhere little or no file copying is done and checking takes up\nmost of the time). Increase this setting only with utmost care,\nwhile monitoring your server health and file checking throughput.\n-c, --checksum\nNormally rclone will look at modification time and size of files to\nsee if they are equal.  If you set this flag then rclone will check\nthe file hash and size to determine if files are equal.\nThis is useful when the remote doesn't support setting modified time\nand a more accurate sync is desired than just checking the file size.\nThis is very useful when transferring between remotes which store the\nsame hash type on the object, e.g. Drive and Swift. For details of which\nremotes support which hash type see the table in the\noverview\nsection\n.\nEg\nrclone --checksum sync s3:/bucket swift:/bucket\nwould run much\nquicker than without the\n--checksum\nflag.\nWhen using this flag, rclone won't update mtimes of remote files if\nthey are incorrect as it would normally.\n--color AUTO|NEVER|ALWAYS\nSpecify when colors (and other ANSI codes) should be added to the output.\nAUTO\nonly allows ANSI codes when the output is a terminal. This is the default.\nNEVER\nnever allow ANSI codes.\nALWAYS\nalways add ANSI codes, regardless of the output format (terminal or file).\n--compare-dest stringArray\nWhen using\nsync\n,\ncopy\nor\nmove\n, the specified paths are checked in addition\nto the destination for files. If a file identical to the source is found, that\nfile is\nnot\ncopied from source. This is useful to copy just files that\nhave changed since the last backup.\nYou must use the same remote as the destination of the sync. The\ncompare directory must not overlap the destination directory.\nSee\n--copy-dest\nand\n--backup-dir\n.\n--config string\nSpecify the location of the rclone configuration file, to override\nthe default. E.g.\nrclone config --config=\"rclone.conf\"\n.\nThe exact default is a bit complex to describe, due to changes\nintroduced through different versions of rclone while preserving\nbackwards compatibility, but in most cases it is as simple as:\n%APPDATA%/rclone/rclone.conf\non Windows\n~/.config/rclone/rclone.conf\non other\nThe complete logic is as follows: Rclone will look for an existing\nconfiguration file in any of the following locations, in priority order:\nrclone.conf\n(in program directory, where rclone executable is)\n%APPDATA%/rclone/rclone.conf\n(only on Windows)\n$XDG_CONFIG_HOME/rclone/rclone.conf\n(on all systems, including Windows)\n~/.config/rclone/rclone.conf\n(see below for explanation of ~ symbol)\n~/.rclone.conf\nIf no existing configuration file is found, then a new one will be created\nin the following location:\nOn Windows: Location 2 listed above, except in the unlikely event\nthat\nAPPDATA\nis not defined, then location 4 is used instead.\nOn Unix: Location 3 if\nXDG_CONFIG_HOME\nis defined, else location 4.\nFallback to location 5 (on all OS), when the rclone directory cannot be\ncreated, but if also a home directory was not found then path\n.rclone.conf\nrelative to current working directory will be used as\na final resort.\nThe\n~\nsymbol in paths above represent the home directory of the current user\non any OS, and the value is defined as following:\nOn Windows:\n%HOME%\nif defined, else\n%USERPROFILE%\n, or else\n%HOMEDRIVE%\\%HOMEPATH%\n.\nOn Unix:\n$HOME\nif defined, else by looking up current user in OS-specific user\ndatabase (e.g. passwd file), or else use the result from shell command\ncd && pwd\n.\nIf you run\nrclone config file\nyou will see where the default location is for\nyou. Running\nrclone config touch\nwill ensure a configuration file exists,\ncreating an empty one in the default location if there is none.\nThe fact that an existing file\nrclone.conf\nin the same directory\nas the rclone executable is always preferred, means that it is easy\nto run in \"portable\" mode by downloading rclone executable to a\nwritable directory and then create an empty file\nrclone.conf\nin the\nsame directory.\nIf the location is set to empty string\n\"\"\nor path to a file\nwith name\nnotfound\n, or the os null device represented by value\nNUL\non\nWindows and\n/dev/null\non Unix systems, then rclone will keep the\nconfiguration file in memory only.\nYou may see a log message \"Config file not found - using defaults\" if there is\nno configuration file. This can be supressed, e.g. if you are using rclone\nentirely with\non the fly remotes\n, by using\nmemory-only configuration file or by creating an empty configuration file, as\ndescribed above.\nThe file format is basic\nINI\n:\nSections of text, led by a\n[section]\nheader and followed by\nkey=value\nentries on separate lines. In rclone each remote is\nrepresented by its own section, where the section name defines the\nname of the remote. Options are specified as the\nkey=value\nentries,\nwhere the key is the option name without the\n--backend-\nprefix,\nin lowercase and with\n_\ninstead of\n-\n. E.g. option\n--mega-hard-delete\ncorresponds to key\nhard_delete\n. Only backend options can be specified.\nA special, and required, key\ntype\nidentifies the\nstorage system\n,\nwhere the value is the internal lowercase name as returned by command\nrclone help backends\n. Comments are indicated by\n;\nor\n#\nat the\nbeginning of a line.\nExample:\n[megaremote]\ntype\n=\nmega\nuser\n=\nyou@example.com\npass\n=\nPDPcQVVjVtzFY-GTdDFozqBhTdsPg3qH\nNote that passwords are in\nobscured\nform. Also, many storage systems uses token-based authentication instead\nof passwords, and this requires additional steps. It is easier, and safer,\nto use the interactive command\nrclone config\ninstead of manually\nediting the configuration file.\nThe configuration file will typically contain login information, and\nshould therefore have restricted permissions so that only the current user\ncan read it. Rclone tries to ensure this when it writes the file.\nYou may also choose to\nencrypt\nthe file.\nWhen token-based authentication are used, the configuration file\nmust be writable, because rclone needs to update the tokens inside it.\nTo reduce risk of corrupting an existing configuration file, rclone\nwill not write directly to it when saving changes. Instead it will\nfirst write to a new, temporary, file. If a configuration file already\nexisted, it will (on Unix systems) try to mirror its permissions to\nthe new file. Then it will rename the existing file to a temporary\nname as backup. Next, rclone will rename the new file to the correct name,\nbefore finally cleaning up by deleting the backup file.\nIf the configuration file path used by rclone is a symbolic link, then\nthis will be evaluated and rclone will write to the resolved path, instead\nof overwriting the symbolic link. Temporary files used in the process\n(described above) will be written to the same parent directory as that\nof the resolved configuration file, but if this directory is also a\nsymbolic link it will not be resolved and the temporary files will be\nwritten to the location of the directory symbolic link.\n--contimeout Duration\nSet the connection timeout. This should be in go time format which\nlooks like\n5s\nfor 5 seconds,\n10m\nfor 10 minutes, or\n3h30m\n.\nThe connection timeout is the amount of time rclone will wait for a\nconnection to go through to a remote object storage system.  It is\n1m\nby default.\n--copy-dest stringArray\nWhen using\nsync\n,\ncopy\nor\nmove\n, the specified paths are checked in addition\nto the destination for files. This part is the same as\n--compare-dest\n, but\nthe difference is that with\n--copy-dest\n, if a file identical to the source\nis found, that file is server-side copied from the specified paths to the\ndestination. This is useful for incremental backup.\nThe remote in use must support server-side copy and you must\nuse the same remote as the destination of the sync.  The compare\ndirectory must not overlap the destination directory.\nSee\n--compare-dest\nand\n--backup-dir\n.\n--dedupe-mode interactive|skip|first|newest|oldest|largest|smallest|rename|list\nMode to run dedupe command in.  One of\ninteractive\n,\nskip\n,\nfirst\n,\nnewest\n,\noldest\n,\nlargest\n,\nsmallest\n,\nrename\nlist\n.  The default\nis\ninteractive\n.   See the\ndedupe\ncommand\nfor more information as to what these options mean.\n--default-time Time\nIf a file or directory does have a modification time rclone can read\nthen rclone will display this fixed time instead.\nThe default is\n2000-01-01 00:00:00 UTC\n. This can be configured in\nany of the ways shown in\ntime options\n.\nFor example\n--default-time 2020-06-01\nto set the default time to the\n1st of June 2020 or\n--default-time 0s\nto set the default time to the\ntime rclone started up.\n--disable string\nThis disables a comma separated list of optional features. For example\nto disable server-side move and server-side copy use:\n--disable move,copy\nThe features can be put in any case.\nTo see a list of which features can be disabled use:\n--disable help\nThe features a remote has can be seen in JSON format with:\nrclone backend features remote:\nSee the overview\nfeatures\nand\noptional features\nto get an idea of\nwhich feature does what.\nNote that some features can be set to\ntrue\nif they are\ntrue\n/\nfalse\nfeature flag features by prefixing them with\n!\n. For example the\nCaseInsensitive\nfeature can be forced to\nfalse\nwith\n--disable CaseInsensitive\nand forced to\ntrue\nwith\n--disable '!CaseInsensitive'\n. In general\nit isn't a good idea doing this but it may be useful in extremis.\n(Note that\n!\nis a shell command which you will\nneed to escape with single quotes or a backslash on unix like\nplatforms.)\nThis flag can be useful for debugging and in exceptional circumstances\n(e.g. Google Drive limiting the total volume of server-side copies to\n100 GiB/day).\n--disable-http2\nThis stops rclone from trying to use HTTP/2 if available. This can\nsometimes speed up transfers due to a\nproblem in the Go standard library\n.\n--dscp string\nSpecify a DSCP value or name to use in connections. This could help QoS\nsystem to identify traffic class. BE, EF, DF, LE, CSx and AFxx are allowed.\nSee the description of\ndifferentiated services\nto get an idea of this field. Setting this to 1 (LE) to identify the flow to\nSCAVENGER class can avoid occupying too much bandwidth in a network with DiffServ\nsupport (\nRFC 8622\n).\nFor example, if you configured QoS on router to handle LE properly. Running:\nrclone copy --dscp LE from:/from to:/to\nwould make the priority lower than usual internet flows.\nThis option has no effect on Windows (see\ngolang/go#42728\n).\n-n, --dry-run\nDo a trial run with no permanent changes.  Use this to see what rclone\nwould do without actually doing it.  Useful when setting up the\nsync\ncommand which deletes files in the destination.\n--expect-continue-timeout Duration\nThis specifies the amount of time to wait for a server's first\nresponse headers after fully writing the request headers if the\nrequest has an \"Expect: 100-continue\" header. Not all backends support\nusing this.\nZero means no timeout and causes the body to be sent immediately,\nwithout waiting for the server to approve.  This time does not include\nthe time to send the request header.\nThe default is\n1s\n.  Set to\n0\nto disable.\n--error-on-no-transfer\nBy default, rclone will exit with return code 0 if there were no errors.\nThis option allows rclone to return exit code 9 if no files were transferred\nbetween the source and destination. This allows using rclone in scripts, and\ntriggering follow-on actions if data was copied, or skipping if not.\nNB: Enabling this option turns a usually non-fatal error into a potentially\nfatal one - please check and adjust your scripts accordingly!\n--fix-case\nNormally, a sync to a case insensitive dest (such as macOS / Windows) will\nnot result in a matching filename if the source and dest filenames have\ncasing differences but are otherwise identical. For example, syncing\nhello.txt\nto\nHELLO.txt\nwill normally result in the dest filename remaining\nHELLO.txt\n.\nIf\n--fix-case\nis set, then\nHELLO.txt\nwill be renamed to\nhello.txt\nto match the source.\nNB:\ndirectory names with incorrect casing will also be fixed\n--fix-case\nwill be ignored if\n--immutable\nis set\nusing\n--local-case-sensitive\ninstead is not advisable;\nit will cause\nHELLO.txt\nto get deleted!\nthe old dest filename must not be excluded by filters.\nBe especially careful with\n--files-from\n,\nwhich does not respect\n--ignore-case\n!\non remotes that do not support server-side move,\n--fix-case\nwill require\ndownloading the file and re-uploading it. To avoid this, do not use\n--fix-case\n.\n--fs-cache-expire-duration Duration\nWhen using rclone via the API rclone caches created remotes for 5\nminutes by default in the \"fs cache\". This means that if you do\nrepeated actions on the same remote then rclone won't have to build it\nagain from scratch, which makes it more efficient.\nThis flag sets the time that the remotes are cached for. If you set it\nto\n0\n(or negative) then rclone won't cache the remotes at all.\nNote that if you use some flags, eg\n--backup-dir\nand if this is set\nto\n0\nrclone may build two remotes (one for the source or destination\nand one for the\n--backup-dir\nwhere it may have only built one\nbefore.\n--fs-cache-expire-interval Duration\nThis controls how often rclone checks for cached remotes to expire.\nSee the\n--fs-cache-expire-duration\ndocumentation above for more\ninfo. The default is 60s, set to 0 to disable expiry.\n--header stringArray\nAdd an HTTP header for all transactions. The flag can be repeated to\nadd multiple headers.\nIf you want to add headers only for uploads use\n--header-upload\nand\nif you want to add headers only for downloads use\n--header-download\n.\nThis flag is supported for all HTTP based backends even those not\nsupported by\n--header-upload\nand\n--header-download\nso may be used\nas a workaround for those with care.\nrclone ls remote:test --header \"X-Rclone: Foo\" --header \"X-LetMeIn: Yes\"\n--header-download stringArray\nAdd an HTTP header for all download transactions. The flag can be repeated to\nadd multiple headers.\nrclone sync --interactive s3:test/src ~/dst --header-download \"X-Amz-Meta-Test: Foo\" --header-download \"X-Amz-Meta-Test2: Bar\"\nSee GitHub issue\n#59\nfor\ncurrently supported backends.\n--header-upload stringArray\nAdd an HTTP header for all upload transactions. The flag can be repeated to add\nmultiple headers.\nrclone sync --interactive ~/src s3:test/dst --header-upload \"Content-Disposition: attachment; filename='cool.html'\" --header-upload \"X-Amz-Meta-Test: FooBar\"\nSee GitHub issue\n#59\nfor\ncurrently supported backends.\n--http-proxy string\nUse this option to set an HTTP proxy for all HTTP based services to\nuse.\nRclone also supports the standard HTTP proxy environment variables\nwhich it will pick up automatically. The is the way the HTTP proxy\nwill normally be set but this flag can be used to override it.\n--human-readable\nRclone commands output values for sizes (e.g. number of bytes) and\ncounts (e.g. number of files) either as\nraw\nnumbers, or\nin\nhuman-readable\nformat.\nIn human-readable format the values are scaled to larger units, indicated with\na suffix shown after the value, and rounded to three decimals. Rclone consistently\nuses binary units (powers of 2) for sizes and decimal units (powers of 10) for counts.\nThe unit prefix for size is according to IEC standard notation, e.g.\nKi\nfor kibi.\nUsed with byte unit,\n1 KiB\nmeans 1024 Byte. In list type of output, only the\nunit prefix appended to the value (e.g.\n9.762Ki\n), while in more textual output\nthe full unit is shown (e.g.\n9.762 KiB\n). For counts the SI standard notation is\nused, e.g. prefix\nk\nfor kilo. Used with file counts,\n1k\nmeans 1000 files.\nThe various\nlist\ncommands output raw numbers by default.\nOption\n--human-readable\nwill make them output values in human-readable format\ninstead (with the short unit prefix).\nThe\nabout\ncommand outputs human-readable by default,\nwith a command-specific option\n--full\nto output the raw numbers instead.\nCommand\nsize\noutputs both human-readable and raw numbers\nin the same output.\nThe\ntree\ncommand also considers\n--human-readable\n, but\nit will not use the exact same notation as the other commands: It rounds to one\ndecimal, and uses single letter suffix, e.g.\nK\ninstead of\nKi\n. The reason for\nthis is that it relies on an external library.\nThe interactive command\nncdu\nshows human-readable by\ndefault, and responds to key\nu\nfor toggling human-readable format.\n--ignore-case-sync\nUsing this option will cause rclone to ignore the case of the files\nwhen synchronizing so files will not be copied/synced when the\nexisting filenames are the same, even if the casing is different.\n--ignore-checksum\nNormally rclone will check that the checksums of transferred files\nmatch, and give an error \"corrupted on transfer\" if they don't.\nYou can use this option to skip that check.  You should only use it if\nyou have had the \"corrupted on transfer\" error message and you are\nsure you might want to transfer potentially corrupted data.\n--ignore-existing\nUsing this option will make rclone unconditionally skip all files\nthat exist on the destination, no matter the content of these files.\nWhile this isn't a generally recommended option, it can be useful\nin cases where your files change due to encryption. However, it cannot\ncorrect partial transfers in case a transfer was interrupted.\nWhen performing a\nmove\n/\nmoveto\ncommand, this flag will leave skipped\nfiles in the source location unchanged when a file with the same name\nexists on the destination.\n--ignore-size\nNormally rclone will look at modification time and size of files to\nsee if they are equal.  If you set this flag then rclone will check\nonly the modification time.  If\n--checksum\nis set then it only\nchecks the checksum.\nIt will also cause rclone to skip verifying the sizes are the same\nafter transfer.\nThis can be useful for transferring files to and from OneDrive which\noccasionally misreports the size of image files (see\n#399\nfor more info).\n-I, --ignore-times\nUsing this option will cause rclone to unconditionally upload all\nfiles regardless of the state of files on the destination.\nNormally rclone would skip any files that have the same\nmodification time and are the same size (or have the same checksum if\nusing\n--checksum\n).\n--immutable\nTreat source and destination files as immutable and disallow\nmodification.\nWith this option set, files will be created and deleted as requested,\nbut existing files will never be updated.  If an existing file does\nnot match between the source and destination, rclone will give the error\nSource and destination exist but do not match: immutable file modified\n.\nNote that only commands which transfer files (e.g.\nsync\n,\ncopy\nor\nmove\n) are affected\nby this behavior, and only modification is disallowed.  Files may still be deleted\nexplicitly (e.g.\ndelete\n,\npurge\n)\nor implicitly (e.g.\nsync\n,\nmove\n).\nUse\ncopy --immutable\nif it is desired to avoid deletion as well as modification.\nThis can be useful as an additional layer of protection for immutable\nor append-only data sets (notably backup archives), where modification\nimplies corruption and should not be propagated.\n--inplace\nThe\n--inplace\nflag changes the behaviour of rclone when uploading\nfiles to some backends (backends with the\nPartialUploads\nfeature\nflag set) such as:\nlocal\nftp\nsftp\npcloud\nWithout\n--inplace\n(the default) rclone will first upload to a\ntemporary file with an extension like this, where\nXXXXXX\nrepresents a\nhash of the source file's fingerprint and\n.partial\nis\n--partial-suffix\nvalue (\n.partial\nby default).\noriginal-file-name.XXXXXX.partial\n(rclone will make sure the final name is no longer than 100 characters\nby truncating the\noriginal-file-name\npart if necessary).\nWhen the upload is complete, rclone will rename the\n.partial\nfile to\nthe correct name, overwriting any existing file at that point. If the\nupload fails then the\n.partial\nfile will be deleted.\nThis prevents other users of the backend from seeing partially\nuploaded files in their new names and prevents overwriting the old\nfile until the new one is completely uploaded.\nIf the\n--inplace\nflag is supplied, rclone will upload directly to\nthe final name without creating a\n.partial\nfile.\nThis means that an incomplete file will be visible in the directory\nlistings while the upload is in progress and any existing files will\nbe overwritten as soon as the upload starts. If the transfer fails\nthen the file will be deleted. This can cause data loss of the\nexisting file if the transfer fails.\nNote that on the local file system if you don't use\n--inplace\nhard\nlinks (Unix only) will be broken. And if you do use\n--inplace\nyou\nwon't be able to update in use executables.\nNote also that versions of rclone prior to v1.63.0 behave as if the\n--inplace\nflag is always supplied.\n-i, --interactive\nThis flag can be used to tell rclone that you wish a manual\nconfirmation before destructive operations.\nIt is\nrecommended\nthat you use this flag while learning rclone\nespecially with\nrclone sync\n.\nFor example\n$ rclone delete --interactive /tmp/dir\nrclone: delete \"important-file.txt\"?\ny) Yes, this is OK (default)\nn) No, skip this\ns) Skip all delete operations with no more questions\n!) Do all delete operations with no more questions\nq) Exit rclone now.\ny/n/s/!/q> n\nThe options mean\ny\n:\nYes\n, this operation should go ahead. You can also press Return\nfor this to happen. You'll be asked every time unless you choose\ns\nor\n!\n.\nn\n:\nNo\n, do not do this operation. You'll be asked every time unless\nyou choose\ns\nor\n!\n.\ns\n:\nSkip\nall the following operations of this type with no more\nquestions. This takes effect until rclone exits. If there are any\ndifferent kind of operations you'll be prompted for them.\n!\n:\nDo all\nthe following operations with no more\nquestions. Useful if you've decided that you don't mind rclone doing\nthat kind of operation. This takes effect until rclone exits . If\nthere are any different kind of operations you'll be prompted for\nthem.\nq\n:\nQuit\nrclone now, just in case!\n--leave-root\nDuring rmdirs it will not remove root directory, even if it's empty.\n-l, --links\nNormally rclone will ignore symlinks or junction points (which behave\nlike symlinks under Windows). Ignored files won't be copied, moved or\ndeleted in a sync.\nIf you supply this flag then rclone will copy symbolic links from any\nsupported backend backend, and store them as text files, with a\n.rclonelink\nsuffix in the destination.\nThe text file will contain the target of the symbolic link.\nThe\n--links\n/\n-l\nflag enables this feature for all supported\nbackends and the VFS. There are individual flags for just enabling it\nfor the VFS\n--vfs-links\nand the local backend\n--local-links\nif\nrequired.\n--list-cutoff int\nWhen syncing rclone needs to sort directory entries before comparing\nthem. Below this threshold (1,000,000) by default, rclone will store\nthe directory entries in memory. 1,000,000 entries will take approx\n1GB of RAM to store. Above this threshold rclone will store directory\nentries on disk and sort them without using a lot of memory.\nDoing this is slightly less efficient then sorting them in memory and\nwill only work well for the bucket based backends (eg s3, b2,\nazureblob, swift) but these are the only backends likely to have\nmillions of entries in a directory.\n--log-file string\nLog all of rclone's output to a file. This is not active by default.\nThis can be useful for tracking down problems with syncs in\ncombination with the\n-v\nflag.  See the\nlogging\nsection\nfor more info.\nIf the file exists, then rclone will append to it.\nNote that if you are using the\nlogrotate\nprogram to manage rclone's\nlogs, then you should use the\ncopytruncate\noption as rclone doesn't\nhave a signal to rotate logs.\nAlternatively you can use the options below to manage rclone's built\nin log rotation.\n--log-file-max-size SizeSuffix\nMaximum size of the log file before it's rotated (eg\n10M\n). This SizeSuffix\nis rounded to the nearest MiB or 1 MiB if lower.\nIf\n--log-file\nis not set then this option will be ignored.\nIf this option is not set, then the other log rotation options will be\nignored.\nFor example if the following flags are in use\nrclone --log-file rclone.log --log-file-max-size 1M --log-file-max-backups 3\nThen this will create log files which look like this\n$ ls -l\n-rw-------  1 user user  1048491 Apr 11 17:15 rclone-2025-04-11T17-15-29.998.log\n-rw-------  1 user user  1048511 Apr 11 17:15 rclone-2025-04-11T17-15-30.467.log\n-rw-------  1 user user  1048559 Apr 11 17:15 rclone-2025-04-11T17-15-30.543.log\n-rw-------  1 user user   521602 Apr 11 17:15 rclone.log\nThe file\nrclone.log\nbeing the current one.\n--log-file-compress\nIf set, compress rotated log files using gzip. This changes the\nextension of the old log files to\n.log.gz\n.\nDefaults to false - don't compress log files.\n--log-file-max-age Duration\nMaximum duration to retain old log files (eg\n7d\n). This is rounded to\nthe dearest day, or 1 day if lower.\nThe default is to retain all old log files.\n--log-file-max-backups int\nMaximum number of old log files to retain\nThe default is to retain all old log files.\n--log-format string\nComma separated list of log format options. The accepted options are:\ndate\n- Add a date in the format YYYY/MM/YY to the log.\ntime\n- Add a time to the log in format HH:MM:SS.\nmicroseconds\n- Add microseconds to the time in format HH:MM:SS.SSSSSS.\nUTC\n- Make the logs in UTC not localtime.\nlongfile\n- Adds the source file and line number of the log statement.\nshortfile\n- Adds the source file and line number of the log statement.\npid\n- Add the process ID to the log - useful with\nrclone mount --daemon\n.\nnolevel\n- Don't add the level to the log.\njson\n- Equivalent to adding\n--use-json-log\nThey are added to the log line in the order above.\nThe default log format is\n\"date,time\"\n.\n--log-level LogLevel\nThis sets the log level for rclone.  The default log level is\nNOTICE\n.\nDEBUG\nis equivalent to\n-vv\n. It outputs lots of debug info - useful\nfor bug reports and really finding out what rclone is doing.\nINFO\nis equivalent to\n-v\n. It outputs information about each transfer\nand prints stats once a minute by default.\nNOTICE\nis the default log level if no logging flags are supplied. It\noutputs very little when things are working normally. It outputs\nwarnings and significant events.\nERROR\nis equivalent to\n-q\n. It only outputs error messages.\nSee also the\nlogging\nsection.\n--windows-event-log LogLevel\nIf this is configured (the default is\nOFF\n) then logs of this level\nand above will be logged to the Windows event log in\naddition\nto\nthe normal logs. These will be logged in JSON format as described\nbelow regardless of what format the main logs are configured for.\nThe Windows event log only has 3 levels of severity\nInfo\n,\nWarning\nand\nError\n. If enabled we map rclone levels like this.\nError\n←\nERROR\n(and above)\nWarning\n←\nWARNING\n(note that this level is defined but not currently used).\nInfo\n←\nNOTICE\n,\nINFO\nand\nDEBUG\n.\nRclone will declare its log source as \"rclone\" if it is has enough\npermissions to create the registry key needed. If not then logs will\nappear as \"Application\". You can run\nrclone version --windows-event-log DEBUG\nonce as administrator to create the registry key in advance.\nNote\nthat the\n--windows-event-log\nlevel must be greater (more\nsevere) than or equal to the\n--log-level\n. For example to log DEBUG\nto a log file but ERRORs to the event log you would use\n--log-file rclone.log --log-level DEBUG --windows-event-log ERROR\nThis option is only supported Windows platforms.\n--use-json-log\nThis switches the log format to JSON. The log messages are then\nstreamed as individual JSON objects, with fields:\nlevel\n,\nmsg\n,\nsource\n,\nand\ntime\n. The resulting format is what is sometimes referred to as\nnewline-delimited JSON\n(NDJSON), or JSON Lines (JSONL). This is well suited for processing by\ntraditional line-oriented tools and shell pipelines, but a complete log\nfile is not strictly valid JSON and needs a parser that can handle it.\nThe JSON logs will be printed on a single line, but are shown expanded\nhere for clarity.\n{\n\"time\"\n:\n\"2025-05-13T17:30:51.036237518+01:00\"\n,\n\"level\"\n:\n\"debug\"\n,\n\"msg\"\n:\n\"4 go routines active\\n\"\n,\n\"source\"\n:\n\"cmd/cmd.go:298\"\n}\nCompleted data transfer logs will have extra\nsize\ninformation. Logs\nwhich are about a particular object will have\nobject\nand\nobjectType\nfields also.\n{\n\"time\"\n:\n\"2025-05-13T17:38:05.540846352+01:00\"\n,\n\"level\"\n:\n\"info\"\n,\n\"msg\"\n:\n\"Copied (new) to: file2.txt\"\n,\n\"size\"\n:\n6\n,\n\"object\"\n:\n\"file.txt\"\n,\n\"objectType\"\n:\n\"*local.Object\"\n,\n\"source\"\n:\n\"operations/copy.go:368\"\n}\nStats logs will contain a\nstats\nfield which is the same as\nreturned from the rc call\ncore/stats\n.\n{\n\"time\"\n:\n\"2025-05-13T17:38:05.540912847+01:00\"\n,\n\"level\"\n:\n\"info\"\n,\n\"msg\"\n:\n\"...text version of the stats...\"\n,\n\"stats\"\n:\n{\n\"bytes\"\n:\n6\n,\n\"checks\"\n:\n0\n,\n\"deletedDirs\"\n:\n0\n,\n\"deletes\"\n:\n0\n,\n\"elapsedTime\"\n:\n0.000904825\n,\n...truncated\nfor\nclarity...\n\"totalBytes\"\n:\n6\n,\n\"totalChecks\"\n:\n0\n,\n\"totalTransfers\"\n:\n1\n,\n\"transferTime\"\n:\n0.000882794\n,\n\"transfers\"\n:\n1\n},\n\"source\"\n:\n\"accounting/stats.go:569\"\n}\n--low-level-retries int\nThis controls the number of low level retries rclone does.\nA low level retry is used to retry a failing operation - typically one\nHTTP request.  This might be uploading a chunk of a big file for\nexample.  You will see low level retries in the log with the\n-v\nflag.\nThis shouldn't need to be changed from the default in normal operations.\nHowever, if you get a lot of low level retries you may wish\nto reduce the value so rclone moves on to a high level retry (see the\n--retries\nflag) quicker.\nDisable low level retries with\n--low-level-retries 1\n.\n--max-backlog int\nThis is the maximum allowable backlog of files in a sync/copy/move\nqueued for being checked or transferred.\nThis can be set arbitrarily large.  It will only use memory when the\nqueue is in use.  Note that it will use in the order of N KiB of memory\nwhen the backlog is in use.\nSetting this large allows rclone to calculate how many files are\npending more accurately, give a more accurate estimated finish\ntime and make\n--order-by\nwork more accurately.\nSetting this small will make rclone more synchronous to the listings\nof the remote which may be desirable.\nSetting this to a negative number will make the backlog as large as\npossible.\n--max-buffer-memory SizeSuffix\nIf set, don't allocate more than given amount of memory as buffers. If\nnot set or set to\n0\nor\noff\nthis will not limit the amount of memory\nin use.\nThis includes memory used by buffers created by the\n--buffer\nflag\nand buffers used by multi-thread transfers.\nMost multi-thread transfers do not take additional memory, but some do\ndepending on the backend (eg the s3 backend for uploads). This means\nthere is a tension between total setting\n--transfers\nas high as\npossible and memory use.\nSetting\n--max-buffer-memory\nallows the buffer memory to be\ncontrolled so that it doesn't overwhelm the machine and allows\n--transfers\nto be set large.\n--max-connections int\nThis sets the maximum number of concurrent calls to the backend API.\nIt may not map 1:1 to TCP or HTTP connections depending on the backend\nin use and the use of HTTP1 vs HTTP2.\nWhen downloading files, backends only limit the initial opening of the\nstream. The bulk data download is not counted as a connection. This\nmeans that the\n--max--connections\nflag won't limit the total number\nof downloads.\nNote that it is possible to cause deadlocks with this setting so it\nshould be used with care.\nIf you are doing a sync or copy then make sure\n--max-connections\nis\none more than the sum of\n--transfers\nand\n--checkers\n.\nIf you use\n--check-first\nthen\n--max-connections\njust needs to be\none more than the maximum of\n--checkers\nand\n--transfers\n.\nSo for\n--max-connections 3\nyou'd use\n--checkers 2 --transfers 2 --check-first\nor\n--checkers 1 --transfers 1\n.\nSetting this flag can be useful for backends which do multipart\nuploads to limit the number of simultaneous parts being transferred.\n--max-delete int\nThis tells rclone not to delete more than N files.  If that limit is\nexceeded then a fatal error will be generated and rclone will stop the\noperation in progress.\n--max-delete-size SizeSuffix\nRclone will stop deleting files when the total size of deletions has\nreached the size specified. It defaults to off.\nIf that limit is exceeded then a fatal error will be generated and\nrclone will stop the operation in progress.\n--max-depth int\nThis modifies the recursion depth for all the commands except purge.\nSo if you do\nrclone --max-depth 1 ls remote:path\nyou will see only\nthe files in the top level directory.  Using\n--max-depth 2\nmeans you\nwill see all the files in first two directory levels and so on.\nFor historical reasons the\nlsd\ncommand defaults to using a\n--max-depth\nof 1 - you can override this with the command line flag.\nYou can use this command to disable recursion (with\n--max-depth 1\n).\nNote that if you use this with\nsync\nand\n--delete-excluded\nthe\nfiles not recursed through are considered excluded and will be deleted\non the destination.  Test first with\n--dry-run\nif you are not sure\nwhat will happen.\n--max-duration Duration\nRclone will stop transferring when it has run for the\nduration specified.\nDefaults to off.\nWhen the limit is reached all transfers will stop immediately.\nUse\n--cutoff-mode\nto modify this behaviour.\nRclone will exit with exit code 10 if the duration limit is reached.\n--max-transfer SizeSuffix\nRclone will stop transferring when it has reached the size specified.\nDefaults to off.\nWhen the limit is reached all transfers will stop immediately.\nUse\n--cutoff-mode\nto modify this behaviour.\nRclone will exit with exit code 8 if the transfer limit is reached.\n--cutoff-mode HARD|SOFT|CAUTIOUS\nConfigure the behavior of\n--max-transfer\nand\n--max-duration\n.\nHARD\nwill stop transferring immediately when rclone reaches the limit.\nThis is the default.\nSOFT\nwill stop starting new transfers when rclone reaches the limit.\nCAUTIOUS\nwill try to prevent rclone from reaching the limit. Only applicable\nfor\n--max-transfer\n.\n-M, --metadata\nSetting this flag enables rclone to copy the metadata from the source\nto the destination. For local backends this is ownership, permissions,\nxattr etc. See the\nmetadata section\nfor more info.\n--metadata-mapper SpaceSepList\nIf you supply the parameter\n--metadata-mapper /path/to/program\nthen\nrclone will use that program to map metadata from source object to\ndestination object.\nThe argument to this flag should be a command with an optional space separated\nlist of arguments. If one of the arguments has a space in then enclose\nit in\n\"\n, if you want a literal\n\"\nin an argument then enclose the\nargument in\n\"\nand double the\n\"\n. See\nCSV encoding\nfor more info.\n--metadata-mapper \"python bin/test_metadata_mapper.py\"\n--metadata-mapper 'python bin/test_metadata_mapper.py \"argument with a space\"'\n--metadata-mapper 'python bin/test_metadata_mapper.py \"argument with \"\"two\"\" quotes\"'\nThis uses a simple JSON based protocol with input on STDIN and output\non STDOUT. This will be called for every file and directory copied and\nmay be called concurrently.\nThe program's job is to take a metadata blob on the input and turn it\ninto a metadata blob on the output suitable for the destination\nbackend.\nInput to the program (via STDIN) might look like this. This provides\nsome context for the\nMetadata\nwhich may be important.\nSrcFs\nis the config string for the remote that the object is currently on.\nSrcFsType\nis the name of the source backend.\nDstFs\nis the config string for the remote that the object is being copied to\nDstFsType\nis the name of the destination backend.\nRemote\nis the path of the object relative to the root.\nSize\n,\nMimeType\n,\nModTime\nare attributes of the object.\nIsDir\nis\ntrue\nif this is a directory (not yet implemented).\nID\nis the source\nID\nof the object if known.\nMetadata\nis the backend specific metadata as described in the backend docs.\n{\n\"SrcFs\"\n:\n\"gdrive:\"\n,\n\"SrcFsType\"\n:\n\"drive\"\n,\n\"DstFs\"\n:\n\"newdrive:user\"\n,\n\"DstFsType\"\n:\n\"onedrive\"\n,\n\"Remote\"\n:\n\"test.txt\"\n,\n\"Size\"\n:\n6\n,\n\"MimeType\"\n:\n\"text/plain; charset=utf-8\"\n,\n\"ModTime\"\n:\n\"2022-10-11T17:53:10.286745272+01:00\"\n,\n\"IsDir\"\n:\nfalse\n,\n\"ID\"\n:\n\"xyz\"\n,\n\"Metadata\"\n:\n{\n\"btime\"\n:\n\"2022-10-11T16:53:11Z\"\n,\n\"content-type\"\n:\n\"text/plain; charset=utf-8\"\n,\n\"mtime\"\n:\n\"2022-10-11T17:53:10.286745272+01:00\"\n,\n\"owner\"\n:\n\"user1@domain1.com\"\n,\n\"permissions\"\n:\n\"...\"\n,\n\"description\"\n:\n\"my nice file\"\n,\n\"starred\"\n:\n\"false\"\n}\n}\nThe program should then modify the input as desired and send it to\nSTDOUT. The returned\nMetadata\nfield will be used in its entirety for\nthe destination object. Any other fields will be ignored. Note in this\nexample we translate user names and permissions and add something to\nthe description:\n{\n\"Metadata\"\n:\n{\n\"btime\"\n:\n\"2022-10-11T16:53:11Z\"\n,\n\"content-type\"\n:\n\"text/plain; charset=utf-8\"\n,\n\"mtime\"\n:\n\"2022-10-11T17:53:10.286745272+01:00\"\n,\n\"owner\"\n:\n\"user1@domain2.com\"\n,\n\"permissions\"\n:\n\"...\"\n,\n\"description\"\n:\n\"my nice file [migrated from domain1]\"\n,\n\"starred\"\n:\n\"false\"\n}\n}\nMetadata can be removed here too.\nAn example python program might look something like this to implement\nthe above transformations.\nimport\nsys\n,\njson\ni\n=\njson\n.\nload\n(\nsys\n.\nstdin\n)\nmetadata\n=\ni\n[\n\"Metadata\"\n]\n# Add tag to description\nif\n\"description\"\nin\nmetadata\n:\nmetadata\n[\n\"description\"\n]\n+=\n\" [migrated from domain1]\"\nelse\n:\nmetadata\n[\n\"description\"\n]\n=\n\"[migrated from domain1]\"\n# Modify owner\nif\n\"owner\"\nin\nmetadata\n:\nmetadata\n[\n\"owner\"\n]\n=\nmetadata\n[\n\"owner\"\n]\n.\nreplace\n(\n\"domain1.com\"\n,\n\"domain2.com\"\n)\no\n=\n{\n\"Metadata\"\n:\nmetadata\n}\njson\n.\ndump\n(\no\n,\nsys\n.\nstdout\n,\nindent\n=\n\"\n\\t\n\"\n)\nYou can find this example (slightly expanded) in the rclone source code at\nbin/test_metadata_mapper.py\n.\nIf you want to see the input to the metadata mapper and the output\nreturned from it in the log you can use\n-vv --dump mapper\n.\nSee the\nmetadata section\nfor more info.\n--metadata-set stringArray\nSpecify value as string in format\nkey=value\nto add metadata\nkey\nwith value\nvalue\nwhen uploading. This can be repeated as many times\nas required. See the\nmetadata section\nfor more info.\n--modify-window Duration\nWhen checking whether a file has been modified, this is the maximum\nallowed time difference that a file can have and still be considered\nequivalent.\nThe default is\n1ns\nunless this is overridden by a remote.  For\nexample OS X only stores modification times to the nearest second so\nif you are reading and writing to an OS X filing system this will be\n1s\nby default.\nThis command line flag allows you to override that computed default.\n--multi-thread-write-buffer-size SizeSuffix\nWhen transferring with multiple threads, rclone will buffer the specified\nnumber of bytes in memory before writing to disk for each thread.\nThis can improve performance if the underlying filesystem does not deal\nwell with a lot of small writes in different positions of the file, so\nif you see transfers being limited by disk write speed, you might want\nto experiment with different values. Specially for magnetic drives and\nremote file systems a higher value can be useful.\nNevertheless, the default of\n128k\nshould be fine for almost all use\ncases, so before changing it ensure that network is not really your\nbottleneck.\nAs a final hint, size is not the only factor: block size (or similar\nconcept) can have an impact. In one case, we observed that exact\nmultiples of 16k performed much better than other values.\n--multi-thread-chunk-size SizeSuffix\nNormally the chunk size for multi thread transfers is set by the backend.\nHowever some backends such as\nlocal\nand\nsmb\n(which implement\nOpenWriterAt\nbut not\nOpenChunkWriter\n) don't have a natural chunk size.\nIn this case the value of this option is used (default 64Mi).\n--multi-thread-cutoff SizeSuffix\nWhen transferring files above specified size  to capable backends,\nrclone will use multiple threads to transfer the file (default 256M).\nCapable backends are marked in the\noverview\nas\nMultithreadUpload\n. (They\nneed to implement either the\nOpenWriterAt\nor\nOpenChunkWriter\ninternal interfaces). These include include,\nlocal\n,\ns3\n,\nazureblob\n,\nb2\n,\noracleobjectstorage\nand\nsmb\nat the time of\nwriting.\nOn the local disk, rclone preallocates the file (using\nfallocate(FALLOC_FL_KEEP_SIZE)\non unix or\nNTSetInformationFile\non\nWindows both of which takes no time) then each thread writes directly\ninto the file at the correct place. This means that rclone won't\ncreate fragmented or sparse files and there won't be any assembly time\nat the end of the transfer.\nThe number of threads used to transfer is controlled by\n--multi-thread-streams\n.\nUse\n-vv\nif you wish to see info about the threads.\nThis will work with the\nsync\n,\ncopy\nand\nmove\ncommands, and friends\ncopyto\n,\nmoveto\n.\nMulti thread transfers will be used with\nrclone mount\nand\nrclone serve\nif\n--vfs-cache-mode\nis set to\nwrites\nor above.\nMost multi-thread transfers do not take additional memory, but some do\n(for example uploading to s3). In the worst case memory usage can be\nat maximum\n--transfers\n*\n--multi-thread-chunk-size\n*\n--multi-thread-streams\nor specifically for the s3 backend\n--transfers\n*\n--s3-chunk-size\n*\n--s3-concurrency\n. However you\ncan use the the\n--max-buffer-memory\nflag\nto control the maximum memory used here.\nNB\nthat this\nonly\nworks with supported backends as the\ndestination but will work with any backend as the source.\nNB\nthat multi-thread copies are disabled for local to local copies\nas they are faster without unless\n--multi-thread-streams\nis set\nexplicitly.\nNB\non Windows using multi-thread transfers to the local disk will\ncause the resulting files to be\nsparse\n.\nUse\n--local-no-sparse\nto disable sparse files (which may cause long\ndelays at the start of transfers) or disable multi-thread transfers\nwith\n--multi-thread-streams 0\n--multi-thread-streams int\nWhen using multi thread transfers (see above\n--multi-thread-cutoff\n)\nthis sets the number of streams to use. Set to\n0\nto disable multi\nthread transfers (Default 4).\nIf the backend has a\n--backend-upload-concurrency\nsetting (eg\n--s3-upload-concurrency\n) then this setting will be used as the\nnumber of transfers instead if it is larger than the value of\n--multi-thread-streams\nor\n--multi-thread-streams\nisn't set.\n--name-transform stringArray\n--name-transform\nintroduces path name transformations for\nrclone copy\n,\nrclone sync\n, and\nrclone move\n. These transformations\nenable modifications to source and destination file names by applying\nprefixes, suffixes, and other alterations during transfer operations.\nFor detailed docs and examples, see\nconvmv\n.\n--no-check-dest\nThe\n--no-check-dest\ncan be used with\nmove\nor\ncopy\nand it causes\nrclone not to check the destination at all when copying files.\nThis means that:\nthe destination is not listed minimising the API calls\nfiles are always transferred\nthis can cause duplicates on remotes which allow it (e.g. Google Drive)\n--retries 1\nis recommended otherwise you'll transfer everything again on a retry\nThis flag is useful to minimise the transactions if you know that none\nof the files are on the destination.\nThis is a specialized flag which should be ignored by most users!\n--no-gzip-encoding\nDon't set\nAccept-Encoding: gzip\n.  This means that rclone won't ask\nthe server for compressed files automatically. Useful if you've set\nthe server to return files with\nContent-Encoding: gzip\nbut you\nuploaded compressed files.\nThere is no need to set this in normal operation, and doing so will\ndecrease the network transfer efficiency of rclone.\n--no-traverse\nThe\n--no-traverse\nflag controls whether the destination file system\nis traversed when using the\ncopy\nor\nmove\ncommands.\n--no-traverse\nis not compatible with\nsync\nand will be ignored if\nyou supply it with\nsync\n.\nIf you are only copying a small number of files (or are filtering most\nof the files) and/or have a large number of files on the destination\nthen\n--no-traverse\nwill stop rclone listing the destination and save\ntime.\nHowever, if you are copying a large number of files, especially if you\nare doing a copy where lots of the files under consideration haven't\nchanged and won't need copying then you shouldn't use\n--no-traverse\n.\nSee\nrclone copy\nfor an example of how to use it.\n--no-unicode-normalization\nDon't normalize unicode characters in filenames during the sync routine.\nSometimes, an operating system will store filenames containing unicode\nparts in their decomposed form (particularly macOS). Some cloud storage\nsystems will then recompose the unicode, resulting in duplicate files if\nthe data is ever copied back to a local filesystem.\nUsing this flag will disable that functionality, treating each unicode\ncharacter as unique. For example, by default é and é will be normalized\ninto the same character. With\n--no-unicode-normalization\nthey will be\ntreated as unique characters.\n--no-update-modtime\nWhen using this flag, rclone won't update modification times of remote\nfiles if they are incorrect as it would normally.\nThis can be used if the remote is being synced with another tool also\n(e.g. the Google Drive client).\n--no-update-dir-modtime\nWhen using this flag, rclone won't update modification times of remote\ndirectories if they are incorrect as it would normally.\n--order-by string\nThe\n--order-by\nflag controls the order in which files in the backlog\nare processed in\nrclone sync\n,\nrclone copy\nand\nrclone move\n.\nThe order by string is constructed like this.  The first part\ndescribes what aspect is being measured:\nsize\n- order by the size of the files\nname\n- order by the full path of the files\nmodtime\n- order by the modification date of the files\nThis can have a modifier appended with a comma:\nascending\nor\nasc\n- order so that the smallest (or oldest) is processed first\ndescending\nor\ndesc\n- order so that the largest (or newest) is processed first\nmixed\n- order so that the smallest is processed first for some threads and\nthe largest for others\nIf the modifier is\nmixed\nthen it can have an optional percentage\n(which defaults to\n50\n), e.g.\nsize,mixed,25\nwhich means that 25% of\nthe threads should be taking the smallest items and 75% the\nlargest. The threads which take the smallest first will always take\nthe smallest first and likewise the largest first threads. The\nmixed\nmode can be useful to minimise the transfer time when you are\ntransferring a mixture of large and small files - the large files are\nguaranteed upload threads and bandwidth and the small files will be\nprocessed continuously.\nIf no modifier is supplied then the order is\nascending\n.\nFor example\n--order-by size,desc\n- send the largest files first\n--order-by modtime,ascending\n- send the oldest files first\n--order-by name\n- send the files with alphabetically by path first\nIf the\n--order-by\nflag is not supplied or it is supplied with an\nempty string then the default ordering will be used which is as\nscanned.  With\n--checkers 1\nthis is mostly alphabetical, however\nwith the default\n--checkers 8\nit is somewhat random.\nLimitations\nThe\n--order-by\nflag does not do a separate pass over the data.  This\nmeans that it may transfer some files out of the order specified if\nthere are no files in the backlog or the source has not been fully scanned yet\nthere are more than\n--max-backlog\nfiles in the backlog\nRclone will do its best to transfer the best file it has so in\npractice this should not cause a problem.  Think of\n--order-by\nas\nbeing more of a best efforts flag rather than a perfect ordering.\nIf you want perfect ordering then you will need to specify\n--check-first\nwhich will find all the files which need\ntransferring first before transferring any.\n--partial-suffix string\nWhen\n--inplace\nis not used, it causes rclone to use\nthe\n--partial-suffix\nas suffix for temporary files.\nSuffix length limit is 16 characters.\nThe default is\n.partial\n.\n--password-command SpaceSepList\nThis flag supplies a program which should supply the config password\nwhen run. This is an alternative to rclone prompting for the password\nor setting the\nRCLONE_CONFIG_PASS\nvariable. It is also used when\nsetting the config password for the first time.\nThe argument to this should be a command with a space separated list\nof arguments. If one of the arguments has a space in then enclose it\nin\n\"\n, if you want a literal\n\"\nin an argument then enclose the\nargument in\n\"\nand double the\n\"\n. See\nCSV encoding\nfor more info.\nEg\n--password-command \"echo hello\"\n--password-command 'echo \"hello with space\"'\n--password-command 'echo \"hello with \"\"quotes\"\" and space\"'\nNote that when changing the configuration password the environment\nvariable\nRCLONE_PASSWORD_CHANGE=1\nwill be set. This can be used to\ndistinguish initial decryption of the config file from the new\npassword.\nSee the\nConfiguration Encryption\nfor more info.\nSee a\nWindows PowerShell example on the Wiki\n.\n-P, --progress\nThis flag makes rclone update the stats in a static block in the\nterminal providing a realtime overview of the transfer.\nAny log messages will scroll above the static block.  Log messages\nwill push the static block down to the bottom of the terminal where it\nwill stay.\nNormally this is updated every 500mS but this period can be overridden\nwith the\n--stats\nflag.\nThis can be used with the\n--stats-one-line\nflag for a simpler\ndisplay.\nTo change the display length of filenames (for different terminal widths),\nsee the\n--stats-file-name-length\noption.  The default output is formatted\nfor 80 character wide terminals.\nNote: On Windows until\nthis bug\nis fixed all non-ASCII characters will be replaced with\n.\nwhen\n--progress\nis in use.\n--progress-terminal-title\nThis flag, when used with\n-P/--progress\n, will print the string\nETA: %s\nto the terminal title.\n-q, --quiet\nThis flag will limit rclone's output to error messages only.\n--refresh-times\nThe\n--refresh-times\nflag can be used to update modification times of\nexisting files when they are out of sync on backends which don't\nsupport hashes.\nThis is useful if you uploaded files with the incorrect timestamps and\nyou now wish to correct them.\nThis flag is\nonly\nuseful for destinations which don't support\nhashes (e.g.\ncrypt\n).\nThis can be used any of the sync commands\nsync\n,\ncopy\nor\nmove\n.\nTo use this flag you will need to be doing a modification time sync\n(so not using\n--size-only\nor\n--checksum\n). The flag will have no\neffect when using\n--size-only\nor\n--checksum\n.\nIf this flag is used when rclone comes to upload a file it will check\nto see if there is an existing file on the destination. If this file\nmatches the source with size (and checksum if available) but has a\ndiffering timestamp then instead of re-uploading it, rclone will\nupdate the timestamp on the destination file. If the checksum does not\nmatch rclone will upload the new file. If the checksum is absent (e.g.\non a\ncrypt\nbackend) then rclone will update the timestamp.\nNote that some remotes can't set the modification time without\nre-uploading the file so this flag is less useful on them.\nNormally if you are doing a modification time sync rclone will update\nmodification times without\n--refresh-times\nprovided that the remote\nsupports checksums\nand\nthe checksums match on the file. However if the\nchecksums are absent then rclone will upload the file rather than\nsetting the timestamp as this is the safe behaviour.\n--retries int\nRetry the entire sync if it fails this many times it fails (default 3).\nSome remotes can be unreliable and a few retries help pick up the\nfiles which didn't get transferred because of errors.\nDisable retries with\n--retries 1\n.\n--retries-sleep Duration\nThis sets the interval between each retry specified by\n--retries\nThe default is\n0\n. Use\n0\nto disable.\n--server-side-across-configs\nAllow server-side operations (e.g. copy or move) to work across\ndifferent configurations.\nThis can be useful if you wish to do a server-side copy or move\nbetween two remotes which use the same backend but are configured\ndifferently.\nNote that this isn't enabled by default because it isn't easy for\nrclone to tell if it will work between any two configurations.\n--size-only\nNormally rclone will look at modification time and size of files to\nsee if they are equal.  If you set this flag then rclone will check\nonly the size.\nThis can be useful transferring files from Dropbox which have been\nmodified by the desktop sync client which doesn't set checksums of\nmodification times in the same way as rclone.\n--stats Duration\nCommands which transfer data\n(\nsync\n,\ncopy\n,\ncopyto\n,\nmove\n,\nmoveto\n) will print data transfer stats at\nregular intervals to show their progress.\nThis sets the interval.\nThe default is\n1m\n. Use\n0\nto disable.\nIf you set the stats interval then all commands can show stats.  This\ncan be useful when running other commands,\ncheck\nor\nmount\nfor\nexample.\nStats are logged at\nINFO\nlevel by default which means they won't\nshow at default log level\nNOTICE\n.  Use\n--stats-log-level NOTICE\nor\n-v\nto make them show.  See the\nlogging\nsection for more\ninfo on log levels.\nNote that on macOS you can send a SIGINFO (which is normally ctrl-T in\nthe terminal) to make the stats print immediately.\n--stats-file-name-length int\nBy default, the\n--stats\noutput will truncate file names and paths longer\nthan 40 characters.  This is equivalent to providing\n--stats-file-name-length 40\n. Use\n--stats-file-name-length 0\nto disable\nany truncation of file names printed by stats.\n--stats-log-level LogLevel\nLog level to show\n--stats\noutput at.  This can be\nDEBUG\n,\nINFO\n,\nNOTICE\n, or\nERROR\n.  The default is\nINFO\n.  This means at the\ndefault level of logging, which is\nNOTICE\n, the stats won't show - if\nyou want them to then use\n--stats-log-level NOTICE\n.  See the\nlogging\nsection for more details on log levels.\n--stats-one-line\nWhen this is specified, rclone condenses the stats into a single line\nshowing the most important stats only.\n--stats-one-line-date\nWhen this is specified, rclone enables the single-line stats and prepends\nthe display with a date string. The default is\n2006/01/02 15:04:05 -\n--stats-one-line-date-format string\nWhen this is specified, rclone enables the single-line stats and prepends\nthe display with a user-supplied date string. The date string MUST be\nenclosed in quotes. Follow\ngolang specs\nfor date formatting syntax.\n--stats-unit string\nBy default, data transfer rates will be printed in bytes per second,\ncorresponding to\n--stats-unit bytes\n.\nThis option allows the data rate to be printed in bits per second,\nby specifying\n--stats-unit bits\n. Data transfer volume will still be\nreported in bytes.\nThe rate is reported as a binary unit, not SI unit. So 1 Mbit/s\nequals 1,048,576 bit/s and not 1,000,000 bit/s.\n--suffix string\nWhen using\nsync\n,\ncopy\nor\nmove\nany files which would have been\noverwritten or deleted will have the suffix added to them.  If there\nis a file with the same path (after the suffix has been added), then\nit will be overwritten.\nThe remote in use must support server-side move or copy and you must\nuse the same remote as the destination of the sync.\nThis is for use with files to add the suffix in the current directory\nor with\n--backup-dir\n. See\n--backup-dir\nfor more info.\nFor example\nrclone copy --interactive /path/to/local/file remote:current --suffix .bak\nwill copy\n/path/to/local\nto\nremote:current\n, but for any files\nwhich would have been updated or deleted have .bak added.\nIf using\nrclone sync\nwith\n--suffix\nand without\n--backup-dir\nthen\nit is recommended to put a filter rule in excluding the suffix\notherwise the\nsync\nwill delete the backup files.\nrclone sync --interactive /path/to/local/file remote:current --suffix .bak --exclude \"*.bak\"\n--suffix-keep-extension\nWhen using\n--suffix\n, setting this causes rclone put the SUFFIX\nbefore the extension of the files that it backs up rather than after.\nSo let's say we had\n--suffix -2019-01-01\n, without the flag\nfile.txt\nwould be backed up to\nfile.txt-2019-01-01\nand with the flag it would\nbe backed up to\nfile-2019-01-01.txt\n.  This can be helpful to make\nsure the suffixed files can still be opened.\nIf a file has two (or more) extensions and the second (or subsequent)\nextension is recognised as a valid mime type, then the suffix will go\nbefore that extension. So\nfile.tar.gz\nwould be backed up to\nfile-2019-01-01.tar.gz\nwhereas\nfile.badextension.gz\nwould be\nbacked up to\nfile.badextension-2019-01-01.gz\n.\n--syslog\nOn capable OSes (not Windows or Plan9) send all log output to syslog.\nThis can be useful for running rclone in a script or\nrclone mount\n.\n--syslog-facility string\nIf using\n--syslog\nthis sets the syslog facility (e.g.\nKERN\n,\nUSER\n).\nSee\nman syslog\nfor a list of possible facilities.  The default\nfacility is\nDAEMON\n.\n--temp-dir string\nSpecify the directory rclone will use for temporary files, to override\nthe default. Make sure the directory exists and have accessible permissions.\nBy default the operating system's temp directory will be used:\nOn Unix systems,\n$TMPDIR\nif non-empty, else\n/tmp\n.\nOn Windows, the first non-empty value from\n%TMP%\n,\n%TEMP%\n,\n%USERPROFILE%\n,\nor the Windows directory.\nWhen overriding the default with this option, the specified path will be\nset as value of environment variable\nTMPDIR\non Unix systems\nand\nTMP\nand\nTEMP\non Windows.\nYou can use the\nconfig paths\ncommand to see the current value.\n--tpslimit float\nLimit transactions per second to this number. Default is 0 which is\nused to mean unlimited transactions per second.\nA transaction is roughly defined as an API call; its exact meaning\nwill depend on the backend. For HTTP based backends it is an HTTP\nPUT/GET/POST/etc and its response. For FTP/SFTP it is a round trip\ntransaction over TCP.\nFor example, to limit rclone to 10 transactions per second use\n--tpslimit 10\n, or to 1 transaction every 2 seconds use\n--tpslimit 0.5\n.\nUse this when the number of transactions per second from rclone is\ncausing a problem with the cloud storage provider (e.g. getting you\nbanned or rate limited).\nThis can be very useful for\nrclone mount\nto control the behaviour of\napplications using it.\nThis limit applies to all HTTP based backends and to the FTP and SFTP\nbackends. It does not apply to the local backend or the Storj backend.\nSee also\n--tpslimit-burst\n.\n--tpslimit-burst int\nMax burst of transactions for\n--tpslimit\n(default\n1\n).\nNormally\n--tpslimit\nwill do exactly the number of transaction per\nsecond specified.  However if you supply\n--tps-burst\nthen rclone can\nsave up some transactions from when it was idle giving a burst of up\nto the parameter supplied.\nFor example if you provide\n--tpslimit-burst 10\nthen if rclone has\nbeen idle for more than 10*\n--tpslimit\nthen it can do 10 transactions\nvery quickly before they are limited again.\nThis may be used to increase performance of\n--tpslimit\nwithout\nchanging the long term average number of transactions per second.\n--track-renames\nBy default, rclone doesn't keep track of renamed files, so if you\nrename a file locally then sync it to a remote, rclone will delete the\nold file on the remote and upload a new copy.\nAn rclone sync with\n--track-renames\nruns like a normal sync, but keeps\ntrack of objects which exist in the destination but not in the source\n(which would normally be deleted), and which objects exist in the\nsource but not the destination (which would normally be transferred).\nThese objects are then candidates for renaming.\nAfter the sync, rclone matches up the source only and destination only\nobjects using the\n--track-renames-strategy\nspecified and either\nrenames the destination object or transfers the source and deletes the\ndestination object.\n--track-renames\nis stateless like all of\nrclone's syncs.\nTo use this flag the destination must support server-side copy or\nserver-side move, and to use a hash based\n--track-renames-strategy\n(the default) the source and the destination must have a compatible\nhash.\nIf the destination does not support server-side copy or move, rclone\nwill fall back to the default behaviour and log an error level message\nto the console.\nEncrypted destinations are not currently supported by\n--track-renames\nif\n--track-renames-strategy\nincludes\nhash\n.\nNote that\n--track-renames\nis incompatible with\n--no-traverse\nand\nthat it uses extra memory to keep track of all the rename candidates.\nNote also that\n--track-renames\nis incompatible with\n--delete-before\nand will select\n--delete-after\ninstead of\n--delete-during\n.\n--track-renames-strategy string\nThis option changes the file matching criteria for\n--track-renames\n.\nThe matching is controlled by a comma separated selection of these tokens:\nmodtime\n- the modification time of the file - not supported on all backends\nhash\n- the hash of the file contents - not supported on all backends\nleaf\n- the name of the file not including its directory name\nsize\n- the size of the file (this is always enabled)\nThe default option is\nhash\n.\nUsing\n--track-renames-strategy modtime,leaf\nwould match files\nbased on modification time, the leaf of the file name and the size\nonly.\nUsing\n--track-renames-strategy modtime\nor\nleaf\ncan enable\n--track-renames\nsupport for encrypted destinations.\nNote that the\nhash\nstrategy is not supported with encrypted destinations.\n--delete-(before,during,after)\nThis option allows you to specify when files on your destination are\ndeleted when you sync folders.\nSpecifying the value\n--delete-before\nwill delete all files present\non the destination, but not on the source\nbefore\nstarting the\ntransfer of any new or updated files. This uses two passes through the\nfile systems, one for the deletions and one for the copies.\nSpecifying\n--delete-during\nwill delete files while checking and\nuploading files. This is the fastest option and uses the least memory.\nSpecifying\n--delete-after\n(the default value) will delay deletion of\nfiles until all new/updated files have been successfully transferred.\nThe files to be deleted are collected in the copy pass then deleted\nafter the copy pass has completed successfully.  The files to be\ndeleted are held in memory so this mode may use more memory.  This is\nthe safest mode as it will only delete files if there have been no\nerrors subsequent to that.  If there have been errors before the\ndeletions start then you will get the message\nnot deleting files as there were IO errors\n.\n--fast-list\nWhen doing anything which involves a directory listing (e.g.\nsync\n,\ncopy\n,\nls\n- in fact nearly every command), rclone has different\nstrategies to choose from.\nThe basic strategy is to list one directory and processes it before using\nmore directory lists to process any subdirectories. This is a mandatory\nbackend feature, called\nList\n, which means it is supported by all backends.\nThis strategy uses small amount of memory, and because it can be parallelised\nit is fast for operations involving processing of the list results.\nSome backends provide the support for an alternative strategy, where all\nfiles beneath a directory can be listed in one (or a small number) of\ntransactions. Rclone supports this alternative strategy through an optional\nbackend feature called\nListR\n. You can see in the storage\nsystem overview documentation's\noptional features\nsection which backends it is enabled for (these tend to be the bucket-based\nones, e.g. S3, B2, GCS, Swift). This strategy requires fewer transactions\nfor highly recursive operations, which is important on backends where this\nis charged or heavily rate limited. It may be faster (due to fewer transactions)\nor slower (because it can't be parallelized) depending on different parameters,\nand may require more memory if rclone has to keep the whole listing in memory.\nWhich listing strategy rclone picks for a given operation is complicated, but\nin general it tries to choose the best possible. It will prefer\nListR\nin\nsituations where it doesn't need to store the listed files in memory, e.g.\nfor unlimited recursive\nls\ncommand variants. In other situations it will\nprefer\nList\n, e.g. for\nsync\nand\ncopy\n, where it needs to keep the listed\nfiles in memory, and is performing operations on them where parallelization\nmay be a huge advantage.\nRclone is not able to take all relevant parameters into account for deciding\nthe best strategy, and therefore allows you to influence the choice in two ways:\nYou can stop rclone from using\nListR\nby disabling the feature, using the\n--disable\noption (\n--disable ListR\n), or you can\nallow rclone to use\nListR\nwhere it would normally choose not to do so due to\nhigher memory usage, using the\n--fast-list\noption. Rclone should always\nproduce identical results either way. Using\n--disable ListR\nor\n--fast-list\non a remote which doesn't support\nListR\ndoes nothing, rclone will just ignore\nit.\nA rule of thumb is that if you pay for transactions and can fit your entire\nsync listing into memory, then\n--fast-list\nis recommended. If you have a\nvery big sync to do, then don't use\n--fast-list\n, otherwise you will run out\nof memory. Run some tests and compare before you decide, and if in doubt then\njust leave the default, let rclone decide, i.e. not use\n--fast-list\n.\n--timeout Duration\nThis sets the IO idle timeout.  If a transfer has started but then\nbecomes idle for this long it is considered broken and disconnected.\nThe default is\n5m\n.  Set to\n0\nto disable.\n--transfers int\nThe number of file transfers to run in parallel.  It can sometimes be\nuseful to set this to a smaller number if the remote is giving a lot\nof timeouts or bigger if you have lots of bandwidth and a fast remote.\nThe default is to run 4 file transfers in parallel.\nLook at --multi-thread-streams if you would like to control single file transfers.\n-u, --update\nThis forces rclone to skip any files which exist on the destination\nand have a modified time that is newer than the source file.\nThis can be useful in avoiding needless transfers when transferring to\na remote which doesn't support modification times directly (or when\nusing\n--use-server-modtime\nto avoid extra API calls) as it is more\naccurate than a\n--size-only\ncheck and faster than using\n--checksum\n. On such remotes (or when using\n--use-server-modtime\n)\nthe time checked will be the uploaded time.\nIf an existing destination file has a modification time older than the\nsource file's, it will be updated if the sizes are different. If the\nsizes are the same, it will be updated if the checksum is different or\nnot available.\nIf an existing destination file has a modification time equal (within\nthe computed modify window) to the source file's, it will be updated\nif the sizes are different. The checksum will not be checked in this\ncase unless the\n--checksum\nflag is provided.\nIn all other cases the file will not be updated.\nConsider using the\n--modify-window\nflag to compensate for time skews\nbetween the source and the backend, for backends that do not support\nmod times, and instead use uploaded times. However, if the backend\ndoes not support checksums, note that syncing or copying within the\ntime skew window may still result in additional transfers for safety.\n--use-mmap\nIf this flag is set then rclone will use anonymous memory allocated by\nmmap on Unix based platforms and VirtualAlloc on Windows for its\ntransfer buffers (size controlled by\n--buffer-size\n).  Memory\nallocated like this does not go on the Go heap and can be returned to\nthe OS immediately when it is finished with.\nIf this flag is not set then rclone will allocate and free the buffers\nusing the Go memory allocator which may use more memory as memory\npages are returned less aggressively to the OS.\nIt is possible this does not work well on all platforms so it is\ndisabled by default; in the future it may be enabled by default.\n--use-server-modtime\nSome object-store backends (e.g, Swift, S3) do not preserve file modification\ntimes (modtime). On these backends, rclone stores the original modtime as\nadditional metadata on the object. By default it will make an API call to\nretrieve the metadata when the modtime is needed by an operation.\nUse this flag to disable the extra API call and rely instead on the server's\nmodified time. In cases such as a local to remote sync using\n--update\n,\nknowing the local file is newer than the time it was last uploaded to the\nremote is sufficient. In those cases, this flag can speed up the process and\nreduce the number of API calls necessary.\nUsing this flag on a sync operation without also using\n--update\nwould cause\nall files modified at any time other than the last upload time to be uploaded\nagain, which is probably not what you want.\n-v, -vv, --verbose\nWith\n-v\nrclone will tell you about each file that is transferred and\na small number of significant events.\nWith\n-vv\nrclone will become very verbose telling you about every\nfile it considers and transfers.  Please send bug reports with a log\nwith this setting.\nWhen setting verbosity as an environment variable, use\nRCLONE_VERBOSE=1\nor\nRCLONE_VERBOSE=2\nfor\n-v\nand\n-vv\nrespectively.\n-V, --version\nPrints the version number\nSSL/TLS options\nThe outgoing SSL/TLS connections rclone makes can be controlled with\nthese options.  For example this can be very useful with the HTTP or\nWebDAV backends. Rclone HTTP servers have their own set of\nconfiguration for SSL/TLS which you can find in their documentation.\n--ca-cert stringArray\nThis loads the PEM encoded certificate authority certificates and uses\nit to verify the certificates of the servers rclone connects to.\nIf you have generated certificates signed with a local CA then you\nwill need this flag to connect to servers using those certificates.\n--client-cert string\nThis loads the PEM encoded client side certificate.\nThis is used for\nmutual TLS authentication\n.\nThe\n--client-key\nflag is required too when using this.\n--client-key string\nThis loads the PEM encoded client side private key used for mutual TLS\nauthentication.  Used in conjunction with\n--client-cert\n.\nSupported types are:\nUnencrypted PKCS#1 (\"BEGIN RSA PRIVATE KEY\")\nUnencrypted PKCS#8 (\"BEGIN PRIVATE KEY\")\nEncrypted PKCS#8 (\"BEGIN ENCRYPTED PRIVATE KEY\")\nLegacy PEM encryption (e.g., DEK-Info headers), which are automatically detected.\n--client-pass string\nThis can be used to supply an optional password to decrypt the client key file.\nNB\nthe password should be obscured so it should be the output of\nrclone obscure YOURPASSWORD\n.\n--no-check-certificate\n--no-check-certificate\ncontrols whether a client verifies the\nserver's certificate chain and host name.\nIf\n--no-check-certificate\nis true, TLS accepts any certificate\npresented by the server and any host name in that certificate.\nIn this mode, TLS is susceptible to man-in-the-middle attacks.\nThis option defaults to\nfalse\n.\nThis should be used only for testing.\nConfiguration encryption\nYour configuration file contains information for logging in to\nyour cloud services. This means that you should keep your\nrclone.conf\nfile in a secure location.\nIf you are in an environment where that isn't possible, you can\nadd a password to your configuration. This means that you will\nhave to supply the password every time you start rclone.\nTo add a password to your rclone configuration, execute\nrclone config\n.\n$ rclone config\nCurrent remotes:\ne) Edit existing remote\nn) New remote\nd) Delete remote\ns) Set configuration password\nq) Quit config\ne/n/d/s/q>\nGo into\ns\n, Set configuration password:\ne/n/d/s/q> s\nYour configuration is not encrypted.\nIf you add a password, you will protect your login information to cloud services.\na) Add Password\nq) Quit to main menu\na/q> a\nEnter NEW configuration password:\npassword:\nConfirm NEW password:\npassword:\nPassword set\nYour configuration is encrypted.\nc) Change Password\nu) Unencrypt configuration\nq) Quit to main menu\nc/u/q>\nYour configuration is now encrypted, and every time you start rclone\nyou will have to supply the password. See below for details.\nIn the same menu, you can change the password or completely remove\nencryption from your configuration.\nThere is no way to recover the configuration if you lose your password.\nYou can also use\nrclone config encryption set\nto set the config encryption directly\nrclone config encryption remove\nto remove it\nrclone config encryption check\nto check that it is encrypted properly.\nrclone uses\nnacl secretbox\nwhich in turn uses XSalsa20 and Poly1305 to encrypt and authenticate\nyour configuration with secret-key cryptography.\nThe password is SHA-256 hashed, which produces the key for secretbox.\nThe hashed password is not stored.\nWhile this provides very good security, we do not recommend storing\nyour encrypted rclone configuration in public if it contains sensitive\ninformation, maybe except if you use a very strong password.\nIf it is safe in your environment, you can set the\nRCLONE_CONFIG_PASS\nenvironment variable to contain your password, in which case it will be\nused for decrypting the configuration.\nYou can set this for a session from a script.  For unix like systems\nsave this to a file called\nset-rclone-password\n:\n#!/bin/echo Source this file don't run it\nread\n-s RCLONE_CONFIG_PASS\nexport\nRCLONE_CONFIG_PASS\nThen source the file when you want to use it.  From the shell you\nwould do\nsource set-rclone-password\n.  It will then ask you for the\npassword and set it in the environment variable.\nAn alternate means of supplying the password is to provide a script\nwhich will retrieve the password and print on standard output.  This\nscript should have a fully specified path name and not rely on any\nenvironment variables.  The script is supplied either via\n--password-command=\"...\"\ncommand line argument or via the\nRCLONE_PASSWORD_COMMAND\nenvironment variable.\nOne useful example of this is using the\npasswordstore\napplication\nto retrieve the password:\nexport RCLONE_PASSWORD_COMMAND=\"pass rclone/config\"\nIf the\npasswordstore\npassword manager holds the password for the\nrclone configuration, using the script method means the password\nis primarily protected by the\npasswordstore\nsystem, and is never\nembedded in the clear in scripts, nor available for examination\nusing the standard commands available.  It is quite possible with\nlong running rclone sessions for copies of passwords to be innocently\ncaptured in log files or terminal scroll buffers, etc.  Using the\nscript method of supplying the password enhances the security of\nthe config password considerably.\nIf you are running rclone inside a script, unless you are using the\n--password-command\nmethod, you might want to disable\npassword prompts. To do that, pass the parameter\n--ask-password=false\nto rclone. This will make rclone fail instead\nof asking for a password if\nRCLONE_CONFIG_PASS\ndoesn't contain\na valid password, and\n--password-command\nhas not been supplied.\nWhenever running commands that may be affected by options in a\nconfiguration file, rclone will look for an existing file according\nto the rules described\nabove\n, and load any it\nfinds. If an encrypted file is found, this includes decrypting it,\nwith the possible consequence of a password prompt. When executing\na command line that you know are not actually using anything from such\na configuration file, you can avoid it being loaded by overriding the\nlocation, e.g. with one of the documented special values for\nmemory-only configuration. Since only backend options can be stored\nin configuration files, this is normally unnecessary for commands\nthat do not operate on backends, e.g.\ncompletion\n. However,\nit will be relevant for commands that do operate on backends in\ngeneral, but are used without referencing a stored remote, e.g.\nlisting local filesystem paths, or\nconnection strings\n:\nrclone --config=\"\" ls .\nConfiguration encryption cheatsheet\nYou can quickly apply a configuration encryption without plain-text\nat rest or transfer. Detailed instructions for popular OSes:\nMac\nGenerate and store a password\nsecurity add-generic-password -a rclone -s config -w $(openssl rand -base64 40)\nAdd the retrieval instruction to your\n.zprofile\n/\n.profile\nexport RCLONE_PASSWORD_COMMAND=\"/usr/bin/security find-generic-password -a rclone -s config -w\"\nLinux\nPrerequisite: Linux doesn't come with a default password manager. Let's install\nthe \"pass\" utility using a package manager, e.g.\napt install pass\n,\nyum install pass\n,\netc.\n;\nthen initialize a password store:\npass init rclone\n.\nGenerate and store a password\necho $(openssl rand -base64 40) | pass insert -m rclone/config\nAdd the retrieval instruction\nexport RCLONE_PASSWORD_COMMAND=\"/usr/bin/pass rclone/config\"\nWindows\nGenerate and store a password\nNew-Object\n-TypeName\nPSCredential\n-ArgumentList\n\"rclone\"\n,\n(\nConvertTo-SecureString\n-String\n([\nSystem.Web.Security.Membership\n]::\nGeneratePassword\n(\n40\n,\n10\n))\n-AsPlainText\n-Force\n)\n|\nExport-Clixml\n-Path\n\"rclone-credential.xml\"\nAdd the password retrieval instruction\n[\nEnvironment\n]::\nSetEnvironmentVariable\n(\n\"RCLONE_PASSWORD_COMMAND\"\n,\n\"[System.Runtime.InteropServices.Marshal]::PtrToStringAuto([System.Runtime.InteropServices.Marshal]::SecureStringToBSTR((Import-Clixml -Path \"\nrclone-credential\n.\nxml\n\").Password))\"\n)\nEncrypt the config file (all systems)\nExecute\nrclone config\n, and select option\ns) Set configuration password\nAdd/update the password from previous steps\nDeveloper options\nThese options are useful when developing or debugging rclone.  There\nare also some more remote specific options which aren't documented\nhere which are used for testing.  These start with remote name e.g.\n--drive-test-option\n- see the docs for the remote in question.\n--cpuprofile string\nWrite CPU profile to a file. This can be analysed with\ngo tool pprof\n.\n--memprofile string\nWrite memory profile to a file. This can be analysed with\ngo tool pprof\n.\n--dump DumpFlags\nThe\n--dump\nflag takes a comma separated list of flags to dump info\nabout.\nNote that some headers, such as\nAccept-Encoding\n, may not be correct\nas shown in the request, and the response may not show\nContent-Encoding\nif the go standard libraries auto gzip encoding was in effect. In this case\nthe body of the request will be gunzipped before showing it.\nThe available flags are:\nheaders\ndumps HTTP headers. Any\nAuthorization:\nheaders will be excluded,\nbut output may still contain sensitive information.  Can be very verbose.\nUseful for debugging only. Use\nauth\nif you do want the\nAuthorization:\nheaders.\nauth\ndumps HTTP headers like\nheaders\n, but also includes any\nAuthorization:\nheaders. This means the output will probably contain sensitive information.\nUse\nheaders\nto dump without\nAuthorization:\nheaders. Can be very verbose.\nUseful for debugging only.\nbodies\ndumps HTTP headers and bodies. May contain sensitive info.\nCan be very verbose.  Useful for debugging only. Note that the bodies\nare buffered in memory so don't use this for enormous files.\nrequests\nis similar to\nbodies\n, but dumps the request bodies and the\nresponse headers.  Useful for debugging download problems.\nresponses\nis similar to\nbodies\n, but dumps the response bodies and the\nrequest headers. Useful for debugging upload problems.\nfilters\ndumps the filters.  Useful to see exactly what include\nand exclude options are filtering on.\ngoroutines\ndumps a list of the running go-routines at the end of\nthe command.\nopenfiles\ndumps a list of the open files at the end of the command.\nIt uses the\nlsof\nUnix command to do that, so you'll need that installed\nto use it.\nmapper\ndumps the JSON blobs being sent to the program supplied with\n--metadata-mapper\nand received from it. It can be useful for debugging\nthe metadata mapper interface.\nFiltering\nFor the filtering options\n--delete-excluded\n--filter\n--filter-from\n--exclude\n--exclude-from\n--exclude-if-present\n--include\n--include-from\n--files-from\n--files-from-raw\n--min-size\n--max-size\n--min-age\n--max-age\n--hash-filter\n--dump filters\n--metadata-include\n--metadata-include-from\n--metadata-exclude\n--metadata-exclude-from\n--metadata-filter\n--metadata-filter-from\nSee the\nfiltering section\n.\nRemote control\nFor the remote control options and for instructions on how to remote control rclone:\n--rc\nAnything starting with\n--rc-\nSee\nthe remote control section\n.\nLogging\nrclone has 4 levels of logging,\nERROR\n,\nNOTICE\n,\nINFO\nand\nDEBUG\n.\nBy default, rclone logs to standard error.  This means you can redirect\nstandard error and still see the normal output of rclone commands (e.g.\nrclone ls\n).\nBy default, rclone will produce\nError\nand\nNotice\nlevel messages.\nIf you use the\n-q\nflag, rclone will only produce\nError\nmessages.\nIf you use the\n-v\nflag, rclone will produce\nError\n,\nNotice\nand\nInfo\nmessages.\nIf you use the\n-vv\nflag, rclone will produce\nError\n,\nNotice\n,\nInfo\nand\nDebug\nmessages.\nYou can also control the log levels with the\n--log-level\nflag.\nIf you use the\n--log-file\noption, rclone will redirect\nError\n,\nInfo\nand\nDebug\nmessages along with standard error to a file.\nIf you use the\n--syslog\nflag then rclone will log to syslog and the\n--syslog-facility\ncontrol which facility it uses.\nRclone prefixes all log messages with their level in capitals, e.g. INFO\nwhich makes it easy to grep the log file for different kinds of\ninformation.\nMetrics\nRclone can publish metrics in the OpenMetrics/Prometheus format.\nTo enable the metrics endpoint, use the\n--metrics-addr\nflag. Metrics can\nalso be published on the\n--rc-addr\nport if the\n--rc\nflag and\n--rc-enable-metrics\nflags are supplied or if using rclone rcd\n--rc-enable-metrics\nRclone provides extensive configuration options for the metrics HTTP endpoint.\nThese settings are grouped under the Metrics section and have a prefix\n--metrics-*\n.\nWhen metrics are enabled with\n--rc-enable-metrics\n, they will be published on\nthe same port as the rc API. In this case, the\n--metrics-*\nflags will be\nignored, and the HTTP endpoint configuration will be managed by the\n--rc-*\nparameters.\nExit code\nIf any errors occur during the command execution, rclone will exit with a\nnon-zero exit code.  This allows scripts to detect when rclone\noperations have failed.\nDuring the startup phase, rclone will exit immediately if an error is\ndetected in the configuration.  There will always be a log message\nimmediately before exiting.\nWhen rclone is running it will accumulate errors as it goes along, and\nonly exit with a non-zero exit code if (after retries) there were\nstill failed transfers.  For every error counted there will be a high\npriority log message (visible with\n-q\n) showing the message and\nwhich file caused the problem. A high priority message is also shown\nwhen starting a retry so the user can see that any previous error\nmessages may not be valid after the retry. If rclone has done a retry\nit will log a high priority message if the retry was successful.\nList of exit codes\n0\n- Success\n1\n- Error not otherwise categorised\n2\n- Syntax or usage error\n3\n- Directory not found\n4\n- File not found\n5\n- Temporary error (one that more retries might fix) (Retry errors)\n6\n- Less serious errors (like 461 errors from dropbox) (NoRetry errors)\n7\n- Fatal error (one that more retries won't fix, like account suspended)\n(Fatal errors)\n8\n- Transfer exceeded - limit set by --max-transfer reached\n9\n- Operation successful, but no files transferred (Requires\n--error-on-no-transfer\n)\n10\n- Duration exceeded - limit set by --max-duration reached\nEnvironment variables\nRclone can be configured entirely using environment variables.  These\ncan be used to set defaults for options or config file entries.\nOptions\nEvery option in rclone can have its default set by environment\nvariable.\nTo find the name of the environment variable, first, take the long\noption name, strip the leading\n--\n, change\n-\nto\n_\n, make\nupper case and prepend\nRCLONE_\n.\nFor example, to always set\n--stats 5s\n, set the environment variable\nRCLONE_STATS=5s\n.  If you set stats on the command line this will\noverride the environment variable setting.\nOr to always use the trash in drive\n--drive-use-trash\n, set\nRCLONE_DRIVE_USE_TRASH=true\n.\nVerbosity is slightly different, the environment variable\nequivalent of\n--verbose\nor\n-v\nis\nRCLONE_VERBOSE=1\n,\nor for\n-vv\n,\nRCLONE_VERBOSE=2\n.\nThe same parser is used for the options and the environment variables\nso they take exactly the same form.\nThe options set by environment variables can be seen with the\n-vv\nflag,\ne.g.\nrclone version -vv\n.\nOptions that can appear multiple times (type\nstringArray\n) are\ntreated slightly differently as environment variables can only be\ndefined once. In order to allow a simple mechanism for adding one or\nmany items, the input is treated as a\nCSV encoded\nstring. For example\nEnvironment variable\nEquivalent options\nRCLONE_EXCLUDE=\"*.jpg\"\n--exclude \"*.jpg\"\nRCLONE_EXCLUDE=\"*.jpg,*.png\"\n--exclude \"*.jpg\"\n--exclude \"*.png\"\nRCLONE_EXCLUDE='\"*.jpg\",\"*.png\"'\n--exclude \"*.jpg\"\n--exclude \"*.png\"\nRCLONE_EXCLUDE='\"/directory with comma , in it /**\"'\n`--exclude \"/directory with comma , in it /**\"\nIf\nstringArray\noptions are defined as environment variables\nand\noptions on the command line then all the values will be used.\nConfig file\nYou can set defaults for values in the config file on an individual\nremote basis. The names of the config items are documented in the page\nfor each backend.\nTo find the name of the environment variable, you need to set, take\nRCLONE_CONFIG_\n+ name of remote +\n_\n+ name of config file option\nand make it all uppercase.\nNote one implication here is the remote's name must be\nconvertible into a valid environment variable name,\nso it can only contain letters, digits, or the\n_\n(underscore) character.\nFor example, to configure an S3 remote named\nmys3:\nwithout a config\nfile (using unix ways of setting environment variables):\n$\nexport\nRCLONE_CONFIG_MYS3_TYPE\n=\ns3\n$\nexport\nRCLONE_CONFIG_MYS3_ACCESS_KEY_ID\n=\nXXX\n$\nexport\nRCLONE_CONFIG_MYS3_SECRET_ACCESS_KEY\n=\nXXX\n$ rclone lsd mys3:\n-1 2016-09-21 12:54:21        -1 my-bucket\n$ rclone listremotes\n|\ngrep mys3\nmys3:\nNote that if you want to create a remote using environment variables\nyou must create the\n..._TYPE\nvariable as above.\nNote that the name of a remote created using environment variable is\ncase insensitive, in contrast to regular remotes stored in config\nfile as documented\nabove\n.\nYou must write the name in uppercase in the environment variable, but\nas seen from example above it will be listed and can be accessed in\nlowercase, while you can also refer to the same remote in uppercase:\n$ rclone lsd mys3:\n-1 2016-09-21 12:54:21        -1 my-bucket\n$ rclone lsd MYS3:\n-1 2016-09-21 12:54:21        -1 my-bucket\nNote that you can only set the options of the immediate backend,\nso RCLONE_CONFIG_MYS3CRYPT_ACCESS_KEY_ID has no effect, if myS3Crypt is\na crypt remote based on an S3 remote. However RCLONE_S3_ACCESS_KEY_ID will\nset the access key of all remotes using S3, including myS3Crypt.\nNote also that now rclone has\nconnection strings\n,\nit is probably easier to use those instead which makes the above example\nrclone lsd :s3,access_key_id=XXX,secret_access_key=XXX:\nPrecedence\nThe various different methods of backend configuration are read in\nthis order and the first one with a value is used.\nParameters in connection strings, e.g.\nmyRemote,skip_links:\nFlag values as supplied on the command line, e.g.\n--skip-links\nRemote specific environment vars, e.g.\nRCLONE_CONFIG_MYREMOTE_SKIP_LINKS\n(see above).\nBackend-specific environment vars, e.g.\nRCLONE_LOCAL_SKIP_LINKS\n.\nBackend generic environment vars, e.g.\nRCLONE_SKIP_LINKS\n.\nConfig file, e.g.\nskip_links = true\n.\nDefault values, e.g.\nfalse\n- these can't be changed.\nSo if both\n--skip-links\nis supplied on the command line and an\nenvironment variable\nRCLONE_LOCAL_SKIP_LINKS\nis set, the command line\nflag will take preference.\nThe backend configurations set by environment variables can be seen with the\n-vv\nflag, e.g.\nrclone about myRemote: -vv\n.\nFor non backend configuration the order is as follows:\nFlag values as supplied on the command line, e.g.\n--stats 5s\n.\nEnvironment vars, e.g.\nRCLONE_STATS=5s\n.\nDefault values, e.g.\n1m\n- these can't be changed.\nOther environment variables\nRCLONE_CONFIG_PASS\nset to contain your config file password (see\nConfiguration Encryption\nsection)\nHTTP_PROXY\n,\nHTTPS_PROXY\nand\nNO_PROXY\n(or the lowercase versions thereof).\nHTTPS_PROXY\ntakes precedence over\nHTTP_PROXY\nfor https requests.\nThe environment values may be either a complete URL or a \"host[:port]\"\nfor, in which case the \"http\" scheme is assumed.\nUSER\nand\nLOGNAME\nvalues are used as fallbacks for current username.\nThe primary method for looking up username is OS-specific: Windows API on\nWindows, real user ID in /etc/passwd on Unix systems. In the documentation\nthe current username is simply referred to as\n$USER\n.\nRCLONE_CONFIG_DIR\n- rclone\nsets\nthis variable for use in config files\nand sub processes to point to the directory holding the config file.\nThe options set by environment variables can be seen with the\n-vv\nand\n--log-level=DEBUG\nflags, e.g.\nrclone version -vv\n.\nContents\nPlatinum Sponsor\nGold Sponsor\nGold Sponsor\nShare and Enjoy\nTwitter\nFacebook\nReddit\nLinks\nRclone forum\nGitHub project\nRclone Wiki\nSponsor\n@njcw", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://rclone.org/docs/"}}
{"text": "Commands\nRclone Commands\nThis is an index of all commands in rclone. Run\nrclone\ncommand --help\nto see the help for that command.\nCommand\nDescription\nrclone\nShow help for rclone commands, flags and backends.\nrclone about\nGet quota information from the remote.\nrclone archive\nPerform an action on an archive.\nrclone archive create\nArchive source file(s) to destination.\nrclone archive extract\nExtract archives from source to destination.\nrclone archive list\nList archive contents from source.\nrclone authorize\nRemote authorization.\nrclone backend\nRun a backend-specific command.\nrclone bisync\nPerform bidirectional synchronization between two paths.\nrclone cat\nConcatenates any files and sends them to stdout.\nrclone check\nChecks the files in the source and destination match.\nrclone checksum\nChecks the files in the destination against a SUM file.\nrclone cleanup\nClean up the remote if possible.\nrclone completion\nOutput completion script for a given shell.\nrclone completion bash\nOutput bash completion script for rclone.\nrclone completion fish\nOutput fish completion script for rclone.\nrclone completion powershell\nOutput powershell completion script for rclone.\nrclone completion zsh\nOutput zsh completion script for rclone.\nrclone config\nEnter an interactive configuration session.\nrclone config create\nCreate a new remote with name, type and options.\nrclone config delete\nDelete an existing remote.\nrclone config disconnect\nDisconnects user from remote\nrclone config dump\nDump the config file as JSON.\nrclone config edit\nEnter an interactive configuration session.\nrclone config encryption\nset, remove and check the encryption for the config file\nrclone config encryption check\nCheck that the config file is encrypted\nrclone config encryption remove\nRemove the config file encryption password\nrclone config encryption set\nSet or change the config file encryption password\nrclone config file\nShow path of configuration file in use.\nrclone config password\nUpdate password in an existing remote.\nrclone config paths\nShow paths used for configuration, cache, temp etc.\nrclone config providers\nList in JSON format all the providers and options.\nrclone config reconnect\nRe-authenticates user with remote.\nrclone config redacted\nPrint redacted (decrypted) config file, or the redacted config for a single remote.\nrclone config show\nPrint (decrypted) config file, or the config for a single remote.\nrclone config string\nPrint connection string for a single remote.\nrclone config touch\nEnsure configuration file exists.\nrclone config update\nUpdate options in an existing remote.\nrclone config userinfo\nPrints info about logged in user of remote.\nrclone convmv\nConvert file and directory names in place.\nrclone copy\nCopy files from source to dest, skipping identical files.\nrclone copyto\nCopy files from source to dest, skipping identical files.\nrclone copyurl\nCopy the contents of the URL supplied content to dest:path.\nrclone cryptcheck\nCryptcheck checks the integrity of an encrypted remote.\nrclone cryptdecode\nCryptdecode returns unencrypted file names.\nrclone dedupe\nInteractively find duplicate filenames and delete/rename them.\nrclone delete\nRemove the files in path.\nrclone deletefile\nRemove a single file from remote.\nrclone gendocs\nOutput markdown docs for rclone to the directory supplied.\nrclone gitannex\nSpeaks with git-annex over stdin/stdout.\nrclone hashsum\nProduces a hashsum file for all the objects in the path.\nrclone link\nGenerate public link to file/folder.\nrclone listremotes\nList all the remotes in the config file and defined in environment variables.\nrclone ls\nList the objects in the path with size and path.\nrclone lsd\nList all directories/containers/buckets in the path.\nrclone lsf\nList directories and objects in remote:path formatted for parsing.\nrclone lsjson\nList directories and objects in the path in JSON format.\nrclone lsl\nList the objects in path with modification time, size and path.\nrclone md5sum\nProduces an md5sum file for all the objects in the path.\nrclone mkdir\nMake the path if it doesn't already exist.\nrclone mount\nMount the remote as file system on a mountpoint.\nrclone move\nMove files from source to dest.\nrclone moveto\nMove file or directory from source to dest.\nrclone ncdu\nExplore a remote with a text based user interface.\nrclone nfsmount\nMount the remote as file system on a mountpoint.\nrclone obscure\nObscure password for use in the rclone config file.\nrclone purge\nRemove the path and all of its contents.\nrclone rc\nRun a command against a running rclone.\nrclone rcat\nCopies standard input to file on remote.\nrclone rcd\nRun rclone listening to remote control commands only.\nrclone rmdir\nRemove the empty directory at path.\nrclone rmdirs\nRemove empty directories under the path.\nrclone selfupdate\nUpdate the rclone binary.\nrclone serve\nServe a remote over a protocol.\nrclone serve dlna\nServe remote:path over DLNA\nrclone serve docker\nServe any remote on docker's volume plugin API.\nrclone serve ftp\nServe remote:path over FTP.\nrclone serve http\nServe the remote over HTTP.\nrclone serve nfs\nServe the remote as an NFS mount\nrclone serve restic\nServe the remote for restic's REST API.\nrclone serve s3\nServe remote:path over s3.\nrclone serve sftp\nServe the remote over SFTP.\nrclone serve webdav\nServe remote:path over WebDAV.\nrclone settier\nChanges storage class/tier of objects in remote.\nrclone sha1sum\nProduces an sha1sum file for all the objects in the path.\nrclone size\nPrints the total size and number of objects in remote:path.\nrclone sync\nMake source and dest identical, modifying destination only.\nrclone test\nRun a test command\nrclone test changenotify\nLog any change notify requests for the remote passed in.\nrclone test histogram\nMakes a histogram of file name characters.\nrclone test info\nDiscovers file name or other limitations for paths.\nrclone test makefile\nMake files with random contents of the size given\nrclone test makefiles\nMake a random file hierarchy in a directory\nrclone test memory\nLoad all the objects at remote:path into memory and report memory stats.\nrclone test speed\nRun a speed test to the remote\nrclone touch\nCreate new file or change file modification time.\nrclone tree\nList the contents of the remote in a tree like fashion.\nrclone version\nShow the version number.\nPlatinum Sponsor\nGold Sponsor\nGold Sponsor\nShare and Enjoy\nTwitter\nFacebook\nReddit\nLinks\nRclone forum\nGitHub project\nRclone Wiki\nSponsor\n@njcw", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://rclone.org/commands/"}}
{"text": "Overview of cloud storage systems\nOverview of cloud storage systems\nEach cloud storage system is slightly different.  Rclone attempts to\nprovide a unified interface to them, but some underlying differences\nshow through.\nFeatures\nHere is an overview of the major features of each cloud storage system.\nName\nHash\nModTime\nCase Insensitive\nDuplicate Files\nMIME Type\nMetadata\n1Fichier\nWhirlpool\n-\nNo\nYes\nR\n-\nAkamai Netstorage\nMD5, SHA256\nR/W\nNo\nNo\nR\n-\nAmazon S3 (or S3 compatible)\nMD5\nR/W\nNo\nNo\nR/W\nRWU\nBackblaze B2\nSHA1\nR/W\nNo\nNo\nR/W\n-\nBox\nSHA1\nR/W\nYes\nNo\n-\n-\nCitrix ShareFile\nMD5\nR/W\nYes\nNo\n-\n-\nCloudinary\nMD5\nR\nNo\nYes\n-\n-\nDropbox\nDBHASH ¹\nR\nYes\nNo\n-\n-\nEnterprise File Fabric\n-\nR/W\nYes\nNo\nR/W\n-\nFileLu Cloud Storage\nMD5\nR/W\nNo\nYes\nR\n-\nFiles.com\nMD5, CRC32\nDR/W\nYes\nNo\nR\n-\nFTP\n-\nR/W ¹⁰\nNo\nNo\n-\n-\nGofile\nMD5\nDR/W\nNo\nYes\nR\n-\nGoogle Cloud Storage\nMD5\nR/W\nNo\nNo\nR/W\n-\nGoogle Drive\nMD5, SHA1, SHA256\nDR/W\nNo\nYes\nR/W\nDRWU\nGoogle Photos\n-\n-\nNo\nYes\nR\n-\nHDFS\n-\nR/W\nNo\nNo\n-\n-\nHiDrive\nHiDrive ¹²\nR/W\nNo\nNo\n-\n-\nHTTP\n-\nR\nNo\nNo\nR\nR\niCloud Drive\n-\nR\nNo\nNo\n-\n-\nInternet Archive\nMD5, SHA1, CRC32\nR/W ¹¹\nNo\nNo\n-\nRWU\nJottacloud\nMD5\nR/W\nYes\nNo\nR\nRW\nKoofr\nMD5\n-\nYes\nNo\n-\n-\nLinkbox\n-\nR\nNo\nNo\n-\n-\nMail.ru Cloud\nMailru ⁶\nR/W\nYes\nNo\n-\n-\nMega\n-\n-\nNo\nYes\n-\n-\nMemory\nMD5\nR/W\nNo\nNo\n-\n-\nMicrosoft Azure Blob Storage\nMD5\nR/W\nNo\nNo\nR/W\n-\nMicrosoft Azure Files Storage\nMD5\nR/W\nYes\nNo\nR/W\n-\nMicrosoft OneDrive\nQuickXorHash ⁵\nDR/W\nYes\nNo\nR\nDRW\nOpenDrive\nMD5\nR/W\nYes\nPartial ⁸\n-\n-\nOpenStack Swift\nMD5\nR/W\nNo\nNo\nR/W\n-\nOracle Object Storage\nMD5\nR/W\nNo\nNo\nR/W\nRU\npCloud\nMD5, SHA1 ⁷\nR/W\nNo\nNo\nW\n-\nPikPak\nMD5\nR\nNo\nNo\nR\n-\nPixeldrain\nSHA256\nR/W\nNo\nNo\nR\nRW\npremiumize.me\n-\n-\nYes\nNo\nR\n-\nput.io\nCRC-32\nR/W\nNo\nYes\nR\n-\nProton Drive\nSHA1\nR/W\nNo\nNo\nR\n-\nQingStor\nMD5\n- ⁹\nNo\nNo\nR/W\n-\nQuatrix by Maytech\n-\nR/W\nNo\nNo\n-\n-\nSeafile\n-\n-\nNo\nNo\n-\n-\nSFTP\nMD5, SHA1 ²\nDR/W\nDepends\nNo\n-\n-\nSia\n-\n-\nNo\nNo\n-\n-\nSMB\n-\nR/W\nYes\nNo\n-\n-\nSugarSync\n-\n-\nNo\nNo\n-\n-\nStorj\n-\nR\nNo\nNo\n-\n-\nUloz.to\nMD5, SHA256 ¹³\n-\nNo\nYes\n-\n-\nUptobox\n-\n-\nNo\nYes\n-\n-\nWebDAV\nMD5, SHA1 ³\nR ⁴\nDepends\nNo\n-\n-\nYandex Disk\nMD5\nR/W\nNo\nNo\nR\n-\nZoho WorkDrive\n-\n-\nNo\nNo\n-\n-\nThe local filesystem\nAll\nDR/W\nDepends\nNo\n-\nDRWU\n¹ Dropbox supports\nits own custom\nhash\n.\nThis is an SHA256 sum of all the 4 MiB block SHA256s.\n² SFTP supports checksums if the same login has shell access and\nmd5sum\nor\nsha1sum\nas well as\necho\nare in the remote's PATH.\n³ WebDAV supports hashes when used with Fastmail Files, Owncloud and Nextcloud only.\n⁴ WebDAV supports modtimes when used with Fastmail Files, Owncloud and Nextcloud\nonly.\n⁵\nQuickXorHash\nis Microsoft's own hash.\n⁶ Mail.ru uses its own modified SHA1 hash\n⁷ pCloud only supports SHA1 (not MD5) in its EU region\n⁸ Opendrive does not support creation of duplicate files using\ntheir web client interface or other stock clients, but the underlying\nstorage platform has been determined to allow duplicate files, and it\nis possible to create them with\nrclone\n.  It may be that this is a\nmistake or an unsupported feature.\n⁹ QingStor does not support SetModTime for objects bigger than 5 GiB.\n¹⁰ FTP supports modtimes for the major FTP servers, and also others\nif they advertised required protocol extensions. See\nthis\nfor more details.\n¹¹ Internet Archive requires option\nwait_archive\nto be set to a non-zero value\nfor full modtime support.\n¹² HiDrive supports\nits own custom\nhash\n.\nIt combines SHA1 sums for each 4 KiB block hierarchically to a single\ntop-level sum.\n¹³ Uloz.to provides server-calculated MD5 hash upon file upload. MD5 and SHA256\nhashes are client-calculated and stored as metadata fields.\nHash\nThe cloud storage system supports various hash types of the objects.\nThe hashes are used when transferring data as an integrity check and\ncan be specifically used with the\n--checksum\nflag in syncs and in\nthe\ncheck\ncommand.\nTo use the verify checksums when transferring between cloud storage\nsystems they must support a common hash type.\nModTime\nAlmost all cloud storage systems store some sort of timestamp\non objects, but several of them not something that is appropriate\nto use for syncing. E.g. some backends will only write a timestamp\nthat represents the time of the upload. To be relevant for syncing\nit should be able to store the modification time of the source\nobject. If this is not the case, rclone will only check the file\nsize by default, though can be configured to check the file hash\n(with the\n--checksum\nflag). Ideally it should also be possible to\nchange the timestamp of an existing file without having to re-upload it.\nKey\nExplanation\n-\nModTimes not supported - times likely the upload time\nR\nModTimes supported on files but can't be changed without re-upload\nR/W\nRead and Write ModTimes fully supported on files\nDR\nModTimes supported on files and directories but can't be changed without re-upload\nDR/W\nRead and Write ModTimes fully supported on files and directories\nStorage systems with a\n-\nin the ModTime column, means the\nmodification read on objects is not the modification time of the\nfile when uploaded. It is most likely the time the file was uploaded,\nor possibly something else (like the time the picture was taken in\nGoogle Photos).\nStorage systems with a\nR\n(for read-only) in the ModTime column,\nmeans the it keeps modification times on objects, and updates them\nwhen uploading objects, but it does not support changing only the\nmodification time (\nSetModTime\noperation) without re-uploading,\npossibly not even without deleting existing first. Some operations\nin rclone, such as\ncopy\nand\nsync\ncommands, will automatically\ncheck for\nSetModTime\nsupport and re-upload if necessary to keep\nthe modification times in sync. Other commands will not work\nwithout\nSetModTime\nsupport, e.g.\ntouch\ncommand on an existing\nfile will fail, and changes to modification time only on a files\nin a\nmount\nwill be silently ignored.\nStorage systems with\nR/W\n(for read/write) in the ModTime column,\nmeans they do also support modtime-only operations.\nStorage systems with\nD\nin the ModTime column means that the\nfollowing symbols apply to directories as well as files.\nCase Insensitive\nIf a cloud storage systems is case sensitive then it is possible to\nhave two files which differ only in case, e.g.\nfile.txt\nand\nFILE.txt\n.  If a cloud storage system is case insensitive then that\nisn't possible.\nThis can cause problems when syncing between a case insensitive\nsystem and a case sensitive system.  The symptom of this is that no\nmatter how many times you run the sync it never completes fully.\nThe local filesystem and SFTP may or may not be case sensitive\ndepending on OS.\nWindows - usually case insensitive, though case is preserved\nOSX - usually case insensitive, though it is possible to format case sensitive\nLinux - usually case sensitive, but there are case insensitive file systems\n(e.g. FAT formatted USB keys)\nMost of the time this doesn't cause any problems as people tend to\navoid files whose name differs only by case even on case sensitive\nsystems.\nDuplicate files\nIf a cloud storage system allows duplicate files then it can have two\nobjects with the same name.\nThis confuses rclone greatly when syncing - use the\nrclone dedupe\ncommand to rename or remove duplicates.\nRestricted filenames\nSome cloud storage systems might have restrictions on the characters\nthat are usable in file or directory names.\nWhen\nrclone\ndetects such a name during a file upload, it will\ntransparently replace the restricted characters with similar looking\nUnicode characters. To handle the different sets of restricted characters\nfor different backends, rclone uses something it calls\nencoding\n.\nThis process is designed to avoid ambiguous file names as much as\npossible and allow to move files between many cloud storage systems\ntransparently.\nThe name shown by\nrclone\nto the user or during log output will only\ncontain a minimal set of\nreplaced characters\nto ensure correct formatting and not necessarily the actual name used\non the cloud storage.\nThis transformation is reversed when downloading a file or parsing\nrclone\narguments. For example, when uploading a file named\nmy file?.txt\nto Onedrive, it will be displayed as\nmy file?.txt\non the console, but\nstored as\nmy file？.txt\nto Onedrive (the\n?\ngets replaced by the similar\nlooking\n？\ncharacter, the so-called \"fullwidth question mark\").\nThe reverse transformation allows to read a file\nunusual/name.txt\nfrom Google Drive, by passing the name\nunusual／name.txt\non the command line\n(the\n/\nneeds to be replaced by the similar looking\n／\ncharacter).\nCaveats\nThe filename encoding system works well in most cases, at least\nwhere file names are written in English or similar languages.\nYou might not even notice it: It just works. In some cases it may\nlead to issues, though. E.g. when file names are written in Chinese,\nor Japanese, where it is always the Unicode fullwidth variants of the\npunctuation marks that are used.\nOn Windows, the characters\n:\n,\n*\nand\n?\nare examples of restricted\ncharacters. If these are used in filenames on a remote that supports it,\nRclone will transparently convert them to their fullwidth Unicode\nvariants\n＊\n,\n？\nand\n：\nwhen downloading to Windows, and back again\nwhen uploading. This way files with names that are not allowed on Windows\ncan still be stored.\nHowever, if you have files on your Windows system originally with these same\nUnicode characters in their names, they will be included in the same conversion\nprocess. E.g. if you create a file in your Windows filesystem with name\nTest：1.jpg\n, where\n：\nis the Unicode fullwidth colon symbol, and use\nrclone to upload it to Google Drive, which supports regular\n:\n(halfwidth\nquestion mark), rclone will replace the fullwidth\n:\nwith the\nhalfwidth\n:\nand store the file as\nTest:1.jpg\nin Google Drive. Since\nboth Windows and Google Drive allows the name\nTest：1.jpg\n, it would\nprobably be better if rclone just kept the name as is in this case.\nWith the opposite situation; if you have a file named\nTest:1.jpg\n,\nin your Google Drive, e.g. uploaded from a Linux system where\n:\nis valid\nin file names. Then later use rclone to copy this file to your Windows\ncomputer you will notice that on your local disk it gets renamed\nto\nTest：1.jpg\n. The original filename is not legal on Windows, due to\nthe\n:\n, and rclone therefore renames it to make the copy possible.\nThat is all good. However, this can also lead to an issue: If you already\nhad a\ndifferent\nfile named\nTest：1.jpg\non Windows, and then use rclone\nto copy either way. Rclone will then treat the file originally named\nTest:1.jpg\non Google Drive and the file originally named\nTest：1.jpg\non Windows as the same file, and replace the contents from one with the other.\nIts virtually impossible to handle all cases like these correctly in all\nsituations, but by customizing the\nencoding option\n, changing the\nset of characters that rclone should convert, you should be able to\ncreate a configuration that works well for your specific situation.\nSee also the\nexample\nbelow.\n(Windows was used as an example of a file system with many restricted\ncharacters, and Google drive a storage system with few.)\nDefault restricted characters\nThe table below shows the characters that are replaced by default.\nWhen a replacement character is found in a filename, this character\nwill be escaped with the\n‛\ncharacter to avoid ambiguous file names.\n(e.g. a file named\n␀.txt\nwould shown as\n‛␀.txt\n)\nEach cloud storage backend can use a different set of characters,\nwhich will be specified in the documentation for each backend.\nCharacter\nValue\nReplacement\nNUL\n0x00\n␀\nSOH\n0x01\n␁\nSTX\n0x02\n␂\nETX\n0x03\n␃\nEOT\n0x04\n␄\nENQ\n0x05\n␅\nACK\n0x06\n␆\nBEL\n0x07\n␇\nBS\n0x08\n␈\nHT\n0x09\n␉\nLF\n0x0A\n␊\nVT\n0x0B\n␋\nFF\n0x0C\n␌\nCR\n0x0D\n␍\nSO\n0x0E\n␎\nSI\n0x0F\n␏\nDLE\n0x10\n␐\nDC1\n0x11\n␑\nDC2\n0x12\n␒\nDC3\n0x13\n␓\nDC4\n0x14\n␔\nNAK\n0x15\n␕\nSYN\n0x16\n␖\nETB\n0x17\n␗\nCAN\n0x18\n␘\nEM\n0x19\n␙\nSUB\n0x1A\n␚\nESC\n0x1B\n␛\nFS\n0x1C\n␜\nGS\n0x1D\n␝\nRS\n0x1E\n␞\nUS\n0x1F\n␟\n/\n0x2F\n／\nDEL\n0x7F\n␡\nThe default encoding will also encode these file names as they are\nproblematic with many cloud storage systems.\nFile name\nReplacement\n.\n．\n..\n．．\nInvalid UTF-8 bytes\nSome backends only support a sequence of well formed UTF-8 bytes\nas file or directory names.\nIn this case all invalid UTF-8 bytes will be replaced with a quoted\nrepresentation of the byte value to allow uploading a file to such a\nbackend. For example, the invalid byte\n0xFE\nwill be encoded as\n‛FE\n.\nA common source of invalid UTF-8 bytes are local filesystems, that store\nnames in a different encoding than UTF-8 or UTF-16, like latin1. See the\nlocal filenames\nsection for details.\nEncoding option\nMost backends have an encoding option, specified as a flag\n--backend-encoding\nwhere\nbackend\nis the name of the backend, or as\na config parameter\nencoding\n(you'll need to select the Advanced\nconfig in\nrclone config\nto see it).\nThis will have default value which encodes and decodes characters in\nsuch a way as to preserve the maximum number of characters (see\nabove).\nHowever this can be incorrect in some scenarios, for example if you\nhave a Windows file system with Unicode fullwidth characters\n＊\n,\n？\nor\n：\n, that you want to remain as those characters on the\nremote rather than being translated to regular (halfwidth)\n*\n,\n?\nand\n:\n.\nThe\n--backend-encoding\nflags allow you to change that. You can\ndisable the encoding completely with\n--backend-encoding Raw\nor set\nencoding = Raw\nin the config file.\nEncoding takes a comma separated list of encodings. You can see the\nlist of all possible values by passing an invalid value to this\nflag, e.g.\n--local-encoding \"help\"\n. The command\nrclone help flags encoding\nwill show you the defaults for the backends.\nEncoding\nCharacters\nEncoded as\nAsterisk\n*\n＊\nBackQuote\n`\n｀\nBackSlash\n\\\n＼\nColon\n:\n：\nCrLf\nCR 0x0D, LF 0x0A\n␍\n,\n␊\nCtl\nAll control characters 0x00-0x1F\n␀␁␂␃␄␅␆␇␈␉␊␋␌␍␎␏␐␑␒␓␔␕␖␗␘␙␚␛␜␝␞␟\nDel\nDEL 0x7F\n␡\nDollar\n$\n＄\nDot\n.\nor\n..\nas entire string\n．\n,\n．．\nDoubleQuote\n\"\n＂\nExclamation\n!\n！\nHash\n#\n＃\nInvalidUtf8\nAn invalid UTF-8 character (e.g. latin1)\n�\nLeftCrLfHtVt\nCR 0x0D, LF 0x0A, HT 0x09, VT 0x0B on the left of a string\n␍\n,\n␊\n,\n␉\n,\n␋\nLeftPeriod\n.\non the left of a string\n.\nLeftSpace\nSPACE on the left of a string\n␠\nLeftTilde\n~\non the left of a string\n～\nLtGt\n<\n,\n>\n＜\n,\n＞\nNone ¹\nNUL 0x00\n␀\nPercent\n%\n％\nPipe\n|\n｜\nQuestion\n?\n？\nRightCrLfHtVt\nCR 0x0D, LF 0x0A, HT 0x09, VT 0x0B on the right of a string\n␍\n,\n␊\n,\n␉\n,\n␋\nRightPeriod\n.\non the right of a string\n.\nRightSpace\nSPACE on the right of a string\n␠\nSemicolon\n;\n；\nSingleQuote\n'\n＇\nSlash\n/\n／\nSquareBracket\n[\n,\n]\n［\n,\n］\n¹ Encoding from NUL 0x00 to ␀ is always implicit except when using Raw.\nIt was previously incorrectly documented as disabling encoding,\nand to maintain backward compatibility, its behavior has not been changed.\nEncoding example: FTP\nTo take a specific example, the FTP backend's default encoding is\n--ftp-encoding \"Slash,Del,Ctl,RightSpace,Dot\"\nHowever, let's say the FTP server is running on Windows and can't have\nany of the invalid Windows characters in file names. You are backing\nup Linux servers to this FTP server which do have those characters in\nfile names. So you would add the Windows set which are\nSlash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot\nto the existing ones, giving:\nSlash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot,Del,RightSpace\nThis can be specified using the\n--ftp-encoding\nflag or using an\nencoding\nparameter in the config file.\nEncoding example: Windows\nAs a nother example, take a Windows system where there is a file with\nname\nTest：1.jpg\n, where\n：\nis the Unicode fullwidth colon symbol.\nWhen using rclone to copy this to a remote which supports\n:\n,\nthe regular (halfwidth) colon (such as Google Drive), you will notice\nthat the file gets renamed to\nTest:1.jpg\n.\nTo avoid this you can change the set of characters rclone should convert\nfor the local filesystem, using command-line argument\n--local-encoding\n.\nRclone's default behavior on Windows corresponds to\n--local-encoding \"Slash,LtGt,DoubleQuote,Colon,Question,Asterisk,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot\"\nIf you want to use fullwidth characters\n：\n,\n＊\nand\n？\nin your filenames\nwithout rclone changing them when uploading to a remote, then set the same as\nthe default value but without\nColon,Question,Asterisk\n:\n--local-encoding \"Slash,LtGt,DoubleQuote,Pipe,BackSlash,Ctl,RightSpace,RightPeriod,InvalidUtf8,Dot\"\nAlternatively, you can disable the conversion of any characters with\n--local-encoding Raw\n.\nInstead of using command-line argument\n--local-encoding\n, you may also set it\nas\nenvironment variable\nRCLONE_LOCAL_ENCODING\n,\nor\nconfigure\na remote of type\nlocal\nin your config,\nand set the\nencoding\noption there.\nThe risk by doing this is that if you have a filename with the regular (halfwidth)\n:\n,\n*\nand\n?\nin your cloud storage, and you try to download\nit to your Windows filesystem, this will fail. These characters are not\nvalid in filenames on Windows, and you have told rclone not to work around\nthis by converting them to valid fullwidth variants.\nMIME Type\nMIME types (also known as media types) classify types of documents\nusing a simple text classification, e.g.\ntext/html\nor\napplication/pdf\n.\nSome cloud storage systems support reading (\nR\n) the MIME type of\nobjects and some support writing (\nW\n) the MIME type of objects.\nThe MIME type can be important if you are serving files directly to\nHTTP from the storage system.\nIf you are copying from a remote which supports reading (\nR\n) to a\nremote which supports writing (\nW\n) then rclone will preserve the MIME\ntypes.  Otherwise they will be guessed from the extension, or the\nremote itself may assign the MIME type.\nMetadata\nBackends may or may support reading or writing metadata. They may\nsupport reading and writing system metadata (metadata intrinsic to\nthat backend) and/or user metadata (general purpose metadata).\nThe levels of metadata support are\nKey\nExplanation\nR\nRead only System Metadata on files only\nRW\nRead and write System Metadata on files only\nRWU\nRead and write System Metadata and read and write User Metadata on files only\nDR\nRead only System Metadata on files and directories\nDRW\nRead and write System Metadata on files and directories\nDRWU\nRead and write System Metadata and read and write User Metadata on files and directories\nSee\nthe metadata docs\nfor more info.\nOptional Features\nAll rclone remotes support a base command set. Other features depend\nupon backend-specific capabilities.\nName\nPurge\nCopy\nMove\nDirMove\nCleanUp\nListR\nStreamUpload\nMultithreadUpload\nLinkSharing\nAbout\nEmptyDir\n1Fichier\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nYes\nAkamai Netstorage\nYes\nNo\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nYes\nAmazon S3 (or S3 compatible)\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nBackblaze B2\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nBox\nYes\nYes\nYes\nYes\nYes\nNo\nYes\nNo\nYes\nYes\nYes\nCitrix ShareFile\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nDropbox\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nYes\nYes\nCloudinary\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nEnterprise File Fabric\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nFiles.com\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nNo\nYes\nFTP\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nNo\nNo\nYes\nGofile\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nYes\nYes\nGoogle Cloud Storage\nYes\nYes\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nGoogle Drive\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nNo\nYes\nYes\nYes\nGoogle Photos\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nHDFS\nYes\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nNo\nYes\nYes\nHiDrive\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nNo\nNo\nYes\nHTTP\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\niCloud Drive\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nImageKit\nYes\nNo\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nInternet Archive\nNo\nYes\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nYes\nNo\nJottacloud\nYes\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nYes\nYes\nKoofr\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nYes\nYes\nMail.ru Cloud\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nMega\nYes\nNo\nYes\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nMemory\nNo\nYes\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nMicrosoft Azure Blob Storage\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nNo\nNo\nNo\nMicrosoft Azure Files Storage\nNo\nYes\nYes\nYes\nNo\nNo\nYes\nYes\nNo\nYes\nYes\nMicrosoft OneDrive\nYes\nYes\nYes\nYes\nYes\nYes ⁵\nNo\nNo\nYes\nYes\nYes\nOpenDrive\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nOpenStack Swift\nYes ¹\nYes\nNo\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nOracle Object Storage\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nNo\nNo\nNo\npCloud\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nPikPak\nYes\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nYes\nYes\nYes\nPixeldrain\nYes\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nYes\nYes\npremiumize.me\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nYes\nYes\nYes\nput.io\nYes\nNo\nYes\nYes\nYes\nNo\nYes\nNo\nNo\nYes\nYes\nProton Drive\nYes\nNo\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nYes\nYes\nQingStor\nNo\nYes\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nQuatrix by Maytech\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nSeafile\nYes\nYes\nYes\nYes\nYes\nYes\nYes\nNo\nYes\nYes\nYes\nSFTP\nNo\nYes ⁴\nYes\nYes\nNo\nNo\nYes\nNo\nNo\nYes\nYes\nSia\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\nNo\nYes\nSMB\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nSugarSync\nYes\nYes\nYes\nYes\nNo\nNo\nYes\nNo\nYes\nNo\nYes\nStorj\nYes ²\nYes\nYes\nNo\nNo\nYes\nYes\nNo\nYes\nNo\nNo\nUloz.to\nNo\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nUptobox\nNo\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nWebDAV\nYes\nYes\nYes\nYes\nNo\nNo\nYes ³\nNo\nNo\nYes\nYes\nYandex Disk\nYes\nYes\nYes\nYes\nYes\nNo\nYes\nNo\nYes\nYes\nYes\nZoho WorkDrive\nYes\nYes\nYes\nYes\nNo\nNo\nNo\nNo\nNo\nYes\nYes\nThe local filesystem\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nYes\nNo\nYes\nYes\n¹ Note Swift implements this in order to delete directory markers but\nit doesn't actually have a quicker way of deleting files other than\ndeleting them individually.\n² Storj implements this efficiently only for entire buckets. If\npurging a directory inside a bucket, files are deleted individually.\n³ StreamUpload is not supported with Nextcloud\n⁴ Use the\n--sftp-copy-is-hardlink\nflag to enable.\n⁵ Use the\n--onedrive-delta\nflag to enable.\nPurge\nThis deletes a directory quicker than just deleting all the files in\nthe directory.\nCopy\nUsed when copying an object to and from the same remote.  This known\nas a server-side copy so you can copy a file without downloading it\nand uploading it again.  It is used if you use\nrclone copy\nor\nrclone move\nif the remote doesn't support\nMove\ndirectly.\nIf the server doesn't support\nCopy\ndirectly then for copy operations\nthe file is downloaded then re-uploaded.\nMove\nUsed when moving/renaming an object on the same remote.  This is known\nas a server-side move of a file.  This is used in\nrclone move\nif the\nserver doesn't support\nDirMove\n.\nIf the server isn't capable of\nMove\nthen rclone simulates it with\nCopy\nthen delete.  If the server doesn't support\nCopy\nthen rclone\nwill download the file and re-upload it.\nDirMove\nThis is used to implement\nrclone move\nto move a directory if\npossible.  If it isn't then it will use\nMove\non each file (which\nfalls back to\nCopy\nthen download and upload - see\nMove\nsection).\nCleanUp\nThis is used for emptying the trash for a remote by\nrclone cleanup\n.\nIf the server can't do\nCleanUp\nthen\nrclone cleanup\nwill return an\nerror.\n‡‡ Note that while Box implements this it has to delete every file\nindividually so it will be slower than emptying the trash via the WebUI\nListR\nThe remote supports a recursive list to list all the contents beneath\na directory quickly.  This enables the\n--fast-list\nflag to work.\nSee the\nrclone docs\nfor more details.\nStreamUpload\nSome remotes allow files to be uploaded without knowing the file size\nin advance. This allows certain operations to work without spooling the\nfile to local disk first, e.g.\nrclone rcat\n.\nMultithreadUpload\nSome remotes allow transfers to the remote to be sent as chunks in\nparallel. If this is supported then rclone will use multi-thread\ncopying to transfer files much faster.\nLinkSharing\nSets the necessary permissions on a file or folder and prints a link\nthat allows others to access them, even if they don't have an account\non the particular cloud provider.\nAbout\nRclone\nabout\nprints quota information for a remote. Typical output\nincludes bytes used, free, quota and in trash.\nIf a remote lacks about capability\nrclone about remote:\nreturns\nan error.\nBackends without about capability cannot determine free space for an\nrclone mount, or use policy\nmfs\n(most free space) as a member of an\nrclone union remote.\nSee\nrclone about command\nEmptyDir\nThe remote supports empty directories. See\nLimitations\nfor details. Most Object/Bucket-based remotes do not support this.\nContents\nPlatinum Sponsor\nGold Sponsor\nGold Sponsor\nShare and Enjoy\nTwitter\nFacebook\nReddit\nLinks\nRclone forum\nGitHub project\nRclone Wiki\nSponsor\n@njcw", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://rclone.org/overview/"}}
