{"text": "Arch boot process - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nArch boot process\n8 languages\nBosanski\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nAutostarting\nGUID Partition Table\nMaster Boot Record\nUnified Extensible Firmware Interface\nfstab\ninit\nmkinitcpio\nsystemd\nIn order to boot Arch Linux, a Linux-capable\nboot loader\nmust be set up. The boot loader is responsible for loading the kernel and\ninitial ramdisk\nbefore initiating the boot process. The procedure is quite different for\nBIOS\nand\nUEFI\nsystems.\nFirmware types\nThe\nfirmware\nis the very first program that is executed once the system is switched on.\nTip\nThe words\nBIOS\nand\nUEFI\nare often used instead of\nfirmware\n.\nDo not confuse with\nLinux firmware\n.\nUEFI\nThe\nUnified Extensible Firmware Interface\nhas support for reading both the partition table as well as file systems. UEFI does not launch any\nboot code from the Master Boot Record (MBR)\nwhether it exists or not, instead booting relies on boot entries in the\nNVRAM\n.\nThe UEFI specification mandates support for the\nFAT12, FAT16, and FAT32\nfile systems (see\nUEFI specification version 2.11, section 13.3.1.1\n), but any conformant vendor can optionally add support for additional file systems; for example,\nHFS+\nor\nAPFS\nin some Apple's firmwares. UEFI implementations also support\nISO 9660\nfor optical discs.\nUEFI launches EFI applications, e.g.\nboot loaders\n, boot managers,\nUEFI shell\n, etc. These applications are usually stored as files in the\nEFI system partition\n. Each vendor can store its files in the EFI system partition under the\n/EFI/\nvendor_name\ndirectory. The applications can be launched by adding a boot entry to the NVRAM or from the UEFI shell.\nThe UEFI specification has support for legacy\nBIOS\nbooting with its\nCompatibility Support Module (CSM)\n. If CSM is enabled in the UEFI, the UEFI will generate CSM boot entries for all drives. If a CSM boot entry is chosen to be booted from, the UEFI's CSM will attempt to boot from the drive's MBR bootstrap code.\nNote\nIntel is phasing out support for CSM, relying on the feature may not be feasible in the future.\n[1]\nBIOS\nA\nBIOS\nor Basic Input-Output System is in most cases stored in a flash memory in the motherboard itself and independent of the system storage. Originally created for the\nIBM PC\nto handle hardware initialization and the boot process, it has been replaced progressively since 2010 by UEFI which does not suffer from the same technical limitations.\nSystem initialization\nSystem switched on, the\npower-on self-test\n(POST) is executed. See also\nModern CPUs have a backstage cast\nby Hugo Landau.\nUEFI\nAfter POST, UEFI initializes the hardware required for booting (disk, keyboard controllers etc.).\nFirmware reads the boot entries in the NVRAM to determine which EFI application to launch and from where (e.g. from which disk and partition).\nA boot entry could simply be a disk. In this case the firmware looks for an\nEFI system partition\non that disk and tries to find an EFI application in the fallback boot path\n\\EFI\\BOOT\\BOOTx64.EFI\n(\nBOOTIA32.EFI\non\nsystems with a IA32 (32-bit) UEFI\n). This is how UEFI bootable removable media work.\nFirmware launches the EFI application.\nThis could be a\nboot loader\nor the Arch\nkernel\nitself using an\nEFI boot stub\n.\nIt could be some other EFI application such as the\nUEFI shell\nor a\nboot manager\nlike\nsystemd-boot\nor\nrEFInd\n.\nIf\nSecure Boot\nis enabled, the boot process will verify authenticity of the EFI binary by signature.\nNote\nSome UEFI systems can only boot from the fallback boot path.\nMultibooting\nSince each OS or vendor can maintain its own files within the\nEFI system partition\nwithout affecting the other, multi-booting using UEFI is just a matter of launching a different EFI application corresponding to the particular operating system's boot loader. This removes the need for relying on the\nchain loading\nmechanisms of one\nboot loader\nto load another OS.\nSee also\nDual boot with Windows\n.\nBIOS\nAfter POST, BIOS initializes the hardware required for booting (disk, keyboard controllers etc.).\nBIOS launches the first 440 bytes (\nthe Master Boot Record bootstrap code area\n) of the first disk in the BIOS disk order.\nThe boot loader's first stage in the MBR boot code then launches its second stage code (if any) from either:\nnext disk sectors after the MBR, i.e. the so called post-MBR gap (only on a MBR partition table),\na partition or a partitionless disk\nvolume boot record\n(VBR),\nfor\nGRUB\non a GPT partitioned disk—a GRUB-specific\nBIOS boot partition\n(it is used in place of the post-MBR gap that does not exist in GPT).\nThe actual\nboot loader\nis launched.\nThe boot loader then loads an operating system by either chain-loading or directly loading the operating system kernel.\nBoot loader\nA\nboot loader\nis a piece of software started by the\nfirmware\n—\nUEFI\nor\nBIOS\n. It is responsible for loading the\nkernel\nwith the wanted\nkernel parameters\nand any external\ninitramfs\nimages.\nA\nboot manager\npresents a menu of boot options, or provides some other way to control the boot process—i.e. it just runs other EFI executables.\nIn the case of UEFI, the kernel itself can be directly launched by the UEFI using the\nEFI boot stub\n. A separate boot loader or a boot manager can still be used for the purpose of editing kernel parameters before booting.\nSystems with\n32-bit IA32 UEFI\nrequire a boot loader that supports mixed mode booting.\nWarning\nTo successfully boot Arch, the boot loader needs access to the kernel and initramfs image(s) which typically reside in the\n/boot\ndirectory. That means the boot loader must have support for everything starting from the block devices, stacked block devices (LVM, RAID, dm-crypt, LUKS, etc.) and ending with the file system on which the kernel(s) and initramfs image(s) reside.\nSince almost no boot loader supports such stacked block devices and since file systems can introduce new features which may not yet be supported by any boot loader (e.g.\narchlinux/packaging/packages/grub#7\n,\nFS#79857\n,\nFS#59047\n,\nFS#58137\n,\nFS#51879\n,\nFS#46856\n,\nFS#38750\n,\nFS#21733\nand\nfscrypt\nencrypted directories), using a separate\n/boot partition\nwith a universally supported file system, such as\nFAT32\n, is oftentimes more feasible.\nFeature comparison\nNote\nAs GPT is part of the UEFI specification, all UEFI boot loaders support GPT disks. GPT on BIOS systems is possible, using either \"hybrid booting\" with\nHybrid MBR\n, or the new\nGPT-only\nprotocol. This protocol may however cause issues with certain BIOS implementations; see\nrodsbooks\nfor details.\nAs\nSecure Boot\nis part of the UEFI specification, all UEFI boot loaders support it, although some have limitations.\nName\nFirmware\nPartition table\nMulti-boot\nFile systems\nNotes\nBIOS\nUEFI\nMBR\nGPT\nClover\nYes\nYes\nNo\nYes\nYes\nExtensible\n2,5\nCan emulate UEFI on legacy BIOS systems.\nEFI boot stub\n–\nYes\n1\nYes\nYes\n–\nInherited from firmware\n2\nThe kernel is a valid EFI executable which can be directly launched from UEFI or from another UEFI boot loader.\nGRUB\nYes\nYes\n3\nYes\nYes\nYes\nBuilt-in\nSupports RAID, LUKS (but not Argon2 PBKDFs) and LVM (but not thin provisioned volumes). See\nGRUB\nfor setup-specific limitations.\nLimine\nYes\nYes\n3\nYes\nYes\nYes\nLimited\nrEFInd\nNo\nYes\nYes\nYes\nYes\n4\nExtensible\n2,5\nSupports auto-detecting kernels and parameters without explicit configuration, and supports fastboot\n[2]\n.\nSyslinux\nYes\nPartial\n1\nYes\nYes\nPartial\nLimited\nNo support for certain file system features.\nCan only access the file system it was\ninstalled to\n.\nsystemd-boot\nNo\nYes\n3\nManual\nYes\nYes\n4\nExtensible\n2,5\nCan only launch binaries from the\nESP\nit is installed to or from the Extended Boot Loader Partition (XBOOTLDR partition) on the same disk.\nAutomatically detects\nunified kernel images\nplaced in\nesp\n/EFI/Linux/\n.\nUnified kernel image\n–\nYes\n3\nYes\nYes\n–\nInherited from firmware\n2\nsystemd-stub(7)\n, a kernel, initramfs and kernel command line packed into EFI executable to be loaded directly from UEFI firmware or another boot loader.\nGRUB Legacy\nYes\nNo\nYes\nNo\nYes\nLimited\nDiscontinued\nin favor of\nGRUB\n.\nLILO\nYes\nNo\nYes\nPartial\nYes\nLimited\nDiscontinued\ndue to limitations (e.g. with Btrfs, GPT, RAID, encryption).\nWhile the binary can be signed for\nSecure Boot\n, it does no following verification, thus breaking the chain of trust.\nFile system support is inherited from the firmware. The UEFI specification mandates support for the FAT12, FAT16 and FAT32 file systems\n[3]\n, but vendors can optionally add support for additional file systems; for example, the firmware in Apple\nMacs\nsupports the HFS+ file system. If the firmware provides an interface for loading\nUEFI drivers\non startup, then support for additional file systems can be added by loading (independently acquired) file system drivers.\nSupports mixed mode booting. I.e. it can boot a 64-bit x86_64 Linux kernel on\n32-bit IA32 UEFI\n.\nA\nboot manager\n. It can only launch other EFI applications, for example, Linux kernel images built with\nCONFIG_EFI_STUB=y\nand\nWindows Boot Manager\n(\nbootmgfw.efi\n).\nSupports loading\nUEFI file system drivers\n.\nSee also\nWikipedia:Comparison of boot loaders\n.\nKernel\nThe\nboot loader\nboots the\nvmlinux image\ncontaining the\nkernel\n.\nThe kernel functions on a low level (\nkernelspace\n) interacting between the hardware of the machine and the programs. The kernel initially performs hardware enumeration and initialization before continuing to userspace. See\nWikipedia:Kernel (operating system)\nand\nWikipedia:Linux kernel\nfor a detailed explanation.\ninitramfs\nAn\ninitramfs\n(\ninit\nial\nRAM\nf\nile\ns\nystem) image is a\ncpio\narchive providing the necessary files for\nearly userspace\n(see below) to successfully start the late userspace. This predominantly means all kernel modules, user space tools, associated libraries, supporting files like udev rules, etc. required to locate, access and mount the root file system. With the concept of initramfs it is possible to handle even more complex setups, like e.g. booting from an external drive, stacked devices (logical volumes, software RAIDs, compression, encryption) or running a tiny SSH server in early userspace for remote unlocking or maintenance tasks of the root file system.\nThe majority of modules will be loaded during later stages of the init process by\nudev\nafter having switched root to the root file system.\nThe process is as follows:\nThe root file system at\n/\nstarts out as an empty\nrootfs\n, which is a special instance of tmpfs or ramfs. This is the temporary root file system where the initramfs images will be unpacked to.\nThe kernel unpacks its builtin initramfs into the temporary root. Arch Linux's\nofficially supported kernels\nuse an empty archive for the builtin initramfs, which is the default when building Linux.\nThe kernel unpacks external initramfs images in the order they are specified by the command line passed by the\nboot loader\n, overwriting any files from the embedded initramfs or previously unpacked files. Note that multiple initramfs images can be combined in a single file and the kernel will process them in their order in the file.\nIf the first initramfs image is uncompressed, after unpacking it, the kernel will look for CPU\nmicrocode\nupdates and ACPI table updates in\n/kernel/x86/microcode/\nand\n/kernel/firmware/acpi/\n, respectively.\nAfter processing the CPU microcode and ACPI table updates, the kernel will proceed to unpack the rest of the initramfs images, if any.\nInitramfs images are Arch Linux' preferred method for setting up the early userspace and can be generated with\nmkinitcpio\n,\ndracut\nor\nbooster\n.\nRunning without initramfs\nSince 6.13.8\nofficially supported kernels\nhave\nBtrfs\nand\nExt4\ndrivers built-in\n[4]\n.\nThis makes it possible for the kernel to use a root partition with these file systems directly and load the rest of external modules needed from there. Although, there are some quirks to keep in mind:\nGPT partition automounting\ncould not be used, so\nroot\nkernel parameter\nis always required.\nPersistent block device naming\nfor\nroot\nis restricted to\nPARTUUID\nand\nPARTLABEL\nonly\n[5]\n.\nMount\noptions for\nrootflags\nare limited, e.g.\nnoatime\nwould not work\n[6]\n. To mitigate possible side effects, you could make the initial mount read-only using\nrootflags=ro\n. Desired options could be applied later on remount via\nfstab\n.\nsystemd-gpt-auto-generator(8)\nis pointless without initramfs and has issues\n[7]\n, disable it by setting\nsystemd.gpt_auto=no\n.\nNote\nOnly regular SCSI/SATA/AHCI drives have built-in modules at the moment. Other storage kinds (\nNVMe\n,\nUSB\n,\ndevice mapper\netc.) would not work.\nLVM\nor encryption also can not be used without initramfs as they require userspace utilities to work.\nAnother thing you really need initramfs for is\nearly microcode loading\n. But it is not necessary to build full image for that, Arch provides\nmicrocode in separate initramfs files\n, which could be used independently.\nIf no initramfs image is provided, the kernel always contains still an empty image to start from\n[8]\n. So there should be no issues with root partition\npinning\n.\nEarly userspace\nThe\nearly userspace\nstage, a.k.a. the\ninitramfs stage\n, takes place in rootfs consisting of the files provided by the\n#initramfs\n. Early userspace starts by the kernel executing the\n/init\nbinary as PID 1.\nThe function of early userspace is\nconfigurable\n, but its main purpose is to bootstrap the system to the point where it can access the root file system. This includes:\nSet up the storage stack where the root file system may be lying on, e.g. through\ndm-crypt\n,\ndm-verity\n,\nmdadm\n,\nLVM\n,\nsystemd-repart\n, etc.\nResolve the\npersistent block device names\nto real device through\nudev\n.\nsystemd-modules-load(8)\nloads kernel modules, such as any block device modules needed to mount the real root file system.\nHandle decryption of the real root file system, if applicable.\nLoad the DRM module, as\nearly KMS\nis enabled by default for in-tree modules.\nNote that the early userspace serves more than just setting up the root file system. There are tasks that can only be performed before the root file system is mounted, such as\nfsck\nand resuming from\nhibernation\n.\nAt the final stage of early userspace, the real root is mounted at\n/sysroot/\n(in case of a\nsystemd\n-based initramfs) or at\n/new_root/\n(in case of a busybox-based one), and then switched to by using\nsystemctl switch-root\nwhen using systemd-based initramfs or\nswitch_root(8)\nwhen using busybox-based initramfs. The late userspace starts by executing the\ninit\nprogram from the real root file system.\nLate userspace\nThe startup of late userspace is executed by the\ninit\nprocess. Arch officially uses\nsystemd\nwhich is built on the concept of units and services, but the functionality described here largely overlaps with other init systems.\ngetty\nThe init process calls\ngetty\nonce for each\nvirtual terminal\n(typically six of them).\ngetty\ninitializes each terminal and protects it from unauthorized access. When the username and password are provided,\ngetty\nchecks them against\n/etc/passwd\nand\n/etc/shadow\n, then calls\nlogin(1)\n.\nLogin\nThe\nlogin\nprogram begins a session for the user by setting environment variables and starting the user's shell, based on\n/etc/passwd\n. The\nlogin\nprogram displays the contents of\n/etc/motd\n(\nm\nessage\no\nf\nt\nhe\nd\nay) after a successful login, just before it executes the login shell. It is a good place to display your Terms of Service to remind users of your local policies or anything you wish to tell them.\nShell\nOnce the user's\nshell\nis started, it will typically run a runtime configuration file, such as\nbashrc\n, before presenting a prompt to the user. If the account is configured to\nstart X at login\n, the runtime configuration file will call\nstartx\nor\nxinit\n. Jump to\n#Graphical session (Xorg)\nfor the end.\nDisplay manager\nThis article or section needs expansion.\nReason:\nThis section only describes the process with\nXorg\nbut does not explain what happens with\nWayland\n. (Discuss in\nTalk:Arch boot process\n)\nAdditionally,\ninit\ncan be configured to start a\ndisplay manager\ninstead of\ngetty\non a specific virtual terminal. This requires manually\nenabling\nits\nsystemd service file\n. The display manager then starts a graphical session.\nGraphical session (Xorg)\nxinit\nruns the user's\nxinitrc\nruntime configuration file, which normally starts a\nwindow manager\nor a\ndesktop environment\n. When the user is finished and exits,\nxinit\n,\nstartx\n, the shell, and login will terminate in that order, returning to\ngetty\nor the display manager.\nSee also\nWikipedia:Booting process of Linux\nInside the Linux boot process\nRod Smith - Managing EFI Boot Loaders for Linux\nNeoSmart: The BIOS/MBR Boot Process\nLennart Poettering - Linux Boot Partitions and How to Set Them Up\nWikipedia:initrd\nEarly Userspace in Arch Linux\nKernel Newbie Corner: initrd and initramfs\nbootup(7)\n(mostly about the systemd initramfs userspace portion)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Arch_boot_process&oldid=849965\n\"\nCategories\n:\nBoot process\nAbout Arch\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nArch boot process\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Arch_boot_process"}}
{"text": "Kernel - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nKernel\n7 languages\nBosanski\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nKernel modules\nCompile kernel module\nsysctl\nAccording to Wikipedia:\nThe\nLinux kernel\nis an open-source monolithic Unix-like computer\noperating system kernel\n.\nArch Linux\nis based on the Linux kernel. There are various alternative Linux kernels available for Arch Linux in addition to the latest stable kernel. This article lists some of the options available in the repositories with a brief description of each. There is also a description of patches that can be applied to the system's kernel. The article ends with an overview of custom kernel compilation with links to various methods.\nKernel packages are\ninstalled\nunder the\n/usr/lib/modules/\npath and subsequently used to copy the\nvmlinuz\nexecutable image to\n/boot/\n.\n[1]\nWhen installing a different kernel or switching between multiple kernels, you must configure your\nboot loader\nto reflect the changes. For downgrading the kernel to an older version, see\nDowngrading packages#Downgrading the kernel\n.\nOfficially supported kernels\nCommunity support on\nforum\nand\nbug reporting\nis available for officially supported kernels.\nStable\n— Vanilla Linux kernel and modules, with a few patches applied.\nhttps://www.kernel.org/\n||\nlinux\nHardened\n— A security-focused Linux kernel applying a set of hardening patches to mitigate kernel and userspace exploits. It also enables more upstream kernel hardening features than\nlinux\n.\nhttps://github.com/anthraxx/linux-hardened\n||\nlinux-hardened\nLongterm\n— Long-term support (LTS) Linux kernel and modules. Useful when using out-of-tree modules which may not issue timely releases compatible with the latest stable kernel.\nhttps://www.kernel.org/\n||\nlinux-lts\nRealtime kernel\n— Maintained by a small group of core developers led by Ingo Molnar. This patch allows nearly all of the kernel to be preempted, with the exception of a few very small regions of code (\"raw_spinlock critical regions\"). This is done by replacing most kernel spinlocks with mutexes that support priority inheritance, as well as moving all interrupt and software interrupts to kernel threads.\nhttps://wiki.linuxfoundation.org/realtime/start\n||\nlinux-rt\n,\nlinux-rt-lts\nNote\nReal-time kernel support was merged into\nLinux 6.12\nZen Kernel\n— Result of a collaborative effort of kernel hackers to provide the best Linux kernel possible for everyday systems. For more details see\nFAQ\nand\nDetailed Feature List\n.\nhttps://github.com/zen-kernel/zen-kernel\n||\nlinux-zen\nCompilation\nFollowing methods can be used to compile your own kernel:\n/Arch Build System\nTakes advantage of the high quality of existing\nlinux\nPKGBUILD\nand the benefits of\npackage management\n.\n/Traditional compilation\nInvolves manually downloading a source tarball, and compiling in your home directory as a normal user.\nWarning\nUsing custom kernels may cause all kinds of stability and reliability issues, including data loss. Having\nbackups\nis strongly advised.\nArch Linux only has official support for\n#Officially supported kernels\n. When using a different kernel, please mention so in support requests.\nTip\nBest way to increase the speed of your system is to first tailor your kernel configuration to your architecture and processor type.\nYou can reduce the size of your kernel (and therefore build time) by not including support for things you do not have or use. For example support for things like Bluetooth, video4linux, 1000Mbit Ethernet, etc.\nThe\nconfig\nfiles for the Arch kernel packages are in the Arch package source files (for example,\n[2]\nlinked from\nlinux\n). The\nconfig\nfile of your currently running kernel may also be available in your file system at\n/proc/config.gz\nif the\nCONFIG_IKCONFIG_PROC\nkernel option is enabled.\nSome of the listed packages may also be available as binary packages via\nUnofficial user repositories\n.\nkernel.org kernels\nGit\n— Linux kernel and modules built using sources from Linus Torvalds' Git repository.\nhttps://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git\n||\nlinux-git\nAUR\nMainline\n— Kernels where all new features are introduced, released every 2-3 months.\nhttps://www.kernel.org/\n||\nlinux-mainline\nAUR\nNext\n— Bleeding edge kernels with features pending to be merged into next mainline release.\nhttps://www.kernel.org/doc/man-pages/linux-next.html\n||\nlinux-next-git\nAUR\nDRM\n— Linux kernel with bleeding-edge GPU drivers.\nhttps://gitlab.freedesktop.org/drm\n||\nlinux-drm-tip-git\nAUR\n,\nlinux-drm-next-git\nAUR\nLongterm\n— Long-term support (LTS) Linux kernel and modules.\nhttps://www.kernel.org/\n||\nlinux-lts66\nAUR\n,\nlinux-lts61\nAUR\n,\nlinux-lts515\nAUR\n,\nlinux-lts510\nAUR\n,\nlinux-lts54\nAUR\nUnofficial kernels\nClear\n— Patches from Intel's Clear Linux project. Provides performance and security optimizations.\nhttps://github.com/clearlinux-pkgs/linux\n||\nlinux-clear\nAUR\nLibre\n— Without\nproprietary\nor\nobfuscated\ndevice drivers.\nhttps://www.fsfla.org/ikiwiki/selibre/linux-libre/\n||\nlinux-libre\nAUR\nLiquorix\n— Kernel replacement built using Debian-targeted configuration and the Zen kernel sources. Designed for desktop, multimedia, and gaming workloads, it is often used as a Debian Linux performance replacement kernel. Damentz, the maintainer of the Liquorix patchset, is a developer for the Zen patchset as well.\nhttps://liquorix.net\n||\nlinux-lqx\nAUR\npf-kernel\n— Provides a handful of awesome features which are not merged into a kernel mainline. Maintained by a kernel engineer. If the port for the included patch for new kernels was not released officially, the patchset provides and supports patch ports to new kernels. The current most prominent patches of linux-pf are UKSM, DDCCI, v4l2loopback and BBRv3.\nhttps://pfkernel.natalenko.name\n|| Packages:\nRepository\n,\nlinux-pf\nAUR\nby pf-kernel developer\npost-factum\nProject C\n— Kernel with Alfred Chen's Project C patch set (BMQ and PDS schedulers).\nhttps://gitlab.com/alfredchen/projectc\n||\nlinux-prjc\nAUR\nNitrous\n— Modified Linux kernel optimized for Skylake and newer.\nhttps://gitlab.com/xdevs23/linux-nitrous\n||\nlinux-nitrous\nAUR\ntkg\n— A highly customizable kernel build system that provides a selection of patches and tweaks aiming for better desktop and gaming performance. It is maintained by Etienne Juvigny. Amongst other patches, it offers various CPU schedulers: CFS, Project C PDS, Project C BMQ, MuQSS and CacULE.\nhttps://github.com/Frogging-Family/linux-tkg\n|| available in\nchaotic-aur\n.\nVFIO\n— The Linux kernel and a few patches written by Alex Williamson (acs override and i915) to enable the ability to do PCI Passthrough with KVM on some machines.\nhttps://lwn.net/Articles/499240/\n||\nlinux-vfio\nAUR\n,\nlinux-vfio-lts\nAUR\nXanMod\n— Aiming to take full advantage in high-performance workstations, gaming desktops, media centers and others and built to provide a more rock-solid, responsive and smooth desktop experience. This kernel uses the BFQ I/O scheduler,\nTCP BBRv3\ncongestion control, x86_64 advanced instruction set support, partial clear linux patchset, and other default changes.\nhttps://xanmod.org/\n||\nlinux-xanmod\nAUR\n,\nlinux-xanmod-lts\nAUR\n,\nlinux-xanmod-rt\nAUR\n,\nlinux-xanmod-bore\nAUR\nlinux-cachyos\n— The Linux SCHED-EXT + BORE + Cachy Sauce Kernel by CachyOS with other patches and improvements kernel and modules\nhttps://github.com/CachyOS/linux-cachyos\n||\nlinux-cachyos\nAUR\nMany of these unofficial kernels contain features that need to be enabled manually. Try reading the documentation in the patches themselves (many already include changes to the\nDocumentation/\ndirectory in the kernel source) or searching up the name of the patchset on the web.\nTroubleshooting\nKernel panics\nA\nkernel panic\noccurs when the Linux kernel enters an unrecoverable failure state. The state typically originates from buggy hardware drivers resulting in the machine being deadlocked, non-responsive, and requiring a reboot. Just prior to deadlock, a diagnostic message is generated, consisting of: the\nmachine state\nwhen the failure occurred, a\ncall trace\nleading to the kernel function that recognized the failure, and a listing of currently loaded modules. Thankfully, kernel panics do not happen very often using\nmainline\nversions of the kernel--such as those supplied by the official repositories--but when they do happen, you need to know how to deal with them.\nNote\nKernel panics are sometimes referred to as\noops\nor\nkernel oops\n.  While both panics and oops occur as the result of a failure state, an\noops\nis more general in that it does not\nnecessarily\nresult in a deadlocked machine: sometimes the kernel can recover from an oops by killing the offending task and carrying on.\nTip\nPass the kernel parameter\noops=panic\nat boot or write\n1\nto\n/proc/sys/kernel/panic_on_oops\nto force a recoverable oops to issue a panic instead.  This is advisable if you are concerned about the small chance of system instability resulting from an oops recovery which may make future errors difficult to diagnose.\nExamine panic message\nIf a kernel panic occurs very early in the boot process, you may see a message on the console containing\nKernel panic - not syncing:\n, but once\nsystemd\nis running, kernel messages will typically be captured and written to the system log. However, when a panic occurs, the diagnostic message output by the kernel is\nalmost never\nwritten to the log file on disk because the machine deadlocks before\nsystem-journald\ngets the chance.\nQR code on a blue screen\nSince\nlinux\n6.10 (for\ndrm_panic\n), the kernel will display a panic as a\nQR code\n(by default) in a blue screen. The\nstack trace\nis visible at the URL given by the QR code. For Arch Linux, it is a link to\nhttps://panic.archlinux.org/panic_report\n. The URL contains various information and the stack trace compressed by gzip and encoded in the\nURL fragment\nwhich is not transferred to the server (it is processed on the client side).\nAn example panic with a link and screenshot can be seen in a\nforum post\n.\nYou can revert to the old behavior by passing the parameter\npanic_screen=kmsg\nto the\ndrm\nkernel module (or\ndrm.panic_screen=kmsg\nas\nkernel parameter\n) to display the stack trace in a console.\nConsole way\nThe \"old\" style way of viewing the crash on the console as it happens is still available (without resorting to setting up a\nkdump crashkernel\n). Boot with the following kernel parameters and attempting to reproduce the panic on tty1:\nsystemd.journald.forward_to_console=1 console=tty1\nTip\nIn the event that the panic message scrolls away too quickly to examine, try passing the kernel parameter\npause_on_oops=\nseconds\nat boot.\nExample scenario: bad module\nIt is possible to make a best guess as to what subsystem or module is causing the panic using the information in the diagnostic message. In this scenario, we have a panic on some imaginary machine during boot. Pay attention to the lines highlighted in\nbold\n:\nkernel: BUG: unable to handle kernel NULL pointer dereference at (null)\n1\nkernel: IP: fw_core_init+0x18/0x1000 [firewire_core]\n2\nkernel: PGD 718d00067\nkernel: P4D 718d00067\nkernel: PUD 7b3611067\nkernel: PMD 0\nkernel:\nkernel: Oops: 0002 [#1] PREEMPT SMP\nkernel: Modules linked in: firewire_core(+) crc_itu_t cfg80211 rfkill ipt_REJECT nf_reject_ipv4 nf_log_ipv4 nf_log_common xt_LOG nf_conntrack_ipv4 ...\n3\nkernel: CPU: 6 PID: 1438 Comm: modprobe Tainted: P           O    4.13.3-1-ARCH #1\nkernel: Hardware name: Gigabyte Technology Co., Ltd. H97-D3H/H97-D3H-CF, BIOS F5 06/26/2014\nkernel: task: ffff9c667abd9e00 task.stack: ffffb53b8db34000\nkernel: RIP: 0010:fw_core_init+0x18/0x1000 [firewire_core]\nkernel: RSP: 0018:ffffb53b8db37c68 EFLAGS: 00010246\nkernel: RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000\nkernel: RDX: 0000000000000000 RSI: 0000000000000008 RDI: ffffffffc16d3af4\nkernel: RBP: ffffb53b8db37c70 R08: 0000000000000000 R09: ffffffffae113e95\nkernel: R10: ffffe93edfdb9680 R11: 0000000000000000 R12: ffffffffc16d9000\nkernel: R13: ffff9c6729bf8f60 R14: ffffffffc16d5710 R15: ffff9c6736e55840\nkernel: FS:  00007f301fc80b80(0000) GS:ffff9c675dd80000(0000) knlGS:0000000000000000\nkernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nkernel: CR2: 0000000000000000 CR3: 00000007c6456000 CR4: 00000000001406e0\nkernel: Call Trace:\nkernel:  do_one_initcall+0x50/0x190\n4\nkernel:  ? do_init_module+0x27/0x1f2\nkernel:  do_init_module+0x5f/0x1f2\nkernel:  load_module+0x23f3/0x2be0\nkernel:  SYSC_init_module+0x16b/0x1a0\nkernel:  ? SYSC_init_module+0x16b/0x1a0\nkernel:  SyS_init_module+0xe/0x10\nkernel:  entry_SYSCALL_64_fastpath+0x1a/0xa5\nkernel: RIP: 0033:0x7f301f3a2a0a\nkernel: RSP: 002b:00007ffcabbd1998 EFLAGS: 00000246 ORIG_RAX: 00000000000000af\nkernel: RAX: ffffffffffffffda RBX: 0000000000c85a48 RCX: 00007f301f3a2a0a\nkernel: RDX: 000000000041aada RSI: 000000000001a738 RDI: 00007f301e7eb010\nkernel: RBP: 0000000000c8a520 R08: 0000000000000001 R09: 0000000000000085\nkernel: R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000c79208\nkernel: R13: 0000000000c8b4d8 R14: 00007f301e7fffff R15: 0000000000000030\nkernel: Code: <c7> 04 25 00 00 00 00 01 00 00 00 bb f4 ff ff ff e8 73 43 9c ec 48\nkernel: RIP: fw_core_init+0x18/0x1000 [firewire_core] RSP: ffffb53b8db37c68\nkernel: CR2: 0000000000000000\nkernel: ---[ end trace 71f4306ea1238f17 ]---\nkernel: Kernel panic - not syncing: Fatal exception\n5\nkernel: Kernel Offset: 0x80000000 from 0xffffffff810000000 (relocation range: 0xffffffff800000000-0xfffffffffbffffffff\nkernel: ---[ end Kernel panic - not syncing: Fatal exception\nIndicates the type of error that caused the panic. In this case it was a programmer bug.\nIndicates that the panic happened in a function called\nfw_core_init\nin module\nfirewire_core\n.\nIndicates that\nfirewire_core\nwas the latest module to be loaded.\nIndicates that the function that called function\nfw_core_init\nwas\ndo_one_initcall\n.\nIndicates that this\noops\nmessage is, in fact, a kernel panic and the system is now deadlocked.\nWe can surmise then, that the panic occurred during the initialization routine of module\nfirewire_core\nas it was loaded.  (We might assume then, that the machine's firewire hardware is incompatible with this version of the firewire driver module due to a programmer error, and will have to wait for a new release.) In the meantime, the easiest way to get the machine running again is to prevent the module from being loaded.  We can do this in one of two ways:\nIf the module is being loaded during the execution of the\ninitramfs\n, reboot with the kernel parameter\nrd.blacklist=firewire_core\n.\nOtherwise reboot with the kernel parameter\nmodule_blacklist=firewire_core\n.\nReboot into root shell and fix problem\nThis article or section is out of date.\nReason:\nrd.rescue\nand\nrd.emergency\nwill not work since\nthe root account in the initramfs is locked\n. (Discuss in\nTalk:Kernel\n)\nThe factual accuracy of this article or section is disputed.\nReason:\nThe keyboard does not work in\nrd.emergency\nso it cannot be used. (Discuss in\nTalk:Kernel\n)\nYou will need a root shell to make changes to the system so the panic no longer occurs. If the panic occurs on boot, there are several strategies to obtain a root shell before the machine deadlocks:\nReboot with the kernel parameter\nemergency\n,\nrd.emergency\n, or\n-b\nto receive a prompt to login just after the root filesystem is mounted and\nsystemd\nis started.\nNote\nAt this point, the root filesystem will be mounted\nread-only\n. Execute\nmount -o remount,rw /\nas the root user to make changes.\nReboot with the kernel parameter\nrescue\n,\nrd.rescue\n,\nsingle\n,\ns\n,\nS\n, or\n1\nto receive a prompt to login just after local filesystems are mounted.\nReboot with the kernel parameter\nsystemd.debug_shell\nto obtain a very early root shell on tty9.  Switch to it with by pressing\nCtrl+Alt+F9\n.\nExperiment by rebooting with different sets of kernel parameters to possibly disable the kernel feature that is causing the panic.  Try the \"old standbys\"\nacpi=off\nand\nnolapic\n.\nTip\nSee\nkernel-parameters.html\nfor all kernel parameters.\nAs a last resort, boot with an\nArch Linux installation medium\nand mount the root filesystem on\n/mnt\nthen execute\narch-chroot /mnt\nas the root user.\nDisable the service or program that is causing the panic, roll-back a faulty update, or fix a configuration problem.\nTip\nIt may be necessary to generate a new\ninitial ramdisk\nimage if the original became corrupted. This can occur when a kernel update is interrupted. For creating a new one, see\nmkinitcpio\n.\nDebugging regressions\nSee\nGeneral troubleshooting#Debugging regressions\n.\nTry\nlinux-mainline\nAUR\nto check if the issue is already fixed upstream. The pinned comment also mentions a repository which contains already built kernels, so it may not be necessary to build it manually, which can take some time.\nIt may also be worth considering trying the LTS kernel (\nlinux-lts\n) to debug issues which did not appear recently. Older versions of the LTS kernel can be found in the\nArch Linux Archive\n.\nIf the issue still persists,\nbisect\nthe\nlinux-git\nAUR\nkernel and report the bug in accordance to the kernel process for\nreporting regressions\n. Depending on the Bugtracker (\nB:\n) entry in the\nMAINTAINERS\nfile this then entails opening an issue via the subsystems mailing lists, Kernel Bugzilla, or in other issue trackers like the DRM Gitlab. It is important to try the \"vanilla\" version without any patches to make sure it is not related to them. If a patch causes the issue, report it to the author of the patch.\nNote\nBisecting the kernel can take a lot of time since it may need to be rebuilt many times.\nBuilding a smaller kernel\nYou can shorten kernel build times by building only the modules required by the local system using\nmodprobed-db\n, or by\nmake localmodconfig\n. Of course you can completely drop irrelevant drivers, for example sound drivers to debug a network problem.\nSee also\nO'Reilly - Linux Kernel in a Nutshell\n(free ebook)\nWhat stable kernel should I use?\nby Greg Kroah-Hartman\nLinux kernel documentation\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Kernel&oldid=853192\n\"\nCategories\n:\nKernel\nLists of software\nHidden categories:\nPages or sections flagged with Template:Out of date\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nKernel\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Kernel"}}
{"text": "Kernel module - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nKernel module\n9 languages\nBosanski\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nBoot debugging\nCompile kernel module\nKernel\nKernel parameters\nKernel modules\nare pieces of code that can be loaded and unloaded into the kernel upon demand. They extend the functionality of the kernel without the need to reboot the system.\nTo create a kernel module, you can read\nThe Linux Kernel Module Programming Guide\n. A module can be configured as built-in or loadable. To dynamically load or remove a module, it has to be configured as a loadable module in the kernel configuration (the line related to the module will therefore display the letter\nM\n).\nTo rebuild a kernel module automatically when a new kernel is installed, see\nDynamic Kernel Module Support\n(DKMS).\nObtaining information\nUsually modules depend on the kernel release and are stored in the\n/usr/lib/modules/\nkernel_release\n/\ndirectory.\nTip\nRun\nuname -r\n(or\nuname --kernel-release\n) to get your current kernel release.\nNote\nModule and\nalias\nnames often use underscores (\n_\n) or dashes (\n-\n); however, those symbols are interchangeable when using the\nmodprobe\ncommand and in configuration files in\n/etc/modprobe.d/\n(automatic conversion to underscores is performed, see\nmodprobe(8) § DESCRIPTION\nand\nmodprobe.d(5) § DESCRIPTION\n).\nTo show what kernel modules are currently loaded:\n$ lsmod\nTo show information about a module:\n$ modinfo\nmodule_name\nTo list the options that are set for a loaded module use\nsystool(1)\nfrom\nsysfsutils\n:\n$ systool -v -m\nmodule_name\nTo display the comprehensive configuration of all the modules:\n$ modprobe -c | less\nTo display the configuration of a particular module:\n$ modprobe -c | grep\nmodule_name\nList the dependencies of a module (or alias), including the module itself:\n$ modprobe --show-depends\nmodule_name\nAutomatic module loading\nToday, all necessary modules loading is handled automatically by\nudev\n, so if you do not need to use any out-of-tree kernel modules, there is no need to put modules that should be loaded at boot in any configuration file. However, there are cases where you might want to load an extra module during the boot process, or blacklist another one for your computer to function properly.\nEarly module loading\nEarly module loading depends on the\ninitramfs\ngenerator used:\nBooster#Early module loading\nDracut#Early kernel module loading\nMkinitcpio#MODULES\nNote\nThe\ninitramfs\nimage may not contain the kernel modules asked for in\n/etc/modules-load.d/\n, it also may lack the files that have been set in that folder (see\n#systemd\n).\nsystemd\nKernel modules can be explicitly listed in files under\n/etc/modules-load.d/\nfor systemd to load them during boot. Each configuration file is named in the style of\n/etc/modules-load.d/\nprogram\n.conf\n. Configuration files simply contain a list of kernel modules names to load, separated by newlines. Empty lines and lines whose first non-whitespace character is\n#\nor\n;\nare ignored.\n/etc/modules-load.d/virtio-net.conf\n# Load virtio_net.ko at boot\nvirtio_net\nSee\nmodules-load.d(5)\nfor more details.\nManual module handling\nKernel modules are handled by tools provided by the\nkmod\npackage, which is installed as a dependency of a kernel package. You can use these tools manually. To load a module:\n# modprobe\nmodule_name\nNote\nIf you have upgraded your kernel but have not yet rebooted,\nmodprobe\nwill fail with no error message and exit with code\n1\n, because the path\n/usr/lib/modules/\nkernel_release\n/\nno longer exists. Check manually if this path exists when\nmodprobe\nfailed to determine if this is the case.\nTo load a module by a file name—i.e. one that is not installed in the\n/usr/lib/modules/\nkernel_release\n/\ndirectory—use any of:\n# insmod\nfile_name\nmodule_options\n# modprobe\nfile_name\nTo unload—\nremove\n—a module, use any of:\n# rmmod\nmodule_name\n# modprobe -r\nmodule_name\n# modprobe --remove\nmodule_name\nSetting module options\nTo pass a parameter to a kernel module, you can pass them manually with\nmodprobe\nor assure certain parameters are always applied using a\nmodprobe\nconfiguration file or by using the\nkernel command line\n. If the module is built into the kernel, the kernel command line must be used and other methods will not work.\nUsing modprobe\nThe basic way to pass parameters to a module is using the\nmodprobe\ncommand. Parameters are specified on command line using simple\nkey\n=\nvalue\nassignments:\n# modprobe\nmodule_name\nparameter_name\n=\nparameter_value\nUsing modprobe.d\nConfiguration files in the\n/etc/modprobe.d/\ndirectory can be used to pass module settings to\nudev\n, which will use\nmodprobe\nto manage the loading of the modules during system boot. Files in this directory can have any name, given that they end with the\n.conf\nextension. The file name matters, see\nmodprobe.d(5) § CONFIGURATION DIRECTORIES AND PRECEDENCE\n. To show the effective configuration:\n$ systemd-analyze cat-config modprobe.d\nThe syntax is:\n/etc/modprobe.d/\nfile_name\n.conf\noptions\nmodule_name parameter_name=parameter_value\nNote\nAll options for a given module\nmust\nbe defined in a single line. New\noptions\nline with the same module name replaces the previous one.\nMultiple module parameters are separated by spaces, in turn a parameter can receive a list of values which is separated by commas:\n/etc/modprobe.d/\nfile_name\n.conf\noptions\nmodule_name param1=value1 param2=value2a,value2b …\nFor example:\n/etc/modprobe.d/thinkfan.conf\n# On ThinkPads, this lets the 'thinkfan' daemon control fan speed\noptions thinkpad_acpi fan_control=1\nNote\nIf any of the affected modules is loaded from the\ninitramfs\n, then you will need to add the appropriate\n.conf\nfile to\nFILES\nin\nmkinitcpio.conf\nor use the\nmodconf\nhook\n, then\nregenerate the initramfs\nto include the\n.conf\nfile. To see the contents of the default initramfs use\nlsinitcpio\n.\nUsing kernel command line\nYou can also pass options to the module using the kernel command line. This is the only working option for modules built into the kernel. For all common\nboot loaders\n, the following syntax is correct:\nmodule_name.parameter_name=parameter_value\nFor example:\nthinkpad_acpi.fan_control=1\nSimply add this to the appropriate line in your boot loader configuration, as described in\nKernel parameters#Boot loader configuration\n.\nAliasing\nAliases are alternate names for a module. For example:\nalias my-mod really_long_modulename\nmeans you can use\nmodprobe my-mod\ninstead of\nmodprobe really_long_modulename\n. You can also use shell-style wildcards, so\nalias my-mod* really_long_modulename\nmeans that\nmodprobe my-mod-something\nhas the same effect. Create an alias:\n/etc/modprobe.d/myalias.conf\nalias my-mod really_long_module_name\nAliases can be internal—contained in the module itself. Internal aliases are usually used for\n#Automatic module loading\nwhen it is needed by an application, e.g. when the kernel detects a new device. To see the module internal aliases:\n$ modinfo --field=alias\nmodule_name\nTo see both configured and internal aliases:\n$ modprobe --showconfig | grep '\\<\nmodule_name\n$'\nBlacklisting\nBlacklisting, in the context of kernel modules, is a mechanism to prevent the kernel module from loading. This could be useful if, for example, the associated hardware is not needed, or if loading that module causes problems: for instance there may be two kernel modules that try to control the same piece of hardware, and loading them together would result in a conflict.\nTip\nDo not confuse the\nblacklisting\nas a generic term with using the\nblacklist\nkeyword as a blacklisting\nparticular case\n.\nSome modules are loaded as part of the\ninitramfs\n.\nmkinitcpio -M\nwill print out all automatically detected modules: to prevent the initramfs from loading some of those modules, blacklist them in a\n.conf\nfile under\n/etc/modprobe.d\nand it shall be added in by the\nmodconf\nhook during image generation. Running\nmkinitcpio -v\nwill list all modules pulled in by the various hooks (e.g.\nfilesystems\nhook,\nblock\nhook, etc.). Remember to add that\n.conf\nfile to the\nFILES\narray in\n/etc/mkinitcpio.conf\nif you do not have the\nmodconf\nhook in your\nHOOKS\narray (e.g. you have deviated from the default configuration), and once you have blacklisted the modules\nregenerate the initramfs\n, and reboot afterwards.\nUsing modprobe.d\nalias\nDisable an\nalias\nby overriding. For example, to prevent Bluetooth module autoloading (assuming a module named\noff\ndoes not exist):\n/etc/modprobe.d/modprobe.conf\nalias net-pf-31 off\nNote\nAlias overriding can prevent automatic module loading, but will still allow the module to be loaded—both automatically and manually—by another alias or the module name.\nblacklist\nTo disable all internal aliases for a given module use the\nblacklist\nkeyword. For example, to prevent the\npcspkr\nmodule from loading on boot to avoid sounds through the\nPC speaker\n:\n/etc/modprobe.d/nobeep.conf\nblacklist pcspkr\nNote\nThe\nblacklist\nconfiguration command—as it deals with aliases—has the same drawback as the\nalias\none does: automatic loading can be prevented, but the module still may be loaded manually, or automatically if another module depends on it.\ninstall\nThere is a workaround for the behaviour described in the\n#alias\nand\n#blacklist\nnotes. The\ninstall\nconfiguration command instructs\nmodprobe\nto run a custom command instead of inserting the module in the kernel as normal, so you can simulate the successful module loading with:\n/etc/modprobe.d/blacklist.conf\ninstall\nmodule_name\n/bin/true\nYou can force the module to always fail loading with\n/bin/false\n: this will effectively prevent the module—and any other that depends on it—from loading by any means, and a log error message may be produced.\nUsing kernel command line\nTip\nThis can be very useful if a broken module makes it impossible to boot your system.\nYou can also blacklist modules from the\nboot loader\nboot entry configuration.\nSimply add\nmodule_blacklist=\nmodule_name_1\n,\nmodule_name_2\n,\nmodule_name_3\nto your kernel command line, as described in\nKernel parameters#Boot loader configuration\n.\nNote\nWhen you are blacklisting more than one module, note that they are separated by commas only. Spaces or anything else might presumably break the syntax.\nmodule_blacklist\nwill make the kernel completely refuse to load the module.\nIf you only want to prevent implicit loading, but maybe load the module manually later, the correct parameter is\nmodprobe.blacklist=\nmodule_name_1\n,\nmodule_name_2\n,\nmodule_name_3\n. This will however not prevent explicit loads during the boot, e.g. by\nsystemd\nor other modules.\nAnother use case for a command line option is to disable hardware-specific components of a module without disabling the module entirely. For example, disabling a microphone while retaining other sound out options. See\nBBS#303475\nfor a few examples.\nTroubleshooting\nModule does not load\nIn case a specific module does not load and the boot log (accessible by running\njournalctl -b\nas root) says that the module is blacklisted, but the directory\n/etc/modprobe.d/\ndoes not show a corresponding entry, check another\nmodprobe\nsource directory at\n/usr/lib/modprobe.d/\nfor blacklisting entries.\nA module will not be loaded if the \"vermagic\" string contained within the kernel module does not match the value of the currently running kernel. If it is known that the module is compatible with the current running kernel the \"vermagic\" check can be ignored with\nmodprobe --force-vermagic\n.\nWarning\nIgnoring the version checks for a kernel module can cause a kernel to crash or a system to exhibit undefined behavior due to incompatibility. Use\n--force-vermagic\nonly with the utmost caution.\nSee also\nDisable PC speaker beep\nWriting a WMI driver\n- an LWM introduction\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Kernel_module&oldid=849494\n\"\nCategories\n:\nKernel\nHardware detection and troubleshooting\nBoot process\nSearch\nSearch\nKernel module\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Kernel_module"}}
{"text": "mkinitcpio - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nmkinitcpio\n7 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nBooster\nBoot debugging\ndracut\nKernel modules\nmkinitcpio/Minimal initramfs\nsystemd\nUnified kernel image\nmkinitcpio\nis a Bash script used to create initramfs images. See\nArch boot process#initramfs\nfor a general introduction.\nIt is important to note that there are two distinct approaches how the various tasks during initial ramdisk phase are performed:\nsystemd based initial ramdisk (new default since version 40)\nsystemd is already started at the beginning of the initial ramdisk phase. The tasks to be executed are determined by regular systemd unit files. See\nsystemd bootup process\n.\nPros\n: Tightly integrated with the rest of the systemd ecosystem, leading to a more consistent and streamlined boot process. Parallelize certain boot tasks more effectively, potentially leading to faster overall boot times in some scenarios. More comprehensive set of features like\nsystemd-cryptsetup-generator\nwith\n/etc/crypttab.initramfs\nor\nGPT partition automounting\n.\nCons\n: More dependencies and larger size: Generally results in a larger initramfs due to the inclusion of systemd binaries and its dependencies. this can slightly increase boot time.\nBusybox based initial ramdisk\nAn init script is started that in turn scans the filesystem of the initial ramdisk for scripts to be executed (here in this context called runtime hooks).\nPros\n: lightweight and smaller in size, fewer dependencies.\nThe concrete variant is determined by the presence or absence of the\nsystemd\nhook in the\nHOOKS\narray of\n/etc/mkinitcpio.conf\n. See\n#Common hooks\nfor more details.\nmkinitcpio\nhas been developed by the Arch Linux developers and from community contributions. See the\npublic Git repository\n.\nInstallation\nInstall\nthe\nmkinitcpio\npackage, which is a dependency of the\nlinux\npackage, so most users will already have it installed.\nAdvanced users may wish to install the latest development version of\nmkinitcpio\nfrom Git with the\nmkinitcpio-git\nAUR\npackage.\nImage creation and activation\nAutomated generation\nEvery time a kernel is installed or upgraded, a\npacman hook\nautomatically generates a\n.preset\nfile saved in\n/etc/mkinitcpio.d/\n. For example\nlinux.preset\nfor the official stable\nlinux\nkernel package. A preset is simply a list of information required to create initial ramdisk images, instead of manually specifying the various parameters and the location of the output files.\nBy default, it contains the instructions to create only the first image, the second must be explicitly enabled:\nThe\ndefault\nramdisk image created following the directives specified in the\nconfiguration\n.\nThe\nfallback\nramdisk image, same as above except that the\nautodetect\nhook is skipped during creation, thus including a full range of modules which supports most systems.\nAfter creating the preset, the pacman hook calls the\nmkinitcpio\nscript which generates the image(s), using the information provided in the preset.\nNote\n.preset\nfiles are used to automatically regenerate the initramfs after a kernel update; be careful when editing them.\nManual generation\nTo run the script manually, refer to the\nmkinitcpio(8)\nmanual page for instructions. In particular, to (re-)generate an initramfs image based on the preset provided by a kernel package, use the\n-p\n/\n--preset\noption followed by the preset to utilize. For example, for the\nlinux\npackage, use the command:\n# mkinitcpio -p linux\nTo (re-)generate initramfs images based on all existing presets, use the\n-P\n/\n--allpresets\nswitch. This is typically used to regenerate all the initramfs images after a change of the global\nconfiguration\n:\n# mkinitcpio -P\nUsers may create any number of initramfs images with a variety of different configurations. The desired image must be specified in the respective\nboot loader\nconfiguration file.\nCustomized generation\nUsers can generate an image using an alternative configuration file. For example, the following will generate an initial ramdisk image according to the directions in\n/etc/mkinitcpio-custom.conf\nand save it as\n/boot/initramfs-custom.img\n.\n# mkinitcpio --config /etc/mkinitcpio-custom.conf --generate /boot/initramfs-custom.img\nIf generating an image for a kernel other than the one currently running, add the kernel release version to the command line. The installed kernel releases can be found in\n/usr/lib/modules/\n, the syntax is consistent with the output of the command\nuname -r\nfor each kernel.\n# mkinitcpio --generate /boot/initramfs-custom2.img --kernel 5.7.12-arch1-1\nUnified kernel images\nmkinitcpio\ncan create\nunified kernel images\n(UKIs) either by itself or via\nsystemd-ukify\n. If\nsystemd-ukify\nis absent or explicitly disabled using\n--no-ukify\n, the UKI will be assembled by mkinitcpio itself. Advanced features of\nukify\nwill not be available then.\nSee\nunified kernel image\nfor details about UKI generation.\nConfiguration\nThe primary configuration file for\nmkinitcpio\nis\n/etc/mkinitcpio.conf\n. Drop-in configuration files are also supported, e.g.\n/etc/mkinitcpio.conf.d/myhooks.conf\n(they aren't taken into account if mkinitcpio is called with\n-c\noption and/or use a preset containing\nALL_config\n). Additionally, preset definitions are provided by kernel packages in the\n/etc/mkinitcpio.d\ndirectory (e.g.\n/etc/mkinitcpio.d/linux.preset\n).\nUsers can modify seven variables within the configuration file, see\nmkinitcpio.conf(5) § VARIABLES\nfor more details:\nMODULES\nKernel modules to be loaded before any boot hooks are run.\nBINARIES\nAdditional binaries to be included in the initramfs image.\nFILES\nAdditional files to be included in the initramfs image.\nHOOKS\nHooks are scripts that execute in the initial ramdisk.\nCOMPRESSION\nUsed to compress the initramfs image.\nCOMPRESSION_OPTIONS\nExtra arguments to pass to the\nCOMPRESSION\nprogram. Usage of this setting is strongly discouraged.\nmkinitcpio\nwill handle special requirements for compressors (e.g. passing\n--check=crc32\nto xz), and misusage can easily lead to an unbootable system.\nMODULES_DECOMPRESS\nWhether to decompress loadable kernel modules and firmware files or to keep them in their original compressed form.\nNote\nSome hooks that may be required for your system like\nlvm2\n,\nmdadm_udev\n, and\nencrypt\nare\nNOT\nenabled by default. Read the\n#HOOKS\nsection carefully for instructions.\nPreset files created by\nmkinitcpio\nbefore Version 36 set the variable\nALL_config\n, which prevents drop-in configuration files from being loaded. To enable drop-in files, comment out the line\nALL_config=\"/etc/mkinitcpio.conf\"\nin older preset files.\nMODULES\nThe\nMODULES\narray is used to specify modules to load before anything else is done.\nModules suffixed with a\n?\nwill not throw errors if they are not found. This might be useful for custom kernels that compile in modules which are listed explicitly in a hook or configuration file.\nNote\nIf using out-of-tree file systems that will be mounted in early userspace (e.g. when using such a file system as the root file system), their modules (e.g.\nreiser4\n)\nmust\nbe added to the\nMODULES\narray.\nWhen using the\nencrypt\nor\nsd-encrypt\nhook, the keyboard modules and/or filesystems needed to unlock the LUKS device during system boot need to be added to the\nMODULES\narray when the target system differs from the one used to run\nmkinitcpio\n.  For example, if you use a keyfile on an ext2 file system but no ext2 file system is mounted at the time\nmkinitcpio\nruns, add\next2\n. See\ndm-crypt/System configuration#cryptkey\nfor more details.\nIf using a keyboard through a USB 3 hub and wish to use it to unlock a LUKS device, add\nusbhid xhci_hcd\n.\nIf using displays connected to a docking station, you might need to add a module for your graphics card to make initrd output visible (e.g.\ni915\nfor most Intel cards).\nBINARIES and FILES\nThese options allow users to add files to the image. Both\nBINARIES\nand\nFILES\nare added before hooks are run, and may be used to override files used or provided by a hook.\nBINARIES\nare auto-located within a standard\nPATH\nand are dependency-parsed, meaning any required libraries will also be added.\nFILES\nare added\nas-is\n. For example:\nFILES=(/etc/modprobe.d/modprobe.conf)\nBINARIES=(kexec)\nNote that as both\nBINARIES\nand\nFILES\nare\nBash\narrays, multiple entries can be added delimited with spaces.\nHOOKS\nThe\nHOOKS\narray is the most important setting in the file. Hooks are small scripts which describe what will be added to the image. For some hooks, they will also contain a runtime component which provides additional behavior, such as starting a daemon, or assembling a stacked block device. Hooks are referred to by their name, and executed in the order they exist in the\nHOOKS\narray of the configuration file.\nThe default\nHOOKS\nsetting should be sufficient for most simple, single disk setups. For root devices which are stacked or multi-block devices such as\nLVM\n,\nRAID\n, or\ndm-crypt\n, see the respective wiki pages for further necessary configuration.\nBuild hooks\nBuild hooks are found in\n/usr/lib/initcpio/install/\n, custom build hooks can be placed in\n/etc/initcpio/install/\n. These files are sourced by the bash shell during runtime of\nmkinitcpio\nand should contain two functions:\nbuild\nand\nhelp\n. The\nbuild\nfunction describes the modules, files, and binaries which will be added to the image. An API, documented by\nmkinitcpio(8)\n, serves to facilitate the addition of these items. The\nhelp\nfunction outputs a description of what the hook accomplishes.\nFor a list of all available hooks:\n$ mkinitcpio -L\nUse\nmkinitcpio'\ns\n-H\n/\n--hookhelp\noption to output help for a specific hook, for example:\n$ mkinitcpio -H udev\nRuntime hooks\nRuntime hooks are found in\n/usr/lib/initcpio/hooks/\n, custom runtime hooks can be placed in\n/etc/initcpio/hooks/\n. For any runtime hook, there should always be a build hook of the same name, which calls\nadd_runscript\nto add the runtime hook to the image. These files are sourced by the busybox ash shell during early userspace. With the exception of cleanup hooks, they will always be run in the order listed in the\nHOOKS\nsetting. Runtime hooks may contain several functions:\nrun_earlyhook\n: Functions of this name will be run once the API file systems have been mounted and the kernel command line has been parsed. This is generally where additional daemons, such as udev, which are needed for the early boot process are started from.\nrun_hook\n: Functions of this name are run shortly after the early hooks. This is the most common hook point, and operations such as assembly of stacked block devices should take place here.\nrun_latehook\n: Functions of this name are run after the root device has been mounted. This should be used, sparingly, for further setup of the root device, or for mounting other file systems, such as\n/usr\n.\nrun_cleanuphook\n: Functions of this name are run as late as possible, and in the reverse order of how they are listed in the\nHOOKS\narray in the configuration file. These hooks should be used for any last minute cleanup, such as shutting down any daemons started by an early hook.\nNote\nRuntime hooks are only used by busybox init.\nsystemd\nhook triggers a systemd based init, which does not run any runtime hooks but uses systemd units instead.\nPost hooks\nPost hooks are executables or shell scripts located in\n/usr/lib/initcpio/post/\n(hooks provided by packages) and\n/etc/initcpio/post/\n(custom hooks). These files are executed after an image is (re)generated in order to perform additional tasks like signing.\nTo each executable the following arguments are passed in this order:\nthe\nkernel\nused (may be empty in some circumstances);\nthe generated\ninitramfs image\n;\n(optional) the generated\nunified kernel image\n.\nAdditionally, the following environment variables are set—\nKERNELVERSION\nthe full kernel version,\nKERNELDESTINATION\nthe default location where the kernel should be located on order to be booted.\nCommon hooks\nA table of common hooks and how they affect image creation and runtime follows. Note that this table is not complete, as packages can provide custom hooks.\nThis article or section needs expansion.\nReason:\nAdd info about\nhostdata\n,\nmemdisk\n,\nsleep\nand\nstrip\n, find out if\ndmraid\n, etc. work/are needed for systemd based initramfs. (Discuss in\nTalk:Mkinitcpio#Improvements for the Common hooks table and section about systemd hook\n)\nbusybox init\nsystemd init\nBuild hook\nRuntime hook\n(busybox init only)\nbase\noptional\nSets up all initial directories and installs base utilities and libraries. Always keep this hook as the first hook unless you know what you are doing, as it provides critical busybox init when not using\nsystemd\nhook.\nOptional when using the\nsystemd\nhook as it only provides a busybox recovery shell. In addition to enabling\nbase\n, you'll need to temporarily add\nSYSTEMD_SULOGIN_FORCE=1\nto your\nkernel parameters\nto use the shell.\n–\nudev\nsystemd\nAdds udevd, udevadm, and a small subset of udev rules to your image.\nStarts the udev daemon and processes uevents from the kernel; creating device nodes. As it simplifies the boot process by not requiring the user to explicitly specify necessary modules, using it is recommended.\nusr\nAdds support for\n/usr\non a separate partition. See\n#/usr as a separate partition\nfor details.\nMounts the\n/usr\npartition after the real root has been mounted.\nresume\nAdds\nlzo\nand\nlz4\nkernel modules to allow resuming when using a hibernation image compression algorithm other than the compile-time default. Adds the\nsystemd-hibernate-resume(8)\nbinary to support resuming from a hibernation image specified via the\nHibernateLocation\nUEFI variable.\nTries to resume from the \"suspend to disk\" state. See\nHibernation\nfor further configuration.\nbtrfs\n–\nSets the required modules to enable\nBtrfs\nfor using multiple devices with Btrfs. You need to have\nbtrfs-progs\ninstalled to use this. This hook is not required for using Btrfs on a single device where the\nfilesystems\nhook suffices.\nRuns\nbtrfs device scan\nto assemble a multi-device Btrfs root file system when\nudev\nhook or\nsystemd\nhook is not present. The\nbtrfs-progs\npackage is required for this hook.\nautodetect\nShrinks your initramfs to a smaller size by creating a whitelist of modules from a scan of sysfs. Be sure to verify included modules are correct and none are missing. This hook must be run before other subsystem hooks in order to take advantage of auto-detection. Any hooks placed before 'autodetect' will be installed in full.\n–\nmicrocode\nPrepends an uncompressed initramfs image with early\nmicrocode\nupdate files for Intel and AMD processors. Uses microcode files from\n/usr/lib/firmware/amd-ucode/\nand\n/usr/lib/firmware/intel-ucode/\nif they are available or extracts\n/boot/amd-ucode.img\nand\n/boot/intel-ucode.img\notherwise.\nIf the\nautodetect\nhook runs before this hook, it will only add early microcode update files for the processor of the system the image is built on.\nThe use of this hook replaces the now deprecated\n--microcode\nflag, and the\nmicrocode\noption in the preset files. This also allows you to drop the microcode\ninitrd\nlines from your boot configuration as they are now packed together with the main initramfs image.\n–\nmodconf\nIncludes modprobe configuration files from\n/etc/modprobe.d/\nand\n/usr/lib/modprobe.d/\n.\n–\nkms\nAdds GPU modules to provide\nearly KMS start\n. Additionally adds modules that are required by privacy screens built into the LCD panel of some laptops.\n–\nkeyboard\nAdds the necessary modules for keyboard devices. Use this if you have a USB or serial keyboard and need it in early userspace (either for entering encryption passphrases or for use in an interactive shell). As a side effect, modules for some non-keyboard input devices might be added too, but this should not be relied on.\nNote\nFor systems that are booted with different hardware configurations (e.g. laptops with external keyboard vs. internal keyboard or\nheadless systems\n), this hook needs to be placed before\nautodetect\nin order to be able to use the keyboard at boot time, for example to unlock an encrypted device when using the\nencrypt\nhook.\n–\nkeymap\nsd-vconsole\nAdds the specified\nconsole keymap(s)\nfrom\n/etc/vconsole.conf\nto the initramfs. If you use\nsystem encryption\n, especially full-disk encryption, make sure you add it before the\nencrypt\nhook.\nLoads the specified console keymap(s) from\n/etc/vconsole.conf\nduring early userspace.\nconsolefont\nAdds the specified\nconsole font\nfrom\n/etc/vconsole.conf\nto the initramfs.\nLoads the specified console font from\n/etc/vconsole.conf\nduring early userspace.\nblock\nAdds block device modules. If the\nautodetect\nhook runs before this hook, it will only add modules for block devices used on the system. Exceptions are the\nahci\n,\nsd_mod\n,\nusb_storage\n,\nuas\n,\nmmc_block\n,\nnvme\n,\nvirtio_scsi\nand\nvirtio_blk\nmodules which will always be added unconditionally.\n–\nnet\nnot implemented\nAdds the necessary modules for a network device. You must have\nmkinitcpio-nfs-utils\ninstalled to use this, see\n#Using net\nfor details.\nProvides handling for an NFS-based root file system.\ndmraid\n?\nProvides support for fakeRAID root devices. You must have\ndmraid\ninstalled to use this. Note that it is preferred to use\nmdadm\nwith the\nmdadm_udev\nhook with fakeRAID if your controller supports it. See\n#Using RAID\nfor details.\nLocates and assembles fakeRAID block devices using\ndmraid\n.\nmdadm_udev\nProvides support for assembling RAID arrays via udev. You must have\nmdadm\ninstalled to use this. See\nRAID#Configure mkinitcpio\nfor details.\n–\nencrypt\nsd-encrypt\nAdds the\ndm_crypt\nkernel module and the\ncryptsetup\ntool to the image. You must have\ncryptsetup\ninstalled to use this.\nNote\nTake notice of the remarks for the\nkeyboard\nhook above to unlock an encrypted device during boot, and/or the filesystem remarks in\n#MODULES\nwhen you use a file to unlock.\nDetects and unlocks an encrypted root partition. See\n#Runtime customization\nfor further configuration.\nFor\nsd-encrypt\nsee\ndm-crypt/System configuration#Using systemd-cryptsetup-generator\n.\nlvm2\nAdds the device mapper kernel module and the\nlvm\ntool to the image. You must have\nlvm2\ninstalled to use this. This is necessary if you have your root file system on\nLVM\n.\n–\nfilesystems\nThis includes necessary file system modules into your image. This hook is\nrequired\nunless you specify your file system modules in\nMODULES\n.\n–\nfsck\nAdds the fsck binary and file system-specific helpers to allow running fsck against your root device (and\n/usr\nif separate) prior to mounting. If added after the\nautodetect\nhook, only the helper specific to your root file system will be added. Usage of this hook is\nstrongly\nrecommended, and it is required with a separate\n/usr\npartition. It is highly recommended that if you include this hook that you also include any necessary modules to ensure your keyboard will work in early userspace.\nThe use of this hook requires the\nrw\nparameter to be set on the\nkernel command line\n(\ndiscussion\n). See\nfsck#Boot time checking\nfor more details.\n–\nacpi_override\nAdds ACPI Machine Language (\n.aml\n) files found in\n/usr/initcpio/acpi_override/\nand\n/etc/initcpio/acpi_override/\nto the early uncompressed initramfs image so that the kernel can override ACPI tables (e.g.\nDSDT\n) very early during boot.\n[1]\n–\nCOMPRESSION\nThe kernel supports several formats for compression of the initramfs:\ngzip\n,\nbzip2\n, lzma (\nxz\n),\nxz\n, lzo (\nlzop\n),\nlz4\nand\nzstd\n. By default mkinitcpio uses zstd compression for kernel version 5.9 and newer and gzip for kernel versions older than 5.9.\nThe provided\nmkinitcpio.conf\nhas the various\nCOMPRESSION\noptions commented out. Uncomment one if you wish to switch to another compression method and make sure you have the corresponding compression utility installed. If none is specified, the default method is used. If you wish to create an uncompressed image, specify\nCOMPRESSION=\ncat\nin the configuration file or use\n-z cat\non the command line.\nTip\nlz4 and xz compression utilities are multithreaded by default and zstd is run in multithreaded mode (with the\n-T0\noption which tries to spawn as many threads as detected cores).\nWith a compression ratio typically around 2.5 on the image in its high compression mode (\n-9\n), lz4 achieves the fastest decompression speed. For a slightly better compression, lzo is still fast to decompress. zstd offers a versatile solution, with multi-threaded compression and a wide range of compression levels through its options — see\nzstd(1) § Operation Modifiers\n. xz achieves the smallest size with a reduction factor around 5 in its high compression preset (\n-9\n), at the cost of a much slower decompression speed.\nCOMPRESSION_OPTIONS\nThese are additional flags passed to the program specified by\nCOMPRESSION\n, such as:\nCOMPRESSION_OPTIONS=(-9)\nThis option can be left empty;\nmkinitcpio\nwill ensure that any supported compression method has the necessary flags to produce a working image.\nWarning\nMisuse of this option may lead to an\nunbootable system\nif the kernel is unable to unpack the resultant archive.\nWith the default zstd compression, to save space for custom kernels (especially with a\ndual boot\nsetup when using the EFI system partition as\n/boot\n), the\n--long\noption is very effective. However, systems with limited RAM may not be able to decompress initramfs using this option. The\n-v\noption may also be desired to see details during the initramfs generation. For example:\nCOMPRESSION=\"zstd\"\nCOMPRESSION_OPTIONS=(-v -5 --long)\nHighest, but slowest, compression can be achieved by using xz with the\n-9e\ncompression level and also decompressing the loadable kernel modules and firmware:\nCOMPRESSION=\"xz\"\nCOMPRESSION_OPTIONS=(-9e)\nMODULES_DECOMPRESS=\"yes\"\nMODULES_DECOMPRESS\nMODULES_DECOMPRESS\ncontrols whether the kernel module and firmware files are decompressed during initramfs creation. The default value is\nno\n.\nArch compresses its\nkernel\nmodules and\nlinux-firmware\nwith zstd at level 19. When using a higher compression than that for the initramfs, setting\nMODULES_DECOMPRESS=\"yes\"\nwill allow to reduce the initramfs size even further. This comes at the expense of increased RAM and CPU usage at early boot which negatively affects systems with limited RAM or weak CPUs since the kernel will spend more time to decompress the whole initramfs image than it would take to decompress the individual modules and firmware upon loading them.\nTip\nNear the end of the initramfs generation process, all remaining\n.bz2\n,\n.gz\n,\n.lz4\n,\n.lzma\n,\n.lzo\n,\n.xz\nand\n.zst\nfiles are moved to the early uncompressed initramfs image to avoid double compression.\nRuntime customization\nThis article or section needs expansion.\nReason:\nWhich options work with the\nsystemd\nhook and which are\nbase\n-only? (Discuss in\nTalk:Mkinitcpio\n)\nRuntime configuration options can be passed to\ninit\nand certain hooks via the kernel command line. Kernel command-line parameters are often supplied by the boot loader. The options discussed below can be appended to the kernel command line to alter default behavior. See\nKernel parameters\nand\nArch boot process\nfor more information.\ninit from base hook\nroot=\nThis is the most important parameter specified on the kernel command line, as it determines what device will be mounted as your proper root device.\nmkinitcpio\nis flexible enough to allow a wide variety of formats; see\nPersistent block device naming#Kernel parameters\nfor examples.\nNote\nThe following boot parameters alter the default behavior of\ninit\nin the initramfs environment. See\n/usr/lib/initcpio/init\nfor details. They will not work when\nsystemd\nhook is being used since the\ninit\nfrom\nbase\nhook is replaced.\nbreak\nIf\nbreak\nor\nbreak=premount\nis specified,\ninit\npauses the boot process (after loading hooks, but before mounting the root file system) and launches an interactive shell which can be used for troubleshooting purposes. This shell can be launched after the root has been mounted by specifying\nbreak=postmount\n. Normal boot continues after exiting from the shell.\ndisablehooks=\nDisable hooks at runtime by adding\ndisablehooks=hook1[,hook2,...]\n. For example:\ndisablehooks=resume\nearlymodules=\nAlter the order in which modules are loaded by specifying modules to load early via\nearlymodules=mod1[,mod2,...]\n. (This may be used, for example, to ensure the correct ordering of multiple network interfaces.)\nSee\nBoot debugging\nand\nmkinitcpio(8)\nfor other parameters.\nUsing RAID\nSee\nRAID#Configure mkinitcpio\n.\nUsing net\nNote\nNFSv4 is not yet supported\nFS#28287\n.\nRequired packages\nnet\nrequires the\nmkinitcpio-nfs-utils\npackage.\nKernel parameters\nComprehensive and up-to-date information can be found in the official\nkernel documentation\n.\nip=\nThis parameter tells the kernel how to configure IP addresses of devices and also how to set up the IP routing table. It can take up to nine arguments separated by colons:\nip=<client-ip>:<server-ip>:<gw-ip>:<netmask>:<hostname>:<device>:<autoconf>:<dns0-ip>:<dns1-ip>:<ntp0-ip>\n.\nIf this parameter is missing from the kernel command line, all fields are assumed to be empty, and the defaults mentioned in the\nkernel documentation\napply. In general this means that the kernel tries to configure everything using autoconfiguration.\nThe\n<autoconf>\nparameter can appear alone as the value to the\nip\nparameter (without all the\n:\ncharacters before). If the value is\nip=off\nor\nip=none\n, no autoconfiguration will take place, otherwise autoconfiguration will take place. The most common way to use this is\nip=dhcp\n.\nFor parameters explanation, see the\nkernel documentation\n.\nExamples:\nip=127.0.0.1:::::lo:none  --> Enable the loopback interface.\nip=192.168.1.1:::::eth2:none --> Enable static eth2 interface.\nip=:::::eth0:dhcp --> Enable dhcp protocol for eth0 configuration.\nNote\nMake sure to use kernel device names (e.g.\neth0\n) for the\n<device>\nparameter, the persistent names (e.g.\nenp2s0\n) will not work. See\nNetwork configuration#Network interfaces\nfor details.\nBOOTIF=\nIf you have multiple network cards, this parameter can include the MAC address of the interface you are booting from. This is often useful as interface numbering may change, or in conjunction with pxelinux IPAPPEND 2 or IPAPPEND 3 option. If not given,\neth0\nwill be used.\nExample:\nBOOTIF=01-A1-B2-C3-D4-E5-F6  # Note the prepended \"01-\" and capital letters.\nnfsroot=\nIf the\nnfsroot\nparameter is NOT given on the command line, the default\n/tftpboot/%s\nwill be used.\nnfsroot=[<server-ip>:]<root-dir>[,<nfs-options>]\nRun\nmkinitcpio -H net\nfor parameter explanation.\nUsing LVM\nIf your root device is on\nLVM\n, see\nInstall Arch Linux on LVM#Adding mkinitcpio hooks\n.\nUsing encrypted root\nIf using an\nencrypted root\nsee\ndm-crypt/System configuration#mkinitcpio\nfor detailed information on which hooks to include.\n/usr as a separate partition\nIf you keep\n/usr\nas a separate partition, you must adhere to the following requirements:\nAdd the\nfsck\nhook, mark\n/usr\nwith a\npassno\nof\n2\nin\n/etc/fstab\nto run the check on the partition at startup. While recommended for everyone, it is mandatory if you want your\n/usr\npartition to be fsck'ed at boot-up. Without this hook,\n/usr\nwill never be fsck'd.\nIf not using the systemd hook, add the\nusr\nhook. This will mount the\n/usr\npartition after root is mounted.\nTips and tricks\nFallback initramfs generation\nAs of version 40 of mkinitcpio, fallback initramfs generation is disabled by default. To enable it:\nChange\nPRESETS=('default')\nline to\nPRESETS=('default' 'fallback')\nin the respective\n.preset\nfiles in\n/etc/mkinitcpio.d/\n.\nRegenerate initramfs\nUpdate your\nboot loader\nconfiguration.\nWarning\nThe lack of a fallback initramfs can deprive you of another option to boot into the system in case a default initramfs fails. Make sure you have a bootable\ninstallation medium\nfor rescue purposes on hand.\nTroubleshooting\nExtracting the image\nIf you are curious about what is inside the initramfs image, you can extract it and poke at the files inside of it.\nThe initramfs image is an SVR4 CPIO archive, generated via the\nfind\nand\nbsdcpio\ncommands, optionally compressed with a compression scheme understood by the kernel. For more information on the compression schemes, see\n#COMPRESSION\n.\nmkinitcpio\nincludes a utility called\nlsinitcpio(1)\nwhich will list and/or extract the contents of initramfs images.\nYou can list the files in the image with:\n# lsinitcpio /boot/initramfs-linux.img\nAnd to extract them all in the current directory:\n# lsinitcpio -x /boot/initramfs-linux.img\nYou can also get a more human-friendly listing of the important parts in the image:\n# lsinitcpio -a /boot/initramfs-linux.img\nRecompressing a modified extracted image\nInvoke the\nbuild_image\nfunction of the\n/usr/bin/mkinitcpio\nscript with parameters\nbuild_image\noutfile\ncompression\nIt can be done by creating a new script with the contents of the\nbuild_image\nfunction and running it with the above parameters.\nThis will compress the contents present in the current directory in a file named\noutfile\n.\nWarning\nIt is a good idea to rename the automatically generated\n/boot/initramfs-linux.img\nbefore you overwrite it, so you can easily undo your changes.  Be prepared for making a mistake that prevents your system from booting.  If this happens, you will need to boot through the fallback, or a boot CD, to restore your original, run\nmkinitcpio\nto overwrite your changes, or fix them yourself and recompress the image.\n\"/dev must be mounted\" when it already is\nThe test used by\nmkinitcpio\nto determine if\n/dev\nis mounted is to see if\n/dev/fd/\nis there. If everything else looks fine, it can be \"created\" manually by:\n# ln -s /proc/self/fd /dev/\n(Obviously,\n/proc\nmust be mounted as well.\nmkinitcpio\nrequires that anyway, and that is the next thing it will check.)\nPossibly missing firmware for module XXXX\nWhen initramfs are being rebuilt after a kernel update, you might get warnings:\n==> WARNING: Possibly missing firmware for module: '\nmodule_name\n'\nIf these messages appear when generating a\ndefault\ninitramfs image, then, as the warning says, installing additional firmware may be required. Most common firmware files can be acquired by\ninstalling\nthe\nlinux-firmware\npackage. For other packages providing firmware see the table below or try searching for the module name in the\nofficial repositories\nor\nAUR\n.\nOtherwise, if the messages only appear when generating the\nfallback\ninitramfs image you have the following options:\nYou can safely ignore the warnings, if you know that you do not use the affected hardware.\nIf you want to suppress the warnings, you can install the missing firmware. The meta-package\nmkinitcpio-firmware\nAUR\ncontains most optional firmwares. Alternatively, manually install the needed packages:\nModule\nPackage\naic94xx\naic94xx-firmware\nAUR\nast\nast-firmware\nAUR\nbfa\nlinux-firmware-qlogic\nbnx2x\nlinux-firmware-broadcom\nliquidio\nlinux-firmware-liquidio\nmlxsw_spectrum\nlinux-firmware-mellanox\nnfp\nlinux-firmware-nfp\nqat_420xx\nlinux-firmware-intel\nqed\nlinux-firmware-qlogic\nqla1280\nlinux-firmware-qlogic\nqla2xxx\nlinux-firmware-qlogic\nwd719x\nwd719x-firmware\nAUR\nxhci_pci\nxhci_pci_renesas\nupd72020x-fw\nAUR\nIf you want to get rid of the warnings, but do not want to waste your system space on unneeded firmware packages, you can disable\nfallback initramfs generation\naltogether.\nFor unavailable firmware, you can suppress the warnings by creating dummy files, e.g.:\n# echo \"Device not available\" > /usr/lib/firmware/qat_420xx.bin\n# echo \"Device not available\" > /usr/lib/firmware/qat_420xx_mmp.bin\nNo PS/2 controller found\nOn some motherboards (mostly ancient ones, but also a few new ones), the i8042 controller cannot be automatically detected. It is rare, but some people will surely be without keyboard. You can detect this situation in advance. If you have a PS/2 port and get\ni8042: PNP: No PS/2 controller found. Probing ports directly\nmessage, add\natkbd\nto the\nMODULES\narray.\n[2]\nStandard rescue procedures\nWith an improper initial ram-disk a system often is unbootable. So follow a system rescue procedure like below:\nBoot succeeds on one machine and fails on another\nmkinitcpio'\ns\nautodetect\nhook filters unneeded\nkernel modules\nin the primary initramfs scanning\n/sys\nand the modules loaded at the time it is run. If you transfer your\n/boot\ndirectory to another machine and the boot sequence fails during early userspace, it may be because the new hardware is not detected due to missing kernel modules. Note that USB 2.0 and 3.0 need different kernel modules.\nTo fix, first try choosing the\nfallback\nimage from your\nboot loader\n, as it is not filtered by\nautodetect\n. Once booted, run\nmkinitcpio\non the new machine to rebuild the primary image with the correct modules. If the fallback image fails, try booting into an Arch Linux live CD/USB, chroot into the installation, and run\nmkinitcpio\non the new machine. As a last resort, try\nmanually\nadding modules to the initramfs.\nCannot open access to console, the root account is locked\nThe\nsystemd\nhook\ndisables the root account\n. To enable the emergency shell, temporarily add\nSYSTEMD_SULOGIN_FORCE=1\nto the\nkernel parameters\n.\nAlternatively, you can use\ninitcpio-hook-shadowcopy\nAUR\n, by installing it and adding the\nshadowcopy\nhook after\nsystemd\nin\n/etc/mkinitcpio.conf\n, and regenerating initramfs with\nmkinitcpio -P\n. More documentation is available in\nits GitHub repo\n.\nSee also\nLinux Kernel documentation on\ninitramfs, \"What is rootfs?\"\nLinux Kernel documentation on\ninitrd\nWikipedia article on\ninitrd\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Mkinitcpio&oldid=852830\n\"\nCategories\n:\nInitramfs\nKernel\nArch projects\nCommands\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nmkinitcpio\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Mkinitcpio"}}
{"text": "GRUB - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nGRUB\n8 languages\nDeutsch\nEspañol\n日本語\nPolski\nPortuguês\nРусский\nTürkçe\n中文（简体）\nFrom ArchWiki\nRelated articles\n/EFI examples\n/Tips and tricks\nArch boot process\nGRUB Legacy\nGUID Partition Table\nMaster Boot Record\nMultiboot USB drive\nUnified Extensible Firmware Interface\nGRUB\n(\nGR\nand\nU\nnified\nB\nootloader) is a\nboot loader\n. The current\nGRUB\nis also referred to as\nGRUB 2\n. The original GRUB, or\nGRUB Legacy\n, corresponds to versions 0.9x. This page exclusively describes GRUB 2.\nNote\nIn the entire article\nesp\ndenotes the mount point of the\nEFI system partition\naka ESP.\nSupported file systems\nGRUB bundles its own support for\nmultiple file systems\n, notably\nFAT32\n,\next4\n,\nBtrfs\nor\nXFS\n. See\n#Unsupported file systems\nfor some caveats.\nWarning\nFile systems can get new features not yet supported by GRUB, making them unsuitable for\n/boot\nunless disabling incompatible features. This can be typically avoided by using a separate\n/boot partition\nwith a universally supported file system such as\nFAT32\n.\nUEFI systems\nNote\nIt is recommended to read and understand the\nUnified Extensible Firmware Interface\n,\nPartitioning#GUID Partition Table\nand\nArch boot process#UEFI 2\npages.\nWhen installing to use UEFI it is important to boot the installation media in UEFI mode, otherwise\nefibootmgr\nwill not be able to add the GRUB UEFI boot entry. Installing to the\nfallback boot path\nwill still work even in BIOS mode since it does not touch the NVRAM.\nTo boot from a disk using UEFI, an EFI system partition is required. Follow\nEFI system partition#Check for an existing partition\nto find out if you have one already, otherwise you need to create it.\nThis whole article assumes that inserting additional GRUB2 modules via\ninsmod\nis possible. As discussed in\n#Shim-lock\n, this is not the case on UEFI systems with Secure Boot enabled. If you want to use any additional GRUB module that is not included in the standard GRUB EFI file\ngrubx64.efi\non a Secure Boot system, you have to re-generate the GRUB EFI\ngrubx64.efi\nwith\ngrub-mkstandalone\nor reinstall GRUB using\ngrub-install\nwith the additional GRUB modules included.\nInstallation\nNote\nUEFI firmwares are not implemented consistently across manufacturers. The procedure described below is intended to work on a wide range of UEFI systems but those experiencing problems despite applying this method are encouraged to share detailed information, and if possible the workarounds found, for their hardware-specific case. A\n/EFI examples\narticle has been provided for such cases.\nThe section assumes you are installing GRUB for x64 (64-bit) UEFI. For IA32 (32-bit) UEFI (not to be confused with 32-bit CPUs), replace\nx86_64-efi\nwith\ni386-efi\nwhere appropriate. Follow the instructions in\nUnified Extensible Firmware Interface#Checking the firmware bitness\nto figure out your UEFI's bitness.\nFirst,\ninstall\nthe packages\ngrub\nand\nefibootmgr\n:\nGRUB\nis the boot loader while\nefibootmgr\nis used by the GRUB installation script to write boot entries to NVRAM.\nThen follow the below steps to install GRUB to your disk:\nMount the EFI system partition\nand in the remainder of this section, substitute\nesp\nwith its mount point.\nChoose a boot loader identifier, here named\nGRUB\n. A directory of that name will be created in\nesp\n/EFI/\nto store the EFI binary and this is the name that will appear in the UEFI boot menu to identify the GRUB boot entry.\nExecute the following command to install the GRUB EFI application\ngrubx64.efi\nto\nesp\n/EFI/GRUB/\nand install its modules to\n/boot/grub/x86_64-efi/\n.\nNote\nMake sure to install the packages and run the\ngrub-install\ncommand from the system in which GRUB will be installed as the boot loader. That means if you are booting from the live installation environment, you need to be inside the chroot when running\ngrub-install\n. If for some reason it is necessary to run\ngrub-install\nfrom outside of the installed system, append the\n--boot-directory=\noption with the path to the mounted\n/boot\ndirectory, e.g\n--boot-directory=/mnt/boot\n.\nSome motherboards cannot handle\nbootloader-id\nwith spaces in it.\nEFI on\nRAID\nmdadm 1 version / metadata 0.90 or 1.0 ONLY!  So partitions start with a complete copy of the FAT filesystem then have mdadm label at the end.\ngrub-install\nrequires\n--no-nvram\nor else it errors with\nefibootmgr: option requires an argument -- 'd'\n. This is a\nlong open bug\n(\nUbuntu discussion\n).  The fastest workaround is to manually add the entry for each partition in the array with\nefibootmgr\n(\nGentoo wiki goes a little more in depth on efibootmgr use\n)\n# grub-install --target=x86_64-efi --efi-directory=\nesp\n--bootloader-id=GRUB\nAfter the above installation completed, the main GRUB directory is located at\n/boot/grub/\n. Read\n/Tips and tricks#Alternative install method\nfor how to specify an alternative location. Note that\ngrub-install\nalso tries to\ncreate an entry in the firmware boot manager\n, named\nGRUB\nin the above example – this will, however, fail if your boot entries are full or the systems prevents the boot order from being manipulated (e.g. Thinkpad BIOSs have a setting called \"Boot Order Lock\" which needs to be disabled for efibootmgr to be able to add/remove entries); use\nefibootmgr\nto remove unnecessary entries.\nWarning\nRemember to\n#Generate the main configuration file\nafter finalizing the configuration or else your os will not be in the grub menu.\nTip\nIf you use the option\n--removable\nthen GRUB will be installed to\nesp\n/EFI/BOOT/BOOTX64.EFI\n(or\nesp\n/EFI/BOOT/BOOTIA32.EFI\nfor the\ni386-efi\ntarget) and you will have the additional ability of being able to boot from the drive in case EFI variables are reset or you move the drive to another computer. Usually you can do this by selecting the drive itself, similar to how you would using BIOS. If dual booting with Windows, be aware Windows usually places an EFI executable there, but its only purpose is to recreate the UEFI boot entry for Windows. If you are installing GRUB on a\nMac\n, you will have to use this option. Some desktop motherboards will only look for an EFI executable in this location, making this option mandatory, in particular with MSI boards.\nIf you execute a UEFI update, this update might delete the existing UEFI boot entries. Therefore, it is a potential fallback strategy to have the \"removable\" boot entry enabled.\nNote\n--efi-directory\nand\n--bootloader-id\nare specific to GRUB UEFI,\n--efi-directory\nreplaces\n--root-directory\nwhich is deprecated.\nYou might note the absence of a\ndevice_path\noption (e.g.:\n/dev/sda\n) in the\ngrub-install\ncommand. In fact any\ndevice_path\nprovided will be ignored by the GRUB UEFI install script. Indeed, UEFI boot loaders do not use a MBR bootcode or partition boot sector at all.\nSee\nUEFI troubleshooting\nin case of problems. Additionally see\n/Tips and tricks#UEFI further reading\n.\nSecure Boot support\nGRUB fully supports secure boot utilising either CA keys or shim; the installation command, however, is different depending on which you intend to use.\nWarning\nIncorrectly configuring\nSecure Boot\ncan render your system unbootable. If for any reason you cannot boot after enabling secure boot then you should disable it in firmware and reboot the system.\nLoading unnecessary modules in your\nboot loader\nhas the potential to present a security risk, only use these commands if you need them.\nCA Keys\nTo make use of CA Keys the command is:\n# grub-install --target=x86_64-efi --efi-directory=\nesp\n--bootloader-id=GRUB --modules=\"tpm\" --disable-shim-lock\nShim-lock\nNote\nBefore following this section you should make sure you have followed the instructions at\nSecure Boot#shim\nand have\nsbsigntools\nset-up and ready to receive keys.\nWhen using Shim-lock, GRUB can only be successfully booted in Secure Boot mode if its EFI binary includes all of the modules necessary to read the filesystem containing the\nvmlinuz\nand\ninitramfs\nimages.\nSince GRUB version\n2.06.r261.g2f4430cc0\n, loading modules in Secure Boot Mode via\ninsmod\nis no longer allowed, as this would violate the expectation to not sideload arbitrary code. If the GRUB modules are not embedded in the EFI binary, and GRUB tries to sideload/\ninsmod\nthem, GRUB will fail to boot with the message:\nerror: prohibited by secure boot policy\nUbuntu, according to\nits official build script\n, embeds the following GRUB modules in its signed GRUB EFI binary\ngrubx64.efi\n:\nthe \"basic\" modules\n, necessary for booting from a CD or from a simple-partitioned disk:\nall_video\n,\nboot\n,\nbtrfs\n,\ncat\n,\nchain\n,\nconfigfile\n,\necho\n,\nefifwsetup\n,\nefinet\n,\next2\n,\nfat\n,\nfont\n,\ngettext\n,\ngfxmenu\n,\ngfxterm\n,\ngfxterm_background\n,\ngzio\n,\nhalt\n,\nhelp\n,\nhfsplus\n,\niso9660\n,\njpeg\n,\nkeystatus\n,\nloadenv\n,\nloopback\n,\nlinux\n,\nls\n,\nlsefi\n,\nlsefimmap\n,\nlsefisystab\n,\nlssal\n,\nmemdisk\n,\nminicmd\n,\nnormal\n,\nntfs\n,\npart_apple\n,\npart_msdos\n,\npart_gpt\n,\npassword_pbkdf2\n,\npng\n,\nprobe\n,\nreboot\n,\nregexp\n,\nsearch\n,\nsearch_fs_uuid\n,\nsearch_fs_file\n,\nsearch_label\n,\nsleep\n,\nsmbios\n,\nsquash4\n,\ntest\n,\ntrue\n,\nvideo\n,\nxfs\n,\nzfs\n,\nzfscrypt\n,\nzfsinfo\nthe \"platform-specific\" modules\nfor x86_64-efi architecture, for example:\nplay\n: to play sounds during boot\ncpuid\n: to the CPU at boot\ntpm\n: to support Measured Boot /\nTrusted Platform Modules\nthe \"advanced\" modules\n, consisting of modules:\ncryptodisk\n: to boot from\nplain-mode encrypted\ndisks\ngcry_\nalgorithm\n: to support particular hashing and encryption algorithms\nluks\n: to boot from\nLUKS\n-encrypted disks:\nlvm\n: to boot from\nLVM\nlogical volume disks\nmdraid09\n,\nmdraid1x\n,\nraid5rec\n,\nraid6rec\n: to boot from\nRAID\nvirtual disks\nYou must construct your list of GRUB modules in the form of a shell variable that we denote as\nGRUB_MODULES\n. You can use the\nlatest Ubuntu script\nas a starting point, and trim away modules that are not necessary on your system. Omitting modules will make the boot process relatively faster, and save some space on the ESP partition.\nYou also need a\nSecure Boot Advanced Targeting (SBAT)\nfile/section included in the EFI binary, to improve the security; if GRUB is launched from the UEFI shim loader.  This SBAT file/section contains metadata about the GRUB binary (version, maintainer, developer, upstream URL) and makes it easier for shim to block certain GRUB versions from being loaded if they have security vulnerabilities\n[1]\n[2]\n, as explained in the\nUEFI shim boot loader secure boot life-cycle improvements\ndocument from shim.\nThe first-stage UEFI\nboot loader\nshim will fail to launch\ngrubx64.efi\nif the SBAT section from\ngrubx64.efi\nis missing!\nIf GRUB is installed, a sample SBAT\n.csv\nfile is provided under\n/usr/share/grub/sbat.csv\n.\nReinstall GRUB using the provided\n/usr/share/grub/sbat.csv\nfile and all the needed\nGRUB_MODULES\nand sign it:\n# grub-install --target=x86_64-efi --efi-directory=\nesp\n--modules=${GRUB_MODULES} --sbat /usr/share/grub/sbat.csv\n# sbsign --key MOK.key --cert MOK.crt --output\nesp\n/EFI/GRUB/grubx64.efi\nesp\n/EFI/GRUB/grubx64.efi\n# cp\nesp\n/EFI/GRUB/grubx64.efi\nesp\n/EFI/BOOT/grubx64.efi\nReboot, select the key in\nMokManager\n, and Secure Boot should be working.\nUsing Secure Boot\nAfter installation see\nSecure Boot#Implementing Secure Boot\nfor instructions on enabling it.\nIf you are using the CA Keys method then key management, enrollment, and file signing can be automated by using\nsbctl\n, see\nSecure Boot#Assisted process with sbctl\nfor details.\nBIOS systems\nGUID Partition Table (GPT) specific instructions\nOn a BIOS/\nGPT\nconfiguration, a\nBIOS boot partition\nis required.  GRUB embeds its\ncore.img\ninto this partition.\nNote\nBefore attempting this method keep in mind that not all systems will be able to support this partitioning scheme. Read more on\nPartitioning#GUID Partition Table\n.\nThe BIOS boot partition is only needed by GRUB on a BIOS/GPT setup. On a BIOS/MBR setup, GRUB uses the post-MBR gap for the embedding the\ncore.img\n. On GPT, however, there is no guaranteed unused space before the first partition.\nFor\nUEFI\nsystems this extra partition is not required, since no embedding of boot sectors takes place in that case. However, UEFI systems still require an\nEFI system partition\n.\nCreate a mebibyte partition (\n+1M\nwith\nfdisk\nor\ngdisk\n) on the disk with no file system and with partition type GUID\n21686148-6449-6E6F-744E-656564454649\n.\nfdisk\n: Create a partition and use the\nt\ncommand to\nchange its partition type\nto\nBIOS boot\n.\ngdisk\n: Create a partition with partition type\nef02\n.\nGNU Parted\n: Create a partition and set the\nbios_grub\nflag on it.\nThis partition can be in any position order but has to be on the first 2 TiB of the disk.  This partition needs to be created before GRUB installation.  When the partition is ready, install the boot loader as per the instructions below.\nThe space before the first partition can also be used as the BIOS boot partition though it will be out of GPT alignment specification.  Since the partition will not be regularly accessed performance issues can be disregarded, though some disk utilities will display a warning about it.  In\nfdisk\nor\ngdisk\ncreate a new partition starting at sector 34 and spanning to 2047 and set the type.  To have the viewable partitions begin at the base consider adding this partition last.\nMaster Boot Record (MBR) specific instructions\nUsually the post-MBR gap (after the 512 byte\nMBR\nregion and before the start of the first partition) in many MBR partitioned systems is 31 KiB when DOS compatibility cylinder alignment issues are satisfied in the partition table. However a post-MBR gap of about 1 to 2 MiB is recommended to provide sufficient room for embedding GRUB's\ncore.img\n(\nFS#24103\n). It is advisable to use a partitioning tool that supports 1 MiB\npartition alignment\nto obtain this space as well as to satisfy other non-512-byte-sector issues (which are unrelated to embedding of\ncore.img\n).\nInstallation\nInstall\nthe\ngrub\npackage. (It will replace\ngrub-legacy\nAUR\nif that is already installed.) Then do:\n# grub-install --target=i386-pc\n/dev/sdX\nwhere\ni386-pc\nis deliberately used regardless of your actual architecture, and\n/dev/sdX\nis the\ndisk\n(\nnot a partition\n) where GRUB is to be installed. For example\n/dev/sda\nor\n/dev/nvme0n1\n, or\n/dev/mmcblk0\n. See\nDevice file#Block device names\nfor a description of the block device naming scheme.\nNow you must\ngenerate the main configuration file\n.\nIf you use\nLVM\nfor your\n/boot\n, you can install GRUB on multiple physical disks.\nTip\nSee\n/Tips and tricks#Alternative installation methods\nfor other ways to install GRUB, such as to a USB stick.\nSee\ngrub-install(8)\nand\nGRUB Manual\nfor more details on the\ngrub-install\ncommand.\nConfiguration\nOn an installed system, GRUB loads the\n/boot/grub/grub.cfg\nconfiguration file each boot. You can follow\n#Generated grub.cfg\nfor using a tool, or\n#Custom grub.cfg\nfor a manual creation.\nGenerated grub.cfg\nThis section only covers editing the\n/etc/default/grub\nconfiguration file. See\n/Tips and tricks\nfor more information.\nNote\nRemember to always\nre-generate the main configuration file\nafter making changes to\n/etc/default/grub\nand/or files in\n/etc/grub.d/\n.\nWarning\nUpdate/reinstall the boot loader (see\n#UEFI systems\nor\n#BIOS systems\n) if a new GRUB version changes the syntax of the configuration file: mismatching configuration can result in an unbootable system. For example, the new configuration might use a function unknown to the existing GRUB binary, causing unexpected behavior.\nGenerate the main configuration file\nAfter the installation, the main configuration file\n/boot/grub/grub.cfg\nneeds to be generated. The generation process can be influenced by a variety of options in\n/etc/default/grub\nand scripts in\n/etc/grub.d/\n. For the list of options in\n/etc/default/grub\nand a concise description of each refer to GNU's\ndocumentation\n.\nIf you have not done additional configuration, the automatic generation will determine the root filesystem of the system to boot for the configuration file. For that to succeed it is important that the system is either booted or\nchrooted\ninto.\nNote\nThe default file path is\n/boot/grub/grub.cfg\n, not\n/boot/grub/i386-pc/grub.cfg\n.\nIf you are trying to run\ngrub-mkconfig\nin a\nchroot\nor\nsystemd-nspawn\ncontainer, you might notice that it does not work:\ngrub-probe: error: failed to get canonical path of\n/dev/sdaX\n. In this case, try using\narch-chroot\nas described in the\nBBS post\n.\nUse the\ngrub-mkconfig\ntool to generate\n/boot/grub/grub.cfg\n:\n# grub-mkconfig -o /boot/grub/grub.cfg\nBy default the generation scripts automatically add menu entries for all installed Arch Linux\nkernels\nto the generated configuration.\nTip\nAfter installing or removing a\nkernel\n, you just need to re-run the above\ngrub-mkconfig\ncommand.\nFor tips on managing multiple GRUB entries, for example when using both\nlinux\nand\nlinux-lts\nkernels, see\n/Tips and tricks#Multiple entries\n.\nTo automatically add entries for other installed operating systems, see\n#Detecting other operating systems\n.\nYou can add additional custom menu entries by editing\n/etc/grub.d/40_custom\nand re-generating\n/boot/grub/grub.cfg\n. Or you can create\n/boot/grub/custom.cfg\nand add them there. Changes to\n/boot/grub/custom.cfg\ndo not require re-running\ngrub-mkconfig\n, since\n/etc/grub.d/41_custom\nadds the necessary\nsource\nstatement to the generated configuration file.\nTip\n/etc/grub.d/40_custom\ncan be used as a template to create\n/etc/grub.d/\nnn\n_custom\n, where\nnn\ndefines the precedence, indicating the order the script is executed.  The order scripts are executed determine the placement in the GRUB boot menu.\nnn\nshould be greater than\n06\nto ensure necessary scripts are executed first.\nSee\n#Boot menu entry examples\nfor custom menu entry examples.\nDetecting other operating systems\nTo have\ngrub-mkconfig\nsearch for other installed systems and automatically add them to the menu,\ninstall\nthe\nos-prober\npackage and\nmount\nthe partitions from which the other systems boot. Then re-run\ngrub-mkconfig\n. If you get the following output:\nWarning: os-prober will not be executed to detect other bootable partitions\nthen edit\n/etc/default/grub\nand add/uncomment:\nGRUB_DISABLE_OS_PROBER=false\nThen try again.\nNote\nThe exact mount point does not matter,\nos-prober\nreads the\nmtab\nto identify places to search for bootable entries.\nRemember to mount the partitions each time you run\ngrub-mkconfig\nin order to include the other operating systems every time.\nos-prober\nmight not work properly when run in a chroot. Try again after rebooting into the system if you experience this.\nTip\nYou might also want GRUB to remember the last chosen boot entry, see\n/Tips and tricks#Recall previous entry\n.\nWindows\nFor Windows installed in UEFI mode, make sure the\nEFI system partition\ncontaining the Windows Boot Manager (\nbootmgfw.efi\n) is mounted. Run\nos-prober\nas root to detect and generate an entry for it.\nFor Windows installed in BIOS mode, mount the Windows\nsystem partition\n(its\nfile system label\nshould be\nSystem Reserved\nor\nSYSTEM\n). Run\nos-prober\nas root to detect and generate an entry for it.\nNote\nos-prober\nmight try to\ngrub-mount\na partition to probe whether the requisite\n.efi\nfile exists. You need to install\nfuse3\nto make\ngrub-mount\nwork properly. Otherwise, you may fail to detect a Windows system.\nNTFS partitions may not always be detected when mounted with the default Linux drivers. If GRUB is not detecting it, try installing\nNTFS-3G\nand remounting.\nAdditional arguments\nTo pass custom additional arguments to the Linux image, you can set the\nGRUB_CMDLINE_LINUX\n+\nGRUB_CMDLINE_LINUX_DEFAULT\nvariables in\n/etc/default/grub\n. The two are appended to each other and passed to kernel when generating regular boot entries. For the\nrecovery\nboot entry, only\nGRUB_CMDLINE_LINUX\nis used in the generation.\nIt is not necessary to use both, but can be useful. For example, you could use\nGRUB_CMDLINE_LINUX_DEFAULT=\"resume=UUID=\nuuid-of-swap-partition\nquiet\"\nwhere\nuuid-of-swap-partition\nis the\nUUID\nof your swap partition to enable resume after\nhibernation\n. This would generate a recovery boot entry without the resume and without\nquiet\nsuppressing kernel messages during a boot from that menu entry. Though, the other (regular) menu entries would have them as options.\nBy default\ngrub-mkconfig\ndetermines the\nUUID\nof the root filesystem for the configuration. To disable this, uncomment\nGRUB_DISABLE_LINUX_UUID=true\n.\nFor generating the GRUB recovery entry you have to ensure that\nGRUB_DISABLE_RECOVERY\nis not set to\ntrue\nin\n/etc/default/grub\n.\nSee\nKernel parameters\nfor more info.\nSetting the top-level menu entry\nBy default,\ngrub-mkconfig\nsorts the included kernels using\nsort -V\nand uses the first kernel in that list as the top-level entry. This means that, for example, since\n/boot/vmlinuz-linux-lts\nis sorted before\n/boot/vmlinuz-linux\n, if you have both\nlinux-lts\nand\nlinux\ninstalled, the LTS kernel will be the top-level menu entry, which may not be desirable. This can be overridden by specifying\nGRUB_TOP_LEVEL=\"\npath_to_kernel\n\"\nin\n/etc/default/grub\n. For example, to make the regular kernel be the top-level menu entry, you can use\nGRUB_TOP_LEVEL=\"/boot/vmlinuz-linux\"\n.\nLVM\nThis article or section is a candidate for merging with\n#Installation\n.\nNotes:\ngrub-mkconfig is capable of detecting that it needs the\nlvm\nmodule, specifying it in\nGRUB_PRELOAD_MODULES\nis not required. Move warning to\n#Installation\n&\n#Installation_2\nor create a\nKnown issues section\nand document it there. (Discuss in\nTalk:GRUB\n)\nWarning\nGRUB does not support thin-provisioned logical volumes.\nIf you use\nLVM\nfor your\n/boot\nor\n/\nroot partition, make sure that the\nlvm\nmodule is preloaded:\n/etc/default/grub\nGRUB_PRELOAD_MODULES=\"... lvm\"\nRAID\nThis article or section is a candidate for merging with\n#Installation\n.\nNotes:\ngrub-mkconfig is capable of detecting that it needs the\nmdraid09\nand/or\nmdraid1x\nmodules, specifying them in\nGRUB_PRELOAD_MODULES\nis not required. Summarize the double grub-install in a note and move it to\n#Installation\n; move\nset root\nstuff to\n#Custom grub.cfg\n. (Discuss in\nTalk:GRUB\n)\nGRUB provides convenient handling of\nRAID\nvolumes. You need to load GRUB modules\nmdraid09\nor\nmdraid1x\nto allow you to address the volume natively:\n/etc/default/grub\nGRUB_PRELOAD_MODULES=\"... mdraid09 mdraid1x\"\nFor example,\n/dev/md0\nbecomes:\nset root=(md/0)\nwhereas a partitioned RAID volume (e.g.\n/dev/md0p1\n) becomes:\nset root=(md/0,1)\nTo install grub when using RAID1 as the\n/boot\npartition (or using\n/boot\nhoused on a RAID1 root partition), on BIOS systems, simply run\ngrub-install\non both of the drives, such as:\n# grub-install --target=i386-pc --debug /dev/sda\n# grub-install --target=i386-pc --debug /dev/sdb\nWhere the RAID 1 array housing\n/boot\nis housed on\n/dev/sda\nand\n/dev/sdb\n.\nNote\nGRUB supports booting from\nBtrfs\nRAID 0/1/10, but\nnot\nRAID 5/6. You may use\nmdadm\nfor RAID 5/6, which is supported by GRUB.\nEncrypted /boot\nGRUB also has special support for booting with an encrypted\n/boot\n. This is done by unlocking a\nLUKS\nblockdevice in order to read its configuration and load any\ninitramfs\nand\nkernel\nfrom it. This option tries to solve the issue of having an\nunencrypted boot partition\n.\nTip\n/boot\nis\nnot\nrequired to be kept in a separate partition; it may also stay under the system's root\n/\ndirectory tree.\nWarning\nGRUB 2.12rc1 has limited support for LUKS2. See the\n#LUKS2\nsection below for details.\nTo enable this feature encrypt the partition with\n/boot\nresiding on it using\nLUKS\nas normal. Then add the following option to\n/etc/default/grub\n:\n/etc/default/grub\nGRUB_ENABLE_CRYPTODISK=y\nThis option is used by grub-install to generate the grub\ncore.img\n.\nMake sure to\ninstall grub\nafter modifying this option or encrypting the partition.\nWithout further changes you will be prompted twice for a passphrase: the first for GRUB to unlock the\n/boot\nmount point in early boot, the second to unlock the root filesystem itself as implemented by the initramfs. You can use a\nkeyfile\nto avoid this.\nWarning\nIf you want to\ngenerate the main configuration file\n, make sure that\n/boot\nis mounted.\nIn order to perform system updates involving the\n/boot\nmount point, ensure that the encrypted\n/boot\nis unlocked and mounted before performing an update. With a separate\n/boot\npartition, this may be accomplished automatically on boot by using\ncrypttab\nwith a\nkeyfile\n.\nNote\nIf you use a special keymap, a default GRUB installation will not know it. This is relevant for how to enter the passphrase to unlock the LUKS blockdevice. See\n/Tips and tricks#Manual configuration of core image for early boot\n.\nIf you experience issues getting the prompt for a password to display (errors regarding cryptouuid, cryptodisk, or \"device not found\"), try reinstalling GRUB and appending\n--modules=\"part_gpt part_msdos\"\nto the end of your\ngrub-install\ncommand.\nTip\nYou can use\npacman hooks\nto automount your\n/boot\nwhen upgrades need to access related files.\nLUKS2\nUse\ngrub-install\nas described in the\n#Installation\nsection to create a bootable GRUB image with LUKS support. Note the following caveats:\nInitial LUKS2 support was added to GRUB 2.06, but with several limitations that are only partially addressed in GRUB 2.12rc1. See\nGRUB bug #55093\n.\nSince GRUB 2.12rc1,\ngrub-install\ncan create a core image to unlock LUKS2. However, it only supports PBKDF2, not Argon2.\nArgon2id (\ncryptsetup\ndefault) and Argon2i PBKDFs are not supported (\nGRUB bug #59409\n), only PBKDF2 is.\nTip\nYou can use\ngrub-improved-luks2-git\nAUR\nthat has been patched for LUKS2 as well as Argon2 support. Note the package's Argon2 support requires an UEFI system.\n[3]\nNote\nBefore GRUB 2.12rc1, you had to manually create an EFI binary using\ngrub-mkimage\nwith a custom GRUB config file. For example,\n/boot/grub/grub-pre.cfg\n, with calls to\ncryptomount\n,\ninsmod normal\n, and\nnormal\n. This is no longer needed,\ngrub-install\nis sufficient. However, you may have to run\ngrub-mkconfig -o /boot/grub/grub.cfg\nat least once after upgrading from 2.06.\nIf you enter an invalid passphrase during boot and end up at the GRUB rescue shell, try\ncryptomount -a\nto mount all (hopefully only one) encrypted partitions or use\ncryptomount -u $crypto_uuid\nto mount a specific one. Then proceed with\ninsmod normal\nand\nnormal\nas usual.\nIf you enter a correct passphrase, but an\nInvalid passphrase\nerror is immediately returned, make sure that the right cryptographic modules are specified. Use\ncryptsetup luksDump\n/dev/nvme0n1p2\nand check whether the hash function (SHA-256, SHA-512) matches the modules (\ngcry_sha256\n,\ngcry_sha512\n) installed and the PBKDF algorithm is pbkdf2. The hash and PBDKDF algorithms can be changed for existing keys by using\ncryptsetup luksConvertKey --hash\nsha256\n--pbkdf pbkdf2\n/dev/nvme0n1p2\n.  Under normal circumstances it should take a few seconds before the passphrase is processed.\nCustom grub.cfg\nThis article or section needs expansion.\nReason:\nAdd instructions on how to write a custom\n/boot/grub/grub.cfg\n. See\nUser:Eschwartz/Grub\nfor a proposed draft. (Discuss in\nTalk:GRUB#Manually generate grub.cfg\n)\nThis section describes the manual creation of GRUB boot entries in\n/boot/grub/grub.cfg\ninstead of relying on\ngrub-mkconfig\n.\nA basic GRUB config file uses the following options:\n(hd\nX\n,\nY\n)\nis the partition\nY\non disk\nX\n, partition numbers starting at 1, disk numbers starting at 0\nset default=\nN\nis the default boot entry that is chosen after timeout for user action\nset timeout=\nM\nis the time\nM\nto wait in seconds for a user selection before default is booted\nmenuentry \"title\" {entry options}\nis a boot entry titled\ntitle\nset root=(hd\nX\n,\nY\n)\nsets the boot partition, where the kernel and GRUB modules are stored (boot need not be a separate partition, and may simply be a directory under the \"root\" partition (\n/\n))\nLoaderDevicePartUUID\nFor GRUB to set the\nLoaderDevicePartUUID\nUEFI variable required by\nsystemd-gpt-auto-generator(8)\nfor\nGPT partition automounting\n, load the\nbli\nmodule in\ngrub.cfg\n:\nif [ \"$grub_platform\" = \"efi\" ]; then\ninsmod bli\nfi\nBoot menu entry examples\nTip\nThese boot entries can also be used when using a\n/boot/grub/grub.cfg\ngenerated by\ngrub-mkconfig\n. Add them to\n/etc/grub.d/40_custom\nand\nre-generate the main configuration file\nor add them to\n/boot/grub/custom.cfg\n.\nFor tips on managing multiple GRUB entries, for example when using both\nlinux\nand\nlinux-lts\nkernels, see\n/Tips and tricks#Multiple entries\n.\nFor\nArchiso\nand\nArchboot\nboot menu entries see\nMultiboot USB drive#Boot entries\n.\nGRUB commands\n\"Shutdown\" menu entry\nmenuentry \"System shutdown\" {\necho \"System shutting down...\"\nhalt\n}\n\"Restart\" menu entry\nmenuentry \"System restart\" {\necho \"System rebooting...\"\nreboot\n}\n\"UEFI Firmware Settings\" menu entry\nif [ ${grub_platform} == \"efi\" ]; then\nmenuentry 'UEFI Firmware Settings' --id 'uefi-firmware' {\nfwsetup\n}\nfi\nEFI binaries\nWhen launched in UEFI mode, GRUB can chainload other EFI binaries.\nTip\nTo show these menu entries only when GRUB is launched in UEFI mode, enclose them in the following\nif\nstatement:\nif [ ${grub_platform} == \"efi\" ]; then\nplace UEFI-only menu entries here\nfi\nUEFI Shell\nYou can launch\nUEFI Shell\nby placing it in the root of the\nEFI system partition\nand adding this menu entry:\nmenuentry \"UEFI Shell\" {\ninsmod fat\ninsmod chain\nsearch --no-floppy --set=root --file /shellx64.efi\nchainloader /shellx64.efi\n}\ngdisk\nDownload the\ngdisk EFI application\nand copy\ngdisk_x64.efi\nto\nesp\n/EFI/tools/\n.\nmenuentry \"gdisk\" {\ninsmod fat\ninsmod chain\nsearch --no-floppy --set=root --file /EFI/tools/gdisk_x64.efi\nchainloader /EFI/tools/gdisk_x64.efi\n}\nChainloading a unified kernel image\nIf you have a\nunified kernel image\ngenerated from following\nSecure Boot\nor other means, you can add it to the boot menu. For example:\nmenuentry \"Arch Linux\" {\ninsmod fat\ninsmod chain\nsearch --no-floppy --set=root --fs-uuid\nFILESYSTEM_UUID\nchainloader /EFI/Linux/arch-linux.efi\n}\nDual-booting\nGNU/Linux\nAssuming that the other distribution is on partition\nsda2\n:\nmenuentry \"Other Linux\" {\nset root=(hd0,2)\nlinux /boot/vmlinuz (add other options here as required)\ninitrd /boot/initramfs.img (if the other kernel uses/needs one)\n}\nAlternatively let GRUB search for the right partition by UUID or file system label:\nmenuentry \"Other Linux\" {\n# assuming that UUID is 763A-9CB6\nsearch --no-floppy --set=root --fs-uuid 763A-9CB6\n# search by label OTHER_LINUX (make sure that partition label is unambiguous)\n#search --no-floppy --set=root --label OTHER_LINUX\nlinux /boot/vmlinuz (add other options here as required, for example: root=UUID=763A-9CB6)\ninitrd /boot/initramfs.img (if the other kernel uses/needs one)\n}\nIf the other distribution has already a valid\n/boot\nfolder with installed GRUB,\ngrub.cfg\n, kernel and initramfs, GRUB can be instructed to load these other\ngrub.cfg\nfiles on-the-fly during boot. For example, for\nhd0\nand the fourth GPT partition:\nmenuentry \"configfile hd0,gpt4\"  {\ninsmod part_gpt\ninsmod btrfs\ninsmod ext2\nset root='hd0,gpt4'\nconfigfile /boot/grub/grub.cfg\n}\nWhen choosing this entry, GRUB loads the\ngrub.cfg\nfile from the other volume and displays that menu. Any environment variable changes made by the commands in file will not be preserved after\nconfigfile\nreturns. Press\nEsc\nto return to the first GRUB menu.\nWindows installed in UEFI/GPT mode\nThis mode determines where the Windows boot loader resides and chain-loads it after GRUB when the menu entry is selected. The main task here is finding the EFI system partition and running the\nboot loader\nfrom it.\nNote\nThis menuentry will work only in UEFI boot mode and only if the Windows bitness matches the UEFI bitness. It will not work in BIOS installed GRUB. See\nDual boot with Windows#Windows UEFI vs BIOS limitations\nand\nDual boot with Windows#Boot loader UEFI vs BIOS limitations\nfor more information.\nif [ \"${grub_platform}\" == \"efi\" ]; then\nmenuentry \"Microsoft Windows Vista/7/8/8.1 UEFI/GPT\" {\ninsmod part_gpt\ninsmod fat\ninsmod chain\nsearch --no-floppy --fs-uuid --set=root $hints_string $fs_uuid\nchainloader /EFI/Microsoft/Boot/bootmgfw.efi\n}\nfi\nwhere\n$hints_string\nand\n$fs_uuid\nare obtained with the following two commands.\nThe\n$fs_uuid\ncommand determines the UUID of the EFI system partition:\n# grub-probe --target=fs_uuid\nesp\n/EFI/Microsoft/Boot/bootmgfw.efi\n1ce5-7f28\nAlternatively one can run\nlsblk --fs\nand read the UUID of the EFI system partition from there.\nThe\n$hints_string\ncommand will determine the location of the EFI system partition, in this case harddrive 0:\n# grub-probe --target=hints_string\nesp\n/EFI/Microsoft/Boot/bootmgfw.efi\n--hint-bios=hd0,gpt1 --hint-efi=hd0,gpt1 --hint-baremetal=ahci0,gpt1\nThese two commands assume the ESP Windows uses is mounted at\nesp\n. There might be case differences in the path to Windows's EFI file, what with being Windows, and all.\nWindows installed in BIOS/MBR mode\nNote\nGRUB supports booting\nbootmgr\ndirectly and\nchainloading\nof partition boot sector is no longer required to boot Windows in a BIOS/MBR setup.\nWarning\nIt is the\nsystem partition\nthat has\n/bootmgr\n, not your \"real\" Windows partition (usually\nC:\n). The system partition's\nfilesystem label\nis\nSystem Reserved\nor\nSYSTEM\nand the partition is only about 100 to 549 MiB in size. See\nWikipedia:System partition and boot partition\nfor more information.\nThroughout this section, it is assumed your Windows partition is\n/dev/sda1\n. A different partition will change every instance of\nhd0,msdos1\n.\nNote\nThese menu entries will work only in BIOS boot mode. It will not work in UEFI installed GRUB. See\nDual boot with Windows#Windows UEFI vs BIOS limitations\nand\nDual boot with Windows#Boot loader UEFI vs BIOS limitations\n.\nIn both examples\nXXXX-XXXX\nis the filesystem UUID which can be found with command\nlsblk --fs\n.\nFor Windows Vista/7/8/8.1/10:\nif [ \"${grub_platform}\" == \"pc\" ]; then\nmenuentry \"Microsoft Windows Vista/7/8/8.1/10 BIOS/MBR\" {\ninsmod part_msdos\ninsmod ntfs\ninsmod ntldr\nsearch --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1\nXXXX-XXXX\nntldr /bootmgr\n}\nfi\nFor Windows XP:\nif [ \"${grub_platform}\" == \"pc\" ]; then\nmenuentry \"Microsoft Windows XP\" {\ninsmod part_msdos\ninsmod ntfs\ninsmod ntldr\nsearch --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1\nXXXX-XXXX\nntldr /ntldr\n}\nfi\nNote\nIn some cases, GRUB may be installed without a clean Windows 8, in which case you cannot boot Windows without having an error with\n\\boot\\bcd\n(error code\n0xc000000f\n). You can fix it by going to Windows Recovery Console (\ncmd.exe\nfrom install disk) and executing:\nX:\\> bootrec.exe /fixboot\nX:\\> bootrec.exe /RebuildBcd\nDo\nnot\nuse\nbootrec.exe /Fixmbr\nbecause it will wipe GRUB out.\nOr you can use Boot Repair function in the Troubleshooting menu - it will not wipe out GRUB but will fix most errors.\nAlso you would better keep plugged in both the target hard drive and your bootable device\nONLY\n. Windows usually fails to repair boot information if any other devices are connected.\nUsing labels\nIt is possible to use file system labels, human-readable strings attached to file systems, by using the\n--label\noption to\nsearch\n. First of all,\nmake sure your file system has a label\n.\nThen, add an entry using labels. An example of this:\nmenuentry \"Arch Linux, session texte\" {\nsearch --label --set=root archroot\nlinux /boot/vmlinuz-linux root=/dev/disk/by-label/archroot ro\ninitrd /boot/initramfs-linux.img\n}\nUsing the command shell\nSince the MBR is too small to store all GRUB modules, only the menu and a few basic commands reside there. The majority of GRUB functionality remains in modules in\n/boot/grub/\n, which are inserted as needed. In error conditions (e.g. if the partition layout changes) GRUB may fail to boot. When this happens, a command shell may appear.\nGRUB offers multiple shells/prompts. If there is a problem reading the menu but the\nboot loader\nis able to find the disk, you will likely be dropped to the \"normal\" shell:\ngrub>\nIf there is a more serious problem (e.g. GRUB cannot find required files), you may instead be dropped to the \"rescue\" shell:\ngrub rescue>\nThe rescue shell is a restricted subset of the normal shell, offering much less functionality. If dumped to the rescue shell, first try inserting the \"normal\" module, then starting the \"normal\" shell:\ngrub rescue> set prefix=(hdX,Y)/boot/grub\ngrub rescue> insmod (hdX,Y)/boot/grub/i386-pc/normal.mod\nrescue:grub> normal\nPager support\nGRUB supports pager for reading commands that provide long output (like the\nhelp\ncommand). This works only in normal shell mode and not in rescue mode. To enable pager, in GRUB command shell type:\nsh:grub> set pager=1\nUsing the command shell environment to boot operating systems\ngrub>\nThe GRUB's command shell environment can be used to boot operating systems.\nA common scenario may be to boot Windows / Linux stored on a drive/partition via\nchainloading\n.\nChainloading\nmeans to load another boot-loader from the current one, ie, chain-loading.\nThe other\nboot loader\nmay be embedded at the start of a partitioned disk (MBR), at the start of a partition or a partitionless disk (VBR), or as an EFI binary in the case of UEFI.\nChainloading a partition's VBR\nset root=(hdX,Y)\nchainloader +1\nboot\nX=0,1,2...\nY=1,2,3...\nFor example to chainload Windows stored in the first partition of the first hard disk,\nset root=(hd0,1)\nchainloader +1\nboot\nSimilarly GRUB installed to a partition can be chainloaded.\nChainloading a disk's MBR or a partitionless disk's VBR\nset root=hdX\nchainloader +1\nboot\nChainloading Windows/Linux installed in UEFI mode\ninsmod fat\nset root=(hd0,gpt4)\nchainloader /EFI/Microsoft/Boot/bootmgfw.efi\nboot\ninsmod fat\nis used for loading the FAT file system module for accessing the Windows\nboot loader\non the UEFI system partition.\n(hd0,gpt4)\nor\n/dev/sda4\nis the UEFI system partition in this example.\nThe entry in the\nchainloader\nline specifies the path of the\n.efi\nfile to be chain-loaded.\nNormal loading\nSee the examples in\n#Using the rescue console\nUsing the rescue console\nSee\n#Using the command shell\nfirst. If unable to activate the standard shell, one possible solution is to boot using a live CD or some other rescue disk to correct configuration errors and reinstall GRUB. However, such a boot disk is not always available (nor necessary); the rescue console is surprisingly robust.\nThe available commands in GRUB rescue include\ninsmod\n,\nls\n,\nset\n, and\nunset\n. This example uses\nset\nand\ninsmod\n.\nset\nmodifies variables and\ninsmod\ninserts new modules to add functionality.\nBefore starting, the user must know the location of their\n/boot\npartition (be it a separate partition, or a subdirectory under their root):\ngrub rescue> set prefix=(hd\nX\n,\nY\n)/boot/grub\nwhere\nX\nis the physical drive number and\nY\nis the partition number.\nNote\nWith a separate boot partition, omit\n/boot\nfrom the path (i.e. type\nset prefix=(hd\nX\n,\nY\n)/grub\n).\nTo expand console capabilities, insert the\nlinux\nmodule:\ngrub rescue> insmod i386-pc/linux.mod\nor simply\ngrub rescue> insmod linux\nThis introduces the\nlinux\nand\ninitrd\ncommands, which should be familiar.\nAn example, booting Arch Linux:\nset root=(hd0,5)\nlinux /boot/vmlinuz-linux root=/dev/sda5\ninitrd /boot/initramfs-linux.img\nboot\nWith a separate boot partition (e.g. when using UEFI), again change the lines accordingly:\nNote\nSince boot is a separate partition and not part of your root partition, you must address the boot partition manually, in the same way as for the prefix variable.\nset root=(hd0,5)\nlinux (hd\nX\n,\nY\n)/vmlinuz-linux root=/dev/sda6\ninitrd (hd\nX\n,\nY\n)/initramfs-linux.img\nboot\nNote\nIf you experienced\nerror: premature end of file /YOUR_KERNEL_NAME\nduring execution of\nlinux\ncommand, you can try\nlinux16\ninstead.\nAfter successfully booting the Arch Linux installation, users can correct\ngrub.cfg\nas needed and then reinstall GRUB.\nTo reinstall GRUB and fix the problem completely, changing\n/dev/sda\nif needed. See\n#Installation\nfor details.\nGRUB removal\nUEFI systems\nBefore removing\ngrub\n, make sure that some other boot loader is installed and configured to take over.\n$ efibootmgr\nBootOrder: 0003,0001,0000,0002\nBoot0000* Windows Boot Manager  HD(2,GPT,4dabbedf-191b-4432-bc09-8bcbd1d7dabf,0x109000,0x32000)/File(\\EFI\\Microsoft\\Boot\\bootmgfw.efi)\nBoot0001* GRUB  HD(2,GPT,4dabbedf-191b-4432-bc09-8bcbd1d7dabf,0x109000,0x32000)/File(\\EFI\\GRUB\\grubx64.efi)\nBoot0002* Linux-Firmware-Updater        HD(2,GPT,5dabbedf-191b-4432-bc09-8bcbd1d7dabf,0x109000,0x32000)/File(\\EFI\\arch\\fwupdx64.efi)\nBoot0003* Linux Boot Manager    HD(2,GPT,4dabbedf-191b-4432-bc09-8bcbd1d7dabf,0x109000,0x32000)/File(\\EFI\\systemd\\systemd-bootx64.efi)\nIf\nBootOrder\nhas\ngrub\nas the first entry, install another\nboot loader\nto put it in front, such as\nsystemd-boot\nabove.\ngrub\ncan then be removed using its\nbootnum\n.\n# efibootmgr --delete-bootnum -b 1\nAlso delete the\nesp\n/EFI/grub\nand\n/boot/grub\ndirectories.\nBIOS systems\nTo replace\ngrub\nwith any other BIOS boot loader, simply install them, which will overwrite the\nMBR boot code\n.\ngrub-install\ncreates the\n/boot/grub\ndirectory that needs to be removed manually. Though some users will want to keep it, should they want to install\ngrub\nagain.\nAfter migrating to UEFI/GPT one may want to\nremove the MBR boot code using dd\n.\nTroubleshooting\nUnsupported file systems\nIn case that GRUB does not support the root file system, an alternative\n/boot\npartition with a supported file system must be created. In some cases, the development version of GRUB\ngrub-git\nAUR\nmay have native support for the file system.\nIf GRUB is used with an unsupported file system it is not able to extract the\nUUID\nof your drive so it uses classic non-persistent\n/dev/\nsdXx\nnames instead. In this case you might have to manually edit\n/boot/grub/grub.cfg\nand replace\nroot=/dev/\nsdXx\nwith\nroot=UUID=\nXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n. You can use the\nblkid\ncommand to get the UUID of your device, see\nPersistent block device naming\n.\nWhile GRUB supports\nF2FS\nsince version 2.0.4, it cannot correctly read its boot files from an F2FS partition that was created with the\nextra_attr\nflag enabled.\nEnable debug messages\nNote\nThis change is overwritten when\n#Generate the main configuration file\n.\nAdd:\nset pager=1\nset debug=all\nto\ngrub.cfg\n.\nmsdos-style error message\ngrub-setup: warn: This msdos-style partition label has no post-MBR gap; embedding will not be possible!\ngrub-setup: warn: Embedding is not possible. GRUB can only be installed in this setup by using blocklists.\nHowever, blocklists are UNRELIABLE and its use is discouraged.\ngrub-setup: error: If you really want blocklists, use --force.\nThis error may occur when you try installing GRUB in a VMware container. Read more about it\nhere\n. It happens when the first partition starts just after the MBR (block 63), without the usual space of 1 MiB (2048 blocks) before the first partition. Read\n#Master Boot Record (MBR) specific instructions\nUEFI\nCommon installation errors\nAn error that may occur on some UEFI devices is\nCould not prepare Boot variable: Read-only file system\n. You have to remount\n/sys/firmware/efi/efivars\nwith read-write enabled.\n# mount -o remount,rw,nosuid,nodev,noexec --types efivarfs efivarfs /sys/firmware/efi/efivars\nSee the\nGentoo Wiki\non installing the\nboot loader\n.\nIf you have a problem running\ngrub-install\nwith\nsysfs\nor\nprocfs\nand it says you must run\nmodprobe efivarfs\ntry\nmounting the efivarfs\nwith the command above.\nWithout\n--target\nor\n--directory\noption, grub-install cannot determine for which firmware to install. In such cases\ngrub-install\nwill print\nsource_dir does not exist. Please specify --target or --directory\n.\nIf after running grub-install you get\nerror:\nesp\ndoesn't look like an EFI partition\n, then the partition is most likely not\nFAT32\nformatted.\nCreate a GRUB entry in the firmware boot manager\ngrub-install\nautomatically tries to create a menu entry in the boot manager. If it does not, then see\nUEFI#efibootmgr\nfor instructions to use\nefibootmgr\nto create a menu entry. However, the problem is likely to be that you have not booted your CD/USB in UEFI mode, as in\nInstallation guide#Verify the boot mode\n.\nAs another example of creating a GRUB entry in the firmware boot manager, consider\nefibootmgr -c\n. This assumes that\n/dev/sda1\nis the EFI System Partition, and is mounted at\n/boot/efi\n. Which are the default behavior of\nefibootmgr\n.  It creates a new boot option, called \"Linux\", and puts it at the top of the boot order list. Options may be passed to modify the default behavior. The default OS Loader is\n\\EFI\\arch\\grub.efi\n.\nDrop to rescue shell\nIf GRUB loads but drops into the rescue shell with no errors, it can be due to one of these two reasons:\nIt may be because of a missing or misplaced\ngrub.cfg\n. This will happen if GRUB UEFI was installed with\n--boot-directory\nand\ngrub.cfg\nis missing,\nIt also happens if the boot partition, which is hardcoded into the\ngrubx64.efi\nfile, has changed.\nGRUB UEFI not loaded\nAn example of a working UEFI:\n# efibootmgr -u\nBootCurrent: 0000\nTimeout: 3 seconds\nBootOrder: 0000,0001,0002\nBoot0000* GRUB HD(1,800,32000,23532fbb-1bfa-4e46-851a-b494bfe9478c)File(\\EFI\\GRUB\\grubx64.efi)\nBoot0001* Shell HD(1,800,32000,23532fbb-1bfa-4e46-851a-b494bfe9478c)File(\\shellx64.efi)\nBoot0002* Festplatte BIOS(2,0,00)P0: SAMSUNG HD204UI\nIf the screen only goes black for a second and the next boot option is tried afterwards, according to\nthis post\n, moving GRUB to the partition root can help. The boot option has to be deleted and recreated afterwards. The entry for GRUB should look like this then:\nBoot0000* GRUB HD(1,800,32000,23532fbb-1bfa-4e46-851a-b494bfe9478c)File(\\grubx64.efi)\nDefault/fallback boot path\nSome UEFI firmwares require a bootable file at a known location before they will show UEFI NVRAM boot entries. If this is the case,\ngrub-install\nwill claim\nefibootmgr\nhas added an entry to boot GRUB, however the entry will not show up in the VisualBIOS boot order selector. The solution is to install GRUB at the default/fallback boot path:\n# grub-install --target=x86_64-efi --efi-directory=\nesp\n--removable\nAlternatively you can move an already installed GRUB EFI executable to the default/fallback path:\n# mv\nesp\n/EFI/grub\nesp\n/EFI/BOOT\n# mv\nesp\n/EFI/BOOT/grubx64.efi\nesp\n/EFI/BOOT/BOOTX64.EFI\nInvalid signature\nIf trying to boot Windows results in an \"invalid signature\" error, e.g. after reconfiguring partitions or adding additional hard drives, (re)move GRUB's device configuration and let it reconfigure:\n# mv /boot/grub/device.map /boot/grub/device.map-old\n# grub-mkconfig -o /boot/grub/grub.cfg\ngrub-mkconfig\nshould now mention all found boot options, including Windows. If it works, remove\n/boot/grub/device.map-old\n.\nBoot freezes\nIf booting gets stuck without any error message after GRUB loading the kernel and the initial ramdisk, try removing the\nadd_efi_memmap\nkernel parameter.\nArch not found from other OS\nSome have reported that other distributions may have trouble finding Arch Linux automatically with\nos-prober\n. If this problem arises, it has been reported that detection can be improved with the presence of\n/etc/lsb-release\n. This file and updating tool is available with the package\nlsb-release\n.\nWarning when installing in chroot\nWhen installing GRUB on a LVM system in a chroot environment (e.g. during system installation), you may receive warnings like\n/run/lvm/lvmetad.socket: connect failed: No such file or directory\nor\nWARNING: failed to connect to lvmetad: No such file or directory. Falling back to internal scanning.\nThis is because\n/run\nis not available inside the chroot. These warnings will not prevent the system from booting, provided that everything has been done correctly, so you may continue with the installation.\nGRUB loads slowly\nGRUB can take a long time to load when disk space is low. Check if you have sufficient free disk space on your\n/boot\nor\n/\npartition when you are having problems.\nerror: unknown filesystem\nGRUB may output\nerror: unknown filesystem\nand refuse to boot for a few reasons. If you are certain that all\nUUIDs\nare correct and all filesystems are valid and supported, it may be because your\nBIOS Boot Partition\nis located outside the first 2 TiB of the drive\n[4]\n. Use a partitioning tool of your choice to ensure this partition is located fully within the first 2 TiB, then reinstall and reconfigure GRUB.\nThis error might also be caused by an\next4\nfilesystem having unsupported features set:\nlarge_dir\n- unsupported.\nmetadata_csum_seed\n- will be supported in GRUB 2.11 (\ncommit\n).\nWarning\nMake sure to check GRUB support for new\nfile system\nfeatures before you enable them on your\n/boot\nfile system.\ngrub-reboot not resetting\nGRUB seems to be unable to write to root Btrfs partitions\n[5]\n. If you use grub-reboot to boot into another entry it will therefore be unable to update its on-disk environment. Either run grub-reboot from the other entry (for example when switching between various distributions) or consider a different file system. You can reset a \"sticky\" entry by executing\ngrub-editenv create\nand setting\nGRUB_DEFAULT=0\nin your\n/etc/default/grub\n(do not forget\ngrub-mkconfig -o /boot/grub/grub.cfg\n).\nOld Btrfs prevents installation\nIf a drive is formatted with Btrfs without creating a partition table (eg. /dev/sdx), then later has partition table written to, there are parts of the BTRFS format that persist. Most utilities and OS's do not see this, but GRUB will refuse to install, even with --force\n# grub-install: warning: Attempting to install GRUB to a disk with multiple partition labels. This is not supported yet..\n# grub-install: error: filesystem `btrfs' does not support blocklists.\nYou can zero the drive, but the easy solution that leaves your data alone is to erase the Btrfs superblock with\nwipefs -o 0x10040 /dev/sdx\nWindows 8/10 not found\nA setting in Windows 8/10 called \"Hiberboot\", \"Hybrid Boot\" or \"Fast Boot\" can prevent the Windows partition from being mounted, so\ngrub-mkconfig\nwill not find a Windows install. Disabling Hiberboot in Windows will allow it to be added to the GRUB menu.\nGRUB rescue and encrypted /boot\nWhen using an\nencrypted /boot\n, and you fail to input a correct password, you will be dropped in grub-rescue prompt.\nThis grub-rescue prompt has limited capabilities. Use the following commands to complete the boot:\ngrub rescue> cryptomount <partition>\ngrub rescue> insmod normal\ngrub rescue> normal\nSee\nthis blog post\nfor a better description.\nGRUB is installed but the menu is not shown at boot\nCheck\n/etc/default/grub\nif\nGRUB_TIMEOUT\nis set to\n0\n, in which case set it to a positive number: it sets the number of seconds before the default GRUB entry is loaded. Also check if\nGRUB_TIMEOUT_STYLE\nis set to\nhidden\nand set it to\nmenu\n, so that the menu will be shown by default. Then\nregenerate the main configuration file\nand reboot to check if it worked.\nIf it does not work, there may be incompatibility problems with the graphical terminal. Set\nGRUB_TERMINAL_OUTPUT\nto\nconsole\nin\n/etc/default/grub\nto disable the GRUB graphical terminal.\nGRUB is installed, but receive \"ERROR CODE 1962 - No operating system found\" message on older Lenovo machines\nSee\nFixing Lenovo’s ERROR CODE 1962 by spoofing the EFI boot entries\n.\nWarning to perform grub-install/grub-mkconfig at each grub update\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThis does not belong in a troubleshooting section. (Discuss in\nTalk:GRUB\n)\nYou can do it manually or use a\npacman hook\n, for example:\n/etc/pacman.d/hooks/grub-update.hook\n[Trigger]\nOperation = Upgrade\nType = Package\nTarget = grub\n[Action]\nDescription = Regenerate grub if updated\nWhen = PostTransaction\nDepends = grub\nExec = /bin/sh -c \"/usr/bin/grub-install --efi-directory=\nesp\n--bootloader-id=GRUB && /usr/bin/grub-mkconfig -o /boot/grub/grub.cfg\"\nChange\ngrub-install\noptions such as the\n--efi-directory\npath to match your settings.\nSee also\nOfficial GRUB Manual\nUbuntu wiki page for GRUB\nGRUB wiki page describing steps to compile for UEFI systems\nWikipedia:BIOS Boot partition\nHow to configure GRUB\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=GRUB&oldid=847289\n\"\nCategories\n:\nBoot loaders\nGNU\nHidden categories:\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Style\nSearch\nSearch\nGRUB\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/GRUB"}}
{"text": "systemd-boot - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nsystemd-boot\n8 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nArch boot process\nSecure Boot\nUnified Extensible Firmware Interface\nsystemd-boot(7)\n, previously called\ngummiboot\n(German for \"rubber dinghy\") and sometimes referred to as\nsd-boot\n, is an easy-to-configure\nUEFI\nboot manager\n. It provides a textual menu to select the boot entry and an editor for the kernel command line.\nNote that\nsystemd-boot\ncan only start EFI executables (e.g., the Linux kernel\nEFI boot stub\n,\nUEFI shell\n,\nGRUB\n, or the\nWindows Boot Manager\n) from the\nEFI system partition\nit is installed to or from an Extended Boot Loader Partition (XBOOTLDR partition) on the same disk.\nNote\nIn the entire article\nesp\ndenotes the mountpoint of the\nEFI system partition\nand\nboot\ndenotes the mountpoint of the optional XBOOTLDR partition. It is assumed that you have\nchrooted\nto the system's mount point.\nSupported file systems\nsystemd-boot inherits the support for the file systems\nfrom the firmware\n(i.e. at least FAT12, FAT16 and FAT32). Additionally it loads any\nUEFI drivers\nplaced in\nesp\n/EFI/systemd/drivers/\n.\nInstallation\nsystemd-boot\nis shipped with the\nsystemd\npackage which is a dependency of the\nbase\nmeta package, so no additional packages need to be installed manually.\nInstalling the UEFI boot manager\nTo install\nsystemd-boot\n, first make sure that the system is booted into UEFI mode and\nUEFI variables\nare accessible. This can be verified by running\nefivar --list\nor, if\nefivar\nis not installed, by running\nls /sys/firmware/efi/efivars\n(if the directory exists, the system is booted into UEFI mode.)\nUse\nbootctl(1)\nto install\nsystemd-boot\nto the ESP:\n# bootctl install\nThis will copy the\nsystemd-boot\nUEFI boot manager to the ESP, create a UEFI boot entry for it and set it as the first in the UEFI boot order.\nOn an x64 UEFI,\n/usr/lib/systemd/boot/efi/systemd-bootx64.efi\nwill be copied to\nesp\n/EFI/systemd/systemd-bootx64.efi\nand\nesp\n/EFI/BOOT/BOOTX64.EFI\n.\nOn an IA32 UEFI,\n/usr/lib/systemd/boot/efi/systemd-bootia32.efi\nwill be copied to\nesp\n/EFI/systemd/systemd-bootia32.efi\nand\nesp\n/EFI/BOOT/BOOTIA32.EFI\n.\nThe UEFI boot entry will be called \"Linux Boot Manager\" and will point to, depending on the\nUEFI bitness\n, either\n\\EFI\\systemd\\systemd-bootx64.efi\nor\n\\EFI\\systemd\\systemd-bootia32.efi\non the ESP.\nNote\nWhen running\nbootctl install\n,\nsystemd-boot\nwill try to locate the ESP at\n/efi\n,\n/boot\n, and\n/boot/efi\n. Setting\nesp\nto a different location requires passing the\n--esp-path=\nesp\noption. (See\nbootctl(1) § OPTIONS\nfor details.)\nInstalling\nsystemd-boot\nwill overwrite any existing\nesp\n/EFI/BOOT/BOOTX64.EFI\n(or\nesp\n/EFI/BOOT/BOOTIA32.EFI\non IA32 UEFI), e.g. Microsoft's version of the file.\nbootctl\nrefrains from operating on UEFI variables/boot entries when running in pid namespace, which is the case for\narch-chroot(8)\n's non-systemd mode. To create the boot entry in the chroot environment, use\narch-chroot -S\ninstead.\nTo conclude the installation,\nconfigure\nsystemd-boot\n.\nInstallation using XBOOTLDR\nThis article or section is a candidate for moving to\nPartitioning#Discrete partitions\n.\nNotes:\nAll partitioning info should be moved to partitioning, to leave only steps relevant to installing systemd-boot if you have such a setup. (Discuss in\nTalk:Systemd-boot\n)\nA separate\n/boot partition\nof type \"Linux extended boot\" (XBOOTLDR) can be created to keep the kernel and initramfs separate from the ESP. This is particularly helpful to\ndual boot with Windows\nwith an existing ESP that is too small.\nPrepare an ESP as usual and create another partition for XBOOTLDR on the same physical drive. The XBOOTLDR partition must have a partition type GUID of\nbc13c2ff-59e6-4262-a352-b275fd6f7172\n[1]\n(\nea00\ntype for\ngdisk\n,\nxbootldr\ntype for\nfdisk\n). The size of the XBOOTLDR partition should be large enough to accommodate all of the kernels you are going to install.\nNote\nsystemd-boot\ndoes not do a file system check like it does for the ESP. Hence, it is possible to use any file system that your UEFI implementation can read.\nUEFI may skip loading partitions other than the ESP when a \"fast boot\" mode is enabled. This can lead to\nsystemd-boot\nfailing to find entries on the XBOOTLDR partition; in that case, disable the \"fast boot\" mode.\nThe XBOOTLDR partition must be on the same physical disk as the ESP for\nsystemd-boot\nto recognize it.\nDuring install, mount the ESP to\n/mnt/efi\nand the XBOOTLDR partition to\n/mnt/boot\n.\nOnce in chroot, use the command:\n# bootctl --esp-path=/efi --boot-path=/boot install\nTo conclude the installation,\nconfigure\nsystemd-boot\n.\nUpdating the UEFI boot manager\nWhenever there is a new version of\nsystemd-boot\n, the UEFI boot manager can be optionally reinstalled by the user. This can be done manually or automatically; the two approaches are described thereafter.\nNote\nThe UEFI boot manager is a standalone EFI executable and any version can be used to boot the system (partial updates do not apply, since pacman only installs the\nsystemd-boot\ninstaller, not\nsystemd-boot\nitself.) However, new versions may add new features or fix bugs, so it is probably a good idea to update\nsystemd-boot\n.\nWarning\nIf you have\nSecure Boot\nenabled, you need to sign the boot manager update. See\n#Signing for Secure Boot\n.\nManual update\nUse\nbootctl\nto update\nsystemd-boot\n:\n# bootctl update\nNote\nAs with\nbootctl install\n,\nsystemd-boot\nwill try to locate the ESP at\n/efi\n,\n/boot\n, and\n/boot/efi\n. Setting\nesp\nto a different location requires passing the\n--esp-path=\nesp\noption.\nAutomatic update\nTo update\nsystemd-boot\nautomatically, either use a\nsystemd service\nor a\npacman hook\n. The two methods are described below.\nsystemd service\nAs of version 250,\nsystemd\nships with\nsystemd-boot-update.service\n.\nEnabling\nthis service will cause systemd-boot to run the following command on every boot:\n# bootctl --no-variables --graceful update\nLike in the\nmanual update\n, this will attempt to locate the ESP at\n/efi\n,\n/boot\nor\n/boot/efi\n. The command will update all installed versions of systemd-boot in the ESP if a newer version is available in\n/usr/lib/systemd/boot/efi/\n. It will look for a systemd-boot file ending in\n.efi.signed\nfirst to allow users to sign the image for use with\nSecure Boot\n.\npacman hook\nThe package\nsystemd-boot-pacman-hook\nAUR\nadds a pacman hook which is executed every time\nsystemd\nis upgraded. This hook differs from the\nsystemd service method\nin that it only attempts to update the boot manager when\nsystemd\nis updated rather than every boot, and it does it immediately rather than waiting until after the next boot.\nRather than installing the AUR package, you may prefer to manually place the following file in\n/etc/pacman.d/hooks/\n:\n/etc/pacman.d/hooks/95-systemd-boot.hook\n[Trigger]\nType = Package\nOperation = Upgrade\nTarget = systemd\n[Action]\nDescription = Gracefully upgrading systemd-boot...\nWhen = PostTransaction\nExec = /usr/bin/systemctl restart systemd-boot-update.service\nSigning for Secure Boot\nIf you have\nSecure Boot\nenabled, you may want to add a pacman hook to automatically sign the boot manager upon every upgrade of the package:\n/etc/pacman.d/hooks/80-secureboot.hook\n[Trigger]\nOperation = Install\nOperation = Upgrade\nType = Path\nTarget = usr/lib/systemd/boot/efi/systemd-boot*.efi\n[Action]\nDescription = Signing systemd-boot EFI binary for Secure Boot\nWhen = PostTransaction\nExec = /bin/sh -c 'while read -r f; do /usr/lib/systemd/systemd-sbsign sign --private-key\n/path/to/keyfile.key\n--certificate\n/path/to/certificate.crt\n--output \"${f}.signed\" \"$f\"; done;'\nDepends = sh\nNeedsTargets\nReplace\n/path/to/keyfile.key\nand\n/path/to/certificate.crt\nwith your signing key and certificate respectively. For better understanding of this hook, consult\nsystemd-sbsign(1)\n.\nThe created\n/usr/lib/systemd/boot/efi/systemd-boot*.efi.\nsigned\nwill automatically be picked up by\nbootctl install\nor\nbootctl update\n. See\nbootctl(1) § SIGNED .EFI FILES\n.\nAs an alternative, use\nsbctl\n.\nConfiguration\nTip\nAfter changing the configuration, run\nbootctl\n(without any arguments) to make sure that systemd-boot will be able to parse it properly.\nLoader configuration\nThe loader configuration is stored in the file\nesp\n/loader/loader.conf\n. See\nloader.conf(5) § OPTIONS\nfor details.\nA loader configuration example is provided below:\nesp\n/loader/loader.conf\ndefault  arch.conf\ntimeout  4\nconsole-mode max\neditor   no\nTip\ndefault\nand\ntimeout\ncan be changed in the boot menu itself and changes will be stored as UEFI variables\nLoaderEntryDefault\nand\nLoaderConfigTimeout\n, overriding these options.\nbootctl set-default \"\"\nand\nbootctl set-timeout \"\"\ncan be used to clear the UEFI variables overriding the\ndefault\nand\ntimeout\noptions, respectively.\nIf you have set\ntimeout 0\n, the boot menu can be accessed by pressing\nSpace\n.\nA basic loader configuration file is located at\n/usr/share/systemd/bootctl/loader.conf\n.\nIf the boot manager—during the entry selection—appears distorted/uses the wrong resolution you can try to set the\nconsole-mode\nto\nauto\n(uses heuristics to select the best resolution),\nkeep\n(keeps the firmware provided resolution) or\n2\n(tries to select the first non-UEFI-standard resolution).\nRemember last entry\nThe\ndefault\ncan be changed to\n@saved\nin order to remember the last picked entry on startup. This is useful for when dual booting Windows and the surprise windows auto update pushes you into Linux.\nesp\n/loader/loader.conf\ndefault @saved\n...\nConsult\nloader.conf(5)\nfor more details.\nAdding loaders\nsystemd-boot\nwill search for\n.conf\nfiles in\n/loader/entries/\non the\nEFI system partition\nit was launched from and additionally the\nXBOOTLDR\npartition on the same disk.\nNote\nEntries in\nesp\n/loader/entries/*.conf\ncan only use files (e.g. kernels, initramfs, images, etc.) in\nesp\n/\nand entries in\nboot\n/loader/entries/*.conf\ncan only use files in\nboot\n/\n.\nThe file path parameters are relative to the root of your EFI system partition or XBOOTLDR partition. E.g., if your EFI system partition or XBOOTLDR partition is mounted at\n/boot\n, then the\n/boot/vmlinuz-linux\nfile must be specified in the\nlinux\nkey as\n/vmlinuz-linux\n.\nWhen\nSecure Boot\nis active,\nunified kernel images\n(UKIs) with an embedded\n.cmdline\nignore all command line options passed to them (either using a boot entry with\noptions\nor interactively). When Secure Boot is not active, the options passed via the command line override the embedded\n.cmdline\n.\nAn example of loader files launching Arch from a volume using its\nUUID\nxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\nis:\nesp\n/loader/entries/arch.conf\ntitle   Arch Linux\nlinux   /vmlinuz-linux\ninitrd  /initramfs-linux.img\noptions root=UUID=\nxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\nrw\nesp\n/loader/entries/arch-fallback.conf\ntitle   Arch Linux (fallback initramfs)\nlinux   /vmlinuz-linux\ninitrd  /initramfs-linux-fallback.img\noptions root=UUID=\nxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\nrw\nSee the\nBoot Loader Specification\nfor details on all configuration options.\nsystemd-boot\nwill automatically check at boot time for\nWindows Boot Manager\nat the location\n/EFI/Microsoft/Boot/Bootmgfw.efi\n,\nApple macOS Boot Manager\nin firmware,\nUEFI shell\n/shellx64.efi\nand\nEFI Default Loader\n/EFI/BOOT/bootx64.efi\n, as well as specially prepared kernel files found in\n/EFI/Linux/\n. When detected, corresponding entries with titles\nauto-windows\n,\nauto-osx\n,\nauto-efi-shell\nand\nauto-efi-default\n, respectively, will be generated. These entries do not require manual loader configuration. However, it does not auto-detect other EFI applications (unlike\nrEFInd\n), so for booting the Linux kernel, manual configuration entries must be created.\nTip\nThe available boot entries which have been configured can be listed with the command\nbootctl list\n.\nAn example entry file is located at\n/usr/share/systemd/bootctl/arch.conf\n.\nThe\nkernel parameters\nfor scenarios such as\nLVM\n,\nLUKS\n,\ndm-crypt\nor\nBtrfs\ncan be found on the relevant pages.\nNote\nIf\nexternal microcode initramfs images\nare used (e.g. when using\nBooster\nas the initramfs generator),\n/boot/amd-ucode.img\nor\n/boot/intel-ucode.img\nmust be specified in a separate\ninitrd\nand always be placed\nfirst\n, before the main initramfs image.\nUEFI Shells or other EFI applications\nIn case you installed a\nUEFI shell\nwith the package\nedk2-shell\n,\nsystemd-boot\nwill auto-detect and create a new entry if the EFI file is placed in\nesp\n/shellx64.efi\n.\nTo perform this an example command after installing the package would be:\n# cp /usr/share/edk2-shell/x64/Shell.efi /boot/shellx64.efi\nOtherwise in case you installed\nother EFI applications\ninto the ESP, you can use the following snippets.\nNote\nThe file path parameter for the\nefi\nline is relative to the root of your\nEFI system partition\n. If your EFI system partition is mounted at\n/boot\nand your EFI binaries reside at\n/boot/EFI/xx.efi\nand\n/boot/yy.efi\n, then you would specify the parameters as\nefi /EFI/xx.efi\nand\nefi /yy.efi\nrespectively.\nesp\n/loader/entries/fwupd.conf\ntitle  Firmware updater\nefi     /EFI/tools/fwupdx64.efi\nesp\n/loader/entries/gdisk.conf\ntitle  GPT fdisk (gdisk)\nefi     /EFI/tools/gdisk_x64.efi\nMemtest86+\nYou need to install\nmemtest86+-efi\nfor this to work. Also sign the EFI binary when using Secure Boot.\nesp\n/loader/entries/memtest.conf\ntitle Memtest86+\nefi /memtest86+/memtest.efi\nNetboot\nsystemd-boot\ncan chainload\nNetboot\n. Download the\nipxe-arch.efi\nEFI binary and signature, verify it and place it as proposed in\nesp\n/EFI/arch_netboot/arch_netboot.efi\n.\nesp\n/loader/entries/arch_netboot.conf\ntitle Arch Linux Netboot\nefi /EFI/arch_netboot/arch_netboot.efi\nGRUB\nsystemd-boot\ncan chainload\nGRUB\n. The location of the\ngrubx64.efi\nbinary matches the used\n--bootloader-id=\nwhen GRUB was installed to the ESP.\nesp\n/loader/entries/grub.conf\ntitle GRUB\nefi /EFI/GRUB/grubx64.efi\nBoot from another disk\nsystemd-boot\ncannot\nlaunch EFI binaries from partitions other than the ESP it is launched from or the XBOOTLDR partition on the same disk, but it can direct the\nUEFI shell\nto do so.\nFirst, install\nedk2-shell\nas\ndescribed above\n. In the UEFI shell, use the\nmap\ncommand to take notes of the\nFS alias\n(ex: HD0a66666a2, HD0b, FS1, or BLK7) of the partition with the corresponding PARTUUID.\nThen, use the\nexit\ncommand to boot back into Linux, where you can create a new loader entry to run the target EFI program through the UEFI shell:\nesp\n/loader/entries/windows.conf\ntitle   Windows\nefi     /shellx64.efi\noptions -nointerrupt -nomap -noversion HD0b:EFI\\Microsoft\\Boot\\Bootmgfw.efi\nEnsure that the\nefi\npath matches the location where the\nshellx64.efi\nhas been copied in the\nesp\npartition. Also, note that the\nshellx64.efi\nEFI file can be moved elsewhere to avoid the automatic entry creation by\nsystemd-boot\n.\nReplace\nHD0b\nwith the previously noted\nFS alias\n.\nThe\n-nointerrupt\noption prevents interrupting the target EFI program with\nCtrl+c\n.\nThe\n-nomap -noversion\noptions hide the default UEFI shell greeting.\nTo have the UEFI shell automatically return to the boot manager if the target EFI program exits (e.g. due to an error), add the\n-exit\noption.\nYou can also add the\n-noconsoleout\noption if there is still unnecessary output in the UEFI shell.\nBooting into UEFI firmware setup\nsystemd-boot will automatically add an entry to boot into UEFI firmware setup if your device's firmware supports rebooting into setup from the OS.\nKernel parameters editor with password protection\nAlternatively you can install\nsystemd-boot-password\nAUR\nwhich supports\npassword\nbasic configuration option. Use\nsbpctl generate\nto generate a value for this option.\nInstall\nsystemd-boot-password\nwith the following command:\n# sbpctl install\nesp\nWith enabled editor you will be prompted for your password before you can edit kernel parameters.\nTips and tricks\nKeys inside the boot menu\nYou can use\nt\nand\nT\nwhile in the menu to adjust the menu timeout and\ne\nto edit the kernel parameters for this boot. Press\nh\nto see a short list of useful hotkeys. See\nsystemd-boot(7) § KEY BINDINGS\nfor the full list of available key bindings inside the boot menu.\nChoosing next boot\nThe boot manager is integrated with the systemctl command, allowing you to choose what option you want to boot after a reboot. For example, suppose you have built a custom kernel and created an entry file\nesp\n/loader/entries/arch-custom.conf\nto boot into it, you can just launch\n$ systemctl reboot --boot-loader-entry=arch-custom.conf\nand your system will reboot into that entry maintaining the default option intact for subsequent boots. To see a list of possible entries pass the\n--boot-loader-entry=help\noption.\nIf you want to boot into the firmware of your motherboard directly, then you can use this command:\n$ systemctl reboot --firmware-setup\nUnified kernel images\nUnified kernel images\n(UKIs) in\nesp\n/EFI/Linux/\nare automatically sourced by systemd-boot, and do not need an entry in\nesp\n/loader/entries\n. (Note that unified kernel images must have a\n.efi\nextension to be identified by\nsystemd-boot\n.)\nTip\nFiles in\nesp\n/loader/entries/\nwill be booted first if no\ndefault\nis set in\nesp\n/loader/loader.conf\n. Remove those entries, or set the default with the full file name, i.e.\ndefault arch-linux.efi\nGrml on ESP\nNote\nThe following instructions are not exclusive to Grml. With slight adjustments, installing other software (e.g.,\nSystemRescueCD\n) is possible.\nTip\nA\nPKGBUILD\nis available:\ngrml-systemd-boot\nAUR\n.\nGrml\nis a small live system with a collection of software for system administration and rescue.\nIn order to install Grml on the ESP, we only need to copy the kernel\nvmlinuz\n, the initramfs\ninitrd.img\n, and the squashed image\ngrml64-small.squashfs\nfrom the iso file to the ESP. To do so, first download\ngrml64-small.iso\nand mount the file (the mountpoint is henceforth denoted\nmnt\n); the kernel and initramfs are located in\nmnt\n/boot/grml64small/\n, and the squashed image resides in\nmnt\n/live/grml64-small/\n.\nNext, create a directory for Grml in your ESP,\n# mkdir -p\nesp\n/grml\nand copy the above-mentioned files in there:\n# cp\nmnt\n/boot/grml64small/vmlinuz\nesp\n/grml\n# cp\nmnt\n/boot/grml64small/initrd.img\nesp\n/grml\n# cp\nmnt\n/live/grml64-small/grml64-small.squashfs\nesp\n/grml\nIn the last step, create an boot entry for systemd-boot: In\nesp\n/loader/entries\ncreate a\ngrml.conf\nfile with the following content:\nesp\n/loader/entries/grml.conf\ntitle   Grml Live Linux\nlinux   /grml/vmlinuz\ninitrd  /grml/initrd.img\noptions apm=power-off boot=live live-media-path=/grml/ nomce net.ifnames=0\nFor an overview of the available boot options, consult the\ncheatcode for Grml\n.\nArchiso on ESP\nTip\nA\nPKGBUILD\nis available:\narchiso-systemd-boot\nAUR\n.\nAs with Grml it is possible to use the Arch Linux ISO. To do this we need to copy the kernel\nvmlinuz-linux\n, the initramfs\ninitramfs-linux.img\n, and the squashfs image\nairootfs.sfs\nfrom the ISO file to the EFI system partition.\nFirst download\narchlinux-YYYY.MM.DD-x86_64.iso\n.\nNext, create a directory for archiso in your ESP:\n# mkdir -p\nesp\n/EFI/archiso\nExtract the contents of the\narch\ndirectory in there:\n# bsdtar -v -x --no-same-permissions --strip-components 1 -f archlinux-\nYYYY\n.\nMM\n.\nDD\n-x86_64.iso -C\nesp\n/EFI/archiso arch\nIn the last step, create a boot entry for the systemd-boot: In\nesp\n/loader/entries\ncreate a\narch-rescue.conf\nfile with the following content:\nesp\n/loader/entries/arch-rescue.conf\ntitle   Arch Linux (rescue system)\nlinux   /EFI/archiso/boot/x86_64/vmlinuz-linux\ninitrd  /EFI/archiso/boot/x86_64/initramfs-linux.img\noptions archisobasedir=/EFI/archiso archisosearchfilename=/EFI/archiso/boot/x86_64/vmlinuz-linux\nFor an overview of the available boot options, consult the\nREADME.bootparams for mkinitcpio-archiso\n.\nRecovery Arch image on the ESP with Secure Boot\nThe official Arch ISO does not currently support\nSecure Boot\n. As a result, Secure Boot must be disabled to boot into the ISO for recovery or maintenance. This undermines system security and is not an ideal approach.\nAn alternative is to create a signed\nunified kernel image\n(UKI) using\nmkosi\n, assuming Secure Boot is already configured and functioning properly on your system. This allows you to boot into a signed recovery Arch environment without disabling Secure Boot or carrying an Arch ISO USB drive wherever your laptop goes.\nhttps://swsnr.de/archlinux-rescue-image-with-mkosi/\ndescribes how to set up Secure Boot-compatible Arch recovery images. A practical starting point with a sane mkosi configuration you can add your packages to is available at\nhttps://codeberg.org/swsnr/rescue-image\n.\nsystemd-boot on BIOS systems\nIf you need a boot loader for BIOS systems that follows\nThe Boot Loader Specification\n, then systemd-boot can be pressed into service on BIOS systems. The\nClover\nboot loader supports booting from BIOS systems and provides a emulated UEFI environment.\nTroubleshooting\nsystemd-boot does not display my boot entry\nThis may be caused by a variety of issues with the configuration file, such as the path to the kernel being specified incorrectly. To check, run:\n# bootctl\nInstalling after booting in BIOS mode\nNote\nThis is not recommended.\nIf booted in BIOS mode, you can still install\nsystemd-boot\n, however this process requires you to tell firmware to launch\nsystemd-boot'\ns EFI file at boot:\nyou have a working UEFI Shell somewhere else.\nyour firmware interface provides a way of properly setting the EFI file that needs to be loaded at boot time.\nsome firmware may use the default\nesp\n/EFI/BOOT/BOOTX64.EFI\nif there is no other entry set in the UEFI.\nIf you can do it, the installation is easier: go into your UEFI Shell or your firmware configuration interface and change your machine's default EFI file to\nesp\n/EFI/systemd/systemd-bootx64.efi\n.\nNote\nThe firmware interface of Dell Latitude series provides everything you need to setup UEFI boot but the UEFI Shell will not be able to write to the computer's ROM.\nManual entry using efibootmgr\nIf the\nbootctl install\ncommand failed, you can create a UEFI boot entry manually using\nefibootmgr\n:\n# efibootmgr --create --disk /dev/sd\nX\n--part\nY\n--loader '\\EFI\\systemd\\systemd-bootx64.efi' --label \"Linux Boot Manager\" --unicode\nwhere\n/dev/sd\nXY\nis the\nEFI system partition\n.\nNote\nThe path to the EFI binary must use the backslash (\n\\\n) as the separator\nManual entry using bcdedit from Windows\nIf for any reason you need to create a UEFI boot entry from Windows, you can use the following commands from an Administrator prompt:\n> bcdedit /copy \"{bootmgr}\" /d \"Linux Boot Manager\"\n> bcdedit /set \"{\nguid\n}\" path \\EFI\\systemd\\systemd-bootx64.efi\nReplace\nguid\nwith the id returned by the first command. You can also set it as the default entry using\n> bcdedit /default \"{\nguid\n}\"\nMenu does not appear after Windows upgrade\nSee\nUEFI#Windows changes boot order\n.\nAdd support for Windows BitLocker TPM unlocking\nTo stop BitLocker from requesting the recovery key, add the following to\nloader.conf\n:\nesp\n/loader/loader.conf\nreboot-for-bitlocker yes\nThis will set the\nBootNext\nUEFI variable, whereby\nWindows Boot Manager\nis loaded without BitLocker requiring the recovery key. This is a one-time change, and\nsystemd-boot\nremains the default boot loader. There is no need to specify Windows as an entry if it was autodetected.\nThis is an experimental feature, so make sure to consult\nloader.conf(5)\n.\nSee also\nhttps://systemd.io/BOOT/\nhttps://bbs.archlinux.org/viewtopic.php?id=254374\nhttps://uapi-group.org/specifications/specs/boot_loader_specification/\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Systemd-boot&oldid=848097\n\"\nCategory\n:\nBoot loaders\nHidden category:\nPages or sections flagged with Template:Move\nSearch\nSearch\nsystemd-boot\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Systemd-boot"}}
{"text": "File systems - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nFile systems\n8 languages\nEspañol\nMagyar\nItaliano\n日本語\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\nPartitioning\nDevice file#lsblk\nFile permissions and attributes\nfsck\nfstab\nList of applications/Utilities#Mount tools\nQEMU#Mounting a partition from a raw image\nudev\nudisks\numask\nUSB storage devices\nFrom\nWikipedia\n:\nIn computing, a file system or filesystem controls how data is stored and retrieved. Without a file system, information placed in a storage medium would be one large body of data with no way to tell where one piece of information stops and the next begins. By separating the data into pieces and giving each piece a name, the information is easily isolated and identified. Taking its name from the way paper-based information systems are named, each group of data is called a \"file\". The structure and logic rules used to manage the groups of information and their names is called a \"file system\".\nIndividual drive partitions can be set up using one of the many different available file systems. Each has its own advantages, disadvantages, and unique idiosyncrasies. A brief overview of supported file systems follows; the links are to Wikipedia pages that provide much more information.\nTypes of file systems\nSee\nfilesystems(5)\nfor a general overview and\nWikipedia:Comparison of file systems\nfor a detailed feature comparison. File systems already loaded by the kernel or built-in are listed in\n/proc/filesystems\n, while all the installed modules can be seen with\nls /lib/modules/$(uname -r)/kernel/fs\n.\nIn-tree and FUSE file systems\nFile system\nCreation command\nUserspace utilities\nArchiso\n[1]\nKernel documentation\n[2]\nNotes\nBcachefs\nbcachefs(8)\nbcachefs-tools\nYes\n[3]\n[\ndead link\n2025-11-16—HTTP 404]\nAvailable in Linux 6.7+, experimental\nBtrfs\nmkfs.btrfs(8)\nbtrfs-progs\nYes\nbtrfs.html\nStability status\nVFAT\nmkfs.fat(8)\ndosfstools\nYes\nvfat.html\nWindows 9x\nfile system. Commonly used for USB flash drives and SD cards.\nexFAT\nmkfs.exfat(8)\nexfatprogs\nYes\nNative file system in Linux 5.4.\n[4]\nCommonly used for USB flash drives and SD cards.\nmkexfatfs(8)\nexfat-utils\nNo\nN/A (FUSE-based)\nF2FS\nmkfs.f2fs(8)\nf2fs-tools\nYes\nf2fs.html\nFlash-based devices. Cannot be shrunk.\next3\nmkfs.ext3(8)\ne2fsprogs\nYes\next3.html\next4\nmkfs.ext4(8)\ne2fsprogs\nYes\next4.html\nHFS\nmkfs.hfsplus(8)\nhfsprogs\nAUR\nNo\nhfs.html\nClassic Mac OS\nfile system\nHFS+\nmkfs.hfsplus(8)\nhfsprogs\nAUR\nNo\nhfsplus.html\nmacOS\n(8–10.12) file system\nJFS\nmkfs.jfs(8)\njfsutils\nYes\njfs.html\nJFFS2\nmkfs.jffs2(1)\nmtd-utils\nNo\nNILFS2\nmkfs.nilfs2(8)\nnilfs-utils\nYes\nnilfs2.html\nMostly intended for flash based devices. Does not support\nxattrs\nand\nACLs\n.\nNTFS\nYes\nntfs3.html\nWindows NT\nfile system.\nNew driver\n, available since Linux 5.15.\nmkfs.ntfs(8)\nntfs-3g\nYes\nN/A (FUSE-based)\nFUSE driver with extended capabilities.\nReiserFS\nmkfs.reiserfs(8)\nreiserfsprogs\nAUR\nNo\nDeprecated since Linux 5.18\nand\nremoved in Linux 6.13\n.\nUDF\nmkfs.udf(8)\nudftools\nYes\nudf.html\nISO/IEC 13346 file system for disc images and DVDs/Blu-rays.\nXFS\nmkfs.xfs(8)\nxfsprogs\nYes\nxfs.html\nxfs-delayed-logging-design.html\nxfs-self-describing-metadata.html\nCannot be shrunk\nOut-of-tree file systems\nFile system\nCreation command\nKernel patchset\nUserspace utilities\nNotes\nAPFS\nmkapfs(8)\nlinux-apfs-rw-dkms\napfsprogs\nmacOS\n(10.13 and newer) file system. Read-only, experimental write support. See also\napfs-fuse-git\nAUR\nFUSE version.\nReiser4\nmkfs.reiser4(8)\nreiser4progs\nAUR\nZFS\nzfs-linux\nAUR\n,\nzfs-dkms\nAUR\nzfs-utils\nAUR\nOpenZFS\nport\nJournaling\nThe ext3/4, HFS+, JFS, NTFS, ReiserFS, and XFS file systems use\njournaling\n. Journaling provides fault-resilience by logging changes before they are committed to the file system. In the event of a system crash or power failure, such file systems are faster to bring back online and less likely to become corrupted. The logging takes place in a dedicated area of the file system.\next3/4 offer data-mode journaling, which can optionally log data in addition to the metadata. Data-mode journaling comes with a speed penalty, because it does two write operations: first to the journal and then to the disk. Therefore, data-mode journaling is not enabled by default. The trade-off between system speed and data safety should be considered when choosing the file system type and features.\nIn the same vein, Reiser4 offers configurable\n\"transaction models\"\n: a special model called\nwandering logs\n, which eliminates the need to write to the disk twice;\nwrite-anywhere\n, a pure copy-on-write approach; and a combined approach called\nhybrid\nwhich heuristically alternates between the two.\nFile systems based on copy-on-write (also known as write-anywhere), such as Reiser4, Btrfs, Bcachefs and ZFS, by design operate on full atomicity and also provide checksums for both metadata and inline data (operations entirely occur, or they entirely do not, and in properly functioning hardware data does not corrupt due to operations half-occurring). Therefore, these file systems are by design much less prone to data loss than other file systems and have no need to use traditional journal to protect metadata, because they are never updated in-place. Although Btrfs still has a journal-like log tree, it is only used to speed-up fdatasync/fsync.\nFAT, exFAT, ext2, and HFS provide neither journaling nor atomicity, They are for temporary or legacy use and not recommended for use when reliable storage is needed.\nFUSE-based file systems\nSee\nFUSE\n.\nStackable file systems\neCryptfs\n— The enterprise cryptographic file system is a package of disk encryption software for Linux. It is implemented as a POSIX-compliant file system–level encryption layer, aiming to offer functionality similar to that of GnuPG at the operating system level.\nhttps://ecryptfs.org\n||\necryptfs-utils\nmergerfs\n— a FUSE based union file system.\nhttps://github.com/trapexit/mergerfs\n||\nmergerfs\nAUR\nmhddfs\n— Multi-HDD FUSE file system, a FUSE based union file system.\nhttp://mhddfs.uvw.ru\n||\nmhddfs\nAUR\noverlayfs\n— OverlayFS is a file system service for Linux which implements a union mount for other file systems.\nhttps://docs.kernel.org/filesystems/overlayfs.html\n||\nlinux\nunionfs-fuse\n— A user space Unionfs implementation.\nhttps://github.com/rpodgorny/unionfs-fuse\n||\nunionfs-fuse\nAUR\nRead-only file systems\nDwarFS\n— DwarFS is a fast high compression read-only file system for Linux and Windows. DwarFS more or less supports the same features as SquashFS, but is able to compress better, and has configurable hash algorithm.\nhttps://github.com/mhx/dwarfs\n||\ndwarfs\nAUR\nEROFS\n— Enhanced Read-Only File System is a lightweight read-only file system, it aims to improve performance and compress storage capacity.\nhttps://erofs.docs.kernel.org/\n||\nerofs-utils\nSquashFS\n— SquashFS is a compressed read-only file system. SquashFS compresses files, inodes and directories, and supports block sizes up to 1 MiB for greater compression.\nhttps://github.com/plougher/squashfs-tools\n||\nsquashfs-tools\nClustered file systems\nBeeGFS\n— A parallel file system, developed and optimized for high-performance computing.\nhttps://www.beegfs.io/c/\n||\nbeegfs-client\nAUR\nCeph\n— Unified, distributed storage system designed for excellent performance, reliability and scalability.\nhttps://ceph.com/\n||\nceph\nAUR\nGlusterfs\n— Cluster file system capable of scaling to several peta-bytes.\nhttps://www.gluster.org/\n||\nglusterfs\nIPFS\n— A peer-to-peer hypermedia protocol to make the web faster, safer, and more open. IPFS aims replace HTTP and build a better web for all of us. Uses blocks to store parts of a file, each network node stores only content it is interested, provides deduplication, distribution, scalable system limited only by users. (currently in alpha)\nhttps://ipfs.io/\n||\nkubo\nMinIO\n— MinIO offers high-performance, S3 compatible object storage.\nhttps://min.io\n||\nminio\nMooseFS\n— MooseFS is a fault tolerant, highly available and high performance scale-out network distributed file system.\nhttps://moosefs.com\n||\nmoosefs\nOpenAFS\n— Open source implementation of the AFS distributed file system\nhttps://www.openafs.org\n||\nopenafs\nAUR\nOrangeFS\n— OrangeFS is a scale-out network file system designed for transparently accessing multi-server-based disk storage, in parallel. Has optimized MPI-IO support for parallel and distributed applications. Simplifies the use of parallel storage not only for Linux clients, but also for Windows, Hadoop, and WebDAV. POSIX-compatible. Part of Linux kernel since version 4.6.\nhttps://www.orangefs.org/\n||\nnot packaged?\nsearch in AUR\nSheepdog\n— Distributed object storage system for volume and container services and manages the disks and nodes intelligently.\nhttps://sheepdog.github.io/sheepdog/\n||\nsheepdog\nAUR\nShared-disk file system\nGFS2\n— GFS2 allows all members of a cluster to have direct concurrent access to the same shared block storage\nhttps://pagure.io/gfs2-utils\n||\ngfs2-utils\nAUR\nOCFS2\n— The Oracle Cluster File System (version 2) is a shared disk file system developed by Oracle Corporation and released under the GNU General Public License\nhttps://oss.oracle.com/projects/ocfs2/\n||\nocfs2-tools\nAUR\nVMware VMFS\n— VMware's VMFS (Virtual Machine File System) is used by the company's flagship server virtualization suite, vSphere.\nhttps://core.vmware.com/resource/vmware-vsphere-vmfs\n||\nvmfs-tools\nAUR\nIdentify existing file systems\nTo identify existing file systems, you can use\nlsblk\n:\n$ lsblk -f\nNAME   FSTYPE LABEL     UUID                                 MOUNTPOINT\nsdb\n└─sdb1 vfat   Transcend 4A3C-A9E9\nAn existing file system, if present, will be shown in the\nFSTYPE\ncolumn. If\nmounted\n, it will appear in the\nMOUNTPOINT\ncolumn.\nCreate a file system\nFile systems are usually created on a\npartition\n, inside logical containers such as\nLVM\n,\nRAID\nand\ndm-crypt\n, or on a regular file (see\nWikipedia:Loop device\n). This section describes the partition case.\nNote\nFile systems can be written directly to a disk, known as a\nsuperfloppy\nor\npartitionless disk\n. Certain limitations are involved with this method, particularly if\nbooting\nfrom such a drive. See\nBtrfs#Partitionless Btrfs disk\nfor an example.\nWarning\nAfter creating a new file system, data previously stored on this partition can unlikely be recovered.\nCreate a backup of any data you want to keep\n.\nThe purpose of a given partition may restrict the choice of file system. For example, an\nEFI system partition\nmust contain a\nFAT32\nfile system, and the file system containing the\n/boot\ndirectory must be supported by the\nboot loader\n.\nBefore continuing,\nidentify the device\nwhere the file system will be created and whether or not it is mounted. For example:\n$ lsblk -f\nNAME   FSTYPE   LABEL       UUID                                 MOUNTPOINT\nsda\n├─sda1                      C4DA-2C4D\n├─sda2 ext4                 5b1564b2-2e2c-452c-bcfa-d1f572ae99f2 /mnt\n└─sda3                      56adc99b-a61e-46af-aab7-a6d07e504652\nMounted file systems\nmust\nbe\nunmounted\nbefore proceeding. In the above example an existing file system is on\n/dev/sda2\nand is mounted at\n/mnt\n. It would be unmounted with:\n# umount /dev/sda2\nTo find just mounted file systems, see\n#List mounted file systems\n.\nTo create a new file system, use\nmkfs(8)\n. See\n#Types of file systems\nfor the exact type, as well as userspace utilities you may wish to install for a particular file system.\nFor example, to create a new file system of type\next4\n(common for Linux data partitions) on\n/dev/sda1\n, run:\n# mkfs.ext4 /dev/sda1\nTip\nUse the\n-L\nflag of\nmkfs.ext4\nto specify a\nfile system label\n.\ne2label\ncan be used to change the label on an existing file system.\nFile systems may be\nresized\nafter creation, with certain limitations. For example, an\nXFS\nfile system's size can be increased, but not reduced. See\nWikipedia:Comparison of file systems#Resize capabilities\nand the respective file system documentation for details.\nThe new file system can now be mounted to a directory of choice.\nMount a file system\nTo manually mount a file system located on a device (e.g., a partition) to a directory, use\nmount(8)\n. This example mounts\n/dev/sda1\nto\n/mnt\n.\n# mount /dev/sda1 /mnt\nThis attaches the file system on\n/dev/sda1\nat the directory\n/mnt\n, making the contents of the file system visible. Any data that existed at\n/mnt\nbefore this action is made invisible until the device is unmounted.\nfstab\ncontains information on how devices should be automatically mounted if present. See the\nfstab\narticle for more information on how to modify this behavior.\nIf a device is specified in\n/etc/fstab\nand only the device or mount point is given on the command line, that information will be used in mounting. For example, if\n/etc/fstab\ncontains a line indicating that\n/dev/sda1\nshould be mounted to\n/mnt\n, then the following will automatically mount the device to that location:\n# mount /dev/sda1\nOr\n# mount /mnt\nmount\ncontains several options, many of which depend on the file system specified.\nThe options can be changed, either by:\nusing flags on the command line with\nmount\nediting\nfstab\ncreating\nudev\nrules\ncompiling the kernel yourself\nor using file system–specific mount scripts (located at\n/usr/bin/mount.*\n).\nSee these related articles and the article of the file system of interest for more information.\nTip\nFile systems can also be mounted with\nsystemd-mount\ninstead of\nmount\n. If the mount point is not specified, the file system will be mounted at\n/run/media/system/\ndevice_identifier\n/\n. This allows to easily mount a file system without having to decide where to mount it. See\nsystemd-mount(1)\nfor usage and more details.\nTo mount file systems as an ordinary user, see\nudisks#Usage\n. This also allows mounting without having root permissions, a full graphical environment or a file manager which utilizes udisks.\nList mounted file systems\nTo list all mounted file systems, use\nfindmnt(8)\n:\n$ findmnt\nfindmnt\ntakes a variety of arguments which can filter the output and show additional information. For example, it can take a device or mount point as an argument to show only information on what is specified:\n$ findmnt /dev/sda1\nfindmnt\ngathers information from\n/etc/fstab\n,\n/etc/mtab\n, and\n/proc/self/mounts\n.\nUnmount a file system\nTo unmount a file system use\numount(8)\n. Either the device containing the file system (e.g.,\n/dev/sda1\n) or the mount point (e.g.,\n/mnt\n) can be specified:\n# umount /dev/sda1\nor\n# umount /mnt\nTroubleshooting\n\"linux Structure needs cleaning\"\nUnmount\nthe file system and run\nfsck\non the problematic volume.\nSee also\nfilesystems(5)\nsystemd-mount(1)\nDocumentation of file systems supported by Linux\nWikipedia:File systems\nWikipedia:Mount (Unix)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=File_systems&oldid=853045\n\"\nCategories\n:\nFile systems\nLists\nHidden categories:\nPages with dead links\nPages with missing package links\nSearch\nSearch\nFile systems\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/File_systems"}}
{"text": "fstab - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nfstab\n9 languages\nDeutsch\nEspañol\nFrançais\nMagyar\nItaliano\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nPersistent block device naming\nFile systems\ntmpfs\nswap\ngenfstab\nThe\nfstab(5)\nfile can be used to define how disk partitions, various other block devices, or remote file systems should be mounted into the file system.\nEach file system is described in a separate line. These definitions will be converted into\nsystemd\nmount units dynamically at boot, and when the configuration of the system manager is reloaded. The default setup will automatically\nfsck\nand mount file systems before starting services that need them to be mounted. For example, systemd automatically makes sure that remote file system mounts like\nNFS\nor\nSamba\nare only started after the network has been set up. Therefore, local and remote file system mounts specified in\n/etc/fstab\nshould work out-of-the-box. See\nsystemd.mount(5)\nfor details.\nThe\nmount\ncommand will use fstab, if just one of either directory or device is given, to fill in the value for the other parameter. When doing so, mount options which are listed in fstab will also be used.\nThis article or section needs expansion.\nReason:\nExplain what\nsystemd-remount-fs.service(8)\ndoes and suggest using\nrootflags\nfor mount options that cannot be applied by remounting. (Discuss in\nTalk:Fstab\n)\nUsage\nA simple\n/etc/fstab\n, using file system UUIDs:\n/etc/fstab\n# <device>                                <dir> <type> <options>                                        <dump> <fsck>\nUUID=0a3407de-014b-458b-b5c1-848e92a327a3 /     ext4 defaults                                           0      1\nUUID=CBB6-24F2                            /boot vfat defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\nUUID=f9fe0b69-a280-415d-a03a-a32752370dee none  swap defaults                                           0      0\nUUID=b411dc99-f0a0-4c87-9e05-184977be8539 /home ext4 defaults                                           0      2\n<device>\ndescribes the block special device or remote file system to be mounted; see\n#Identifying file systems\n.\n<dir>\nis the directory where the file system will be\nmounted\nto, a.k.a. the mountpoint. The directory must be created beforehand.\n<type>\nis the\nfile system\ntype.\n<options>\nare the file system mount options; see\nmount(8) § FILESYSTEM-INDEPENDENT MOUNT OPTIONS\nand\next4(5) § Mount options for ext4\n.\n<dump>\nis checked by the\ndump(8)\nutility. This field is usually set to\n0\n, which disables the check.\n<fsck>\nsets the order for file system checks at boot time; see\nfsck(8)\n. For the root device it should be\n1\n. For other partitions it should be\n2\n, or\n0\nto disable checking.\nTip\nThe\nauto\ntype lets the mount command guess what type of file system is used. This is useful for\noptical media\n(CD/DVD/Blu-ray).\nIf the root file system is\nbtrfs\nor\nXFS\n, the fsck order should be set to\n0\ninstead of\n1\n. See\nfsck.btrfs(8)\nand\nfsck.xfs(8)\n.\nAll specified devices within\n/etc/fstab\nwill be automatically mounted on startup and when the\n-a\nflag is used with\nmount(8)\nunless the\nnoauto\noption is specified. Devices that are listed and not present will result in an error unless the\nnofail\noption is used.\nSee\nfstab(5) § DESCRIPTION\nfor details.\nIdentifying file systems\nThis article or section needs expansion.\nReason:\nThere are more device paths than just kernel name descriptors.\n/dev/disk/by-*/*\n,\n/dev/mapper/*\n,\n/dev/md/*\nhave various levels of persistence and there should be no issue using them. (Discuss in\nTalk:Fstab\n)\nThere are different ways to identify file systems that will be mounted in\n/etc/fstab\n: kernel name descriptor, file system label and UUID, and GPT partition label and UUID for GPT disks. Kernel name descriptors should not be used, while UUIDs or PARTUUIDs should be preferred over labels. See\nPersistent block device naming\nfor more explanations. It is recommended to read that article first before continuing with this article.\nIn this section, we will describe how to mount file systems using all the mount methods available via examples. The output of the commands\nlsblk -f\nand\nblkid\nused in the following examples are available in the article\nPersistent block device naming\n.\nKernel name descriptors\nRun\nlsblk -f\nto list the partitions and prefix the values in the\nNAME\ncolumn with\n/dev/\n.\n/etc/fstab\n# <device <dir> <type> <options>                                          <dump> <fsck>\n/dev/sda2 /     ext4   defaults                                           0      1\n/dev/sda1 /boot vfat   defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\n/dev/sda3 /home ext4   defaults                                           0      2\n/dev/sda4 none  swap   defaults                                           0      0\nWarning\nKernel name descriptors for block devices\nare not\npersistent\nand can change each boot, they should not be used in configuration files (including\n/etc/fstab\n).\nFile system labels\nRun\nlsblk -f\nto list the partitions, and prefix the values in the\nLABEL\ncolumn with\nLABEL=\nor alternatively run\nblkid\nand use the LABEL values without the quotes:\n/etc/fstab\n# <device>   <dir> <type> <options>                                          <dump> <fsck>\nLABEL=System /     ext4   defaults                                           0      1\nLABEL=ESP    /boot vfat   defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\nLABEL=Data   /home ext4   defaults                                           0      2\nLABEL=Swap   none  swap   defaults                                           0      0\nNote\nIf any of your fields contains spaces, see\n#Filepath spaces\n.\nFile system UUIDs\nRun\nlsblk -f\nto list the partitions, and prefix the values in the\nUUID\ncolumn with\nUUID=\nor alternatively run\nblkid\nand use the UUID values without the quotes:\n/etc/fstab\n# <device>                                <dir> <type> <options>                                        <dump> <fsck>\nUUID=0a3407de-014b-458b-b5c1-848e92a327a3 /     ext4 defaults                                           0      1\nUUID=CBB6-24F2                            /boot vfat defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\nUUID=b411dc99-f0a0-4c87-9e05-184977be8539 /home ext4 defaults                                           0      2\nUUID=f9fe0b69-a280-415d-a03a-a32752370dee none  swap defaults                                           0      0\nGPT partition labels\nRun\nblkid\nto list the partitions, and use the\nPARTLABEL\nvalues without the quotes:\n/etc/fstab\n# <device>                           <dir> <type> <options>                                        <dump> <fsck>\nPARTLABEL=GNU/Linux                  /     ext4 defaults                                           0      1\nPARTLABEL=EFI\\040system\\040partition /boot vfat defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\nPARTLABEL=Home                       /home ext4 defaults                                           0      2\nPARTLABEL=Swap                       none  swap defaults                                           0      0\nNote\nIf any of your fields contains spaces, see\n#Filepath spaces\n.\nGPT partition UUIDs\nRun\nblkid\nto list the partitions, and use the\nPARTUUID\nvalues without the quotes:\n/etc/fstab\n# <device>                                    <dir> <type> <options>                                        <dump> <fsck>\nPARTUUID=98a81274-10f7-40db-872a-03df048df366 /     ext4 defaults                                           0      1\nPARTUUID=d0d0d110-0a71-4ed6-936a-304969ea36af /boot vfat defaults,nodev,nosuid,noexec,fmask=0177,dmask=0077 0      2\nPARTUUID=7280201c-fc5d-40f2-a9b2-466611d3d49e /home ext4 defaults                                           0      2\nPARTUUID=039b6c1c-7553-4455-9537-1befbc9fbc5b none  swap defaults                                           0      0\nTips and tricks\nAutomount with systemd\nSee\nsystemd.mount(5)\nfor all systemd mount options.\nLocal partition\nIn case of a large partition, it may be more efficient to allow services that do not depend on it to start while it is checked by\nfsck\n. This can be achieved by adding the following options to the\n/etc/fstab\nentry of the partition:\nx-systemd.automount\nThis will fsck and mount the partition only when it is first accessed, and the kernel will buffer all file access to it until it is ready.\nThis method can be relevant if one has, for example, a significantly large\n/home\npartition.\nNote\nThis will make the file system type\nautofs\nwhich is ignored by\nlocate\nby default.\nRemote file system\nThe same applies to remote file system mounts. If you want them to be mounted only upon access, you will need to use the\nx-systemd.automount\nparameters. In addition, you can use the\nx-systemd.mount-timeout=\noption to specify how long systemd should wait for the mount command to finish. Also, the\n_netdev\noption ensures systemd understands that the mount is network dependent and order it after the network is online.\nx-systemd.automount,x-systemd.mount-timeout=30,_netdev\nEncrypted file system\nIf you have secondary encrypted file systems with keyfiles, you can also add the\nnofail\nparameter to the corresponding entries in\n/etc/crypttab\nand\n/etc/fstab\n.\nsystemd\nwill not wait for the cryptsetup service to finish unlocking and mounting the filesystem on boot, but instead may finish mounting this after reaching default.target. This will avoid any boot delay caused by unlocking secondary partitions that are not required immediately after boot. See\ndm-crypt/System configuration#Non blocking mounting\nfor cryptsetup configuration\nSince mount services will by default only wait for 90 seconds for the partition to be available, any delay in making the keyfile available may cause the mount to fail. To avoid this, add the option\nx-systemd.mount-timeout=0\nto fstab in order to make sure that the mount service waits indefinitely for the partition to be unlocked.\n/etc/fstab\nUUID=0a3407de-014b-458b-b5c1-848e92a327a3 /data ext4 defaults,nofail,x-systemd.device-timeout=0    0 2\nAutomatic unmount\nYou may also specify an idle timeout for a mount with the\nx-systemd.idle-timeout\nflag.  For example:\nx-systemd.automount,x-systemd.idle-timeout=1min\nThis will make systemd unmount the mount after it has been idle for 1 minute.\nExternal devices\nThe factual accuracy of this article or section is disputed.\nReason:\nthe nofail option does not work as described here. (Discuss in\nTalk:Fstab#3.2 External Device options\n)\nExternal devices that are to be mounted when present but ignored if absent may require the\nnofail\noption. This prevents errors being reported at boot. For example:\n/etc/fstab\nLABEL=MyExternalDrive /media/backup    jfs    nofail,x-systemd.device-timeout=5    0  2\nThe\nnofail\noption is best combined with the\nx-systemd.device-timeout\noption. This is because the default device timeout is 90 seconds, so a disconnected external device with only\nnofail\nwill make your boot take 90 seconds longer, unless you reconfigure the timeout as shown. Make sure not to set the timeout to 0, as this translates to infinite timeout.\nFilepath spaces\nSince spaces are used in\nfstab\nto delimit fields, if any field (\nPARTLABEL\n,\nLABEL\nor the mount point) contains spaces, these spaces must be replaced by escape characters\n\\\nfollowed by the 3 digit octal code\n040\n:\n/etc/fstab\nUUID=47FA-4071         /home/username/Camera\n\\040\nPictures   vfat  defaults      0  0\nLABEL=Storage\n\\040\ndrive /media/100\n\\040\nGB\n\\040\n(Storage)       ext4  defaults,user 0  2\natime options\nBelow atime options can impact drive performance.\nThe\nstrictatime\noption updates the access time of the files every time they are accessed. This is more purposeful when Linux is used for servers; it does not have much value for desktop use. The drawback about the\nstrictatime\noption is that even reading a file from the page cache (reading from memory instead of the drive) will still result in a write.\nThe\nnoatime\noption fully disables writing file access times to the drive every time you read a file. This works well for almost all applications, except for those that need to know if a file has been read since the last time it was modified. The write time information to a file will continue to be updated anytime the file is written to with this option enabled.\nThe\nnodiratime\noption disables the writing of file access times only for directories while other files still get access times written.\nNote\nnoatime\nimplies\nnodiratime\n.\nYou do not need to specify both\n.\nrelatime\nupdates the access time only if the previous access time was earlier than the current modify or change time. In addition, since Linux 2.6.30, the access time is always updated if the previous access time was more than 24 hours old. This option is used when the\ndefaults\noption,\natime\noption (which means to use the kernel default, which is\nrelatime\n; see\nmount(8)\nand\nOnce upon atime\n) or no options at all are specified.\nWhen using\nMutt\nor other applications that need to know if a file has been read since the last time it was modified, the\nnoatime\noption should not be used; using the\nrelatime\noption is acceptable and still provides a performance improvement.\nSince kernel 4.0 there is another related option:\nlazytime\nreduces writes to disk by maintaining changes to inode timestamps (access, modification and creation times) only in memory. The on-disk timestamps are updated only when either (1) the file inode needs to be updated for some change unrelated to file timestamps, (2) a sync to disk occurs, (3) an undeleted inode is evicted from memory or (4) if more than 24 hours passed since the last time the in-memory copy was written to disk.\nWarning\nIn the event of a system crash, the access and modification times on disk might be out of date by up to 24 hours.\nNote that the\nlazytime\noption works\nin combination\nwith the aforementioned\n*atime\noptions, not as an alternative. That is\nrelatime\nby default, but can be even\nstrictatime\nwith the same or less cost of disk writes as the plain\nrelatime\noption.\nRemounting the root partition\nIf for some reason the root partition has been improperly mounted read only, remount the root partition with read-write access with the following command:\n# mount -o remount,rw /\nGPT partition automounting\nWhen using UEFI/GPT, it is possible to omit certain partitions from\n/etc/fstab\nby partitioning according to the\nDiscoverable Partitions Specification\nand have\nsystemd-gpt-auto-generator(8)\nmount the partitions. See\nsystemd#GPT partition automounting\n.\nTo specify custom mount options for these volumes, use a\nby-designator identifier\nas the device name:\n/etc/fstab\n/dev/disk/by-designator/root  /     ext4  defaults,noatime  0 1\n/dev/disk/by-designator/swap  none  swap  defaults,discard  0 0\nBind mount\nYou can link directories with the\nbind\noption:\n/etc/fstab\n# <device>                             <dir>                         <type> <options>     <dump> <fsck>\nUUID=94649E22649E06E0                  /media/user/OS/               ntfs    defaults,rw,errors=remount-ro  0  0\n/media/user/OS/Users/user/Music/       /home/user/Music/             none    defaults,bind 0   0\n/media/user/OS/Users/user/Pictures/    /home/user/Pictures/          none    defaults,bind 0   0\n/media/user/OS/Users/user/Videos/      /home/user/Videos/            none    defaults,bind 0   0\n/media/user/OS/Users/user/Downloads/   /home/user/Downloads/         none    defaults,bind 0   0\n/media/user/OS/Users/user/Documents/   /home/user/Documents/         none    defaults,bind 0   0\n/media/user/OS/Users/user/projects/    /home/user/projects/windows/  none    defaults,bind 0   0\nSee\nmount(8) § Bind mount operation\nfor details.\nAutomatically generate an fstab using genfstab\nYou can use the\ngenfstab\ntool to create an fstab file. See\ngenfstab\nfor details.\nGUI utilities\nHere is a list of programs that can be used to modify mount points. They might not have all the features possible for editing fstab, but have all of the most used ones and might make your workflow much easier:\nGNOME Disks\n— A GNOME utility for dealing with storage devices. Part of\ngnome\n.\nhttps://apps.gnome.org/DiskUtility/\n||\ngnome-disk-utility\nKDE Partition Manager\n— Utility to help you manage the disks, partitions, and file systems on your computer. Part of\nkde-system\n.\nhttps://apps.kde.org/partitionmanager/\n||\npartitionmanager\nModifying user permissions and ownership\nIf you want to allow any user to mount the drive, consider adding these mount options to add onto your fstab entries.\nNote\nThis is also used for filesystems that do not have file permission abilities, which will also set the owner and permissions of the entire drive to the user who mounted it.\nusers\n- Allow any user to mount and to unmount the filesystem, even when some other ordinary user mounted it. This option implies the options noexec, nosuid, and nodev (unless overridden by subsequent options, as in the option line users,exec,dev,suid). Simply add\nusers\nto the mount options to enable this.\nuser\n- Allow an ordinary user to mount the filesystem. Only allows the same user to unmount. This option implies the options noexec, nosuid, and nodev (unless overridden by subsequent options, as in the option line user,exec,dev,suid). Simply add\nuser\nto the mount options to enable this.\nFor filesystems that do not have file permissions built in such as FAT and exFAT, you can explicitly set the user or group for the entire drive and its files. You can view the ID of a specific user in\n/etc/passwd\n. The uid is the third number in the entry, and the group id is the fourth.\nuid\n- Set the owner ID of the drive\ngid\n- Set the group ID of the drive\nFor ext4, btrfs, and other filesystems that have permission abilities, other users might not be permitted to see the drive. Be sure to double check the permissions of\n/path/to/drive/\nand modify them for what you need.\nVerify changes\nUse\nfindmnt --verify --verbose\nto check for syntax errors and invalid options in fstab.\nSee also\nFull device listing including block device\nFilesystem Hierarchy Standard\n30x Faster Cache and Site Speed with TMPFS\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Fstab&oldid=847192\n\"\nCategories\n:\nFile systems\nBoot process\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nfstab\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Fstab"}}
{"text": "RAID - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nRAID\n5 languages\nEspañol\nMagyar\n日本語\nPortuguês\n中文（简体）\nFrom ArchWiki\nRelated articles\nLVM on software RAID\nLVM#RAID\nInstall Arch Linux with Fake RAID\nConvert a single drive system to RAID\nZFS\nZFS/Virtual disks\nSwap#Striping\nBtrfs#RAID\nR\nedundant\nA\nrray of\nI\nndependent\nD\nisks (\nRAID\n) is a storage technology that combines multiple disk drive components—typically disk drives or partitions thereof—into a logical unit. Depending on the RAID implementation, this logical unit can be a file system or an additional transparent layer that can hold several partitions.\nData is distributed across the drives in one of several ways called\n#RAID levels\n, depending on the level of redundancy and performance required. The RAID level chosen can thus prevent data loss in the event of a hard disk failure, increase performance or be a combination of both.\nThis article explains how to create and manage a software RAID array using\nmdadm(8)\n.\nWarning\nBe sure to\nback up\nall data before proceeding.\nRAID levels\nDespite redundancy implied by most RAID levels, RAID does not guarantee that data is safe. A RAID will not protect data if there is a fire, the computer is stolen or multiple hard drives fail at once. Furthermore, installing a system with RAID is a complex process that may destroy data.\nStandard RAID levels\nThere are many different\nlevels of RAID\n; listed below are the most common.\nRAID 0\nUses striping to combine disks. Even though it\ndoes not provide redundancy\n(actually decreasing reliability), it is still considered RAID. It does, however,\nprovide a big speed benefit\n. If the speed increase is worth the possibility of data loss (for\nswap\npartition for example), choose this RAID level. On a server, RAID 1 and RAID 5 arrays are more appropriate. The size of a RAID 0 array block device is the size of the smallest component partition times the number of component partitions.\nRAID 1\nThe most straightforward RAID level: straight mirroring. As with other RAID levels, it only makes sense if the partitions are on different physical disk drives. If one of those drives fails, the block device provided by the RAID array will continue to function as normal. The example will be using RAID 1 for everything except\nswap\nand temporary data. Please note that with a software implementation, the RAID 1 level is the only option for the boot partition, because bootloaders reading the boot partition do not understand RAID, but a RAID 1 component partition can be read as a normal partition. The size of a RAID 1 array block device is the size of the smallest component partition.\nRAID 5\nRequires 3 or more physical drives, and provides the redundancy of RAID 1 combined with the speed and size benefits of RAID 0. RAID 5 uses striping, like RAID 0, but also stores parity blocks\ndistributed across each member disk\n. In the event of a failed disk, these parity blocks are used to reconstruct the data on a replacement disk. RAID 5 can withstand the loss of one member disk.\nNote\nRAID 5 is a common choice due to its combination of speed and data redundancy. The caveat is that if one drive were to fail and another drive failed before that drive was replaced, all data will be lost. Furthermore, with modern disk sizes and expected unrecoverable read error (URE) rates on consumer disks, the rebuild of a 4TiB array is\nexpected\n(i.e. higher than 50% chance) to have at least one URE. Because of this, RAID 5 is no longer advised by the storage industry.\nRAID 6\nRequires 4 or more physical drives, and provides the benefits of RAID 5 but with security against two drive failures. RAID 6 also uses striping, like RAID 5, but stores two distinct parity blocks\ndistributed across each member disk\n. In the event of a failed disk, these parity blocks are used to reconstruct the data on a replacement disk. RAID 6 can withstand the loss of two member disks. The robustness against unrecoverable read errors is somewhat better, because the array still has parity blocks when rebuilding from a single failed drive. However, given the overhead, RAID 6 is costly and in most settings RAID 10 in far2 layout (see below) provides better speed benefits and robustness, and is therefore preferred.\nNested RAID levels\nRAID 1+0\nRAID1+0 is a nested RAID that combines two of the standard levels of RAID to gain performance and additional redundancy. It is commonly referred to as\nRAID10\n, however, Linux MD RAID10 is slightly different from simple RAID layering, see below.\nRAID 10\nRAID10 under Linux is built on the concepts of RAID1+0, however, it implements this as a single layer, with multiple possible layouts.\nThe\nnear X\nlayout on Y disks repeats each chunk X times on Y/2 stripes, but does not need X to divide Y evenly. The chunks are placed on almost the same location on each disk they are mirrored on, hence the name. It can work with any number of disks, starting at 2. Near 2 on 2 disks is equivalent to RAID1, near 2 on 4 disks to RAID1+0.\nThe\nfar X\nlayout on Y disks is designed to offer striped read performance on a mirrored array. It accomplishes this by dividing each disk in two sections, say front and back, and what is written to disk 1 front is mirrored in disk 2 back, and vice versa. This has the effect of being able to stripe sequential reads, which is where RAID0 and RAID5 get their performance from. The drawback is that sequential writing has a very slight performance penalty because of the distance the disk needs to seek to the other section of the disk to store the mirror. RAID10 in far 2 layout is, however, preferable to layered RAID1+0\nand\nRAID5 whenever read speeds are of concern and availability / redundancy is crucial. However, it is still not a substitute for backups. See the wikipedia page for more information.\nWarning\nmdadm cannot reshape arrays in\nfar X\nlayouts which means once the array is created, you will not be able to\nmdadm --grow\nit. For example, if you have a 4x1TB RAID10 array and you want to switch to 2TB disks, your usable capacity will remain 2TB. For such use cases, stick to\nnear X\nlayouts.\nRAID level comparison\nRAID level\nData redundancy\nPhysical drive utilization\nRead performance\nWrite performance\nMin drives\n0\nNo\n100%\nnX\nBest\nnX\nBest\n2\n1\nYes\n50%\nUp to nX if multiple processes are reading, otherwise 1X\n1X\n2\n5\nYes\n67% - 94%\n(n−1)X\nSuperior\n(n−1)X\nSuperior\n3\n6\nYes\n50% - 88%\n(n−2)X\n(n−2)X\n4\n10,far2\nYes\n50%\nnX\nBest;\non par with RAID0 but redundant\n(n/2)X\n2\n10,near2\nYes\n50%\nUp to nX if multiple processes are reading, otherwise 1X\n(n/2)X\n2\n* Where\nn\nis standing for the number of dedicated disks.\nLINEAR\nLINEAR\nallows to map two or more devices into a single device, without parallel accesses like\nRAID0\nbut allowing to fully use disks from different sizes. To create a pseudo RAID using this mode without\nmdadm\n, one can either use the low-level\ndmsetup(8)\nutility, the high-level\nLVM\nframework or the\nBtrfs\nfilesystem.\nImplementation\nThe RAID devices can be managed in different ways:\nSoftware RAID\nThis is the easiest implementation as it does not rely on obscure proprietary firmware and software to be used. The array is managed by the operating system either by:\nan abstraction layer (e.g.\nmdadm\n);\nNote\nThis is the method we will use later in this guide.\na logical volume manager (e.g.\nLVM\n);\na component of a file system (e.g.\nZFS\n,\nBtrfs\n).\nHardware RAID\nThe array is directly managed by a dedicated hardware card installed in the PC to which the disks are directly connected. The RAID logic runs on an on-board processor independently of\nthe host processor (CPU)\n. Although this solution is independent of any operating system, the latter requires a driver in order to function properly with the hardware RAID controller. The RAID array can either be configured via an option rom interface or, depending on the manufacturer, with a dedicated application when the OS has been installed. The configuration is transparent for the Linux kernel: it does not see the disks separately.\nFakeRAID\nThis type of RAID is properly called BIOS or Onboard RAID, but is falsely advertised as hardware RAID. The array is managed by pseudo-RAID controllers where the RAID logic is implemented in an option ROM or in the firmware itself\nwith a EFI SataDriver\n(in case of\nUEFI\n), but are not full hardware RAID controllers with\nall\nRAID features implemented. Therefore, this type of RAID is sometimes called FakeRAID.\ndmraid\nwill be used to deal with these controllers. Here are some examples of FakeRAID controllers:\nIntel Rapid Storage\n, JMicron JMB36x RAID ROM, AMD RAID, ASMedia 106x, and NVIDIA MediaShield.\nWhich type of RAID do I have?\nSince software RAID is implemented by the user, the type of RAID is easily known to the user.\nHowever, discerning between FakeRAID and true hardware RAID can be more difficult. As stated, manufacturers often incorrectly distinguish these two types of RAID and false advertising is always possible. The best solution in this instance is to run the\nlspci\ncommand and looking through the output to find the RAID controller. Then do a search to see what information can be located about the RAID controller. Hardware RAID controllers appear in this list, but FakeRAID implementations do not. Also, true hardware RAID controllers are often rather expensive, so if someone customized the system, then it is very likely that choosing a hardware RAID setup made a very noticeable change in the computer's price.\nInstallation\nInstall\nmdadm\n.\nmdadm\nis used for administering pure software RAID using plain block devices: the underlying hardware does not provide any RAID logic, just a supply of disks.\nmdadm\nwill work with any collection of block devices. Even if unusual. For example, one can thus make a RAID array from a collection of thumb drives.\nPrepare the devices\nWarning\nThese steps erase everything on a device, so type carefully!\nIf the device is being reused or re-purposed from an existing array, erase any old RAID configuration information:\n# mdadm --misc --zero-superblock /dev/\ndrive\nor if a particular partition on a drive is to be deleted:\n# mdadm --misc --zero-superblock /dev/\npartition\nNote\nZapping a partition's superblock should not affect the other partitions on the disk.\nDue to the nature of RAID functionality it is very difficult to\nsecurely wipe disks\nfully on a running array. Consider whether it is useful to do so before creating it.\nYou can do the whole disk preparation procedure from a GUI with\nblivet-gui\nAUR\n.\nPartition the devices\nIt is highly recommended to partition the disks to be used in the array. Since most RAID users are selecting disk drives larger than 2 TiB, GPT is required and recommended. See\nPartitioning\nfor more information on partitioning and the available\npartitioning tools\n.\nNote\nIt is also possible to create a RAID directly on the raw disks (without partitions), but not recommended because it can cause problems when swapping a failed disk.\nTip\nWhen replacing a failed disk of a RAID, the new disk has to be exactly the same size as the failed disk or bigger — otherwise the array recreation process will not work. Even hard drives of the same manufacturer and model can have small size differences. By leaving a little space at the end of the disk unallocated one can compensate for the size differences between drives, which makes choosing a replacement drive model easier. Therefore, it is good practice to leave about 100 MiB of unallocated space at the end of the disk.\nGUID Partition Table\nAfter creating the partitions, their\npartition type GUIDs\nshould be\nA19D880F-05FC-4D3B-A006-743F0F84911E\n(it can be assigned by selecting partition type\nLinux RAID\nin\nfdisk\nor\nFD00\nin\ngdisk\n).\nIf a larger disk array is employed, consider assigning\nfilesystem labels\nor\npartition labels\nto make it easier to identify an individual disk later.\nCreating partitions that are of the same size on each of the devices is recommended.\nMaster Boot Record\nFor those creating partitions on HDDs with a MBR partition table, the\npartition types IDs\navailable for use are:\n0xDA\nfor non-FS data (\nNon-FS data\nin\nfdisk\n). This is the\nrecommended\nmdadm partition type for RAID arrays on Arch Linux.\n0xFD\nfor RAID autodetect arrays (\nLinux RAID autodetect\nin\nfdisk\n). This partition type should only be used if RAID autodetection is desireable (non-\ninitramfs\nsystem, old mdadm metadata format).\nSee\nLinux Raid Wiki:Partition Types\nfor more information.\nBuild the array\nUse\nmdadm\nto build the array. See\nmdadm(8)\nfor supported options. Several examples are given below.\nWarning\nDo not simply copy/paste the examples below; make sure you substitute the correct options and drive letters.\nNote\nIf this is a RAID1 array which is intended to boot from\nSyslinux\na limitation in syslinux v4.07 requires the metadata value to be 1.0 rather than the default of 1.2.\nWhen creating an array from\nArch installation medium\nuse the option\n--homehost=\nyourhostname\n(or\n--homehost=any\nto always have the same name regardless of the host) to set the\nhostname\n, otherwise the hostname\narchiso\nwill be written in the array metadata.\nTip\nYou can specify a custom raid device name using the option\n--name=\nMyRAIDName\nor by setting the raid device path to\n/dev/md/\nMyRAIDName\n. Udev will create symlinks to the raid arrays in\n/dev/md/\nusing that name. If\nhomehost\nmatches the current\nhostname\n(or if homehost is set to\nany\n) the link will be\n/dev/md/\nname\n, if the hostname does not match the link be\n/dev/md/\nhomehost\n:\nname\n.\nThe following example shows building a 2-device RAID1 array:\n# mdadm --create --verbose --level=1 --raid-devices=2 /dev/md/MyRAID1Array /dev/sdb1 /dev/sdc1\nThe following example shows building a RAID5 array with 4 active devices and 1 spare device:\n# mdadm --create --verbose --level=5 --raid-devices=4 /dev/md/MyRAID5Array /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1 --spare-devices=1 /dev/sdf1\nTip\n--chunk\nis used to change the chunk size from the default value. See\nChunks: the hidden key to RAID performance\nfor more on chunk size optimisation.\nThe following example shows building a RAID10,far2 array with 2 devices:\n# mdadm --create --verbose --level=10 --raid-devices=2 --layout=f2 /dev/md/MyRAID10Array /dev/sdb1 /dev/sdc1\nThe array is created under the virtual device\n/dev/mdX\n, assembled and ready to use (in degraded mode). One can directly start using it while mdadm resyncs the array in the background. It can take a long time to restore parity. Check the progress with:\n$ cat /proc/mdstat\nUpdate configuration file\nBy default, most of\nmdadm.conf\nis commented out, and it contains just the following:\n/etc/mdadm.conf\n...\nDEVICE partitions\n...\nThis directive tells mdadm to examine the devices referenced by\n/proc/partitions\nand assemble as many arrays as possible. This is fine if you really do want to start all available arrays and are confident that no unexpected superblocks will be found (such as after installing a new storage device). A more precise approach is to explicitly add the arrays to\n/etc/mdadm.conf\n:\n# mdadm --detail --scan >> /etc/mdadm.conf\nThis results in something like the following:\n/etc/mdadm.conf\n...\nDEVICE partitions\n...\nARRAY /dev/md/MyRAID1Array metadata=1.2 name=pine:MyRAID1Array UUID=27664f0d:111e493d:4d810213:9f291abe\nThis also causes mdadm to examine the devices referenced by\n/proc/partitions\n. However, only devices that have superblocks with a UUID of\n27664…\nare assembled in to active arrays.\nSee\nmdadm.conf(5)\nfor more information.\nAssemble the array\nOnce the configuration file has been updated the array can be assembled using mdadm:\n# mdadm --assemble --scan\nFormat the RAID filesystem\nTip\nTo create multiple volumes inside a RAID array, follow the\nLVM on software RAID\narticle.\nThe array can now be formatted with a\nfile system\nlike any other partition, just keep in mind that:\nDue to the large volume size not all filesystems are suited (see:\nWikipedia:Comparison of file systems#Limits\n).\nThe filesystem should support growing and shrinking while online (see:\nWikipedia:Comparison of file systems#Features\n).\nOne should calculate the correct stride and stripe-width for optimal performance.\nCalculating the stride and stripe width\nTwo parameters are required to optimise the filesystem structure to fit optimally within the underlying RAID structure: the\nstride\nand\nstripe width\n. These are derived from the RAID\nchunk size\n, the filesystem\nblock size\n, and the\nnumber of \"data disks\"\n.\nThe chunk size is a property of the RAID array, decided at the time of its creation.\nmdadm\n's current default is 512 KiB. It can be found with\nmdadm\n:\n# mdadm --detail /dev/mdX | grep 'Chunk Size'\nThe block size is a property of the filesystem, decided at\nits\ncreation. The default for many filesystems, including ext4, is 4 KiB. See\n/etc/mke2fs.conf\nfor details on ext4.\nThe number of \"data disks\" is the minimum number of devices in the array required to completely rebuild it without data loss. For example, this is N for a raid0 array of N devices and N-1 for raid5.\nOnce you have these three quantities, the stride and the stripe width can be calculated using the following formulas:\nstride = chunk size / block size\nstripe width = number of data disks * stride\nExample 1. RAID0\nExample formatting to ext4 with the correct stripe width and stride:\nHypothetical RAID0 array is composed of 2 physical disks.\nChunk size is 512 KiB.\nBlock size is 4 KiB.\nstride = chunk size / block size. In this example, the math is 512/4 so the stride = 128.\nstripe width = # of physical\ndata\ndisks * stride. In this example, the math is 2*128 so the stripe width = 256.\n# mkfs.ext4 -v -L myarray -b 4096 -E stride=128,stripe-width=256 /dev/md0\nExample 2. RAID5\nExample formatting to ext4 with the correct stripe width and stride:\nHypothetical RAID5 array is composed of 4 physical disks; 3 data discs and 1 parity disc.\nChunk size is 512 KiB.\nBlock size is 4 KiB.\nstride = chunk size / block size. In this example, the math is 512/4 so the stride = 128.\nstripe width = # of physical\ndata\ndisks * stride. In this example, the math is 3*128 so the stripe width = 384.\n# mkfs.ext4 -v -L myarray -b 4096 -E stride=128,stripe-width=384 /dev/md0\nFor more on stride and stripe width, see:\nRAID Math\n.\nExample 3. RAID10,far2\nExample formatting to ext4 with the correct stripe width and stride:\nHypothetical RAID10 array is composed of 2 physical disks. Because of the properties of RAID10 in far2 layout, both count as data disks.\nChunk size is 512 KiB.\nBlock size is 4 KiB.\nstride = chunk size / block size.\nIn this example, the math is 512/4 so the stride = 128.\nstripe width = # of physical\ndata\ndisks * stride.\nIn this example, the math is 2*128 so the stripe width = 256.\n# mkfs.ext4 -v -L myarray -b 4096 -E stride=128,stripe-width=256 /dev/md0\nMounting from a Live CD\nUsers wanting to mount the RAID partition from a Live CD, use:\n# mdadm --assemble /dev/md\nnumber\n/dev/\ndisk1\n/dev/\ndisk2\n/dev/\ndisk3\n/dev/\ndisk4\nIf your RAID 1 that is missing a disk array was wrongly auto-detected as RAID 1 (as per\nmdadm --detail /dev/md\nnumber\n) and reported as inactive (as per\ncat /proc/mdstat\n), stop the array first:\n# mdadm --stop /dev/md\nnumber\nInstalling Arch Linux on RAID\nNote\nThe following section is applicable only if the root filesystem resides on the array. Users may skip this section if the array holds a data partition(s).\nYou should create the RAID array between the\nPartitioning\nand\nformatting\nsteps of the Installation Procedure. Instead of directly formatting a partition to be your root file system, it will be created on a RAID array.\nFollow the section\n#Installation\nto create the RAID array. Then continue with the installation procedure until the pacstrap step is completed.\nWhen using\nUEFI boot\n, also read\nEFI system partition#ESP on software RAID1\n.\nUpdate configuration file\nNote\nThis should be done outside of the chroot, hence the prefix\n/mnt\nto the filepath.\nAfter the base system is installed the default configuration file,\nmdadm.conf\n, must be updated like so:\n# mdadm --detail --scan >> /mnt/etc/mdadm.conf\nAlways check the\nmdadm.conf\nconfiguration file using a text editor after running this command to ensure that its contents look reasonable.\nNote\nTo prevent failure of\nmdmonitor.service\nat boot (activated by udev), you will need to uncomment\nMAILADDR\nand provide an e-mail address and/or application to handle notification of problems with your array at the bottom of\nmdadm.conf\n. See\n#Email notifications\n.\nContinue with the installation procedure until you reach the step\nInstallation guide#Initramfs\n, then follow the next section.\nConfigure mkinitcpio\nNote\nThis should be done whilst chrooted.\nInstall\nmdadm\nand add\nmdadm_udev\nto the\nHOOKS\narray of the\nmkinitcpio.conf\nto add support for mdadm into the initramfs image:\n/etc/mkinitcpio.conf\n...\nHOOKS=(base udev autodetect microcode modconf kms keyboard keymap consolefont block\nmdadm_udev\nfilesystems fsck)\n...\nThen\nregenerate the initramfs\n.\nNote\nEvery time when you make changes to\n/etc/mdadm.conf\n, the initramfs needs to be regenerated.\nConfigure the boot loader\nRoot device\nPoint the\nroot\nparameter to the mapped device. E.g.:\nroot=/dev/md/\nMyRAIDArray\nIf booting from a software raid partition fails using the kernel device node method above, an alternative way is to use one of the methods from\nPersistent block device naming\n, for example:\nroot=LABEL=Root_Label\nSee also\nGRUB#RAID\n.\nRAID0 layout\nNote\nThis also affects existing mdraid RAID0 users that upgrade from an older version of the Linux kernel to 5.3.4 or newer.\nSince version 5.3.4 of the Linux kernel, you need to explicitly tell the kernel which RAID0 layout should be used: RAID0_ORIG_LAYOUT (\n1\n) or RAID0_ALT_MULTIZONE_LAYOUT (\n2\n).\n[1]\nYou can do this by providing the\nkernel parameter\nas follows:\nraid0.default_layout=2\nThe correct value depends upon the kernel version that was used to create the raid array: use\n1\nif created using kernel 3.14 or earlier, use\n2\nif using a more recent version of the kernel. One way to check this is to look at the creation time of the raid array:\nmdadm --detail /dev/md1\n/dev/md1:\nVersion : 1.2\nCreation Time : Thu Sep 24 10:17:41 2015\nRaid Level : raid0\nArray Size : 975859712 (930.65 GiB 999.28 GB)\nRaid Devices : 3\nTotal Devices : 3\nPersistence : Superblock is persistent\nUpdate Time : Thu Sep 24 10:17:41 2015\nState : clean\nActive Devices : 3\nWorking Devices : 3\nFailed Devices : 0\nSpare Devices : 0\nChunk Size : 512K\nConsistency Policy : none\nName : archiso:root\nUUID : 028de718:20a81234:4db79a2c:e94fd560\nEvents : 0\nNumber   Major   Minor   RaidDevice State\n0     259        2        0      active sync   /dev/nvme0n1p1\n1     259        6        1      active sync   /dev/nvme2n1p1\n2     259        5        2      active sync   /dev/nvme1n1p2\nHere we can see that this raid array was created on September 24, 2015. The release date of Linux Kernel 3.14 was March 30, 2014, and as such this raid array is most likely created using a multizone layout (\n2\n).\nRAID Maintenance\nScrubbing\nIt is good practice to regularly run data\nscrubbing\nto check for and fix errors. Depending on the size/configuration of the array, a scrub may take multiple hours to complete.\nTo initiate a data scrub:\n# echo check > /sys/block/mdX/md/sync_action\nAlternatively, you may\nenable\nthe included\nmdcheck_start.timer\nwhich performs weekly scans.\nThe check operation scans the drives for bad sectors and automatically repairs them. If it finds good sectors that contain bad data (i.e. a mismatch, the data in a sector does not agree with what the data from another disk indicates that it should be, for example the parity block + the other data blocks would cause us to think that this data block is incorrect), then no action is taken, but the event is logged (see below). This \"do nothing\" allows admins to inspect the data in the sector and the data that would be produced by rebuilding the sectors from redundant information and pick the correct data to keep.\nAs with many tasks/items relating to mdadm, the status of the scrub can be queried by reading\n/proc/mdstat\n.\nExample:\n$ cat /proc/mdstat\nPersonalities : [raid6] [raid5] [raid4] [raid1]\nmd0 : active raid1 sdb1[0] sdc1[1]\n3906778112 blocks super 1.2 [2/2] [UU]\n[>....................]  check =  4.0% (158288320/3906778112) finish=386.5min speed=161604K/sec\nbitmap: 0/30 pages [0KB], 65536KB chunk\nTo stop a currently running data scrub safely:\n# echo idle > /sys/block/md0/md/sync_action\nNote\nIf the system is rebooted after a partial scrub has been suspended, the scrub will start over.\nWhen the scrub is complete, admins may check how many blocks (if any) have been flagged as bad:\n# cat /sys/block/md0/md/mismatch_cnt\nGeneral notes on scrubbing\nNote\nUsers may alternatively echo\nrepair\nto\n/sys/block/md0/md/sync_action\nbut this is ill-advised since if a mismatch in the data is encountered, it would be automatically updated to be consistent. The danger is that we really do not know whether it is the parity or the data block that is correct (or which data block in case of RAID1). It is luck-of-the-draw whether or not the operation gets the right data instead of the bad data.\nIt is a good idea to set up a cron job as root to schedule a periodic scrub. See\nraid-check\nAUR\nwhich can assist with this. To perform a periodic scrub using systemd timers instead of cron, See\nraid-check-systemd\nAUR\nwhich contains the same script along with associated systemd timer unit files.\nNote\nFor typical platter drives, scrubbing can take approximately\nsix seconds per gigabyte\n(that is one hour forty-five minutes per terabyte) so plan the start of your cron job or timer appropriately.\nRAID1 and RAID10 notes on scrubbing\nDue to the fact that RAID1 and RAID10 writes in the kernel are unbuffered, an array can have non-0 mismatch counts even when the array is healthy. These non-0 counts will only exist in transient data areas where they do not pose a problem. However, we cannot tell the difference between a non-0 count that is just in transient data or a non-0 count that signifies a real problem. This fact is a source of false positives for RAID1 and RAID10 arrays. It is however still recommended to scrub regularly in order to catch and correct any bad sectors that might be present in the devices.\nRemoving devices from an array\nOne can remove a\nblock device\nfrom the array after marking it as faulty:\n# mdadm --fail /dev/md0 /dev/\nfailing_array_member\nNow remove it from the array:\n# mdadm --remove /dev/md0 /dev/\nfailing_array_member\nIf the device has not failed entirely, but you would like to replace it, e.g. because it looks like it is dying, you can actually handle replacement more gracefully by first adding a new drive and then telling mdadm to replace it.\nFor example, with\n/dev/sdc1\nas the new one and\n/dev/sdb1\nas the failing one:\n# mdadm /dev/md0 --add /dev/sdc1\n# mdadm /dev/md0 --replace /dev/sdb1 --with /dev/sdc1\nThe\n--with /dev/sdc1\npart is optional, but more explicit. See\n[2]\nfor more details.\nTo remove a device permanently (for example, to use it individually from now on), follow the steps above (fail/remove or add/replace) and then run:\n# mdadm --zero-superblock /dev/\nfailing_array_member\nWarning\nDo not issue this command on linear or RAID0 arrays or data loss will occur!\nReusing the removed disk without zeroing the superblock will cause loss of all data on the next boot. (After mdadm will try to use it as the part of the raid array).\nStop using an array:\nUmount target array\nStop the array with:\nmdadm --stop /dev/md0\nRepeat the three command described in the beginning of this section on each device.\nRemove the corresponding line from\n/etc/mdadm.conf\n.\nAdding a new device to an array\nAdding new devices with mdadm can be done on a running system with the devices mounted.\nPartition the new device using the same layout as one of those already in the arrays as discussed above.\nAssemble the RAID array if it is not already assembled:\n# mdadm --assemble /dev/md0 /dev/sda1 /dev/sdb1\nAdd the new device to the array:\n# mdadm --add /dev/md0 /dev/sdc1\nThis should not take long for mdadm to do.\nThis article or section needs expansion.\nReason:\nA\n--backup-file\nshould be created prior to\ngrow\n(Discuss in\nTalk:RAID#Add a drive (RAID5, RAID6)\n)\nDepending on the type of RAID (for example, with RAID1), mdadm may add the device as a spare without syncing data to it. You can increase the number of disks the RAID uses by using\n--grow\nwith the\n--raid-devices\noption. For example, to increase an array to four disks:\n# mdadm --grow /dev/md0 --raid-devices=4\nYou can check the progress with:\n# cat /proc/mdstat\nCheck that the device has been added with the command:\n# mdadm --misc --detail /dev/md0\nNote\nFor RAID0 arrays you may get the following error message:\nmdadm: add new device failed for /dev/sdc1 as 2: Invalid argument\nThis is because the above commands will add the new disk as a \"spare\" but RAID0 does not have spares. If you want to add a device to a RAID0 array, you need to \"grow\" and \"add\" in the same command, as demonstrated below:\n# mdadm --grow /dev/md0 --raid-devices=3 --add /dev/sdc1\nIncreasing size of a RAID volume\nIf larger disks are installed in a RAID array or partition size has been increased, it may be desirable to increase the size of the RAID volume to fill the larger available space. This process may be begun by first following the above sections pertaining to replacing disks. Once the RAID volume has been rebuilt onto the larger disks it must be \"grown\" to fill the space.\n# mdadm --grow /dev/md0 --size=max\nNext, partitions present on the RAID volume\n/dev/md0\nmay need to be resized. See\nPartitioning\nfor details. Finally, the filesystem on the above mentioned partition will need to be resized. If partitioning was performed with\ngparted\nthis will be done automatically. If other tools were used, unmount and then resize the filesystem manually.\n# umount /storage\n# fsck.ext4 -f /dev/md0p1\n# resize2fs /dev/md0p1\nChange sync speed limits\nSyncing can take a while. If the machine is not needed for other tasks the speed limit can be increased.\n# cat /proc/mdstat\nPersonalities : [raid10]\nmd127 : active raid10 sdd1[3] sdc1[2] sdb1[1] sda1[0]\n31251490816 blocks super 1.2 512K chunks 2 far-copies [4/4] [UUUU]\n[=>...................]  resync =  5.2% (1629533760/31251490816) finish=2071.7min speed=238293K/sec\nbitmap: 221/233 pages [884KB], 65536KB chunk\nIn the above example, it would seem the max speed is limited to approximately 238 M/sec.\nCheck the current speed limit (in kibibytes per second, KiB/s):\n# sysctl dev.raid.speed_limit_min\ndev.raid.speed_limit_min = 1000\n# sysctl dev.raid.speed_limit_max\ndev.raid.speed_limit_max = 200000\nSet a new maximum speed of raid resyncing operations using\nsysctl\n:\n# sysctl -w dev.raid.speed_limit_min=600000\n# sysctl -w dev.raid.speed_limit_max=600000\nThen check out the syncing speed and estimated finish time.\n# cat /proc/mdstat\nPersonalities : [raid10]\nmd127 : active raid10 sdd1[3] sdc1[2] sdb1[1] sda1[0]\n31251490816 blocks super 1.2 512K chunks 2 far-copies [4/4] [UUUU]\n[=>...................]  resync =  5.3% (1657016448/31251490816) finish=1234.9min speed=399407K/sec\nbitmap: 221/233 pages [884KB], 65536KB chunk\nRAID5 performance\nTo improve RAID5 performance for fast storage (e.g.\nNVMe\n), increase\n/sys/block/mdx/md/group_thread_cnt\nto more threads. For example, to use 8 threads to operate on a RAID5 device:\n# echo 8 > /sys/block/md0/md/group_thread_cnt\nSee\ngit kernel commit 851c30c9badf\n.\nUpdate RAID superblock\nTo update the RAID superblock, you need to first unmount the array and then stop the array with the following command:\n# mdadm --stop /dev/md0\nThen you can update certain parameters by reassembling the array. For example, to update the\nhomehost\n:\n# mdadm --assemble --update=homehost --homehost=NAS /dev/md0 /dev/sda1 /dev/sdb1\nSee the arguments of\n--update\nfor details.\nMonitoring\nA simple one-liner that prints out the status of the RAID devices:\n# awk '/^md/ {printf \"%s: \", $1}; /blocks/ {print $NF}' </proc/mdstat\nmd1: [UU]\nmd0: [UU]\nWatch mdstat\n# watch -t 'cat /proc/mdstat'\nOr preferably using\ntmux\n:\n# tmux split-window -l 12 \"watch -t 'cat /proc/mdstat'\"\nTrack IO with iotop\nThe\niotop\npackage displays the input/output stats for processes. Use this command to view the IO for raid threads.\n# iotop -a $(sed 's/^/-p /g' <<<`pgrep \"_raid|_resync|jbd2\"`)\nTrack IO with iostat\nThe\niostat\nutility from\nsysstat\npackage displays the input/output statistics for devices and partitions.\n# iostat -dmy 1 /dev/md0\n# iostat -dmy 1 # all\nmdadm via systemd\nmdadm\nprovides the\nsystemd\nservice\nmdmonitor.service\nwhich can be useful for monitoring the health of your raid arrays and notifying you if anything goes wrong.\nThis service is special in that it cannot be manually activated like a regular service;\nmdadm\nwill take care of activating it via udev upon assembling your arrays on system startup, but it will\nonly\ndo so if an email address and/or program has been configured for its notifications (see below).\nEmail notifications\nWarning\nFailure to configure an email address will result in the monitoring service silently failing to start.\nNote\nIn order to send emails, a properly configured\nmail transfer agent\nis required.\nTo enable this functionality, edit\n/etc/mdadm.conf\nand define the email address:\nMAILADDR\nuser@domain\nThen, to verify that everything is working as it should, run the following command:\n# mdadm --monitor --scan --oneshot --test\nIf the test is successful and the email is delivered, then you are done; the next time your arrays are reassembled,\nmdmonitor.service\nwill begin monitoring them for errors.\nProgram notifications\nLike Email notification above, edit\n/etc/mdadm.conf\nand edit the line:\nPROGRAM /usr/sbin/handle-mdadm-events\nThe argument for PROGRAM is the script you want to run for any event. Which then interact with proper network monitoring agents. Or even IM clients or push notification services like ntfy.sh for home users.\nTest in the same way as for email notification above.\nTroubleshooting\nIf you are getting error when you reboot about \"invalid raid superblock magic\" and you have additional hard drives other than the ones you installed to, check that your hard drive order is correct. During installation, your RAID devices may be hdd, hde and hdf, but during boot they may be hda, hdb and hdc. Adjust your kernel line accordingly. This is what happened to me anyway.\nError: \"kernel: ataX.00: revalidation failed\"\nIf you suddenly (after reboot, changed BIOS settings) experience Error messages like:\nFeb  9 08:15:46 hostserver kernel: ata8.00: revalidation failed (errno=-5)\nIt does not necessarily mean that a drive is broken. You often find panic links on the web which go for the worst. In a word, No Panic. Maybe you just changed APIC or ACPI settings within your BIOS or Kernel parameters somehow. Change them back and you should be fine. Ordinarily, turning ACPI and/or ACPI off should help.\nStart arrays read-only\nWhen an md array is started, the superblock will be written, and resync may begin. To start read-only set the kernel module\nmd_mod\nparameter\nstart_ro\n. When this is set, new arrays get an 'auto-ro' mode, which disables all internal io (superblock updates, resync, recovery) and is automatically switched to 'rw' when the first write request arrives.\nNote\nThe array can be set to true 'ro' mode using\nmdadm --readonly\nbefore the first write request, or resync can be started without a write using\nmdadm --readwrite\n.\nTo set the parameter at boot, add\nmd_mod.start_ro=1\nto your kernel line.\nOr set it at module load time by\nKernel module#Using modprobe.d\nor from directly from\n/sys/\n:\n# echo 1 > /sys/module/md_mod/parameters/start_ro\nRecovering from a broken or missing drive in the raid\nYou might get the above mentioned error also when one of the drives breaks for whatever reason. In that case you will have to force the raid to still turn on even with one disk short. Type this (change where needed):\n# mdadm --manage /dev/md0 --run\nNow you should be able to mount it again with something like this (if you had it in fstab):\n# mount /dev/md0\nNow the raid should be working again and available to use, however with one disk short. So, to add that one disc partition it the way like described above in\n#Prepare the devices\n. Once that is done you can add the new disk to the raid by doing:\n# mdadm --manage --add /dev/md0 /dev/sdd1\nIf you type:\n# cat /proc/mdstat\nyou probably see that the raid is now active and rebuilding.\nYou also might want to update your configuration (see:\n#Update configuration file\n).\nBenchmarking\nThere are several tools for benchmarking a RAID. The most notable improvement is the speed increase when multiple threads are reading from the same RAID volume.\nbonnie++\ntests database type access to one or more files, and creation, reading, and deleting of small files which can simulate the usage of programs such as Squid, INN, or Maildir format e-mail. The enclosed\nZCAV\nprogram tests the performance of different zones of a hard drive without writing any data to the disk.\nhdparm\nshould\nnot\nbe used to benchmark a RAID, because it provides very inconsistent results.\nSee also\nLinux kernel RAID documentation\nLinux Software RAID\n(thomas-krenn.com)\nLinux RAID wiki entry\nin The Linux kernel archives\nHow Bitmaps Work\nChapter 19. Managing RAID\nof Red Hat Enterprise Linux 9 documentation\nLinux-RAID FAQ\non the Linux documentation project\nBAARF\n(Archive.org) including\nWhy should I not use RAID 5?\n(Archive.org) by Art S. Kagel\nIntroduction to RAID\n,\nNested-RAID: RAID-5 and RAID-6 Based Configurations\n,\nIntro to Nested-RAID: RAID-01 and RAID-10\n, and\nNested-RAID: The Triple Lindy\nin Linux Magazine\nHowTo: Speed Up Linux Software Raid Building And Re-syncing\nWikipedia:Non-RAID drive architectures\nmailing list\nKernel Linux-Raid mailing list\nmdadm\nmdadm source code\nSoftware RAID on Linux with mdadm\nin Linux Magazine\nWikipedia - mdadm\nForum threads\nRaid Performance Improvements with bitmaps\nGRUB and GRUB2\nCan't install grub2 on software RAID\nUse RAID metadata 1.2 in boot and root partition\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=RAID&oldid=853961\n\"\nCategory\n:\nStorage virtualization\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nRAID\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/RAID"}}
{"text": "LVM - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nLVM\n6 languages\nDeutsch\nEspañol\nMagyar\n日本語\nPortuguês\n中文（简体）\nFrom ArchWiki\nRelated articles\nInstall Arch Linux on LVM\nLVM on software RAID\ndm-crypt/Encrypting an entire system#LVM on LUKS\ndm-crypt/Encrypting an entire system#LUKS on LVM\nResizing LVM-on-LUKS\nCreate root filesystem snapshots with LVM\nFrom\nWikipedia:Logical Volume Manager (Linux)\n:\nLogical Volume Manager (LVM) is a\ndevice mapper\nframework that provides\nlogical volume management\nfor the\nLinux kernel\n.\nBackground\nLVM building blocks\nLogical Volume Management utilizes the kernel's\ndevice-mapper\nfeature to provide a system of\npartitions\nindependent of underlying disk layout. With LVM you abstract your storage and have \"virtual partitions\", making\nextending/shrinking\neasier (subject to potential filesystem limitations).\nVirtual partitions allow addition and removal without worry of whether you have enough contiguous space on a particular disk, getting caught up fdisking a disk in use (and wondering whether the kernel is using the old or new partition table), or, having to move other partitions out of the way.\nBasic building blocks of LVM:\nPhysical volume (PV)\nUnix block device node, usable for storage by LVM. Examples: a hard disk, an\nMBR\nor\nGPT\npartition, a loopback file, a device mapper device (e.g.\ndm-crypt\n). It hosts an LVM header.\nVolume group (VG)\nGroup of PVs that serves as a container for LVs. PEs are allocated from a VG for a LV.\nLogical volume (LV)\n\"Virtual/logical partition\" that resides in a VG and is composed of PEs. LVs are Unix block devices analogous to physical partitions, e.g. they can be directly formatted with a\nfile system\n.\nPhysical extent (PE)\nThe smallest contiguous extent (default 4 MiB) in the PV that can be assigned to a LV. Think of PEs as parts of PVs that can be allocated to any LV.\nExample:\nPhysical disks\nDisk1 (/dev/sda):\n┌──────────────────────────────────────┬─────────────────────────────────────┐\n│ Partition1  50 GiB (Physical volume) │ Partition2 80 GiB (Physical volume) │\n│ /dev/sda1                            │ /dev/sda2                           │\n└──────────────────────────────────────┴─────────────────────────────────────┘\nDisk2 (/dev/sdb):\n┌──────────────────────────────────────┐\n│ Partition1 120 GiB (Physical volume) │\n│ /dev/sdb1                            │\n└──────────────────────────────────────┘\nLVM logical volumes\nVolume Group1 (/dev/MyVolGroup/ = /dev/sda1 + /dev/sda2 + /dev/sdb1):\n┌─────────────────────────┬─────────────────────────┬──────────────────────────┐\n│ Logical volume1 15 GiB  │ Logical volume2 35 GiB  │ Logical volume3 200 GiB  │\n│ /dev/MyVolGroup/rootvol │ /dev/MyVolGroup/homevol │ /dev/MyVolGroup/mediavol │\n└─────────────────────────┴─────────────────────────┴──────────────────────────┘\nNote\nLogical volumes are accessible at both\n/dev/\nVolumeGroupName\n/\nLogicalVolumeName\nand\n/dev/mapper/\nVolumeGroupName-LogicalVolumeName\n. However,\nlvm(8) § VALID NAMES\nrecommends the former format for \"software and scripts\" (e.g.\nfstab\n) since the latter is intended for \"internal use\" and subject to possible \"change between releases and distributions\".\nAdvantages\nLVM gives you more flexibility than just using normal hard drive partitions:\nUse any number of disks as one big disk.\nHave logical volumes stretched over several disks (\nRAID\n, mirroring, striping which offer advantages such as additional resilience and performance\n[1]\n).\nCreate small logical volumes and resize them \"dynamically\" as they get filled up.\nResize logical volumes regardless of their order on disk. It does not depend on the position of the LV within VG, there is no need to ensure surrounding available space.\nResize/create/delete logical and physical volumes online. File systems on them still need to be resized, but some (such as\nExt4\nand\nBtrfs\n) support online resizing.\nOnline/live migration of LV (or segments) being used by services to different disks without having to restart services.\nSnapshots allow you to backup a frozen copy of the file system, while keeping service downtime to a minimum and easily merge the snapshot into the original volume later.\nSupport for unlocking separate volumes without having to enter a key multiple times on boot (\nmake LVM on top of LUKS\n).\nBuilt-in support for caching of frequently used data (\nlvmcache(7)\n).\nDisadvantages\nAdditional steps in setting up the system (may require changes to\nmkinitcpio\nconfiguration), more complicated. Requires (multiple) daemons to constantly run.\nIf dual-booting, note that Windows does not support LVM; you will be unable to access any LVM partitions from Windows. 3rd Party software may allow to mount certain kinds of LVM setups.\n[2]\nIf your physical volumes are not on a RAID-1, RAID-5 or RAID-6 losing one disk\ncan\nlose one or more logical volumes if you span (or extend) your logical volumes across multiple non-redundant disks.\nIt is not always easy to shrink the space used by the logical volume manager, meaning the physical volumes used for the logical volumes. If the physical extents are scattered across the physical volume until the end you might need to inspect the segments and move them (potentially to another physical device) or the same device with custom allocation settings (e.g.\n--alloc anywhere\n). If you want to dual-boot with other operating systems (e.g. with Microsoft Windows), the only space left on the device for Microsoft Windows is the space not used by LVM / not used as physical volume.\nPotentially worse performance than using plain partitions.\n[3]\nMay not work well with all file systems, especially those that are designed to be (multi-)device aware. For example,\nBtrfs\noffers some of the same functionality (\nmulti device support\n,\n(sub)volumes\n, snapshots and\nRAID\n) which could clash (read further about issues with LVM snapshots with\nBtrfs\n).\nInstallation\nMake sure the\nlvm2\npackage is\ninstalled\n.\nIf you have LVM volumes not activated via the\ninitramfs\n,\nenable\nlvm2-monitor.service\n, which is provided by the\nlvm2\npackage.\nVolume operations\nPhysical volumes\nCreating\nTo create a PV on\n/dev/sda1\n, run:\n# pvcreate /dev/sda1\nYou can check the PV is created using the following command:\n# pvs\nGrowing\nAfter extending or prior to reducing the size of a device that has a physical volume on it, you need to grow or shrink the PV using\npvresize(8)\n.\nTo expand the PV on\n/dev/sda1\nafter enlarging the\npartition\n, run:\n# pvresize /dev/sda1\nThis will automatically detect the new size of the device and extend the PV to its maximum.\nNote\nThis command can be done while the volume is online.\nShrinking\nTo shrink a physical volume prior to reducing its underlying device, add the\n--setphysicalvolumesize\nsize\nparameters to the command,\ne.g.\n:\n# pvresize --setphysicalvolumesize 40G /dev/sda1\nThe above command may leave you with this error:\n/dev/sda1: cannot resize to 25599 extents as later ones are allocated.\n0 physical volume(s) resized / 1 physical volume(s) not resized\nIndeed\npvresize\nwill refuse to shrink a PV if it has allocated extents after where its new end would be. One needs to run\npvmove\nbeforehand to relocate these elsewhere in the volume group if there is sufficient free space.\nMove physical extents\nBefore freeing up physical extents at the end of the volume, one must run\npvdisplay -v -m\nto see them. An alternative way to view segments in a tabular form is\npvs --segments -v\n.\nIn the below example, there is one physical volume on\n/dev/sdd1\n, one volume group\nvg1\nand one logical volume\nbackup\n.\n# pvdisplay -v -m\nFinding all volume groups.\nUsing physical volume(s) on command line.\n--- Physical volume ---\nPV Name               /dev/sdd1\nVG Name               vg1\nPV Size               1.52 TiB / not usable 1.97 MiB\nAllocatable           yes\nPE Size               4.00 MiB\nTotal PE              399669\nFree PE               153600\nAllocated PE          246069\nPV UUID               MR9J0X-zQB4-wi3k-EnaV-5ksf-hN1P-Jkm5mW\n--- Physical Segments ---\nPhysical extent 0 to 153600:\nFREE\nPhysical extent 153601 to 307199:\nLogical volume\t/dev/vg1/backup\nLogical extents\t1 to 153599\nPhysical extent 307200 to 307200:\nFREE\nPhysical extent 307201 to 399668:\nLogical volume\t/dev/vg1/backup\nLogical extents\t153601 to 246068\nOne can observe\nFREE\nspace are split across the volume. To shrink the physical volume, we must first move all used segments to the beginning.\nHere, the first free segment is from 0 to 153600 and leaves us with 153601 free extents. We can now move this segment number from the last physical extent to the first extent. The command will thus be:\n# pvmove --alloc anywhere /dev/sdd1:307201-399668 /dev/sdd1:0-92467\n/dev/sdd1: Moved: 0.1 %\n/dev/sdd1: Moved: 0.2 %\n...\n/dev/sdd1: Moved: 99.9 %\n/dev/sdd1: Moved: 100.0 %\nNote\nThis command moves 399668 - 307201 + 1 = 92468 PEs\nfrom\nthe last segment\nto\nthe first segment. This is possible as the first segment encloses 153600 free PEs, which can contain the 92467 - 0 + 1 = 92468 moved PEs.\nThe\n--alloc anywhere\noption is used as we move PEs inside the same partition. In case of different partitions, the command would look something like this:\n# pvmove /dev/sdb1:1000-1999 /dev/sdc1:0-999\nThis command may take a long time (one to two hours) in case of large volumes. It might be a good idea to run this command in a\ntmux\nor\nGNU Screen\nsession. Any unwanted stop of the process could be fatal.\nOnce the operation is complete, run\nfsck\nto make sure your file system is valid.\nResize physical volume\nOnce all your free physical segments are on the last physical extents, run\nvgdisplay\nwith root privileges and see your free PE.\nThen you can now run again the command:\n# pvresize --setphysicalvolumesize\nsize\nPhysicalVolume\nSee the result:\n# pvs\nPV         VG   Fmt  Attr PSize    PFree\n/dev/sdd1  vg1  lvm2 a--     1t     500g\nResize partition\nLast, you need to shrink the partition with your favorite\npartitioning tool\n.\nVolume groups\nCreating a volume group\nTo create a VG\nMyVolGroup\nwith an associated PV\n/dev/sdb1\n, run:\n# vgcreate MyVolGroup /dev/sdb1\nYou can check the VG\nMyVolGroup\nis created using the following command:\n# vgs\nYou can bind multiple PVs when creating a VG like this:\n# vgcreate MyVolGroup /dev/sdb1 /dev/sdb2\nActivating a volume group\nNote\nYou can restrict the volumes that are activated automatically by setting the\nauto_activation_volume_list\nin\n/etc/lvm/lvm.conf\n. If in doubt, leave this option commented out.\n# vgchange -a y MyVolGroup\nBy default, this will reactivate the volume group when applicable. For example, if you had a drive failure in a mirror and you swapped the drive; and ran (1)\npvcreate\n, (2)\nvgextend\nand (3)\nvgreduce --removemissing --force\n.\nRepairing a volume group\nTo start the rebuilding process of the degraded mirror array in this example, you would run:\n# lvconvert --repair /dev/MyVolGroup/mirror\nYou can monitor the rebuilding process (Cpy%Sync Column output) with:\n# lvs -a -o +devices\nDeactivating a volume group\nJust invoke\n# vgchange -a n MyVolGroup\nThis will deactivate the volume group and allow you to unmount the container it is stored in.\nRenaming a volume group\nUse the\nvgrename(8)\ncommand to rename an existing volume group.\nEither of the following commands renames the existing volume group\nMyVolGroup\nto\nmy_volume_group\n# vgrename /dev/MyVolGroup /dev/my_volume_group\n# vgrename MyVolGroup my_volume_group\nMake sure to update all configuration files (e.g.\n/etc/fstab\nor\n/etc/crypttab\n) that reference the renamed volume group.\nAdd physical volume to a volume group\nYou first create a new physical volume on the block device you wish to use, then extend your volume group\n# pvcreate /dev/sdb1\n# vgextend MyVolGroup /dev/sdb1\nThis of course will increase the total number of physical extents on your volume group, which can be allocated by logical volumes as you see fit.\nNote\nIt is considered good form to have a\npartition table\non your storage medium below LVM. Use the appropriate partition type:\n8e\nfor MBR, and\nE6D6D379-F507-44C2-A23C-238F2A3DF928\nfor GPT partitions (\n8e00\ntype code in\ngdisk\n,\nlvm\ntype alias in\nfdisk\n).\nRemove partition from a volume group\nIf you created a logical volume on the partition,\nremove\nit first.\nAll of the data on that partition needs to be moved to another partition. Fortunately, LVM makes this easy:\n# pvmove /dev/sdb1\nIf you want to have the data on a specific physical volume, specify that as the second argument to\npvmove\n:\n# pvmove /dev/sdb1 /dev/sdf1\nThen the physical volume needs to be removed from the volume group:\n# vgreduce MyVolGroup /dev/sdb1\nOr remove all empty physical volumes:\n# vgreduce --all MyVolGroup\nFor example: if you have a bad disk in a group that cannot be found because it has been removed or failed:\n# vgreduce --removemissing --force MyVolGroup\nAnd lastly, if you want to use the partition for something else, and want to avoid LVM thinking that the partition is a physical volume:\n# pvremove /dev/sdb1\nLogical volumes\nNote\nlvresize(8)\nprovides more or less the same options as the specialized\nlvextend(8)\nand\nlvreduce(8)\ncommands, while allowing to do both types of operation. Notwithstanding this, all those utilities offer a\n-r\n/\n--resizefs\noption which allows to resize the file system together with the LV using\nfsadm(8)\n(\next2\n,\next3\n,\next4\n,\nReiserFS\nand\nXFS\nsupported). Therefore it may be easier to simply use\nlvresize\nfor both operations and use\n--resizefs\nto simplify things a bit, except if you have specific needs or want full control over the process.\nWarning\nWhile enlarging a file system can often be done on-line (\ni.e.\nwhile it is mounted), even for the root partition, shrinking will nearly always require to first unmount the file system so as to prevent data loss. Make sure your file system supports what you are trying to do.\nTip\nIf a logical volume will be formatted with\next4\n, leave at least 256 MiB free space in the volume group to allow using\ne2scrub(8)\n. After creating the last volume with\n-l 100%FREE\n, this can be accomplished by reducing its size with\nlvreduce -L -256M\nvolume_group\n/\nlogical_volume\n.\nCreating a logical volume\nTo create a LV\nhomevol\nin a VG\nMyVolGroup\nwith 300 GiB of capacity, run:\n# lvcreate -L 300G MyVolGroup -n homevol\nor, to create a LV\nhomevol\nin a VG\nMyVolGroup\nwith the rest of capacity, run:\n# lvcreate -l 100%FREE MyVolGroup -n homevol\nTo create the LV while restricting it to specific PVs within the VG, append them to the command:\n# lvcreate -L 300G MyVolGroup -n homevol /dev/sda1\nThe new LV will appear as\n/dev/MyVolGroup/homevol\n. Now you can\nformat\nthe LV with an appropriate file system.\nYou can check the LV is created using the following command:\n# lvs\nRenaming a logical volume\nTo rename an existing logical volume, use the\nlvrename(8)\ncommand.\nEither of the following commands renames logical volume\nold_vol\nin volume group\nMyVolGroup\nto\nnew_vol\n.\n# lvrename /dev/MyVolGroup/old_vol /dev/MyVolGroup/new_vol\n# lvrename MyVolGroup old_vol new_vol\nMake sure to update all configuration files (e.g.\n/etc/fstab\nor\n/etc/crypttab\n) that reference the renamed logical volume.\nResizing the logical volume and file system in one go\nNote\nOnly\next2\n,\next3\n,\next4\n,\nReiserFS\nand\nXFS\nfile systems\nare supported. For a different type of file system see\n#Resizing the logical volume and file system separately\n.\nExtend the logical volume\nmediavol\nin\nMyVolGroup\nby 10 GiB  and resize its file system\nall at once\n:\n# lvresize -L +10G --resizefs MyVolGroup/mediavol\nSet the size of logical volume\nmediavol\nin\nMyVolGroup\nto 15 GiB and resize its file system\nall at once\n:\n# lvresize -L 15G --resizefs MyVolGroup/mediavol\nIf you want to fill all the free space on a volume group, use the following command:\n# lvresize -l +100%FREE --resizefs MyVolGroup/mediavol\nSee\nlvresize(8)\nfor more detailed options.\nResizing the logical volume and file system separately\nFor file systems not supported by\nfsadm(8)\nwill need to use the\nappropriate utility\nto resize the file system before shrinking the logical volume or after expanding it.\nTo extend logical volume\nmediavol\nwithin volume group\nMyVolGroup\nby 2 GiB\nwithout\ntouching its file system:\n# lvresize -L +2G MyVolGroup/mediavol\nNow expand the file system (\next4\nin this example) to the maximum size of the underlying logical volume:\n# resize2fs /dev/MyVolGroup/mediavol\nFor\nBtrfs\n,\nbtrfs-filesystem(8)\nexpects the mountpoint instead of the device, the equivalent is:\n# btrfs filesystem resize max\n/mnt/my-mountpoint\nTo reduce the size of logical volume\nmediavol\nin\nMyVolGroup\nby 500 MiB, first calculate the resulting file system size and shrink the file system (\nExt4\nin this example) to the new size:\n# resize2fs /dev/MyVolGroup/mediavol\nNewSize\nUnlike Ext4,\nBtrfs\nsupports online shrinking (again, a mountpoint should be specified) e.g.:\n# btrfs filesystem resize -500M\n/mnt/my-mountpoint\nWhen the file system is shrunk, reduce the size of logical volume:\n# lvresize -L -500M MyVolGroup/mediavol\nTo calculate the exact logical volume size for\next2\n,\next3\n,\next4\nfile systems, use a simple formula:\nLVM_EXTENTS = FS_BLOCKS × FS_BLOCKSIZE ÷ LVM_EXTENTSIZE\n.\n# tune2fs -l /dev/MyVolGroup/mediavol | grep Block\nBlock count:              102400000\nBlock size:               4096\nBlocks per group:         32768\n# vgdisplay MyVolGroup | grep \"PE Size\"\nPE Size               4.00 MiB\nNote\nThe file system block size is in bytes. Make sure to use the same units for both block and extent size.\n102400000 blocks × 4096 bytes/block ÷ 4 MiB/extent = 100000 extents\nPassing\n--resizefs\nwill confirm that the correctness.\n# lvreduce -l 100000 --resizefs /dev/MyVolGroup/mediavol\n...\nThe filesystem is already 102400000 (4k) blocks long.  Nothing to do!\n...\nLogical volume sysvg/root successfully resized.\nSee\nlvresize(8)\nfor more detailed options.\nRemoving a logical volume\nWarning\nBefore you remove a logical volume, make sure to move all data that you want to keep somewhere else; otherwise, it will be lost!\nFirst, find out the name of the logical volume you want to remove. You can get a list of all logical volumes with:\n# lvs\nNext, look up the mountpoint of the chosen logical volume:\n$ lsblk\nThen unmount the filesystem on the logical volume:\n# umount /\nmountpoint\nFinally, remove the logical volume:\n# lvremove\nvolume_group\n/\nlogical_volume\nFor example:\n# lvremove MyVolGroup/homevol\nConfirm by typing in\ny\n.\nMake sure to update all configuration files (e.g.\n/etc/fstab\nor\n/etc/crypttab\n) that reference the removed logical volume.\nYou can verify the removal of the logical volume by typing\nlvs\nas root again (see first step of this section).\nSnapshots\nLVM supports CoW (Copy-on-Write) snapshots. A CoW snapshot initially points to the original data. When data blocks are overwritten, the original copy is left intact and the new blocks are written elsewhere on-disk. This has several desirable properties:\nCreating snapshots is fast, because it does not copy data (just the much shorter list of pointers to the on-disk locations).\nSnapshots require just enough free space to hold the new data blocks (plus a negligible amount for the pointers to the new blocks). For example, a snapshot of 35 GiB of data, where you write only 2 GiB (on both the original and snapshot), only requires 2 GiB of free space.\nLVM snapshots are at the block level. They make a new block device, with no apparent relationship to the original except when dealing with the LVM tools. Therefore, deleting files in the original copy does not free space in the snapshots. If you need filesystem-level snapshots, you rather need\nbtrfs\n,\nZFS\nor\nbcachefs\n.\nWarning\nA CoW snapshot\nis not a backup\n, because it does not make a second copy of the original data. For example, a damaged disk sector that affects original data also affects the snapshots. That said, a snapshot can be helpful while using other tools to make backups, as outlined\nbelow\n.\nBtrfs expects different filesystems to have different UUIDs. If you snapshot a LVM volume that contains a btrfs filesystem, make sure to change the UUID of the original or the copy, before both are mounted (or made visible to the kernel, for example if an unrelated daemon triggers a\nbtrfs device scan\n). For details see\nbtrfs wiki Gotcha's\n.\nConfiguration\nYou create snapshot logical volumes just like normal ones.\n# lvcreate --size 100M --snapshot --name snap01vol /dev/MyVolGroup/lvol\nWith that volume, you may modify less than 100 MiB of data, before the snapshot volume fills up.\nReverting the modified\nlvol\nlogical volume to the state when the\nsnap01vol\nsnapshot was taken can be done with\n# lvconvert --merge /dev/MyVolGroup/snap01vol\nIn case the origin logical volume is active, merging will occur on the next reboot (merging can be done even from a LiveCD).\nNote\nThe snapshot will no longer exist after merging.\nAlso multiple snapshots can be taken and each one can be merged with the origin logical volume at will.\nBackups\nA snapshot provides a frozen copy of a file system to make backups. For example, a backup taking two hours provides a more consistent image of the file system than directly backing up the partition.\nThe snapshot can be mounted and backed up with\ndd\nor\ntar\n. The size of the backup file done with\ndd\nwill be the size of the files residing on the snapshot volume.\nTo restore just create a snapshot, mount it, and write or extract the backup to it. And then merge it with the origin.\nSee\nCreate root filesystem snapshots with LVM\nfor automating the creation of clean root file system snapshots during system startup for backup and rollback.\nThis article or section needs expansion.\nReason:\nShow scripts to automate snapshots of root before updates, to rollback... updating\nmenu.lst\nto boot snapshots (maybe in a separate article?) (Discuss in\nTalk:LVM\n)\nEncryption\nSee\ndm-crypt/Encrypting an entire system#LUKS on LVM\nand\ndm-crypt/Encrypting an entire system#LVM on LUKS\nfor the possible schemes of combining LUKS with LVM.\nCache\nThis article or section needs expansion.\nReason:\nLVM also supports\n--type writecache\nwhich uses dm-writecache. (Discuss in\nTalk:LVM\n)\nFrom\nlvmcache(7)\n:\nThe cache logical volume type uses a small and fast LV to improve the performance of a large and slow LV. It does this by storing the frequently used blocks on the faster LV. LVM refers to the small fast LV as a cache pool LV. The large slow LV is called the origin LV. Due to requirements from dm-cache (the kernel driver), LVM further splits the cache pool LV into two devices - the cache data LV and cache metadata LV. The cache data LV is where copies of data blocks are kept from the origin LV to increase speed. The cache metadata LV holds the accounting information that specifies where data blocks are stored (e.g. on the origin LV or on the cache data LV).  Users should be familiar with these LVs if they wish to create the best and most robust cached logical volumes. All of these associated LVs must be in the same VG.\nCreate cache\nConvert your fast disk (\n/dev/\nfastdisk\n) to PV and add to your existing VG (\nMyVolGroup\n):\n# vgextend MyVolGroup /dev/\nfastdisk\nUsing a cache logical volume\nCreate a cache logical volume with automatic metadata on\n/dev/\nfastdisk\nand convert the existing LV\nMyVolGroup/rootvol\nto a cached LV, all in one step:\n# lvcreate --type cache --cachemode writethrough -l 100%FREE -n root_cachevol MyVolGroup/rootvol /dev/\nfastdisk\nTip\nInstead of using\n-l 100%FREE\nto allocate 100% of available space from PV\n/dev/\nfastdisk\n, you can use\n-L 20G\ninstead to allocate only 20 GiB for cachevol.\nUsing a cache pool\nWith a cache logical volume, LVM automatically manages metadata and data for the cache. But you can also manually create the metatada and cache LVs, and create a cache pool:\n# lvcreate -n cache_meta -l 1%FREE MyVolGroup /dev/\nfastdisk\n# lvcreate -n cache_data -l 100%FREE MyVolGroup /dev/\nfastdisk\n# lvconvert --type cache-pool --cachemode writeback --poolmetadata MyVolGroup/cache_meta MyVolGroup/cache_data\n# lvconvert --type cache --cachepool MyVolGroup/cache_data MyVolGroup/rootvol\nCachemode options\nCachemode has two possible options:\nwritethrough\nensures that any data written will be stored both in the cache LV and on the origin LV. The loss of a device associated with the cache LV in this case would not mean the loss of any data;\nwriteback\nensures better performance, but at the cost of a higher risk of data loss in case the drive used for cache fails.\nIf a specific\n--cachemode\nis not indicated, the system will assume\nwritethrough\nas default.\nTip\nCache hit and miss counts can be viewed with\nlvdisplay\nor alternatively with\nlvm-cache-stats\nfrom\nlibblockdev-lvm\nwhich also shows them in percentages.\nRemove cache\nIf you ever need to undo the one step creation operation above:\n# lvconvert --uncache MyVolGroup/rootvol\nThis commits any pending writes still in the cache back to the origin LV, then deletes the cache. Other options are available and described in\nlvmcache(7)\n.\nRAID\nLVM may be used to create a\nsoftware RAID\n. It is a good choice if the user does not have hardware RAID and was planning on using LVM anyway. From\nlvmraid(7)\n:\nlvm(8)\nRAID is a way to create a Logical Volume (LV) that uses multiple physical devices to improve performance or tolerate device failures.  In LVM, the physical devices are Physical Volumes (PVs) in a single Volume Group (VG).\nLVM RAID supports RAID 0, RAID 1, RAID 4, RAID 5, RAID 6 and RAID 10. See\nWikipedia:Standard RAID levels\nfor details on each level.\nTip\nmdadm\nmay also be used to create a software RAID. It is arguably simpler, more popular, and easier to setup.\nSetup RAID\nCreate physical volumes:\n# pvcreate /dev/sda2 /dev/sdb2\nCreate volume group on the physical volumes:\n# vgcreate MyVolGroup /dev/sda2 /dev/sdb2\nNew volumes\nCreate logical volumes using\nlvcreate --type\nraidlevel\n, see\nlvmraid(7)\nand\nlvcreate(8)\nfor more options.\n# lvcreate --type RaidLevel [OPTIONS] -n Name -L Size VG [PVs]\nPlease mind how the examples below each specify the physical volumes. This can make sense in some situations to have LVM use a specific subset of devices for your new logical volume. But generally speaking, this is not necessary.\nRAID 0\nFor example:\n# lvcreate -n myraid1vol -i 2 -I 64 -L 70G VolGroup00 /dev/nvme1n1p1 /dev/nvme0n1p1\nwill create a 70 GiB striped (raid0) logical volume named \"myraid1vol\" in VolGroup00. Stripes will be spread over\n/dev/nvme1n1p1\nand\n/dev/nvme0n1p1\n. Stripesize is set to be 64K.\nRAID 1\nFor example:\n# lvcreate --type raid1 --mirrors 1 -L 20G -n myraid1vol MyVolGroup /dev/sda2 /dev/sdb2\nwill create a 20 GiB mirrored logical volume named \"myraid1vol\" in VolGroup00 on\n/dev/sda2\nand\n/dev/sdb2\n.\nRAID 5\nRAID5 requires at least three drives (number of\n--stripes\nplus one parity device). Data and parity blocks are stored on each device, typically in a rotating pattern.\nFor example:\n# lvcreate --type raid5 --stripes 2 -L 40G -n myraid5vol MyVolGroup /dev/sda2 /dev/sdb2 /dev/sdc2\nwill create a 40 GiB striped logical volume named \"myraid5vol\" in VolGroup00 on\n/dev/sda2\n,\n/dev/sdb2\nand\n/dev/sdc2\n. On each disk, the RAID5 will occupy about 20 GiB.\nRAID 6\nRAID6 requires at least five drives (number of\n--stripes\nplus two parity devices). As with RAID5, data and parity blocks are stored on each device, typically in a rotating pattern.\nFor example:\n# lvcreate --type raid6 --stripes 3 -L 60G -n myraid6vol MyVolGroup /dev/sda2 /dev/sdb2 /dev/sdc2 /dev/sdd2\nwill create a 60 GiB striped logical volume named \"myraid6vol\" in VolGroup00 on\n/dev/sda2\n,\n/dev/sdb2\n,\n/dev/sdc2\nand\n/dev/sdd2\n. On each disk, the RAID6 will occupy about 20 GiB.\nRAID 10\nFor example:\n# lvcreate -n myraid1vol -L 100G --type raid10 -m 1 -i 2 MyVolGroup /dev/sdd1 /dev/sdc1 /dev/sdb1 /dev/sda5\nwill create a 100 GiB RAID10 logical volume named \"myraid1vol\" in VolGroup00 on\n/dev/sdd1\n,\n/dev/sdc1\n,\n/dev/sdb1\n, and\n/dev/sda5\n.\nExisting volumes\nYou can convert easily a non-RAID (e.g. linear) volume to pretty much any other raid configuration provided that you have enough physical devices to meet the RAID requirements. Some of them will require you to go through intermediate steps which\nlvconvert\nwill inform you about and prompt you to agree.\nraid10\nbelow can be replaced with\nraid0\n,\nraid1\n,\nraid5\netc.\n# lvconvert --type raid10 /dev/vg01/lv01\nUse specific PVs:\n# lvconvert --type raid10 /dev/vg01/lv01 /dev/sda1 /dev/sdb2 /dev/nvme0n1p1 ...\nYou can keep track of the progress of conversion with:\n# watch lvs -o name,vg_name,copy_percent\nThin provisioning\nNote\nWhen mounting a thin LV file system, always remember to use the\ndiscard\noption or to use\nfstrim\nregularly, to allow the thin LV to shrink as files are deleted.\nFrom\nlvmthin(7)\n:\nBlocks in a standard\nlvm(8)\nLogical Volume (LV) are allocated when the LV is created, but blocks in a thin provisioned LV are allocated as they are written. Because of this, a thin provisioned LV is given a virtual size, and can then be much larger than physically available storage. The amount of physical storage provided for thin provisioned LVs can be increased later as the need arises.\nExample: implementing virtual private servers\nHere is the classic use case. Suppose you want to start your own VPS service, initially hosting about 100 VPSes on a single PC with a 930 GiB hard drive. Hardly any of the VPSes will actually use all of the storage they are allotted, so rather than allocate 9 GiB to each VPS, you could allow each VPS a maximum of 30 GiB and use thin provisioning to only allocate as much hard drive space to each VPS as they are actually using. Suppose the 930 GiB hard drive is\n/dev/sdb\n. Here is the setup.\nPrepare the volume group,\nMyVolGroup\n.\n# vgcreate MyVolGroup /dev/sdb\nCreate the thin pool LV,\nMyThinPool\n. This LV provides the blocks for storage.\n# lvcreate --type thin-pool -n MyThinPool -l 95%FREE MyVolGroup\nThe thin pool is composed of two sub-volumes, the data LV and the metadata LV. This command creates both automatically. But the thin pool stops working if either fills completely, and LVM currently does not support the shrinking of either of these volumes. This is why the above command allows for 5% of extra space, in case you ever need to expand the data or metadata sub-volumes of the thin pool.\nFor each VPS, create a thin LV. This is the block device exposed to the user for their root partition.\n# lvcreate -n SomeClientsRoot -V 30G --thinpool MyThinPool MyVolGroup\nThe block device\n/dev/MyVolGroup/SomeClientsRoot\nmay then be used by a\nVirtualBox\ninstance as the root partition.\nUse thin snapshots to save more space\nThin snapshots are much more powerful than regular snapshots, because they are themselves thin LVs. See Red Hat's guide\n[4]\nfor a complete list of advantages thin snapshots have.\nInstead of installing Linux from scratch every time a VPS is created, it is more space-efficient to start with just one thin LV containing a basic installation of Linux:\n# lvcreate -n GenericRoot -V 30G --thinpool MyThinPool MyVolGroup\n*** install Linux at /dev/MyVolGroup/GenericRoot ***\nThen create snapshots of it for each VPS:\n# lvcreate -s MyVolGroup/GenericRoot -n SomeClientsRoot\nThis way, in the thin pool there is only one copy the data common to all VPSes, at least initially. As an added bonus, the creation of a new VPS is instantaneous.\nSince these are thin snapshots, a write operation to\nGenericRoot\nonly causes one COW operation in total, instead of one COW operation per snapshot. This allows you to update\nGenericRoot\nmore efficiently than if each VPS were a regular snapshot.\nExample: zero-downtime storage upgrade\nThere are applications of thin provisioning outside of VPS hosting. Here is how you may use it to grow the effective capacity of an already-mounted file system without having to unmount it. Suppose, again, that the server has a single 930 GiB hard drive. The setup is the same as for VPS hosting, only there is only one thin LV and the LV's size is far larger than the thin pool's size.\n# lvcreate -n MyThinLV -V 16T --thinpool MyThinPool MyVolGroup\nThis extra virtual space can be filled in with actual storage at a later time by extending the thin pool.\nSuppose some time later, a storage upgrade is needed, and a new hard drive,\n/dev/sdc\n, is plugged into the server. To upgrade the thin pool's capacity, add the new hard drive to the VG:\n# vgextend MyVolGroup /dev/sdc\nNow, extend the thin pool:\n# lvextend -l +95%FREE MyVolGroup/MyThinPool\nSince this thin LV's size is 16 TiB, you could add another 15.09 TiB of hard drive space before finally having to unmount and resize the file system.\nNote\nYou will probably want to use\nreserved blocks\nor a\ndisk quota\nto prevent applications from attempting to use more physical storage than there actually is.\nCustomizing\nSome customisation is available by editing\n/etc/lvm/lvm.conf\n. You may find it useful to customize the output of\nlvs\nand\npvs\nwhich by default does not include the % sync (useful to see progress of conversion between e.g. linear and raid type) and type of logical volume:\n/etc/lvm/lvm.conf\nreport {\nlvs_cols = \"lv_name,lv_attr,lv_active,vg_name,lv_size,lv_layout,lv_allocation_policy,copy_percent,chunk_size\"\npvs_cols = \"pv_name,vg_name,pv_size,pv_free,pv_used,dev_size\"\n}\nTroubleshooting\nLVM commands do not work\nLoad proper module:\n# modprobe dm_mod\nThe\ndm_mod\nmodule should be automatically loaded. In case it does not, explicitly\nload the module at boot\n.\nTry preceding commands with\nlvm\nlike this:\n# lvm pvdisplay\nLogical volumes do not show up\nIf you are trying to mount existing logical volumes, but they do not show up in\nlvscan\n, you can use the following commands to activate them:\n# vgscan\n# vgchange -ay\nLVM on removable media\nSymptoms:\n# vgscan\nReading all physical volumes.  This may take a while...\n/dev/backupdrive1/backup: read failed after 0 of 4096 at 319836585984: Input/output error\n/dev/backupdrive1/backup: read failed after 0 of 4096 at 319836643328: Input/output error\n/dev/backupdrive1/backup: read failed after 0 of 4096 at 0: Input/output error\n/dev/backupdrive1/backup: read failed after 0 of 4096 at 4096: Input/output error\nFound volume group \"backupdrive1\" using metadata type lvm2\nFound volume group \"networkdrive\" using metadata type lvm2\nCause: removing an external LVM drive without deactivating the volume group(s) first. Before you disconnect, make sure to:\n# vgchange -an\nvolume_group_name\nFix: assuming you already tried to activate the volume group with\nvgchange -ay\nvg\n, and are receiving the Input/output errors:\n# vgchange -an\nvolume_group_name\nUnplug the external drive and wait a few minutes:\n# vgscan\n# vgchange -ay\nvolume_group_name\nSuspend/resume with LVM and removable media\nThe factual accuracy of this article or section is disputed.\nReason:\nProvided solution will not work in more complex setups like LUKS on LVM. (Discuss in\nTalk:LVM#LVM on removable media\n)\nIn order for LVM to work properly with removable media – like an external USB drive – the volume group of the external drive needs to be deactivated before suspend. If this is not done, you may get buffer I/O errors on the dm device (after resume). For this reason, it is not recommended to mix external and internal drives in the same volume group.\nTo automatically deactivate the volume groups with external USB drives, tag each volume group with the\nsleep_umount\ntag in this way:\n# vgchange --addtag sleep_umount\nvg_external\nOnce the tag is set, use the following unit file for systemd to properly deactivate the volumes before suspend. On resume, they will be automatically activated by LVM.\n/etc/systemd/system/ext_usb_vg_deactivate.service\n[Unit]\nDescription=Deactivate external USB volume groups on suspend\nBefore=sleep.target\n[Service]\nType=oneshot\nExecStart=-/etc/systemd/system/deactivate_sleep_vgs.sh\n[Install]\nWantedBy=sleep.target\nand this script:\n/etc/systemd/system/deactivate_sleep_vgs.sh\n#!/bin/sh\nTAG=@sleep_umount\nvgs=$(vgs --noheadings -o vg_name $TAG)\necho \"Deactivating volume groups with $TAG tag: $vgs\"\n# Unmount logical volumes belonging to all the volume groups with tag $TAG\nfor vg in $vgs; do\nfor lv_dev_path in $(lvs --noheadings  -o lv_path -S lv_active=active,vg_name=$vg); do\necho \"Unmounting logical volume $lv_dev_path\"\numount $lv_dev_path\ndone\ndone\n# Deactivate volume groups tagged with sleep_umount\nfor vg in $vgs; do\necho \"Deactivating volume group $vg\"\nvgchange -an $vg\ndone\nFinally,\nenable\nthe unit.\nResizing a contiguous logical volume fails\nIf trying to extend a logical volume errors with:\n\" Insufficient suitable contiguous allocatable extents for logical volume \"\nThe reason is that the logical volume was created with an explicit contiguous allocation policy (options\n-C y\nor\n--alloc contiguous\n) and no further adjacent contiguous extents are available.\n[5]\n[\ndead link\n2025-11-17—SSL error]\nTo fix this, prior to extending the logical volume, change its allocation policy with\nlvchange --alloc inherit\nlogical_volume\n. If you need to keep the contiguous allocation policy, an alternative approach is to move the volume to a disk area with sufficient free extents. See\n[6]\n.\nCommand \"grub-mkconfig\" reports \"unknown filesystem\" errors\nMake sure to remove snapshot volumes before\ngenerating grub.cfg\n.\nThinly-provisioned root volume device times out\nWith a large number of snapshots,\nthin_check\nruns for a long enough time so that waiting for the root device times out. To compensate, add the\nrootdelay=60\nkernel boot parameter to your boot loader configuration.  Or, make\nthin_check\nskip checking block mappings (see\n[7]\n) and\nregenerate the initramfs\n:\n/etc/lvm/lvm.conf\nthin_check_options = [ \"-q\", \"--clear-needs-check-flag\", \"--skip-mappings\" ]\nDelay on shutdown\nIf you use RAID, snapshots or thin provisioning and experience a delay on shutdown, make sure\nlvm2-monitor.service\nis\nstarted\n. See\nFS#50420\n.\nHibernating into a thinly-provisioned swap volume\nSee\nPower management/Suspend and hibernate#Hibernation into a thinly-provisioned LVM volume\n.\nSee also\nLVM2 Resource Page\non SourceWare.org\nGentoo:LVM\nRed Hat Enterprise 9: Configuring and managing logical volumes\nUbuntu LVM Guide Part 1\nPart 2 details snapshots\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=LVM&oldid=853734\n\"\nCategory\n:\nStorage virtualization\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Accuracy\nPages with dead links\nSearch\nSearch\nLVM\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/LVM"}}
{"text": "dm-crypt - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\ndm-crypt\n10 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPolski\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\nData-at-rest encryption\nRemoving system encryption\ndm-crypt is the Linux kernel's\ndevice mapper\ncrypto target. From\nWikipedia:dm-crypt\n, it is:\na transparent disk encryption subsystem in [the] Linux kernel... [It is] implemented as a device mapper target and may be stacked on top of other device mapper transformations.  It can thus encrypt whole disks (including removable media), partitions, software RAID volumes, logical volumes, as well as files. It appears as a block device, which can be used to back file systems, swap or as an LVM physical volume.\nUsage\n/Drive preparation\nDeals with operations like\nsecurely erasing the drive\nand\ndm-crypt\nspecific points for\npartitioning it\n.\n/Device encryption\nCovers how to manually utilize dm-crypt to encrypt a system through the\ncryptsetup\ncommand. It covers examples of the\nencryption options\n, deals with the creation of\nkeyfiles\n, LUKS specific commands for\nkey management\nas well as for\nBackup and restore\n.\n/System configuration\nIllustrates how to configure\nmkinitcpio\n,\nkernel parameters\nand the\ncrypttab\nfile when encrypting a system.\n/Swap encryption\nCovers how to add swap to an encrypted system, as swap must be encrypted as well to protect any data swapped out by the system. This part details methods\nwithout\nand\nwith\nsuspend-to-disk support.\n/Specialties\nDeals with special operations like\nsecuring the unencrypted boot partition\n,\nusing GPG or OpenSSL encrypted keyfiles\n, a method to\nboot and unlock via the network\n, another for\nsetting up discard/TRIM for a SSD\n, and sections dealing with\nthe encrypt hook and multiple disks\n.\n/Mounting at login\nExample scenarios\n/Encrypting a non-root file system\nIf you need to encrypt a device that is not used for booting a system, like a\npartition\nor a\nfile container\n.\n/Encrypting an entire system\nIf you want to encrypt an entire system, in particular a root partition. Several scenarios are covered, including the use of\ndm-crypt\nwith the\nLUKS\nextension,\nplain\nmode encryption and encryption and\nLVM\n.\nSee also\ndm-crypt\n- The project homepage\ncryptsetup\n- The LUKS homepage and\nFAQ\n- the main and foremost help resource.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Dm-crypt&oldid=838291\n\"\nCategory\n:\nData-at-rest encryption\nSearch\nSearch\ndm-crypt\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Dm-crypt"}}
{"text": "dm-crypt - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\ndm-crypt\n10 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPolski\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\n(Redirected from\nLUKS\n)\nRelated articles\nData-at-rest encryption\nRemoving system encryption\ndm-crypt is the Linux kernel's\ndevice mapper\ncrypto target. From\nWikipedia:dm-crypt\n, it is:\na transparent disk encryption subsystem in [the] Linux kernel... [It is] implemented as a device mapper target and may be stacked on top of other device mapper transformations.  It can thus encrypt whole disks (including removable media), partitions, software RAID volumes, logical volumes, as well as files. It appears as a block device, which can be used to back file systems, swap or as an LVM physical volume.\nUsage\n/Drive preparation\nDeals with operations like\nsecurely erasing the drive\nand\ndm-crypt\nspecific points for\npartitioning it\n.\n/Device encryption\nCovers how to manually utilize dm-crypt to encrypt a system through the\ncryptsetup\ncommand. It covers examples of the\nencryption options\n, deals with the creation of\nkeyfiles\n, LUKS specific commands for\nkey management\nas well as for\nBackup and restore\n.\n/System configuration\nIllustrates how to configure\nmkinitcpio\n,\nkernel parameters\nand the\ncrypttab\nfile when encrypting a system.\n/Swap encryption\nCovers how to add swap to an encrypted system, as swap must be encrypted as well to protect any data swapped out by the system. This part details methods\nwithout\nand\nwith\nsuspend-to-disk support.\n/Specialties\nDeals with special operations like\nsecuring the unencrypted boot partition\n,\nusing GPG or OpenSSL encrypted keyfiles\n, a method to\nboot and unlock via the network\n, another for\nsetting up discard/TRIM for a SSD\n, and sections dealing with\nthe encrypt hook and multiple disks\n.\n/Mounting at login\nExample scenarios\n/Encrypting a non-root file system\nIf you need to encrypt a device that is not used for booting a system, like a\npartition\nor a\nfile container\n.\n/Encrypting an entire system\nIf you want to encrypt an entire system, in particular a root partition. Several scenarios are covered, including the use of\ndm-crypt\nwith the\nLUKS\nextension,\nplain\nmode encryption and encryption and\nLVM\n.\nSee also\ndm-crypt\n- The project homepage\ncryptsetup\n- The LUKS homepage and\nFAQ\n- the main and foremost help resource.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Dm-crypt&oldid=838291\n\"\nCategory\n:\nData-at-rest encryption\nSearch\nSearch\ndm-crypt\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/LUKS"}}
{"text": "Network configuration - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nNetwork configuration\n9 languages\nČeština\nEspañol\nSuomi\nMagyar\nItaliano\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nDomain name resolution\nFirewalls\nInternet sharing\nNetwork Debugging\nRouter\nThis article describes how to configure network connections on\nOSI layer 3\nand above. Medium-specifics are handled in the\n/Ethernet\nand\n/Wireless\nsubpages.\nCheck the connection\nThis article or section needs expansion.\nReason:\nStep 4. is unclear,\n#Routing table\ndoes not explain what a correct setup looks like. (Discuss in\nTalk:Network configuration\n)\nTo troubleshoot a network connection, go through the following conditions and ensure that you meet them:\nYour\nnetwork interface\nis listed and enabled. Otherwise, check the device driver – see\n/Ethernet#Device driver\nor\n/Wireless#Device driver\n.\nYou are connected to the network. The cable is plugged in or you are\nconnected to the wireless LAN\n.\nYour network interface has an\nIP address\n.\nYour\nrouting table\nis correctly set up.\nYou can\nping\na local IP address (e.g. your default gateway).\nYou can\nping\na public IP address (e.g.\n9.9.9.9\n, which is a DNS server operated by the Quad9 Foundation and is a convenient address to test with).\nCheck if you can resolve domain names\n(e.g.\narchlinux.org\n).\nNote\nIf your network is fine during install, but can't ping in the new system, even having proper networking services (e.g.\nNetworkManager\n) installed, check whether your network needed device authenation (i.e. School network). If so, wait prabably 2 hours and try again. The reason may be that during the installation, the host name \"archiso\", is changed to \"archlinux\" in the installed system, causing authenation failure, therefore ignoring the connection request from the new system.\nPing\nping\nis used to test if you can reach a host.\n$ ping www.example.com\nPING www.example.com (93.184.216.34) 56(84) bytes of data.\n64 bytes from 93.184.216.34 (93.184.216.34): icmp_seq=1 ttl=56 time=11.632 ms\n64 bytes from 93.184.216.34 (93.184.216.34): icmp_seq=2 ttl=56 time=11.726 ms\n64 bytes from 93.184.216.34 (93.184.216.34): icmp_seq=3 ttl=56 time=10.683 ms\n...\nFor every reply received, the\nping\nutility will print a line like the above until you interrupt (\nCtrl+c\n) it interactively. For more information see the\nping(8)\nmanual. Note that computers can be configured not to respond to ICMP echo requests.\n[1]\nIf you receive an error message (see\nping error indications\n) or no reply, this may be related to incomplete configuration, but also your default gateway or your Internet Service Provider (ISP). You can run a\ntraceroute\nto further diagnose the route to the host.\nNetwork management\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nSplit into manual configuration with iproute2 and automatic with DHCP & SLAAC. (Discuss in\nTalk:Network configuration#Style_notice_in_Network_Management_section\n)\nTo set up a network connection, go through the following steps:\nEnsure your\nnetwork interface\nis listed and enabled.\nConnect to the network. Plug in the Ethernet cable or\nconnect to the wireless LAN\n.\nConfigure your network connection:\nMost networks use the\nDynamic Host Configuration Protocol\nfor network configuration. Clients can automatically obtain a dynamic or static IP address from the DHCP server via\na standalone DHCP client or using a network manager\n.\nIf the network does not have a DHCP server, you can configure a static IP address, routing table and DNS servers manually for each client. See\n#Static IP address\nfor details.\nNote\nThe installation image uses\nsystemd-networkd\n, which is configured as a DHCP client for\nEthernet\n,\nWLAN\nand\nWWAN\nnetwork interfaces, and\nsystemd-resolved\nconfigured for system-wide\nDNS\n, see\nsystemd-resolved#DNS\n.\nManual\niproute2\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThis section does not fit in\n#Network management\n– it does not\nmanage\nanything, it only introduces the\niproute2\npackage. (Discuss in\nTalk:Network configuration\n)\niproute2\nis a dependency of the\nbase\nmeta package\nand provides the\nip(8)\ncommand-line interface, used to manage\nnetwork interfaces\n,\nIP addresses\nand the\nrouting table\n. Be aware that configuration made using\nip\nwill be lost after a reboot. For persistent configuration, you can automate\nip\ncommands using scripts and\nsystemd units\n. Also note that\nip\ncommands can generally be abbreviated, for clarity they are however spelled out in this article.\nNote\nArch Linux has deprecated\nnet-tools\nin favor of\niproute2\n.\n[2]\nSee also\nDeprecated Linux networking commands and their replacements\n.\nStatic IP address\nA static IP address can be configured with most standard\nnetwork managers\nand also\ndhcpcd\n.\nTo manually configure a static IP address, add an IP address as described in\n#IP addresses\n, set up your\nrouting table\nand\nconfigure your DNS servers\n.\nIP addresses\nIP addresses\nare managed using\nip-address(8)\n.\nList IP addresses:\n$ ip address show\nAdd an IP address to an interface:\n# ip address add\naddress/prefix_len\nbroadcast + dev\ninterface\nNote that:\nthe address is given in\nCIDR notation\nto also supply a\nsubnet mask\n+\nis a special symbol that makes\nip\nderive the\nbroadcast address\nfrom the IP address and the subnet mask\nNote\nMake sure manually assigned IP addresses do not conflict with DHCP assigned ones.\nDelete an IP address from an interface:\n# ip address del\naddress/prefix_len\ndev\ninterface\nDelete all addresses matching a criteria, e.g. of a specific interface:\n# ip address flush dev\ninterface\nTip\nIPv4 addresses can be calculated with\nipcalc\n(\nipcalc\n).\nRouting table\nThe\nrouting table\nis used to determine if you can reach an IP address directly or what gateway (router) you should use. If no other route matches the IP address, the\ndefault gateway\nis used.\nThe routing table is managed using\nip-route(8)\n.\nPREFIX\nis either a CIDR notation or\ndefault\nfor the default gateway.\nList IPv4 routes:\n$ ip route show\nList IPv6 routes:\n$ ip -6 route show\nAdd a route:\n# ip route add\nPREFIX\nvia\naddress\ndev\ninterface\nDelete a route:\n# ip route del\nPREFIX\nvia\naddress\ndev\ninterface\nAutomatic\nThis article or section needs expansion.\nReason:\nExplain\nSLAAC\n. (Discuss in\nTalk:Network configuration\n)\nAutomatic network configuration is accomplished using\nDynamic Host Configuration Protocol\n(DHCP). The network's DHCP server provides IP address(es), the default gateway IP address(es) and optionally also DNS name servers upon request\nfrom the DHCP client.\nSee\nRouter#DNS and DHCP\nfor a DHCP server comparison table.\nNetwork managers\nA network manager lets you manage network connection settings in so called network profiles to facilitate switching networks.\nTip\nYou can check if a DHCPv4 server is running with\ndhcping\n.\nNote\nEach network interface should be managed by only one DHCP client or network manager, so it is advised to run only one DHCP client or network manager on the system.\nSoftware\nConnection type\nWireless authentication\nIP address, route and DNS management\nInterface\nEthernet\nPPPoE\nMobile broadband\nStatic IP\nDHCP client\nDomain name resolution\nCLI\nTUI\nGUI\ndhclient\n1\nYes\nNo\nNo\nNo\n2\nYes\ninternal\nYes (writes\n/etc/resolv.conf\n)\nNo\nNo\nNo\ndhcpcd\nYes\nNo\nNo\nLaunches wpa_supplicant\n3\nYes\ninternal\nYes\n(uses\nresolvconf\nor writes\n/etc/resolv.conf\n)\nNo\nNo\ndhcpcd-ui\nAUR\nConnMan\nYes\nNo\nYes (via\nofono\nAUR\n)\nYes (via\nwpa_supplicant\nor\niwd\n)\nYes\ninternal\nYes\n(runs a builtin resolver and writes\n/etc/resolv.conf\n)\nconnmanctl(1)\nYes\nYes\nnetctl\nYes\nYes\n(via\nppp\n)\nYes (via\nppp\n)\nYes (via\nwpa_supplicant\n)\nYes\ndhcpcd\nor\ndhclient\nYes\n(uses\nresolvconf\n)\nnetctl(1)\nwifi-menu(1)\n4\nNo\nNetworkManager\nYes\nYes\n(via\nppp\n)\nYes\n(via\nmodemmanager\n)\nYes (via\nwpa_supplicant\nor\niwd\n)\nYes\ninternal,\ndhclient\nor\ndhcpcd\n5\nYes\n(uses\nsystemd-resolved\n,\nresolvconf\nor writes\n/etc/resolv.conf\n)\nnmcli(1)\nnmtui(1)\nYes\nsystemd-networkd\nYes\nNo\nNo\nNo\n2\nYes\ninternal\nYes (uses\nsystemd-resolved\n)\nnetworkctl(1)\nNo\nNo\nwpa_supplicant\nIEEE 802.1X\nNo\nNo\nYes\nNo\nwpa_cli(8)\nNo\nwpa_supplicant_gui\nAUR\niwd\nIEEE 802.1X\nNo\nNo\nYes\nYes\ninternal\nYes\n(uses\nsystemd-resolved\nor\nresolvconf\n)\niwctl(1)\nimpala\niwgtk\nAUR\nNo longer maintained as of early 2022. ISC advises no longer using it in production.\nWireless authentication can be configured separately with\nwpa_supplicant\nor\niwd\n.\nWireless authentication must be configured separately with\nwpa_supplicant\n.\nOnly Wi-Fi connections can be managed.\nNetworkManager does not use dhcpcd for DHCPv6, see\nNetworkManager#DHCP client\n.\nNetwork interfaces\nNetwork interfaces are managed by\nudev\nand configured by\nsystemd.link(5)\nfiles. The default configuration assigns names to your\nnetwork interface controllers\nusing\nPredictable Network Interface Names\n, which prefixes interfaces names with\nen\n(wired/\nEthernet\n),\nwl\n(wireless/\nWLAN\n), or\nww\n(mobile broadband/\nWWAN\n). See\nsystemd.net-naming-scheme(7)\n.\nTip\nThe system\n/usr/lib/systemd/network/99-default.link\nis generally sufficient for most cases.\nTo change interface names, see\n#Change interface name\nand\n#Revert to traditional interface names\n.\nYou can run\nudevadm test-builtin net_setup_link\n/sys/path/to/network/device\nas the root user to diagnose problems with\n.link\nfiles.\nNote\nThe predictable network interface names can change after adding or removing a PCIe device if the system firmware decides to renumber the devices. See\nsystemd issue 33347\n.\nThe\niwd\npackage contains a\n.link\nfile that disables predictable network interface names. Merely having it installed will prevent all network interfaces from being renamed to predictable names. See\niwd#Wireless device is not renamed by udev\n.\nListing network interfaces\nBoth wired and wireless interface names can be found via\nls /sys/class/net\nor\nip link\n. Note that\nlo\nis the\nvirtual loopback interface\nand not used in making network connections.\nWireless device names can also be retrieved using\niw dev\n. See also\n/Wireless#Get the name of the interface\n.\nIf your network interface is not listed, make sure your device driver was loaded successfully. See\n/Ethernet#Device driver\nor\n/Wireless#Device driver\n.\nEnabling and disabling network interfaces\nNetwork interfaces can be enabled or disabled using\nip link set\ninterface\nup|down\n, see\nip-link(8)\n.\nTo check the status of the interface\nenp2s0\n:\n$ ip link show dev enp2s0\n2: enp2s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master br0 state DOWN mode DEFAULT qlen 1000\n...\nThe\nUP\nin\n<BROADCAST,MULTICAST,UP,LOWER_UP>\nis what indicates the interface is up, not the later\nstate DOWN\n.\nNote\nIf your default route is through interface\nenp2s0\n, taking it down will also remove the route, and bringing it back up will not automatically re-establish the default route.  See\n#Routing table\nfor re-establishing it.\nChange interface name\nThis article or section needs expansion.\nReason:\nSuggest using an\nalternative name\n(altname), or assigning one, as an alternative to changing the interface name. (Discuss in\nTalk:Network configuration\n)\nNote\nWhen changing the naming scheme, do not forget to update all network-related configuration files and custom systemd unit files to reflect the change.\nYou can change the device name by defining the name manually with a\nsystemd.link(5)\nfile. The file must be ordered lexicographically before\n99-default.link\n, for example:\n/etc/systemd/network/10-net0.link\n[Match]\nPermanentMACAddress=aa:bb:cc:dd:ee:ff\n[Link]\nName=net0\nAlternatively, a udev rule can be used:\n/etc/udev/rules.d/10-network.rules\nSUBSYSTEM==\"net\", ACTION==\"add\", ATTR{address}==\"aa:bb:cc:dd:ee:ff\", NAME=\"net0\"\nThese rules will be applied automatically at boot. To apply the change immediately, do a manual trigger of the udev rule on the\nnet\nsubsystem:\n# udevadm trigger --verbose --subsystem-match=net --action=add\nIf you want to run a\ntest\non the changes made,\nudevadm --debug test /sys/class/net/*\ncan be of help.\nNote\nThe priority of\nName\nis lower than\nNamePolicy\n, so make sure the latter is unset/empty or the name will not be changed.\nThe network interface must be down before changing its name.\n[3]\nTo get the MAC address of each card, run\nip link\n.\nMake sure to use the lower-case hex values in your udev rules. It does not like upper-case.\nIf the network card has a dynamic MAC, you can use\nPath\n(which can be checked using\nnetworkctl status\ninterface_name\n):\n/etc/systemd/network/10-net1.link\n[Match]\nPath=pci-0000:01:00.0\n[Link]\nName=net1\nOr, use a udev rule with\nDEVPATH\n:\n/etc/udev/rules.d/10-network.rules\nSUBSYSTEM==\"net\", DEVPATH==\"/devices/pci*/*1c.0/*/net/*\", NAME=\"net1\"\nTo get the\nDEVPATH\nof all currently-connected devices, see where the symlinks in\n/sys/class/net/\nlead. For example:\n$ file /sys/class/net/*\n/sys/class/net/enp0s20f0u4u1: symbolic link to ../../devices/pci0000:00/0000:00:14.0/usb2/2-4/2-4.1/2-4.1:1.0/net/enp0s20f0u4u1\n/sys/class/net/enp0s31f6:     symbolic link to ../../devices/pci0000:00/0000:00:1f.6/net/enp0s31f6\n/sys/class/net/lo:            symbolic link to ../../devices/virtual/net/lo\n/sys/class/net/wlp4s0:        symbolic link to ../../devices/pci0000:00/0000:00:1c.6/0000:04:00.0/net/wlp4s0\nThe device path should match both the new and old device name, since the rule may be executed more than once on bootup. For example, in the given rule,\n\"/devices/pci*/*1c.0/*/net/en*\"\nwould be wrong since it will stop matching once the name is changed to\nnet1\n. Only the system-default rule will fire the second time around, causing the name to be changed back.\nIf you are using a USB network device (e.g. Android phone tethering) that has a dynamic MAC address and you want to be able to use different USB ports, you could use a rule that matched depending on vendor and model ID instead:\n/etc/systemd/network/20-net2.link\n[Match]\nProperty=ID_VENDOR_ID=12ab ID_MODEL_ID=3cd4\n[Link]\nName=net2\nor\n/etc/udev/rules.d/10-network.rules\nSUBSYSTEM==\"net\", ACTION==\"add\", ATTRS{idVendor}==\"12ab\", ATTRS{idProduct}==\"3cd4\", NAME=\"net2\"\nNote\nWhen choosing the static names\nit should be avoided to use names in the format of \"eth\nX\n\" and \"wlan\nX\n\"\n, because this may lead to race conditions between the kernel and udev during boot. Instead, it is better to use interface names that are not used by the kernel as default, e.g.:\nnet0\n,\nnet1\n,\nwifi0\n,\nwifi1\n. For further details please see the\nsystemd\ndocumentation.\nRevert to traditional interface names\nIf you would prefer to retain traditional interface names such as\neth0\n,\nPredictable Network Interface Names\ncan be disabled by changing the default\nNamePolicy\nfor udev's\nnet_setup_link\nbuilt-in:\n/etc/systemd/network/99-default.link.d/traditional-naming.conf\n[Link]\nNamePolicy=keep kernel\nAlternatively,\nnet_setup_link\ncan be completely disabled by masking the corresponding udev rule:\n# ln -s /dev/null /etc/udev/rules.d/80-net-setup-link.rules\nor by adding\nnet.ifnames=0\nto the\nkernel parameters\n.\nNote\nsystemd.link(5)\nrelies on\nnet_setup_link\nto work. Prefer to use the first approach unless you fully understand what you are doing.\nSet device MTU and queue length\nThe factual accuracy of this article or section is disputed.\nReason:\nCreating a\n30-mtu.link\nfile means that\n99-default.link\nwill not get applied. (Discuss in\nTalk:Network configuration\n)\nYou can change the device\nMTU\nand queue length by defining manually with a\nsystemd.link(5)\nconfig. For example:\n/etc/systemd/network/30-mtu.link\n[Match]\nType=wlan\n[Link]\nMTUBytes=1500\nTransmitQueueLength=2000\nOr through a udev rule:\n/etc/udev/rules.d/10-network.rules\nACTION==\"add\", SUBSYSTEM==\"net\", KERNEL==\"wl*\", ATTR{mtu}=\"1500\", ATTR{tx_queue_len}=\"2000\"\nMTUBytes\n: Using a value larger than 1500 (so called\njumbo frames\n) can significantly speed up your network transfers. Note that all network interfaces, including switches in the local network, must support the same MTU in order to use jumbo frames. For PPPoE, the MTU should not be larger than 1492. You can also set MTU via\nsystemd.netdev(5)\n.\nTransmitQueueLength\n: Small value for slower devices with a high latency like modem links and ISDN. High value is recommended for server connected over the high-speed internet connections that perform large data transfers.\nSet the hostname\nA\nhostname\nis a unique name created to identify a machine on a network, configured in\n/etc/hostname\n—see\nhostname(5)\nand\nhostname(7)\nfor details. The file can contain the system's domain name, if any. To set the hostname,\nedit\n/etc/hostname\nto include a single line with\nyourhostname\n:\n/etc/hostname\nyourhostname\nTip\nFor advice on choosing a hostname, see\nRFC 1178\n.\nAlternatively, using\nhostnamectl(1)\n:\n# hostnamectl hostname\nyourhostname\nTo temporarily set the hostname (until reboot), use\nhostname(1)\nfrom\ninetutils\n:\n# hostname\nyourhostname\nTo set the \"pretty\" hostname and other machine metadata, see\nmachine-info(5)\n.\nLocal network hostname resolution\nTo make your machine accessible in your LAN via its hostname you can:\nedit the\n/etc/hosts\nfile for every device in your LAN, see\nhosts(5)\nset up a\nDNS server\nto resolve your hostname and make the LAN devices use it (e.g. via\nDHCP\n)\nor the easy way: use a\nZero-configuration networking\nservice:\nHostname resolution via Microsoft's\nNetBIOS\n. Provided by\nSamba\non Linux. It only requires the\nnmb.service\n. Computers running Windows, macOS, or Linux with\nnmb\nrunning, will be able to find your machine.\nHostname resolution via\nmDNS\n. Provided by either\nnss_mdns\nwith\nAvahi\n(see\nAvahi#Hostname resolution\nfor setup details) or\nsystemd-resolved\n. Computers running macOS, or Linux with Avahi or systemd-resolved running, will be able to find your machine. The older Win32 API does not support mDNS, which may prevent some older Windows applications from accessing your device.\nTips and tricks\nBonding or LAG\nSee\nnetctl\nor\nsystemd-networkd\n, or\nWireless bonding\n.\nIP address aliasing\nIP aliasing is the process of adding more than one IP address to a network interface. With this, one node on a network can have multiple connections to a network, each serving a different purpose. Typical uses are virtual hosting of Web and FTP servers, or reorganizing servers without having to update any other machines (this is especially useful for nameservers).\nExample\nTo manually set an alias, for some NIC, use\niproute2\nto execute\n# ip addr add 192.168.2.101/24 dev enp2s0 label enp2s0:1\nTo remove a given alias execute\n# ip addr del 192.168.2.101/24 dev enp2s0:1\nPackets destined for a subnet will use the primary alias by default. If the destination IP is within a subnet of a secondary alias, then the source IP is set respectively. Consider the case where there is more than one NIC, the default routes can be listed with\nip route\n.\nPromiscuous mode\nToggling\npromiscuous mode\nwill make a (wireless) NIC forward all traffic it receives to the OS for further processing. This is opposite to \"normal mode\" where a NIC will drop frames it is not intended to receive. It is most often used for advanced network troubleshooting and\npacket sniffing\n.\n/etc/systemd/system/promiscuous@.service\n[Unit]\nDescription=Set %i interface in promiscuous mode\nAfter=network.target\n[Service]\nType=oneshot\nExecStart=/usr/bin/ip link set dev %i promisc on\nRemainAfterExit=yes\n[Install]\nWantedBy=multi-user.target\nIf you want to enable promiscuous mode on interface\nenp2s0\n,\nenable\npromiscuous@enp2s0.service\n.\nInvestigate sockets\nss\nis a utility to investigate network ports and is part of the\niproute2\npackage. It has a similar functionality to the\ndeprecated\nnetstat utility.\nCommon usage includes:\nDisplay all TCP Sockets with service names:\n$ ss -at\nDisplay all TCP Sockets with port numbers:\n$ ss -atn\nDisplay all UDP Sockets:\n$ ss -au\nFor more information see\nss(8)\n.\nTroubleshooting\nThe TCP window scaling problem\nTCP packets contain a \"window\" value in their headers indicating how much data the other host may send in return. This value is represented with only 16 bits, hence the window size is at most 64KiB. TCP packets are cached for a while (they have to be reordered), and as memory is (or used to be) limited, one host could easily run out of it.\nBack in 1992, as more and more memory became available,\nRFC:1323\nwas written to improve the situation: Window Scaling. The \"window\" value, provided in all packets, will be modified by a Scale Factor defined once, at the very beginning of the connection. That 8-bit Scale Factor allows the Window to be up to 32 times higher than the initial 64KiB.\nIt appears that some broken routers and firewalls on the Internet are rewriting the Scale Factor to 0 which causes misunderstandings between hosts. The Linux kernel 2.6.17 introduced a new calculation scheme generating higher Scale Factors, virtually making the aftermaths of the broken routers and firewalls more visible.\nThe resulting connection is at best very slow or broken.\nHow to diagnose the problem\nFirst of all, let us make it clear: this problem is odd. In some cases, you will not be able to use TCP connections (HTTP, FTP, ...) at all and in others, you will be able to communicate with some hosts (very few).\nWhen you have this problem, the output from\ndmesg\nis okay, logs are clean and\nip addr\nwill report normal status... and actually everything appears normal.\nIf you cannot browse any website, but you can ping some random hosts, chances are great that you are experiencing this problem: ping uses ICMP and is not affected by TCP problems.\nYou can try to use\nWireshark\n. You might see successful UDP and ICMP communications but unsuccessful TCP communications (only to foreign hosts).\nWays of fixing it\nBad\nTo fix it the bad way, you can change the\ntcp_rmem\nvalue, on which Scale Factor calculation is based. Although it should work for most hosts, it is not guaranteed, especially for very distant ones.\n# sysctl -w net.ipv4.tcp_rmem=\"4096 87380 174760\"\nGood\nSimply disable Window Scaling. Since Window Scaling is a nice TCP feature, it may be uncomfortable to disable it, especially if you cannot fix the broken router. There are several ways to disable Window Scaling, and it seems that the most bulletproof way (which will work with most kernels) is to add the following line to\n/etc/sysctl.d/99-disable_window_scaling.conf\n(see also\nsysctl\n):\nnet.ipv4.tcp_window_scaling = 0\nBest\nThis problem is caused by broken routers/firewalls, so let us change them. Some users have reported that the broken router was their very own DSL router.\nMore about it\nThis section is based on the LWN article\nTCP window scaling and broken routers\nand an archived Kernel Trap article:\nWindow Scaling on the Internet\n.\nThere are also several relevant threads on the LKML.\nlocal hostname is resolved over the network\nnss-myhostname(8)\n(an\nNSS\nmodule provided by\nsystemd\nand enabled by default in\n/etc/nsswitch.conf\n) provides\nlocalhost\nand the local\nhostname\nresolution to an IP address. Some software may, however, still instead read\n/etc/hosts\ndirectly; see\n[4]\n[5]\nfor examples.\nTo prevent such software from unsafely resolving the local hostname over the network, add an entry for it to the\nhosts(5)\nfile:\n/etc/hosts\n127.0.0.1        localhost\n::1              localhost\n127.0.1.1\nyourhostname\nFor a system with a permanent IP address, replace\n127.0.1.1\nwith that permanent IP address. For a system with a\nfully qualified domain name\n, insert the fully qualified domain name before the hostname (see the following link for\nthe reasoning\n). For example:\n/etc/hosts\n127.0.0.1        localhost\n::1              localhost\n203.0.113.45     host1.fqdomain.example host1\nNote\nThe order of hostnames/aliases that follow the IP address in\n/etc/hosts\nis significant. The first string is considered the canonical hostname and may be appended with parent domains, where domain components are separated by a dot. All following strings on the same line are considered aliases. See\nhosts(5)\nfor more information.\nSee also\nLinux Network Administrators Guide\nDebian Reference: Network setup\nRHEL7: Networking Guide\nMonitoring and tuning the Linux Networking Stack: Receiving data\nMonitoring and tuning the Linux Networking Stack: Sending data\nTracing a packet journey using tracepoints, perf and eBPF\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Network_configuration&oldid=853724\n\"\nCategory\n:\nNetwork configuration\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Style\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nNetwork configuration\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Network_configuration"}}
{"text": "Network configuration/Wireless - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nNetwork configuration/Wireless\n6 languages\nDeutsch\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\n<\nNetwork configuration\n(Redirected from\nWireless network configuration\n)\nRelated articles\nSoftware access point\nAd-hoc networking\nInternet sharing\nWireless bonding\nNetwork Debugging\nBluetooth\nThe main article on network configuration is\nNetwork configuration\n.\nConfiguring wireless is a two-part process; the first part is to identify and ensure the correct driver for your wireless device is installed (they are available on the installation media, but often have to be installed explicitly), and to configure the interface. The second is choosing a method of managing wireless connections. This article covers both parts, and provides additional links to wireless management tools.\nThe\n#iw\nsection describes how to manually manage your wireless network interface / your wireless LANs using\niw\n. The\nNetwork configuration#Network managers\nsection describes several programs that can be used to automatically manage your wireless interface, some of which include a GUI and all of which include support for network profiles (useful when frequently switching wireless networks, like with laptops).\nDevice driver\nThe default Arch Linux kernel is\nmodular\n, meaning many of the drivers for machine hardware reside on the hard drive and are available as\nmodules\n. At boot,\nudev\ntakes an inventory of your hardware and loads appropriate modules (drivers) for your corresponding hardware, which will in turn allow creation of a network\ninterface\n.\nSome wireless chipsets also require firmware, in addition to a corresponding driver. Many firmware images are provided by the\nlinux-firmware\npackage; however, proprietary firmware images are not included and have to be installed separately. This is described in\n#Installing driver/firmware\n.\nNote\nIf the proper module is not loaded by udev on boot, simply\nload it manually\n. If udev loads more than one driver for a device, the resulting conflict may prevent successful configuration. Make sure to\nblacklist\nthe unwanted module.\nCheck the driver status\nTo check if the driver for your card has been loaded, check the output of the\nlspci -k\nor\nlsusb -v\ncommand, depending on if the card is connected by PCIe or USB. You should see that some kernel driver is in use, for example:\n$ lspci -knnd ::0280\n00:14.3 Network controller [0280]: Intel Corporation BE201 320MHz [8086:a840] (rev 10)\nSubsystem: Intel Corporation Device [8086:00e4]\nKernel driver in use: iwlwifi\nKernel modules: iwlwifi\nNote\nIf the card is a USB device, running\ndmesg | grep usbcore\nas root should give something like\nusbcore: registered new interface driver rtl8187\nas output.\nIf you do not see the card at all, it may not be seated/plugged in properly in its M.2 slot/PCIe slot/USB port. Try re-plugging it in.\nAlso check the output of the\nip link\ncommand to see if a wireless interface was created; usually the naming of the wireless\nnetwork interfaces\nstarts with the letters \"wl\", e.g.\nwlan0\nor\nwlp2s0\n. Then bring the interface up with:\n# ip link set\ninterface\nup\nFor example, assuming the interface is\nwlan0\n, this is\nip link set wlan0 up\n.\nNote\nIf you get errors like\nRTNETLINK answers: Operation not possible due to RF-kill\n, make sure that the device is not hard-blocked or soft-blocked. See\n#Rfkill caveat\nfor details.\nIf you get the error message\nSIOCSIFFLAGS: No such file or directory\n, it most certainly means that your wireless chipset requires a firmware to function.\nCheck kernel messages for firmware being loaded:\n# dmesg | grep firmware\n[    3.347770] iwlwifi 0000:00:14.3: Direct firmware load for iwlwifi-bz-b0-fm-c0-99.ucode failed with error -2\n[    3.351615] iwlwifi 0000:00:14.3: loaded firmware version 98.d661c37c.0 bz-b0-fm-c0-98.ucode op_mode iwlmld\nIf there is no relevant output, check the messages for the full output for the module you identified earlier (\niwlwifi\nin this example) to identify the relevant message or further issues:\n# dmesg | grep iwlwifi\n[    3.330590] iwlwifi 0000:00:14.3: enabling device (0000 -> 0002)\n[    3.347075] iwlwifi 0000:00:14.3: Detected crf-id 0xbadcafe, cnv-id 0x1080900 wfpm id 0x80005b20\n[    3.347090] iwlwifi 0000:00:14.3: PCI dev a840/00e4, rev=0x461, rfid=0x20112200\n[    3.347092] iwlwifi 0000:00:14.3: Detected Intel(R) Wi-Fi 7 BE201 320MHz\n[    3.347770] iwlwifi 0000:00:14.3: Direct firmware load for iwlwifi-bz-b0-fm-c0-99.ucode failed with error -2\n[    3.351213] iwlwifi 0000:00:14.3: TLV_FW_FSEQ_VERSION: FSEQ Version: 0.0.4.196\n[    3.351615] iwlwifi 0000:00:14.3: loaded firmware version 98.d661c37c.0 bz-b0-fm-c0-98.ucode op_mode iwlmld\n[    3.914194] iwlwifi 0000:00:14.3: Detected RF FM, rfid=0x20112200\n[    3.914986] iwlwifi 0000:00:14.3: loaded PNVM version 752be616\nIf the kernel module is successfully loaded and the interface is up, you can skip the next section.\nInstalling driver/firmware\nCheck the following lists to discover if your card is supported:\nSee the table of\nexisting Linux wireless drivers\nand follow to the specific driver's page, which contains a list of supported devices. There is also a\nList of Wi-Fi Device IDs in Linux\n.\nThe\nUbuntu Wiki\nhas a good list of wireless cards and whether or not they are supported either in the Linux kernel or by a user-space driver (includes driver name).\nLinux Wireless Support\nand The Linux Questions'\nHardware Compatibility List\n(HCL) also have a good database of kernel-friendly hardware.\nNote that some vendors ship products that may contain different chip sets, even if the product identifier is the same. Only the USB ID (for USB devices) or PCI ID (for PCIe devices) is authoritative.\nIf your wireless card is listed above, follow the\n#Troubleshooting drivers and firmware\nsubsection of this page, which contains information about installing drivers and firmware of some specific wireless cards. Then\ncheck the driver status\nagain.\nIf your wireless card is not listed above, it is likely supported only under Windows (some Broadcom, 3com, etc). For these, you can try to use\nndiswrapper\n.\nUtilities\nJust like other network interfaces, the wireless ones are controlled with\nip\nfrom the\niproute2\npackage.\nManaging a wireless connection can be accomplished using\nnetwork manager\nwhich will use\nwpa_supplicant\nor\niwd\nfor wireless authentication, or using\nwpa_supplicant\nor\niwd\ndirectly. For lower level configuring, or if you are using a legacy driver or a legacy authentication method, there are\niw\nand the deprecated\nwireless_tools\n.\niw and wireless_tools comparison\nSoftware\nPackage\nWEXT\n2\nnl80211\nWEP\nWPA/WPA2/WPA3\nArchiso\niw\niw\nNo\nYes\nYes\nNo\nYes\nwireless_tools\n1\nwireless_tools\nYes\nNo\nYes\nNo\nYes\nDeprecated.\nNote that some ancient drivers only support WEXT.\nThe table below gives an overview of comparable commands for\niw\nand\nwireless_tools\n. See\nReplacing iwconfig with iw\nfor more examples.\niw\ncommand\nwireless_tools\ncommand\nDescription\niw dev\nwlan0\nlink\niwconfig\nwlan0\nGetting link status.\niw dev\nwlan0\nscan\niwlist\nwlan0\nscan\nScanning for available access points.\niw dev\nwlan0\nset type ibss\niwconfig\nwlan0\nmode ad-hoc\nSetting the operation mode to\nad-hoc\n.\niw dev\nwlan0\nconnect\nyour_essid\niwconfig\nwlan0\nessid\nyour_essid\nConnecting to open network.\niw dev\nwlan0\nconnect\nyour_essid\n2432\niwconfig\nwlan0\nessid\nyour_essid\nfreq 2432M\nConnecting to open network specifying channel.\niw dev\nwlan0\nconnect\nyour_essid\nkey 0:\nyour_key\niwconfig\nwlan0\nessid\nyour_essid\nkey\nyour_key\nConnecting to WEP encrypted network using hexadecimal key.\niwconfig\nwlan0\nessid\nyour_essid\nkey s:\nyour_key\nConnecting to WEP encrypted network using ASCII key.\niw dev\nwlan0\nset power_save on\niwconfig\nwlan0\npower on\nEnabling power save.\niw\nNote\nNote that most of the commands have to be executed with\nroot permissions\n. Executed with normal user rights, some of the commands (e.g.\niw list\n) will exit without error but not produce the correct output either, which can be confusing.\nDepending on your hardware and encryption type, some of these steps may not be necessary. Some cards are known to require interface activation and/or access point scanning before being associated to an access point and being given an IP address. Some experimentation may be required. For instance, WPA/WPA2 users may try to directly activate their wireless network from step\n#Connect to an access point\n.\nExamples in this section assume that your wireless device interface is\ninterface\nand that you are connecting to\nyour_essid\nWi-Fi access point. Replace both accordingly.\nGet the name of the interface\nTip\nSee\nofficial documentation\nof the\niw\ntool for more examples.\nTo get the name of your wireless interface, do:\n$ iw dev\nThe name of the interface will be output after the word \"Interface\". For example, it is commonly\nwlan0\n.\nGet the status of the interface\nTo check link status, use the following command.\n$ iw dev\ninterface\nlink\nYou can get statistic information, such as the amount of tx/rx bytes, signal strength etc., with the following command:\n$ iw dev\ninterface\nstation dump\nActivate the interface\nTip\nUsually this step is not required.\nSome cards require that the kernel interface be activated before you can use\niw\nor\nwireless_tools\n:\n# ip link set\ninterface\nup\nNote\nIf you get errors like\nRTNETLINK answers: Operation not possible due to RF-kill\n, make sure that hardware switch is\non\n. See\n#Rfkill caveat\nfor details.\nTo verify that the interface is up, inspect the output of the following command:\n$ ip link show\ninterface\n3: wlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state DOWN mode DORMANT group default qlen 1000\nlink/ether 12:34:56:78:9a:bc brd ff:ff:ff:ff:ff:ff\nThe\nUP\nin\n<BROADCAST,MULTICAST,UP,LOWER_UP>\nis what indicates the interface is up, not the later\nstate DOWN\n.\nDiscover access points\nTo see what access points are available:\n# iw dev\ninterface\nscan | less\nNote\nIf it displays\nInterface does not support scanning\n, then you probably forgot to install the firmware. In some cases, this message is also displayed when not running\niw\nas root.\nTip\nDepending on your location, you might need to set the correct\nregulatory domain\nin order to see all available networks.\nThe important points to check:\nSSID:\nthe name of the network.\nSignal:\nis reported in a wireless power ratio in dBm (e.g. from -100 to 0). The closer the negative value gets to zero, the better the signal. Observing the reported power on a good quality link and a bad one should give an idea about the individual range.\nSecurity:\nit is not reported directly, check the line starting with\ncapability\n. If there is\nPrivacy\n, for example\ncapability: ESS Privacy ShortSlotTime (0x0411)\n, then the network is protected somehow.\nIf you see an\nRSN\ninformation block, then the network is protected by\nRobust Security Network\nprotocol, also known as WPA2.\nIf you see an\nWPA\ninformation block, then the network is protected by\nWi-Fi Protected Access\nprotocol.\nIn the\nRSN\nand\nWPA\nblocks, you may find the following information:\nGroup cipher:\nvalue in TKIP, CCMP, both, others.\nPairwise ciphers:\nvalue in TKIP, CCMP, both, others. Not necessarily the same value than Group cipher.\nAuthentication suites:\nvalue in PSK, 802.1x, others. For home router, you will usually find PSK (\ni.e.\npassphrase). In universities, you are more likely to find 802.1x suite which requires login and password. Then you will need to know which key management is in use (e.g. EAP), and what encapsulation it uses (e.g. PEAP). See\n#WPA2 Enterprise\nand\nWikipedia:Authentication protocol\nfor details.\nIf you see neither\nRSN\nnor\nWPA\nblocks but there is\nPrivacy\n, then WEP is used.\nSet operating mode\nYou might need to set the proper operating mode of the wireless card. More specifically, if you are going to connect an\nad-hoc network\n, you need to set the operating mode to\nibss\n:\n# iw dev\ninterface\nset type ibss\nNote\nChanging the operating mode on some cards might require the wireless interface to be\ndown\n(\nip link set\ninterface\ndown\n).\nNote\nDuring changing of the operating mode to AP (\niw\ninterface\nset type ap\n) you will get an error like this:\nYou need to run a management daemon, e.g. hostapd,\nsee\nhttps://wireless.wiki.kernel.org/en/users/documentation/hostapd\nfor more information on how to do that.\nThis can be bypassed by changing the operating mode to\n__ap\n(\niw\ninterface\nset type __ap\n).\n[1]\nConnect to an access point\nDepending on the encryption, you need to associate your wireless device with the access point to use and pass the encryption key:\nNo encryption\n# iw dev\ninterface\nconnect \"\nyour_essid\n\"\nWEP\nusing a hexadecimal or ASCII key (the format is distinguished automatically, because a WEP key has a fixed length):\n# iw dev\ninterface\nconnect \"\nyour_essid\n\" key 0:\nyour_key\nusing a hexadecimal or ASCII key, specifying the third set up key as default (keys are counted from zero, four are possible):\n# iw dev\ninterface\nconnect \"\nyour_essid\n\" key d:2:\nyour_key\nOther\niw\ncan only handle WEP. To connect using other encryption schemes, see the section on\n#Authentication\nbelow.\nRegardless of the method used, you can check if you have associated successfully:\n# iw dev\ninterface\nlink\nAuthentication\nThis article or section needs expansion.\nReason:\nAdd\nOpportunistic Wireless Encryption (OWE) a.k.a. Enhanced Open\n. Warn against WEP and open networks. (Discuss in\nTalk:Network configuration/Wireless\n)\nThere are mainly two options for Wi-Fi authentication on Linux:\nwpa_supplicant\nand\niwd\n.\nWPA2 Personal\nWPA2 Personal, a.k.a. WPA2-PSK, is a mode of\nWi-Fi Protected Access\n.\nYou can authenticate to WPA2 Personal networks using\nwpa_supplicant\nor\niwd\n, or connect using a\nnetwork manager\n. If you only authenticated to the network, then to have a fully functional connection, you will still need to assign the IP address(es) and routes either\nmanually\nor using a\nDHCP\nclient.\nWPA2 Enterprise\nWPA2 Enterprise\nis a mode of\nWi-Fi Protected Access\n. It provides better security and key management than\nWPA2 Personal\n, and supports other enterprise-type functionality, such as VLANs and\nNAP\n. However, it requires an external authentication server, called\nRADIUS\nserver, to handle the authentication of users. This is in contrast to Personal mode which does not require anything beyond the wireless router or access points (APs), and uses a single passphrase or password for all users.\nThe Enterprise mode enables users to log onto the Wi-Fi network with a username and password and/or a digital certificate. Since each user has a dynamic and unique encryption key, it also helps to prevent user-to-user snooping on the wireless network, and improves encryption strength.\nThis section describes the configuration of\nnetwork clients\nto connect to a wireless access point with WPA2 Enterprise mode. See\nSoftware access point#RADIUS\nfor information on setting up an access point itself.\nNote\nEnterprise mode requires a more complex client configuration, whereas Personal mode only requires entering a passphrase when prompted. Clients likely need to install the server’s CA certificate (plus per-user certificates if using EAP-TLS), and then manually configure the wireless security and 802.1X authentication settings.\nFor a comparison of protocols, see the following\ntable\n.\nWarning\nIt is possible to use WPA2 Enterprise without the client checking the server CA certificate. However, you should always seek to do so, because without authenticating the access point, the connection can be subject to a man-in-the-middle attack. This may happen because while the connection handshake itself may be encrypted, the most widely used setups transmit the password itself either in plain text or the easily breakable\n#MS-CHAPv2\n. Hence, the client might send the password to a malicious access point which then proxies the connection.\nMS-CHAPv2\nWPA2-Enterprise wireless networks demanding MSCHAPv2 type-2 authentication with PEAP sometimes require\npptpclient\nin addition to the stock\nppp\npackage.\nnetctl\nseems to work out of the box without ppp-mppe, however. In either case, usage of MSCHAPv2 is discouraged as it is highly vulnerable, although using another method is usually not an option.\neduroam\neduroam\nis an international roaming service for users in research, higher education and further education, based on WPA2 Enterprise.\nNote\nCheck connection details\nfirst\nwith your institution before applying any profiles listed in this section. Example profiles are not guaranteed to work or match any security requirements.\nWhen storing connection profiles unencrypted, it is recommended restrict read access to the root account by specifying\nchmod 600\nprofile\nas root.\nIf authentication keeps failing with NetworkManager, try setting\nphase1-auth-flags=32\nfor TLS 1.0 or\nphase1-auth-flags=64\nfor TLS 1.1, as described in\n[2]\nand\nNetworkManager#WPA Enterprise connections fail to authenticate with OpenSSL \"unsupported protocol\" error\n.\nTip\nConfiguration for\nNetworkManager\ncan be generated with the\neduroam Configuration Assistant Tool\n. It requires\npython\nand\npython-dbus\nto be installed.\nManual/automatic setup\nwpa_supplicant\ncan be configured directly by its configuration file or using its CLI/GUI front ends and used in combination with a DHCP client. See the examples in\n/usr/share/doc/wpa_supplicant/wpa_supplicant.conf\nfor configuring the connection details.\niwd#WPA Enterprise\nNetworkManager\ncan create WPA2 Enterprise profiles with\nnmcli\n,\nnmtui\nor the\ngraphical front ends\n.\nConnMan\nneeds a separate configuration file before\nconnecting\nto the network. See\nconnman-service.config(5)\nand\nConnMan#Connecting to eduroam (802.1X)\nfor details.\nnetctl\nsupports wpa_supplicant configuration through blocks included with\nWPAConfigSection=\n. See\nnetctl.profile(5)\nfor details.\nNote\nSpecial quoting rules apply: see\nnetctl.profile(5) § SPECIAL QUOTING RULES\n.\nTip\nCustom certificates can be specified by adding the line\n'ca_cert=\"/path/to/special/certificate.cer\"'\nin\nWPAConfigSection\n.\nWPA3 Personal\nWPA3 Personal, a.k.a. WPA3-SAE, is a mode of\nWi-Fi Protected Access\n.\nBoth\nwpa_supplicant\nand\niwd\nsupport WPA3 Personal.\nWPA3 Enterprise\nWPA3 Enterprise is a mode of\nWi-Fi Protected Access\n.\nwpa_supplicant\n(since version 2:2.10-8) supports WPA3 Enterprise. See\nFS#65314\n.\nTips and tricks\nRespecting the regulatory domain\nThe\nregulatory domain\n, or \"regdomain\", is used to reconfigure wireless drivers to make sure that wireless hardware usage complies with local laws set by the FCC, ETSI and other organizations. Regdomains use\nISO 3166-1 alpha-2 country codes\n. For example, the regdomain of the United States would be \"US\", China would be \"CN\", etc.\nRegdomains affect the availability of wireless channels. In the 2.4GHz band, the allowed channels are 1-11 for the US, 1-14 for Japan, and 1-13 for most of the rest of the world. In the 5GHz band, the rules for allowed channels are much more complex. In either case, consult\nthis list of WLAN channels\nfor more detailed information.\nRegdomains also affect the limit on the\neffective isotropic radiated power (EIRP)\nfrom wireless devices. This is derived from transmit power/\"tx power\", and is measured in\ndBm/mBm (1dBm=100mBm) or mW (log scale)\n. In the 2.4GHz band, the maximum is 30dBm in the US and Canada, 20dBm in most of Europe, and 20dBm-30dBm for the rest of the world. In the 5GHz band, maximums are usually lower. Consult the\nwireless-regdb\nfor more detailed information (EIRP dBm values are in the second set of brackets for each line).\nMisconfiguring the regdomain can be useful - for example, by allowing use of an unused channel when other channels are crowded, or by allowing an increase in tx power to widen transmitter range. However,\nthis is not recommended\nas it could break local laws and cause interference with other radio devices.\nThe kernel loads the database directly when\nwireless-regdb\nis\ninstalled\n. For direct loading, the kernel should, for security's sake, be configured with\nCONFIG_CFG80211_USE_KERNEL_REGDB_KEYS\nset to yes to allow for cryptographic verification of the database. This is true of the stock Arch kernel, but if you are using an alternate kernel, or compiling your own, you should verify this. More information is available at\nthis guide\n[\ndead link\n2024-07-30—domain name not resolved]\n.\nTo configure the regdomain, install\nwireless-regdb\nand reboot, then edit\n/etc/conf.d/wireless-regdom\nand uncomment the appropriate domain.\nThe current regdomain can be temporarily set to the United States with:\n# iw reg set US\nAnd queried with:\n$ iw reg get\nNote\nYour device may be set to country \"00\", which is the \"world regulatory domain\" and contains generic settings. If this cannot be unset, check your configuration as detailed below.\nHowever, setting the regdomain may not alter your settings. Some devices have a regdomain set in firmware/EEPROM, which dictates the limits of the device, meaning that setting regdomain in software\ncan only increase restrictions\n, not decrease them. For example, a CN device could be set in software to the US regdomain, but because CN has an EIRP maximum of 20dBm, the device will not be able to transmit at the US maximum of 30dBm.\nFor example, to see if the regdomain is being set in firmware for an Atheros device:\n# journalctl -kg ath:\nFor other chipsets, it may help to search for \"EEPROM\", \"regdomain\", or simply the name of the device driver.\nTo see if your regdomain change has been successful, and to query the number of available channels and their allowed transmit power:\n$ iw list | grep -A 15 Frequencies:\nwpa_supplicant\ncan also use a regdomain in the\ncountry=\nline of\n/etc/wpa_supplicant/wpa_supplicant.conf\n.\nIt is also possible to configure the\ncfg80211\nkernel module to use a specific regdomain by adding, for example,\noptions cfg80211 ieee80211_regdom=JP\nas\nmodule options\n. The module option is inherited from the\nold regulatory implementation\nand in modern kernels act as a userspace regulatory hint as if it came through\nnl80211\nthrough utilities like\niw\nand\nwpa_supplicant\n.\nRfkill caveat\nMany laptops have a hardware button (or switch) to turn off the wireless card; however, the card can also be blocked by the kernel. This can be handled by\nrfkill(8)\n. To show the current status:\n$ rfkill\nID TYPE      DEVICE      SOFT      HARD\n0 bluetooth hci0   unblocked unblocked\n1 wlan      phy0   unblocked unblocked\nIf the card is\nhard-blocked\n, use the hardware button (switch) to unblock it. If the card is not\nhard-blocked\nbut\nsoft-blocked\n, use the following command:\n# rfkill unblock wlan\nNote\nIt is possible that the card will go from\nhard-blocked\nand\nsoft-unblocked\nstate into\nhard-unblocked\nand\nsoft-blocked\nstate by pressing the hardware button (i.e. the\nsoft-blocked\nbit is just switched no matter what). This can be adjusted by tuning some options of the\nrfkill\nkernel module\n.\nHardware buttons to toggle wireless cards are handled by a vendor specific\nkernel module\n. Frequently, these are\nWMI\nmodules. Particularly for very new hardware models, it happens that the model is not fully supported in the latest stable kernel yet. In this case, it often helps to search the kernel bug tracker for information and report the model to the maintainer of the respective vendor kernel module, if it has not happened already.\nSee also\n[3]\n.\nPower saving\nSee\nPower saving#Network interfaces\n.\nTroubleshooting\nThis section contains general troubleshooting tips, not strictly related to problems with drivers or firmware. For such topics, see next section\n#Troubleshooting drivers and firmware\n.\nTemporary internet access\nIf you have problematic hardware and need internet access to, for example, download some software or get help in forums, you can make use of Android's built-in feature for internet sharing via USB cable. See\nAndroid tethering#USB tethering\nfor more information.\nObserving logs\nA good first measure to troubleshoot is to analyze the system's logfiles first. In order not to manually parse through them all, it can help to open a second terminal/console window and watch the kernels messages with\n# dmesg -w\nwhile performing the action, e.g. the wireless association attempt.\nWhen using a tool for network management, the same can be done for systemd with\n# journalctl -f\nFrequently, a wireless error is accompanied by a deauthentication with a particular reason code, for example:\nwlan0: deauthenticating from XX:XX:XX:XX:XX:XX by local choice (reason=3)\nLooking up\nthe reason code\nmight give a first hint. Maybe it also helps you to look at the control message\nflowchart\n, the journal messages will follow it.\nThe individual tools used in this article further provide options for more detailed debugging output, which can be used in a second step of the analysis, if required.\nFailed to get IP address\nThis article or section is out of date.\nReason:\niwconfig\nis deprecated,  see\n#iw and wireless tools comparison\n(Discuss in\ntalk:Network_configuration/Wireless#wireless_tools\n)\nIf you can get an IP address for a wired interface and not for a wireless interface, try disabling the wireless card's\npower saving\nfeatures (specify\noff\ninstead of\non\n).\nIf you get a timeout error due to a\nwaiting for carrier\nproblem, then you might have to set the channel mode to\nauto\nfor the specific device:\n# iwconfig\nwlan0\nchannel auto\nBefore changing the channel to auto, make sure your wireless interface is down. After it has successfully changed it, you can bring the interface up again and continue from there.\nValid IP address but cannot resolve host\nIf you are on a public wireless network that may have a\ncaptive portal\n, make sure to query an HTTP page (not an HTTPS page) from your web browser, as some captive portals only redirect HTTP.\nIf this is not the issue,\ncheck if you can resolve domain names\n, it may be necessary to use the DNS server advertised via DHCP.\nSetting RTS and fragmentation thresholds\nWireless hardware disables RTS and fragmentation by default. These are two different methods of increasing throughput at the expense of bandwidth (i.e. reliability at the expense of speed). These are useful in environments with wireless noise or many adjacent access points, which may create interference leading to timeouts or failing connections.\nPacket fragmentation improves throughput by splitting up packets with size exceeding the fragmentation threshold. The maximum value (2346) effectively disables fragmentation since no packet can exceed it. The minimum value (256) maximizes throughput, but may carry a significant bandwidth cost.\n# iw phy0 set frag 512\nRTS\nimproves throughput by performing a handshake with the access point before transmitting packets with size exceeding the RTS threshold. The maximum threshold (2347) effectively disables RTS since no packet can exceed it. The minimum threshold (0) enables RTS for all packets, which is probably excessive for most situations.\n# iw phy0 set rts 500\nNote\nphy0\nis the name of the wireless device as listed by\niw phy\n.\nRandom disconnections\nCause #1\nIf your\njournal\nsays\nwlan0: deauthenticating from MAC by local choice (reason=3)\nand you lose your Wi-Fi connection, it is likely that you have a bit too aggressive power-saving on your Wi-Fi card. Try disabling the wireless card's\npower saving\nfeatures (specify\noff\ninstead of\non\n).\nIf your card does not support enabling/disabling power save mode, check the BIOS for power management options. Disabling PCI-Express power management in the BIOS of a Lenovo W520 resolved this issue.\nCause #2\nIf you are experiencing frequent disconnections and your\njournal\nshows messages such as\nieee80211 phy0: wlan0: No probe response from AP xx:xx:xx:xx:xx:xx after 500ms, disconnecting\ntry changing the channel bandwidth to\n20MHz\nthrough your router's settings page.\nCause #3\nOn some laptop models with hardware rfkill switches (e.g., Thinkpad X200 series), due to wear or bad design, the switch (or its connection to the mainboard) might become loose over time resulting in seemingly random hardblocks/disconnects when you accidentally touch the switch or move the laptop.\nThere is no software solution to this, unless your switch is electrical and the BIOS offers the option to disable the switch.\nIf your switch is mechanical (and most are), there are lots of possible solutions, most of which aim to disable the switch: Soldering the contact point on the mainboard or Wi-Fi card, gluing or blocking the switch, using a screw nut to tighten the switch or removing it altogether.\nCause #4\nAnother cause for frequent disconnects or a complete failure to connect may also be a sub-standard router, incomplete settings of the router, interference by other wireless devices or low quality signal.\nTo troubleshoot, first try to connect to the router with no authentication and by getting closer to it. If it does not work, reboot the router and try with another device first.\nIf that works, enable WPA/WPA2 again but choose fixed and/or limited router settings. For example:\nIf the router is considerably older than the wireless device you use for the client, test if it works with setting the router to one wireless mode.\nDisable mixed-mode authentication (e.g. only WPA2 with AES, or TKIP if the router is old).\nTry a fixed/free channel rather than \"auto\" channel (maybe the router next door is old and interfering).\nDisable\nWPS\n.\nChange the router's 5 GHz channel(s) to a\nnon-DFS (Dynamic Frequency Selection) channel\n. Connections on such channels\nmay be dropped or suddenly switched\ndue to interference from nearby weather radar.\nTry setting your client to 2.4 GHz only instead of letting it choose what it thinks is best between 5 GHz and 2.4 GHz (the later has a lower throughput but will provide a more stable connection over longer distances).\nDisable\n40MHz\nchannel bandwidth (lower throughput but less likely collisions) with\ncfg80211.cfg80211_disable_40mhz_24ghz=1\n.\nIf the router has quality of service settings, check completeness of settings (e.g. Wi-Fi Multimedia (WMM) is part of optional QoS flow control. An erroneous router firmware may advertise its existence although the setting is not enabled).\nCause #5\nOn some wireless network adapters (e.g. Qualcomm Atheros AR9485), random disconnects can happen with a DMA error:\n# journalctl -xb\nath: phy0: DMA failed to stop in 10 ms AR_CR=0x00000024 AR_DIAG_SW=0x02000020 DMADBG_7=0x0000a400\nwlp1s0: authenticate with 56:e7:ee:7b:55:bc\nwlp1s0: send auth to 56:e7:ee:7b:55:bc (try 1/3)\nwlp1s0: send auth to 56:e7:ee:7b:55:bc (try 2/3)\nwlp1s0: send auth to 56:e7:ee:7b:55:bc (try 3/3)\nwlp1s0: authentication with 56:e7:ee:7b:55:bc timed out\nA possible workaround is to disable the\nIntel IOMMU driver (DMA)\n, adding\nintel_iommu=off\nto the\nkernel parameters\n[4]\n.\nNote\nThe Intel IOMMU driver is needed for some advanced virtual machine features, like PCI pass-through.\nCause #6\nIf you are using a device with\niwlwifi\nand\niwlmvm\nfor wireless connectivity, and your Wi-Fi card appears to disappear when on battery power (perhaps after a reboot or resuming from suspend), this can be fixed by configuring power saving settings in iwlmvm.\nCreate the file\n/etc/modprobe.d/iwlmvm.conf\nif it does not exist already, then add the following line to it:\n/etc/modprobe.d/iwlmvm.conf\noptions iwlmvm power_scheme=1\nA\npower_scheme\nof 1 sets iwlmvm to \"Always Active.\" Available options are:\nValue\nDescription\n1\nAlways Active\n2\nBalanced\n3\nLow-power\nThis fix was discovered at\n[5]\n.\nCause #7\nIf your device undergoes long periods of inactivity (e.g. a file server), the disconnection may be due to power saving, which will block incoming traffic and prevent connections. Try disabling power saving for the interface:\n# iw dev\ninterface\nset power_save off\nYou can create a udev rule to do this on boot, see\nPower management#Network interfaces\n.\nCause #8\nIf you notice occasional interruptions when connected to a mesh network (e.g., Wi-Fi 6) and notice a message such as:\n# journalctl -b\nkernel: wlan0: disconnect from AP aa:bb:cc:dd:ee:ff for new auth to 11:22:33:44:55:66\nYou are experiencing roaming issues. Depending on your mean of connection and the issue at hand, one could:\nLock the BSSID (the\naa:bb:cc:dd:ee:ff\nshow above) in NetworkManager if roaming is not desired (see\nNetworkManager#Regular network disconnects, latency and lost packets (Wi-Fi)\n).\nAdjust the\nbgscan\nsetting in\nWpa_supplicant#Roaming\nWi-Fi networks invisible because of incorrect regulatory domain\nIf the computer's Wi-Fi channels do not match those of the user's country, some in-range Wi-Fi networks might be invisible because they use wireless channels that are not allowed by default. The solution is to configure the regulatory domain correctly; see\n#Respecting the regulatory domain\n.\nTroubleshooting drivers and firmware\nThis section covers methods and procedures for installing kernel modules and\nfirmware\nfor specific chipsets, that differ from generic method.\nSee\nKernel modules\nfor general information on operations with modules.\nRalink/MediaTek\nSome chipsets require additional firmware:\nlinux-firmware-mediatek\nrt2x00\nUnified driver for Ralink chipsets (it replaces\nrt2500\n,\nrt61\n,\nrt73\n, etc). This driver has been in the Linux kernel since 2.6.24, you only need to load the right module for the chip:\nrt2400pci\n,\nrt2500pci\n,\nrt2500usb\n,\nrt61pci\nor\nrt73usb\nwhich will autoload the respective\nrt2x00\nmodules too.\nA list of devices supported by the modules is available at the project's\nhomepage\n.\nAdditional notes\nSince kernel 3.0, rt2x00 includes also these drivers:\nrt2800pci\n,\nrt2800usb\n.\nSince kernel 3.0, the staging drivers\nrt2860sta\nand\nrt2870sta\nare replaced by the mainline drivers\nrt2800pci\nand\nrt2800usb\n[6]\n.\nSome devices have a wide range of options that can be configured with\niwpriv\n. These are documented in the\nsource tarballs\navailable from Ralink.\nrt3090\nFor devices which use the rt3090 chipset, it should be possible to use the\nrt2800pci\ndriver; however, it does not work with this chipset very well (e.g. sometimes it is not possible to use higher rate than 2Mb/s).\nrt3290\nThe rt3290 chipset is recognised by the kernel\nrt2800pci\nmodule. However, some users experience problems and reverting to a patched Ralink driver seems to be beneficial in these\ncases\n.\nrt3573\nNew chipset as of 2012. It may require proprietary drivers from Ralink. Different manufacturers use it; see the\nBelkin N750 DB wireless usb adapter\nforums thread.\nmt7612u\nNew chipset as of 2014, released under their new commercial name MediaTek. It is an AC1200 or AC1300 chipset. Manufacturer provides drivers for Linux on their\nsupport page\n. As of kernel 5.5 it should be supported by the included\nmt76\ndriver.\nDFS channels are currently not supported in 5 GHz AP mode\n.\nmt7921 / mt7922\nThere are some high latency problems with these MediaTek chipsets. To fix this, the only solution is to disable ASPM:\n/etc/modprobe.d/wifi.conf\noptions mt7921e disable_aspm=1\nThis configuration file will take effect on next reboot or after reloading the module with\nmodprobe\n:\n# modprobe -r mt7921e && modprobe mt7921e\nThese are also sometimes branded as AMD RZ608 (mt7921) and RZ616 (mt7922).\nRealtek\nThis article or section is out of date.\nReason:\nNeed complete reorganisation: most drivers are now in kernel, and covered by rtw88 and rtw89 series. However there is useful information or alternative out-of-tree drivers that could help those who experience difficulties. (Discuss in\nTalk:Network configuration/Wireless\n)\nSee\n[7]\nfor a list of Realtek chipsets and specifications.\nrtl8192cu\nThe driver is now in the kernel, but many users have reported being unable to make a connection although scanning for networks does work.\n8192cu-dkms\nAUR\nincludes many patches; try this if it does not work fine with the driver in kernel.\nrtl8723ae/rtl8723be\nThe\nrtl8723ae\nand\nrtl8723be\nmodules are included in the mainline Linux kernel.\nSome users may encounter errors with powersave on this card. This is shown with occasional disconnects that are not recognized by high level network managers (\nnetctl\n,\nNetworkManager\n). This error can be confirmed by running\ndmesg -w\nas root or\njournalctl -f\nas root and looking for output related to powersave and the\nrtl8723ae\n/\nrtl8723be\nmodule. If you have this issue, use the\nfwlps=0\nkernel module parameter\nwhich should prevent the Wi-Fi card from automatically sleeping and halting connection.\nIf you have poor signal, perhaps your device has only one physical antenna connected, and antenna autoselection is broken. You can force the choice of antenna with\nant_sel=1\nor\nant_sel=2\nkernel option.\n[8]\nrtl88xxau\nRealtek chipsets rtl8811au, rtl8812au, rtl8814au and rtl8821au designed for various USB adapters ranging from AC600 to AC1900. Several packages provide various kernel drivers, these require\nDKMS\n(the\ndkms\npackage and the kernel headers installed):\nChipset\nPackage\nNotes\nrtl88xxyy\nrtw88-dkms-git\nAUR\nA backport of the Realtek Wifi 5 drivers from the wireless-next repo. Supports:\nPCIe: RTL8723DE, RTL8814AE, RTL8821CE, RTL8822BE, RTL8822CE\nSDIO: RTL8723CS, RTL8723DS, RTL8821CS, RTL8822BS, RTL8822CS\nUSB : RTL8723DU, RTL8811AU, RTL8811CU, RTL8812AU, RTL8812BU, RTL8812CU, RTL8814AU, RTL8821AU, RTL8821CU, RTL8822BU, RTL8822CU\nrtl8812au\nrtl8812au-dkms-git\nAUR\n(probably deprecated) Alternative official Realtek driver version for rtl8812au\nonly\n.\nrtl8811au, rtl8821au\nrtl8821au-dkms-git\nAUR\n(probably deprecated) Alternative driver version for rtl8821au.\nrtl8814au\nrtl8814au-dkms-git\nAUR\n(probably deprecated) Possibly works for rtl8813au too.\nrtl8811cu/rtl8821cu\nrtl8821cu-dkms-git\nAUR\nprovides a kernel module for the Realtek 8811cu and 8821cu chipset.\nThis requires\nDKMS\n, so make sure you have your proper kernel headers installed.\nIf no wireless interface shows up even though the\n8821cu\nmodule is loaded, you may need to manually specify the\nrtw_RFE_type\nkernel module parameter\n[9]\n[10]\n. Try e.g.\nrtw_RFE_type=0x26\n, other values might also work.\nrtl8821ce\nrtl8821ce-dkms-git\nAUR\nprovides a kernel module for the Realtek 8821ce chipset found in the Asus X543UA.\nThis requires\nDKMS\n, so make sure you have your proper kernel headers installed.\nNote\nIt has been reported\n[11]\nthat the default\nrtl8821ce\nmodule provided by Realtek is broken for Linux kernel ≥ 5.9, which may lead to low connectivity. The AUR version above should be preferred. See\nthe statement on GitHub.\nUse\nlspci -k\nto check whether the default kernel driver (\nrtw88_8821ce\n) is in use. If it is,\nblacklist\nit and reboot your system.\nrtl8822bu\nrtl88x2bu-dkms-git\nAUR\nprovides a kernel module for the Realtek 8822bu chipset found in the Edimax EW7822ULC USB3, Asus AC53 Nano USB 802.11ac and TP-Link Archer T3U adapter.\nThis requires\nDKMS\n, so make sure you have your proper kernel headers installed.\nrtl8xxxu\nThis article or section needs expansion.\nReason:\nSpecific issues with the mainline module and kernel versions should be stated. (Discuss in\nTalk:Network configuration/Wireless\n)\nIssues with the\nrtl8xxxu\nmainline kernel module may be solved by compiling a third-party module for the specific chipset. The source code can be found in\nGitHub repositories\n.\nSome drivers may be already prepared in the AUR, e.g.\nrtl8723bu-dkms-git\nAUR\n,\nrtl8852au-dkms-git\nAUR\n,\nrtl8852bu-dkms-git\nAUR\n,\nrtl8852cu-dkms-git\nAUR\n.\nRTW88\nRWT88 kernel module is included in all\nofficially supported\nArch Linux kernels. The number of supported devices grew over time, currently it supports most RTW88 chip devices if configured and compiled to do so.\nAs of Linux 6.10.3, the driver supports: 882BE (\npossibly\n), 8703B, 8723CS, 8723D, 8723DE, 8723DS, 8723DU, 8723X, 8821C, 8821CE, 8821CS, 8821CU, 8822B, 8822BE, 8822BS, 8822BU, 8822C, 8822CE, 8822CS, 8822CU.\nTo get more up-to-date list, Ctrl+F\nCONFIG_RTW88_\nlinux\n's\nconfig\nor check out\nwireless-next upstream\n.\nMake sure\nthat\nwireless-regdom is configured\n. Otherwise, you will be\nable to see\nall Wi-Fi networks, but\nwill not be able to connect\n. Out-of-tree driver\nrtl88x2bu-dkms-git\nAUR\ncan connect without such configuration, so it's important to set regulatory domain when switching from it.\nHere is how those symptoms look in dmesg:\n[ +13.369951] wlan0: send auth to *WiFi_AP_mac* (try 1/3)\n[  +0.000685] wlan0: authenticated\n[  +0.000449] wlan0: associate with *WiFi_AP_mac* (try 1/3)\n[  +0.000866] wlan0: RX AssocResp from *router_mac* (capab=0x1011 status=0 aid=2)\n[  +0.323058] wlan0: associated\n[  +0.000046] wlan0: deauthenticating from *WiFi_AP_mac* by local choice (Reason: 3=DEAUTH_LEAVING)\nAnd in iwd log:\nevent: state, old: autoconnect_full, new: connecting\nevent: connect-timeout, reason: 0\nevent: connect-failed, status: 1\nRTW89\nThe RTW89 kernel module has been merged into the upstream kernel and provides support for newer Realtek wireless chipsets.\nThis driver supports: 8852AE, 8851BE, 8852BE, and 8852CE.\nOn some computers, you may experience unstable connections. It seems like a common issue on late models from HP and Lenovo.\nTry disabling ASPM-related features using the config below.\n/etc/modprobe.d/70-rtw89.conf\noptions rtw89_pci disable_aspm_l1=y disable_aspm_l1ss=y\noptions rtw89_core disable_ps_mode=y\nSee also:\nhttps://github.com/lwfinger/rtw89#option-configuration\nhttps://github.com/lwfinger/rtw89/issues/275#issuecomment-1784155449\nAtheros\nThere are different drivers for devices with Atheros chipset:\nath5k\nis a driver which replaces the obsolete\nmadwifi\ndriver. Currently a better choice for some chipsets, but not all chipsets are supported (see below).\nath9k\nis intended for newer Atheros chipsets. All of the chips with 802.11n capabilities are supported.\nath12k\nis a Linux driver for Qualcomm Wi-Fi 7 (IEEE 802.11be) devices. ath12k uses mac80211.\nThere are some other drivers for some Atheros devices. See\nLinux Wireless documentation\nfor details.\nath5k\nExternal resources:\nhttps://wireless.docs.kernel.org/en/latest/en/users/drivers/ath5k.html\nDebian:ath5k\nIf you find web pages randomly loading very slow, or if the device is unable to lease an IP address, try to switch from hardware to software encryption by loading the\nath5k\nmodule with\nnohwcrypt=1\noption. See\nKernel modules#Setting module options\nfor details.\nSome laptops may have problems with their wireless LED indicator flickering red and blue. To solve this problem, do:\n# echo none > /sys/class/leds/ath5k-phy0::tx/trigger\n# echo none > /sys/class/leds/ath5k-phy0::rx/trigger\nFor alternatives, see\nthis bug report\n.\nath9k\nExternal resources:\nhttps://wireless.wiki.kernel.org/en/users/drivers/ath9k\nDebian:ath9k\nAs of Linux 3.15.1, some users have been experiencing a decrease in bandwidth. In some cases, this can fixed by setting the\nnohwcrypt=1\nkernel module parameter\nfor the\nath9k\nmodule.\nNote\nUse the command\nlsmod\nto see what modules are in use and change\nath9k\nif it is named differently (e.g.\nath9k_htc\n).\nPower saving\nAlthough\nLinux Wireless\nsays that dynamic power saving is enabled for Atheros ath9k single-chips newer than AR9280, for some devices (e.g. AR9285),\npowertop\nmight still report that power saving is disabled. In this case, enable it manually.\nOn some devices (e.g. AR9285), enabling the power saving might result in the following error:\n# iw dev wlan0 set power_save on\ncommand failed: Operation not supported (-95)\nThe solution is to set the\nps_enable=1\nkernel module parameter\nfor the\nath9k\nmodule.\nIntel\niwlegacy\niwlegacy\nis the wireless driver for Intel's 3945 and 4965 wireless chips. The firmware is included in the\nlinux-firmware\npackage.\nudev\nshould load the driver automatically, otherwise load\niwl3945\nor\niwl4965\nmanually. See\nKernel modules\nfor details.\nIf you have problems connecting to networks in general (e.g. random failures with your card on bootup or your link quality is very poor), try to disable 802.11n:\n/etc/modprobe.d/iwl4965.conf\noptions iwl4965 11n_disable=1\niwlwifi\niwlwifi\nis the wireless driver for Intel's current wireless chips, such as 5100AGN, 5300AGN, and 5350AGN. See the\nfull list of supported devices\n.\nIf you have problems connecting to networks in general or your link quality is very poor, try to disable 802.11n, and perhaps also enable software encryption:\n/etc/modprobe.d/iwlwifi.conf\noptions iwlwifi 11n_disable=1 swcrypto=1\nIf you have a problem with slow uplink speed you may try disabling\npower saving\nfor your wireless adapter.\nIf you have an 802.11ax (Wi-Fi 6) access point and have problems detecting the beacons or an unreliable connection, review\nIntel Article 54799\n.\nNote\nUsing\n11n_disable=1\nwill also prevent 802.11ac and only allow connection with slower protocols (802.11a in the 5GHz band or 802.11b/g in the 2.4 GHz band).\nBluetooth coexistence\nIf you have difficulty connecting a bluetooth headset and maintaining good downlink speed, try disabling\nBluetooth coexistence\n:\n/etc/modprobe.d/iwlwifi.conf\noptions iwlwifi bt_coex_active=0\nNote\nSince kernel version 5.8, the\nbt_coex_active\nand\nsw_crypto\nmodule options have been disabled for the hardware handled by the\niwlmvm\nkernel module. For older hardware handled by the\niwldvm\nmodule, the options are still enabled.\nFirmware issues\nMake sure your\nfirmware is fully updated\nbefore trying anything else.\nYou may have some issue where the driver outputs stack traces & errors, which can cause some stuttering.\n# dmesg\nMicrocode SW error detected.  Restarting 0x2000000.\nAlternatively, you may simply experience miscellaneous issues (e.g.\nconnection issues on 5GHz, random disconnections, no connection on resume\n).\nTo confirm it is the cause of the issues,\ndowngrade\nthe package\nlinux-firmware\n.\nIf confirmed, move the buggy firmware files so that an older version is loaded (to be able to have an up to date\nlinux-firmware\nsince it is not only providing firmware updates for your Intel Wi-Fi card):\n# for i in {64..73} ; do mv /usr/lib/firmware/iwlwifi-ty-a0-gf-a0-$i.ucode.xz /usr/lib/firmware/iwlwifi-ty-a0-gf-a0-$i.ucode.xz.bak ; done\nTo avoid having to repeat these steps manually after each update, use the\nNoExtract\nand\nNoUpgrade\narrays in\npacman.conf\nwith a wildcard to block their installation.\nAdapter not detected after booting from Windows\nIf the Wi-Fi adapter is not getting detected after finishing a session in Windows, this might be due to Windows'\nFast Startup\nfeature which is enabled by default. Try\ndisabling Fast Startup\n. The\niwlwifi kernel driver wiki has an entry for this\n.\nDisabling LED blink\nNote\nThis works with the\niwlegacy\nand\niwlwifi\ndrivers.\nThe default settings on the module are to have the LED blink on activity. Some people find this extremely annoying. To have the LED on solid when Wi-Fi is active, you can use the\nsystemd-tmpfiles\n:\n/etc/tmpfiles.d/phy0-led.conf\nw /sys/class/leds/phy0-led/trigger - - - - phy0radio\nRun\nsystemd-tmpfiles --create phy0-led.conf\nfor the change to take effect, or reboot.\nTo see all the possible trigger values for this LED:\n# cat /sys/class/leds/phy0-led/trigger\nTip\nIf you do not have\n/sys/class/leds/phy0-led\n, you may try to use the\nled_mode=\"1\"\nmodule option\n. It should be valid for both\niwlwifi\nand\niwlegacy\ndrivers.\nAicsemi\nAIC8800/8801/8800DC/8800DW/8800FC\nThe\naic8800-dkms\nAUR\npackage should be used with these devices. These drivers are out of the mainline Linux kernel and require\nDKMS\n.\nAIC8800D80\nFor this chip variant,\naic8800d80-dkms\nAUR\npackage should be used instead of the one mentioned above.\nBroadcom\nSee\nBroadcom wireless\n.\nOther drivers/devices\nTenda w322u\nTreat this Tenda card as an\nrt2870sta\ndevice. See\n#rt2x00\n.\norinoco\nThis should be a part of the kernel package and be installed already.\nSome Orinoco chipsets are Hermes II. You can use the\nwlags49_h2_cs\ndriver instead of\norinoco_cs\nand gain WPA support. To use the driver,\nblacklist\norinoco_cs\nfirst.\nprism54\nThe driver\np54\nis included in kernel, but you have to download the appropriate firmware for your card from\nthis site\nand install it into the\n/usr/lib/firmware\ndirectory.\nNote\nThere is also an older, deprecated driver\nprism54\n, which might conflict with the newer driver (\np54pci\nor\np54usb\n). Make sure to\nblacklist\nprism54\n.\nzd1211rw\nzd1211rw\nis a driver for the ZyDAS ZD1211 802.11b/g USB WLAN chipset, and it is included in recent versions of the Linux kernel. See\n[12]\nfor a list of supported devices. You only need to\ninstall\nthe firmware for the device, provided by the\nzd1211-firmware\nAUR\npackage.\nhostap_cs\nHost AP\nis a Linux driver for wireless LAN cards based on Intersil's Prism2/2.5/3 chipset. The driver is included in Linux kernel.\nNote\nMake sure to\nblacklist\nthe\norinico_cs\ndriver, it may cause problems.\nndiswrapper\nNdiswrapper is a wrapper script that allows you to use some Windows drivers in Linux. You will need the\n.inf\nand\n.sys\nfiles from your Windows driver.\nTip\nIf you need to extract these files from an\n.exe\nfile, you can use\ncabextract\n.\nFollow these steps to configure ndiswrapper.\nInstall\nndiswrapper\n.\nInstall the driver to\n/etc/ndiswrapper/\n:\n# ndiswrapper -i filename.inf\nList all installed drivers for ndiswrapper:\n$ ndiswrapper -l\nLet ndiswrapper write its configuration in\n/etc/modprobe.d/ndiswrapper.conf\n:\n# ndiswrapper -m\n# depmod -a\nThe ndiswrapper install is almost finished; you can\nload the module at boot\n.\nTest that ndiswrapper will load now:\n# modprobe ndiswrapper\nSee\nNetwork configuration#Listing network interfaces\nfor more assurance the wireless interface now exists.\nIf you have problems, some help is available at:\nndiswrapper howto\nand\nndiswrapper FAQ\n.\nSee also\nThe Linux Wireless project\nAircrack-ng guide on installing drivers\nWireless Device Database Wiki\n(This fork is hosted by wi-cat.ru since the original wiki has shut down. There are two less complete versions available:\nTechInfoDepot\n,\ndeviwiki\n)\nhttps://github.com/morrownr/USB-WiFi\n– various information on different Wi-Fi adapters and chipsets, including performance tests, driver info and general info\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Network_configuration/Wireless&oldid=844324\n\"\nCategories\n:\nWireless networking\nNetwork configuration\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages with dead links\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nNetwork configuration/Wireless\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Wireless_network_configuration"}}
{"text": "NetworkManager - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nNetworkManager\n7 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nNetwork configuration\nWireless network configuration\nNetworkManager\nis a program for providing detection and configuration for systems to automatically connect to networks.\nNetworkManager\ncan be useful for both wireless and wired networks. For wireless networks, NetworkManager prefers known wireless networks and has the ability to switch to the most reliable network.  NetworkManager-aware applications can switch from online and offline mode.\nNetworkManager also prefers wired connections over wireless ones, has support for modem connections and certain types of VPN.\nWarning\nBy default, secrets—e.g. Wi-Fi passwords—are accessible to the root user in the filesystem and to users with access to settings via the GUI (e.g. via\n#nm-applet\n). For more information, see\n#Encrypted Wi-Fi passwords\n.\nInstallation\nNetworkManager can be\ninstalled\nwith the package\nnetworkmanager\n, which contains a daemon, a command line interface (\nnmcli\n) and a curses‐based interface (\nnmtui\n).\nEnable NetworkManager\nAfter installation, you should\nstart/enable\nNetworkManager.service\n. Once the NetworkManager daemon is started, it will automatically connect to any available \"system connections\" that have already been configured. Any \"user connections\" or unconfigured connections will need\nnmcli\nor an applet to configure and connect.\nNote\nEach network interface should be managed by only one\nDHCP client or network manager\n, so it is advised to run only one DHCP client or network manager on the system. Find a list of the currently running services with\nsystemctl --type=service\nand then\nstop\nor reconfigure those that conflict.\nIf\nsystemd-resolved\nis not\nstarted\n, an error message will start flooding your logs. See\n#Unit dbus-org.freedesktop.resolve1.service not found\nfor more info.\nAdditional interfaces\nnm-connection-editor\nfor a graphical user interface,\nnetwork-manager-applet\nfor a system tray applet (see the\n#nm-applet\nsection).\nMobile broadband support\nNetworkManager uses\nModemManager\nfor mobile broadband connection support.\nInstall\nmodemmanager\nand\nusb_modeswitch\n. Afterwards\nenable\nand\nstart\nModemManager.service\n.\nIt may be necessary to\nrestart\nNetworkManager.service\nfor it to detect ModemManager. After you restart it, re-plug the modem again and it should be recognized.\nAdd connections from a front-end (e.g.\nnm-connection-editor\n) and select mobile broadband as the connection type. After selecting your ISP and billing plan,\nAPN\nand other settings should be filled in automatically using information from\nmobile-broadband-provider-info\n.\nPPPoE / DSL support\nInstall\nppp\npackage for PPPoE / DSL connection support. To actually add PPPoE connection, use\nnm-connection-editor\nand add new DSL/PPPoE connection.\nVPN support\nNetworkManager since version 1.16 has native support for\nWireGuard\n, all it needs is the\nwireguard\nkernel module. Read the\nWireGuard in NetworkManager blog post\nfor details.\nSupport for other VPN types is based on a plug-in system. They are provided in the following packages:\nnetworkmanager-openconnect\nfor\nOpenConnect\nnetworkmanager-openvpn\nfor\nOpenVPN\nnetworkmanager-pptp\nfor\nPPTP Client\nnetworkmanager-strongswan\nfor\nstrongSwan\nnetworkmanager-vpnc\nnetworkmanager-fortisslvpn\nAUR\nnetworkmanager-iodine-git\nAUR\nnetworkmanager-libreswan\nAUR\nnetworkmanager-l2tp\nnetworkmanager-ssh\nAUR\nnetwork-manager-sstp\nWarning\nThere are a lot of\nbugs\nrelated to VPN support. Check the daemon processes options set via the GUI correctly and double-check with each package release.\nNote\nTo have fully functioning DNS resolution when using VPN, you should set up\nconditional forwarding\n.\nThese plug-ins may not have a documented command line interface, or may not work at all without an applet running. This is not an issue if you are using a regular desktop environment; if you are not, you should run\n#nm-applet\nwhile configuring or activating the connection so that you get the necessary dialogues.\n[1]\nUsage\nNetworkManager comes with\nnmcli(1)\nand\nnmtui(1)\n.\nnmcli examples\nList nearby Wi-Fi networks:\n$ nmcli device wifi list\nConnect to a Wi-Fi network:\n$ nmcli device wifi connect\nSSID_or_BSSID\npassword\npassword\nConnect to a hidden Wi-Fi network:\n$ nmcli device wifi connect\nSSID_or_BSSID\npassword\npassword\nhidden yes\nConnect to a Wi-Fi on the\nwlan1\ninterface:\n$ nmcli device wifi connect\nSSID_or_BSSID\npassword\npassword\nifname wlan1\nprofile_name\nDisconnect an interface:\n$ nmcli device disconnect ifname eth0\nGet a list of connections with their names, UUIDs, types and backing devices:\n$ nmcli connection show\nActivate a connection (i.e. connect to a network with an existing profile):\n$ nmcli connection up\nname_or_uuid\nDelete a connection:\n$ nmcli connection delete\nname_or_uuid\nSee a list of network devices and their state:\n$ nmcli device\nTurn off Wi-Fi:\n$ nmcli radio wifi off\nEdit a connection\nFor a comprehensive list of settings, see\nnm-settings(5)\n.\nFirstly, you need to get a list of connections:\n$ nmcli connection\nNAME                UUID                                  TYPE      DEVICE\nWired connection 2  e7054040-a421-3bef-965d-bb7d60b7cecf  ethernet  enp5s0\nWired connection 1  997f2782-f0fc-301d-bfba-15421a2735d8  ethernet  enp0s25\nMY-HOME-WIFI-5G     92a0f7b3-2eba-49ab-a899-24d83978f308  wifi       --\nHere you can use the first column as connection-id used later. In this example, we pick\nWired connection 2\nas a connection-id.\nYou have three methods to configure a connection\nWired connection 2\nafter it has been created:\nnmcli interactive editor\nnmcli connection edit 'Wired connection 2'\n.\nUsage is well documented from the editor.\nnmcli command line interface\nnmcli connection modify 'Wired connection 2'\nsetting\n.\nproperty\nvalue\n. See\nnmcli(1)\nfor usage. For example, you can change its IPv4 route metric to 200 using\nnmcli connection modify 'Wired connection 2' ipv4.route-metric 200\ncommand.\nTo remove a setting, pass an empty field (\"\") to it like this:\nnmcli connection modify 'Wired connection 2'\nsetting\n.\nproperty\n\"\"\nConnection file\nIn\n/etc/NetworkManager/system-connections/\n, modify the corresponding\nWired connection 2.nmconnection\nfile .\nDo not forget to reload the configuration file with\nnmcli connection reload\n.\nnmtui\nNetworkManager ships a text user interface (TUI) for managing connections, the system hostname and radio switches. It can be launched by running\nnmtui\n.\nFront-ends\nTo provide integration with a\ndesktop environment\n, most users will want to install an applet. This not only provides easy access to network selection and configuration, but also provides the agent necessary for securely storing secrets. Various desktop environments have their own applet; otherwise, you can use\n#nm-applet\n.\nGNOME\nGNOME\nhas a built-in tool, accessible from the Network settings.\nKDE Plasma\nInstall\nthe\nplasma-nm\npackage. After that, add it to the KDE taskbar via the\nPanel options > Add widgets > Networks\nmenu.\nnm-applet\nnetwork-manager-applet\nis a GTK 3 front-end which works under Xorg environments with a systray.\nTo store connection secrets install and configure an application which implements the\nSecret Service D-Bus API\nsuch as\nGNOME/Keyring\n,\nKDE Wallet\n, or\nKeePassXC\n.\nBe aware that after enabling the tick-box option\nMake available to other users\nfor a connection, NetworkManager stores the password in plain-text, though the respective file is accessible only to root (or other users via\nnm-applet\n). See\n#Encrypted Wi-Fi passwords\n.\nIn order to run\nnm-applet\nwithout a systray, you can use\ntrayer\nAUR\nor\nstalonetray\n. For example, you can add a script like this one in your path:\nnmgui\n#!/bin/sh\nnm-applet    2>&1 > /dev/null &\nstalonetray  2>&1 > /dev/null\nkillall nm-applet\nWhen you close the\nstalonetray\nwindow, it closes\nnm-applet\ntoo, so no extra memory is used once you are done with network settings.\nThe applet can show notifications for events such as connecting to or disconnecting from a Wi-Fi network. For these notifications to display, ensure that you have a notification server installed - see\nDesktop notifications\n. If you use the applet without a notification server, you might see some messages in stdout/stderr, and the applet might hang. See\n[2]\n.\nIn order to run\nnm-applet\nwith such notifications disabled, start the applet with the following command:\n$ nm-applet --no-agent\nTip\nnm-applet\nmight be started automatically with a\nautostart desktop file\n, to add the\n--no-agent\noption modify the Exec line there, i.e.\nExec=nm-applet --no-agent\nWarning\nOn\ni3\n, if nm-applet is started with the\n--no-agent\noption, it is not possible to connect to a new encrypted Wi-Fi network by clicking on the item list because no password input dialogue window will pop out.\njournal\nwill show\nno secrets: No agents were available for this request\n.\nAppindicator\nAs of version 1.18.0 Appindicator support is\navailable\nin the official\nnetwork-manager-applet\npackage. To use nm-applet in an Appindicator environment start the applet with the following command:\n$ nm-applet --indicator\nnetworkmanager-dmenu\nAlternatively there is\nnetworkmanager-dmenu\nwhich is a small script to manage NetworkManager connections with\ndmenu\nor\nrofi\ninstead of\nnm-applet\n. It provides all essential features such as connection to existing NetworkManager Wi-Fi or wired connections, connect to new Wi-Fi connections, requests passphrase if required, connect to existing VPN connections, enable/disable networking, launch\nnm-connection-editor\nGUI, connect to Bluetooth networks.\nswitchboard\nPantheon's\nswitchboard\noffers a desktop environment-agnostic way to configure NetworkManager when combined with\nswitchboard-plug-network\nand\nnm-connection-editor\n. It can be ran with the following command:\n$ io.elementary.settings\nConfiguration\nNetworkManager will require some additional steps to be able run properly. Make sure you have configured\n/etc/hosts\nas described in\nNetwork configuration#Set the hostname\nsection.\nNetworkManager has a global configuration file at\n/etc/NetworkManager/NetworkManager.conf\n. Additional configuration files can be placed in\n/etc/NetworkManager/conf.d/\n. Usually no configuration needs to be done to the global defaults.\nAfter editing a configuration file, the changes can be applied by running:\n# nmcli general reload\nNetworkManager-wait-online\nEnabling\nNetworkManager.service\nalso enables\nNetworkManager-wait-online.service\n, which is a oneshot system service that waits for the network to be configured. The latter has\nWantedBy=network-online.target\n, so it will finish only when\nnetwork-online.target\nitself is enabled or pulled in by some other unit. See also\nsystemd#Running services after the network is up\n.\nBy default,\nNetworkManager-wait-online.service\nwaits for NetworkManager startup to complete, rather than waiting for network connectivity specifically (see\nnm-online(1)\n). If\nNetworkManager-wait-online.service\nfinishes before the network is really up, resulting in failed services on boot,\nextend the unit\nto remove the\n-s\nfrom the\nExecStart\nline:\n[Service]\nExecStart=\nExecStart=/usr/bin/nm-online -q\nBe aware that this can cause\nother issues\n.\nIn some cases, the service will still fail to start successfully on boot due to the timeout setting being too short.\nEdit\nthe service to change\nNM_ONLINE_TIMEOUT\nfrom\n60\nto a higher value.\nSet up PolicyKit permissions\nBy default, all users in active local sessions are allowed to change most network settings without a password. See\nGeneral troubleshooting#Session permissions\nto check your session type. In most cases, everything should work out of the box.\nSome actions (such as changing the system hostname) require an administrator password. In this case, you need to\nadd\nyourself to the\nwheel\ngroup and run a\nPolkit authentication agent\nwhich will prompt for your password.\nFor remote sessions (e.g.\nheadless VNC\n), you have several options for obtaining the necessary privileges to use NetworkManager:\nAdd\nyourself to the\nwheel\ngroup. You will have to enter your password for every action. Note that your user account may be granted other permissions as well, such as the ability to use\nsudo\nwithout entering the root password.\nAdd\nyourself to the\nnetwork\ngroup and create\n/etc/polkit-1/rules.d/50-org.freedesktop.NetworkManager.rules\nwith the following content:\npolkit.addRule(function(action, subject) {\nif (action.id.indexOf(\"org.freedesktop.NetworkManager.\") == 0 && subject.isInGroup(\"network\")) {\nreturn polkit.Result.YES;\n}\n});\nAll users in the\nnetwork\ngroup will be able to add and remove networks without a password (which means you do not have to run a Polkit authentication agent, so this option will also work in SSH sessions).\nProxy settings\nNetworkManager does support some proxy settings. While they can not be directly modified using\nnmtui\n,\nnm-applet\nand\nnmcli\nsupport those.\nSee the proxy settings in\nnm-settings-nmcli(5)\n.\nAdditionally, custom proxy commands can always be run using dispatcher scripts, see\n#Dispatcher examples\n.\nSee also\nProxy settings\n.\nChecking connectivity\nNetworkManager can try to reach a webserver after connecting to a network in order to determine if it is e.g behind a captive portal. The default host (configured in\n/usr/lib/NetworkManager/conf.d/20-connectivity.conf\n) is\nping.archlinux.org\n(a CNAME alias of redirect.archlinux.org). To use a different webserver or to disable connectivity checking, create\n/etc/NetworkManager/conf.d/20-connectivity.conf\n, see\nNetworkManager.conf(5) § CONNECTIVITY SECTION\n. Below is an example of using GNOME servers (it does not require the use of\nGNOME\n):\n/etc/NetworkManager/conf.d/20-connectivity.conf\n[connectivity]\nuri=http://nmcheck.gnome.org/check_network_status.txt\nTo disable NetworkManager's connectivity check, use the following configuration. This can be useful when connected to a VPN that blocks connectivity checks.\n/etc/NetworkManager/conf.d/20-connectivity.conf\n[connectivity]\nenabled=false\nNote\nAlthough automatic connectivity checks are a potential privacy leak, Arch Linux's default connectivity URL is committed to not logging any access. See\n[3]\n[4]\n.\nCaptive portals\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nComplex scripts should not be maintained on the wiki. (Discuss in\nTalk:NetworkManager\n)\nFor those behind a\ncaptive portal\n, the desktop manager may automatically open a window asking for credentials. If your desktop does not, you can use\ncapnet-assist\npackage (however, it currently has a broken NetworkManager dispatcher script). Alternatively, you can create a NetworkManager dispatcher script with the following content:\n/etc/NetworkManager/dispatcher.d/90-open_captive_portal\n#!/bin/sh -e\n# Script to dispatch NetworkManager events\n#\n# Runs shows a login webpage on walled garden networks.\n# See NetworkManager(8) for further documentation of the dispatcher events.\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nif [ -x \"/usr/bin/logger\" ]; then\nlogger=\"/usr/bin/logger -s -t captive-portal\"\nelse\nlogger=\":\"\nfi\nwait_for_process() {\nPNAME=$1\nwhile [ -z \"$(/usr/bin/pgrep $PNAME)\" ]; do\nsleep 3;\ndone\n}\n#launch the browser, but on boot we need to wait that nm-applet starts\nstart_browser() {\nlocal user=\"$1\"\nlocal display=\"$2\"\nexport DISPLAY=\"$display\"\nwait_for_process nm-applet\nexport XAUTHORITY=\"/home/$user/.Xauthority\"\n$logger \"Running browser as '$user' with display '$display' to login in captive portal\"\nsudo -u \"$user\" --preserve-env=DISPLAY,XAUTHORITY -H xdg-open http://capnet.elementary.io 2>&1 > /dev/null\n}\n# Run the right scripts\ncase \"$2\" in\nconnectivity-change)\n$logger -p user.debug \"dispatcher script triggered on connectivity change: $CONNECTIVITY_STATE\"\nif [ \"$CONNECTIVITY_STATE\" = \"PORTAL\" ]; then\n# Match last column of who's output with ' :[at least one digit] '\nwho | awk '$NF ~ /\\(:[0-9]+\\)/ { print $1 \" \" substr($NF, 2, length($NF)-2) };' | \\\nwhile read user display; do\nstart_browser $user $display || $logger -p user.err \"Failed for user: '$user' display: '$display'\"\ndone\nfi\n;;\n*)\n# In a down phase\nexit 0\n;;\nesac\nMake the script\nexecutable\n. But that script assumes you use X and simply opens http page. It might not work for everyone.\nYou will need to\nrestart\nNetworkManager.service\nor reboot for this to start working. Once you do, the dispatcher script should open a login window once it detects you are behind a captive portal.\nSimple solution is\ncaptive-portal-sh\n- shell script that obtains captive portal URL and opens it in your default browser (for Wayland users only).\nAnother solution is\ncaptive-browser-git\nAUR\nbased on Google Chrome.\niwd support for captive portal support on legacy hardware\nSome older Wi-Fi chips (e.g. Broadcom BCM4360) require the proprietary\nwl\ndriver, which lacks support for the OWE/Elliptic-Curve handshake that many captive-portal hotspots use before presenting a login page. By switching NetworkManager’s Wi-Fi backend to\niwd\n(see\n#Using iwd as the Wi-Fi backend\n), which implements the full OWE key exchange in userspace over the existing driver, you can complete the encrypted association, obtain a DHCP lease, and trigger the portal “PORTAL” state. Once that is done, any dispatcher script or browser-launcher will reliably pop up the login page on hardware that otherwise could never fully connect.\nDHCP client\nBy default NetworkManager uses its internal DHCP client. The internal DHCPv4 plugin is based on the\nnettools' n-dhcp4\nlibrary, while the internal DHCPv6 plugin is made from code based on systemd-networkd.\nTo use a different DHCP client\ninstall\none of the alternatives:\ndhcpcd\n-\ndhcpcd\ndhclient\n-\ndhclient\nTo change the DHCP client backend, set the option\nmain.dhcp=\ndhcp_client_name\nwith a configuration file in\n/etc/NetworkManager/conf.d/\n. E.g.:\n/etc/NetworkManager/conf.d/dhcp-client.conf\n[main]\ndhcp=dhcpcd\nNote\nDo not enable the systemd units shipped with the\ndhclient\nand\ndhcpcd\npackages. They will conflict with NetworkManager, see the note in\n#Installation\nfor details.\nDNS management\nNetworkManager's DNS management is described in the GNOME project's wiki page—\nProjects/NetworkManager/DNS\n.\nDNS caching and conditional forwarding\nNetworkManager has a plugin to enable DNS caching and conditional forwarding (\npreviously\ncalled \"split DNS\" in NetworkManager's documentation) using\ndnsmasq\nor\nsystemd-resolved\n. The advantages of this setup is that DNS lookups will be cached, shortening resolve times, and DNS lookups of VPN hosts will be routed to the relevant VPN's DNS servers. This is especially useful if you are connected to more than one VPN.\nNote\nIf\n/etc/resolv.conf\nis a symlink to\n/run/systemd/resolve/stub-resolv.conf\n,\n/run/systemd/resolve/resolv.conf\n,\n/lib/systemd/resolv.conf\nor\n/usr/lib/systemd/resolv.conf\n, NetworkManager will choose systemd-resolved automatically. To use dnsmasq, you must first remove that symlink, then restart NetworkManager.\ndnsmasq\nMake sure\ndnsmasq\nhas been installed. Then set\nmain.dns=dnsmasq\nwith a configuration file in\n/etc/NetworkManager/conf.d/\n:\n/etc/NetworkManager/conf.d/dns.conf\n[main]\ndns=dnsmasq\nNow run\nnmcli general reload\nas root. NetworkManager will automatically start dnsmasq and add\n127.0.0.1\nto\n/etc/resolv.conf\n. The original DNS servers can be found in\n/run/NetworkManager/no-stub-resolv.conf\n. You can verify dnsmasq is being used by doing the same DNS lookup twice with\ndrill example.com\nand verifying the server and query times.\nNote\nYou do not need to start\ndnsmasq.service\nor edit\n/etc/dnsmasq.conf\n. NetworkManager will start dnsmasq without using the systemd service and without reading the dnsmasq's default configuration file(s).\nThe dnsmasq instance started by NetworkManager will bind to\n127.0.0.1:53\n, you cannot run any other software (including\ndnsmasq.service\n) on the same address and port.\nCustom dnsmasq configuration\nCustom configurations can be created for\ndnsmasq\nby creating configuration files in\n/etc/NetworkManager/dnsmasq.d/\n. For example, to change the size of the DNS cache (which is stored in RAM):\n/etc/NetworkManager/dnsmasq.d/cache.conf\ncache-size=1000\nYou can check the configuration file syntax with:\n$ dnsmasq --test --conf-file=/dev/null --conf-dir=/etc/NetworkManager/dnsmasq.d\nSee\ndnsmasq(8)\nfor all available options.\nIPv6\nThe factual accuracy of this article or section is disputed.\nReason:\nThis does not solve the issue because NetworkManager does not add\n::1\nto\n/etc/resolv.conf\n. Unless\n@::1\nis manually passed to drill, it will still fail with\nError: error sending query: No (valid) nameservers defined in the resolver\n. (Discuss in\nTalk:NetworkManager\n)\nEnabling\ndnsmasq\nin NetworkManager may break IPv6-only DNS lookups (i.e.\ndrill -6 [hostname]\n) which would otherwise work. In order to resolve this, creating the following file will configure\ndnsmasq\nto also listen to the IPv6 loopback:\n/etc/NetworkManager/dnsmasq.d/ipv6-listen.conf\nlisten-address=::1\nIn addition,\ndnsmasq\nalso does not prioritize upstream IPv6 DNS. Unfortunately NetworkManager does not do this (\nUbuntu Bug\n). A workaround would be to disable IPv4 DNS in the NetworkManager config, assuming one exists.\nDNSSEC\nThe dnsmasq instance started by NetworkManager by default will not validate\nDNSSEC\n. To enable DNSSEC validation, thus breaking DNS resolution with name servers that do not support it, create the following configuration file:\n/etc/NetworkManager/dnsmasq.d/dnssec.conf\nconf-file=/usr/share/dnsmasq/trust-anchors.conf\ndnssec\nsystemd-resolved\nThis article or section needs expansion.\nReason:\nNetworkManager 1.16 adds a new setting\nmain.systemd-resolved\n[5]\n(enabled by default). It unconditionally sends DNS configuration to systemd-resolved. Related to \"Preserving resolv.conf\" from\nsystemd-resolved#DNS\n? (Discuss in\nTalk:NetworkManager\n)\nNetworkManager can use\nsystemd-resolved\nas a DNS resolver and cache. Make sure that\nsystemd-resolved\nis properly configured and that\nsystemd-resolved.service\nis\nstarted\nbefore using it.\nsystemd-resolved will be used automatically if\n/etc/resolv.conf\nis a\nsymlink\nto\n/run/systemd/resolve/stub-resolv.conf\n,\n/run/systemd/resolve/resolv.conf\nor\n/usr/lib/systemd/resolv.conf\n.\nYou can enable it explicitly by setting\nmain.dns=systemd-resolved\nwith a configuration file in\n/etc/NetworkManager/conf.d/\n:\n/etc/NetworkManager/conf.d/dns.conf\n[main]\ndns=systemd-resolved\nDNS resolver with an openresolv subscriber\nIf\nopenresolv\nhas a subscriber for your local\nDNS resolver\n, set up the subscriber and\nconfigure NetworkManager to use openresolv\n.\nBecause NetworkManager advertises a single \"interface\" to\nresolvconf\n, it is not possible to implement conditional forwarding between two NetworkManager connections. See\nNetworkManager issue 153\n.\nThis can be partially mitigated if you set\nprivate_interfaces=\"*\"\nin\n/etc/resolvconf.conf\n[6]\n. Any queries for domains that are not in search domain list will not get forwarded. They will be handled according to the local resolver's configuration, for example, forwarded to another DNS server or resolved recursively from the DNS root.\nCustom DNS servers\nSetting custom global DNS servers\nTo set DNS servers for all connections, specify them in\nNetworkManager.conf(5)\nusing the syntax\nservers=\nserveripaddress1\n,\nserveripaddress2\n,\nserveripaddress3\nin a section named\n[global-dns-domain-*]\n. For example:\n/etc/NetworkManager/conf.d/dns-servers.conf\n[global-dns-domain-*]\nservers=::1,127.0.0.1\nNote\nIf you use\nNetworkManager's dnsmasq or systemd-resolved plugin\nor\nopenresolv subscribers\n, then do not specify loopback addresses with the\nservers=\noption, it can break DNS resolution.\nThe specified servers do not get sent to\nsystemd-resolved\n, the connection's DNS servers are used instead. See\nNetworkManager issue 1366\nand\nsystemd issue 33754\n.\nSetting custom DNS servers in a connection\nSetting custom DNS servers in a connection (GUI)\nSetup will depend on the type of front-end used; the process usually involves right-clicking on the applet, editing (or creating) a profile, and then choosing DHCP type as\nAutomatic (specify addresses)\n. The DNS addresses will need to be entered and are usually in this form:\n127.0.0.1,\nDNS-server-one\n, ...\n.\nSetting custom DNS servers in a connection (nmcli / connection file)\nTo setup DNS Servers per connection, you change the\nipv4.dns\nand\nipv6.dns\nsettings (and their associated\ndns-search\nand\ndns-options\n) in the\nconnection settings\n.\nIf\nmethod\nis set to\nauto\n(when you use DHCP/RA), you need to set\nignore-auto-dns\nto\nyes\n.\nTo use DNS over TLS (\nrequires systemd-resolved\n), specify the DNS servers using the syntax\ndns=\nip.address\n#\nservername\n;\nand additionally set the\nconnection.dns-over-tls\nsetting to\n2\n. For example, to use Quad9:\n/etc/NetworkManager/system-connections/Example Wi-Fi.nmconnection\n...\n[connection]\n...\ndns-over-tls=2\n[ipv4]\n...\ndns=9.9.9.9#dns.quad9.net;149.112.112.112#dns.quad9.net;\nignore-auto-dns=true\n[ipv6]\n...\ndns=2620:fe::fe#dns.quad9.net;2620:fe::9#dns.quad9.net;\nignore-auto-dns=true\nNote\nThis example uses Quad9. Replace it with a DNS resolver you trust. See\nDomain name resolution#Third-party DNS services\n.\n/etc/resolv.conf\nNetworkManager's\n/etc/resolv.conf\nmanagement mode is configured with the\nmain.rc-manager\nsetting.\nnetworkmanager\nsets it to\nsymlink\nas opposed to the upstream default\nauto\n. The setting and its values are documented in the\nNetworkManager.conf(5)\nman page.\nTip\nUsing openresolv allows NetworkManager to coexist with other\nresolvconf\nsupporting software or, for example, to run a local DNS caching and split-DNS resolver for which openresolv has a\nsubscriber\n. Note that conditional forwarding is\nnot yet fully supported\nwhen using NetworkManager with openresolv.\nNetworkManager\nalso offers hooks via so called dispatcher scripts that can be used to alter the\n/etc/resolv.conf\nafter network changes. See\n#Network services with NetworkManager dispatcher\nand\nNetworkManager(8)\nfor more information.\nNote\nIf NetworkManager is configured to use either\ndnsmasq\nor\nsystemd-resolved\n, then the appropriate loopback addresses will be written to\n/etc/resolv.conf\n.\nThe\nresolv.conf\nfile NetworkManager writes or would write to\n/etc/resolv.conf\ncan be found at\n/run/NetworkManager/resolv.conf\n.\nA\nresolv.conf\nfile with the acquired name servers and search domains can be found at\n/run/NetworkManager/no-stub-resolv.conf\n.\nUnmanaged /etc/resolv.conf\nTo stop NetworkManager from touching\n/etc/resolv.conf\n, set\nmain.dns=none\nwith a configuration file in\n/etc/NetworkManager/conf.d/\n:\n/etc/NetworkManager/conf.d/dns.conf\n[main]\ndns=none\nTip\nYou might also want to set\nmain.systemd-resolved=false\n, so that NetworkManager does not send the DNS configuration to\nsystemd-resolved\n.\nNote\nSee\n#DNS caching and conditional forwarding\n, to configure NetworkManager using other DNS backends like\ndnsmasq\nand\nsystemd-resolved\n, instead of using\nmain.dns=none\n.\nAfter that\n/etc/resolv.conf\nmight be a broken symlink that you will need to remove. Then, just create a new\n/etc/resolv.conf\nfile.\nUse openresolv\nNote\nNetworkManager does not support using systemd-resolved's\nresolvconf\ninterface (\nresolvectl(1) § COMPATIBILITY WITH RESOLVCONF(8)\n) which is provided by\nsystemd-resolvconf\n.\nDo not set\nmain.rc-manager=resolvconf\nwhen using\nsystemd-resolved\n, instead make sure to\ncorrectly create the /etc/resolv.conf symlink\nor\nconfigure NetworkManager to use systemd-resolved explicitly\n.\nMake sure the\nsystemd-resolvconf\npackage is not installed when systemd-resolved is not used. Unless\nsystemd-resolved.service\nstarted, it will break all networking software (not just NetworkManager) that use resolvconf.\nTo configure NetworkManager to use\nopenresolv\n, set\nmain.rc-manager=resolvconf\nwith a configuration file in\n/etc/NetworkManager/conf.d/\n:\n/etc/NetworkManager/conf.d/rc-manager.conf\n[main]\nrc-manager=resolvconf\nFirewall\nYou can\nassign a firewalld zone\nbased on your current connection. For example a restrictive firewall when at work, and a less restrictive one when at home.\nThis can also be done with\nNetworkManager dispatcher\n.\nNetwork services with NetworkManager dispatcher\nThere are quite a few network services that you will not want running until NetworkManager brings up an interface. NetworkManager has the ability to start services when you connect to a network and stop them when you disconnect (e.g. when using\nNFS\n,\nSMB\nand\nNTPd\n).\nTo activate the feature you need to\nenable\nand\nstart\nthe\nNetworkManager-dispatcher.service\n.\nOnce the service is active, scripts can be added to the\n/etc/NetworkManager/dispatcher.d\ndirectory.\nScripts must be owned by\nroot\n, otherwise the dispatcher will not execute them. For added security, set group\nownership\nto root as well:\n# chown root:root /etc/NetworkManager/dispatcher.d/\n10-script.sh\nMake sure the file is\nexecutable\n.\nThe scripts will be run in alphabetical order at connection time, and in reverse alphabetical order at disconnect time. To ensure what order they come up in, it is common to use numerical characters prior to the name of the script (e.g.\n10-portmap\nor\n30-netfs\n(which ensures that the\nportmapper\nis up before NFS mounts are attempted).\nScripts will receive the following arguments:\nInterface name:\ne.g.\neth0\nAction:\nup\n,\ndown\n,\nvpn-up\n,\nvpn-down\n, ... (see\nNetworkManager-dispatcher(8)\nfor the complete list)\nWarning\nIf you connect to foreign or public networks, be aware of what services you are starting and what servers you expect to be available for them to connect to. You could make a security hole by starting the wrong services while connected to a public network.\nAvoiding the dispatcher timeout\nIf the above is working, then this section is not relevant. However, there is a general problem related to running dispatcher scripts which take longer to be executed. Initially an internal timeout of three seconds only was used. If the called script did not complete in time, it was killed. Later the timeout was extended to about 20 seconds (see the\nBugtracker\nfor more information). If the timeout still creates the problem, a work around may be to use a\ndrop-in file\nfor the\nNetworkManager-dispatcher.service\nto remain active after exit:\n/etc/systemd/system/NetworkManager-dispatcher.service.d/remain_after_exit.conf\n[Service]\nRemainAfterExit=yes\nNow start and enable the modified\nNetworkManager-dispatcher\nservice.\nWarning\nAdding the\nRemainAfterExit\nline to it will prevent the dispatcher from closing. Unfortunately, the dispatcher\nhas\nto close before it can run your scripts again. With it the dispatcher will not time out but it also will not close, which means that the scripts will only run once per boot. Therefore, do not add the line unless the timeout is definitely causing a problem.\nDispatcher examples\nAutomatically set the timezone\nCreate a\nNetworkManager dispatcher script\nand make it\nexecutable\n:\n/etc/NetworkManager/dispatcher.d/09-timezone\n#!/bin/sh\ncase \"$2\" in\nup)\ntimedatectl set-timezone \"$(curl --fail https://ipapi.co/timezone)\"\n;;\nesac\nTip\nUsing\nconnectivity-change\ninstead of\nup\ncan prevent timezone changes when connecting to VPNs with clients such as\nOpenConnect\n.\nAlternatively, the tool\ntzupdate\nAUR\nautomatically sets the timezone based on the geolocation of the IP address. This\ncomparison of the most popular IP geolocation apis\nmay be helpful in deciding which API to use in production.\nMount remote directory with sshfs\nAs the script is run in a very restrictive environment, you have to export\nSSH_AUTH_SOCK\nin order to connect to your SSH agent. There are different ways to accomplish this, see\nthis message\nfor more information. The example below works with\nGNOME Keyring\n, and will ask you for the password if not unlocked already. In case NetworkManager connects automatically on login, it is likely\ngnome-keyring\nhas not yet started and the export will fail (hence the sleep). The\nUUID\nto match can be found with the command\nnmcli connection status\nor\nnmcli connection list\n.\n#!/bin/sh\nUSER='username'\nREMOTE='user@host:/remote/path'\nLOCAL='/local/path'\ninterface=$1 status=$2\nif [ \"$CONNECTION_UUID\" = \"\nuuid\n\" ]; then\ncase $status in\nup)\n# sleep 10\nSSH_AUTH_SOCK=$(find /tmp -maxdepth 1 -type s -user \"$USER\" -name 'ssh')\nexport SSH_AUTH_SOCK\nsu \"$USER\" -c \"sshfs $REMOTE $LOCAL\"\n;;\ndown)\nfusermount -u \"$LOCAL\"\n;;\nesac\nfi\nMounting of SMB shares\nSome\nSMB\nshares are only available on certain networks or locations (e.g. at home). You can use the dispatcher to only mount SMB shares that are present at your current location.\nThe following script will check if we connected to a specific network and mount shares accordingly:\n/etc/NetworkManager/dispatcher.d/30-mount-smb.sh\n#!/bin/sh\n# Find the connection UUID with \"nmcli connection show\" in terminal.\n# All NetworkManager connection types are supported: wireless, VPN, wired...\nif [ \"$2\" = \"up\" ]; then\nif [ \"$CONNECTION_UUID\" = \"uuid\" ]; then\nmount /your/mount/point &\n# add more shares as needed\nfi\nfi\nThe following script will unmount all SMB shares before a software initiated disconnect from a specific network:\n/etc/NetworkManager/dispatcher.d/pre-down.d/30-umount-smb.sh\n#!/bin/sh\nif [ \"$CONNECTION_UUID\" = \"uuid\" ]; then\numount -a -l -t cifs\nfi\nNote\nMake sure this script is located in the\npre-down.d\nsub-directory as shown above, otherwise it will unmount all shares on any connection state change.\nThe following script will attempt to unmount all SMB shares following an unexpected disconnect from a specific network:\n/etc/NetworkManager/dispatcher.d/40-umount-smb.sh\n#!/bin/sh\nif [ \"$CONNECTION_UUID\" = \"uuid\" ]; then\nif [ \"$2\" = \"down\" ]; then\numount -a -l -t cifs\nfi\nfi\nNote\nSince NetworkManager 0.9.8, the\npre-down\nand\ndown\nevents are not executed on shutdown or restart, see\nthis bug report\nfor more info.\nThe previous\numount\nscripts are still prone to leaving applications actually accessing the mount to 'hang'.\nAn alternative is to use the script as seen in\nNFS#Using a NetworkManager dispatcher\n:\n/etc/NetworkManager/dispatcher.d/30-smb.sh\n#!/bin/sh\n# Find the connection UUID with \"nmcli con show\" in terminal.\n# All NetworkManager connection types are supported: wireless, VPN, wired...\nWANTED_CON_UUID=\"CHANGE-ME-NOW-9c7eff15-010a-4b1c-a786-9b4efa218ba9\"\nif [ \"$CONNECTION_UUID\" = \"$WANTED_CON_UUID\" ]; then\n# Script parameter $1: network interface name, not used\n# Script parameter $2: dispatched event\ncase \"$2\" in\n\"up\")\nmount -a -t cifs\n;;\n\"down\"|\"pre-down\"|\"vpn-pre-down\")\numount -l -a -t cifs >/dev/null\n;;\nesac\nfi\nNote\nThis script ignores mounts with the\nnoauto\noption, remove this mount option or use\nauto\nto allow the dispatcher to manage these mounts.\nCreate a symlink inside\n/etc/NetworkManager/dispatcher.d/pre-down/\nto catch the\npre-down\nevents:\n# ln -s ../30-smb.sh /etc/NetworkManager/dispatcher.d/pre-down.d/30-smb.sh\nMounting of NFS shares\nSee\nNFS#Using a NetworkManager dispatcher\n.\nUse dispatcher to automatically toggle wireless depending on LAN cable being plugged in\nThe idea is to only turn Wi-Fi on when the LAN cable is unplugged (for example when detaching from a laptop dock), and for Wi-Fi to be automatically disabled, once a LAN cable is plugged in again.\nCreate the following dispatcher script\n[7]\n, replacing\nYour_Ethernet_Interface\nwith your ethernet interface's device name.\nNote\nYou can get a list of interfaces using\nnmcli\n(\nnmcli d | grep ethernet\n). The Ethernet interfaces start with\nen\nor\neth\n, e.g.\nenp0s5\nor\neth0\n.\nRemember to make the script\nexecutable\n. You can verify that it works by\nrestarting\nNetworkManager.service\n, running\nip a\n, and checking that\nwlp3s0\n(or whatever your Wi-Fi interface is called) is in\nstate DOWN\n. If you encounter unexpected behavior, check the\njournal\nof\nNetworkManager-dispatcher.service\n.\n/etc/NetworkManager/dispatcher.d/99-wifi-auto-toggle\n#!/bin/sh\nLOG_PREFIX=\"WiFi Auto-Toggle\"\nETHERNET_INTERFACE=\"\nYour_Ethernet_Interface\n\"\nif [ \"$1\" = \"$ETHERNET_INTERFACE\" ]; then\ncase \"$2\" in\nup)\necho \"$LOG_PREFIX ethernet up\"\nnmcli radio wifi off\n;;\ndown)\necho \"$LOG_PREFIX ethernet down\"\nnmcli radio wifi on\n;;\nesac\nelif [ \"$(nmcli -g GENERAL.STATE device show $ETHERNET_INTERFACE)\" = \"20 (unavailable)\" ]; then\necho \"$LOG_PREFIX failsafe\"\nnmcli radio wifi on\nfi\nNote\nThere is a fail-safe for the case when the LAN interface was connected when the computer was last on, and then disconnected while the computer was off. That would mean the radio would still be off when the computer is turned back on, and with a disconnected LAN interface, you would have no network.\nUse dispatcher to connect to a VPN after a network connection is established\nIn this example we want to connect automatically to a previously defined VPN connection after connecting to a specific Wi-Fi network. First thing to do is to create the dispatcher script that defines what to do after we are connected to the network.\nThe factual accuracy of this article or section is disputed.\nReason:\nA scripting without\niwgetid\ndoes work too and may be more reliable? (Discuss in\nTalk:NetworkManager#Fixes for automatic VPN dispatcher script\n)\nNote\nThis script will require\nwireless_tools\nin order to use\niwgetid\n.\n/etc/NetworkManager/dispatcher.d/vpn-up\n#!/bin/sh\nVPN_NAME=\"name of VPN connection defined in NetworkManager\"\nESSID=\"Wi-Fi network ESSID (not connection name)\"\ninterface=$1 status=$2\ncase $status in\nup|vpn-down)\nif iwgetid | grep -qs \":\\\"$ESSID\\\"\"; then\nnmcli connection up id \"$VPN_NAME\"\nfi\n;;\ndown)\nif iwgetid | grep -qs \":\\\"$ESSID\\\"\"; then\nif nmcli connection show --active | grep \"$VPN_NAME\"; then\nnmcli connection down id \"$VPN_NAME\"\nfi\nfi\n;;\nesac\nIf you would like to attempt to automatically connect to VPN for all Wi-Fi networks, you can use the following definition of the ESSID:\nESSID=$(iwgetid -r)\n. Remember to set the script's permissions\naccordingly\n.\nTrying to connect with the above script may still fail with\nNetworkManager-dispatcher.service\ncomplaining about 'no valid VPN secrets', because of\nthe way VPN secrets are stored\n. Fortunately, there are different options to give the above script access to your VPN password.\n1: One of them requires editing the VPN connection configuration file to make NetworkManager store the secrets by itself rather than inside a keyring\nthat will be inaccessible for root\n: open up\n/etc/NetworkManager/system-connections/\nname of your VPN connection\n.nmconnection\nand change the\npassword-flags\nand\nsecret-flags\nfrom\n1\nto\n0\n.\nIf that alone does not work, you may have to create a\npasswd-file\nin a safe location with the same permissions and ownership as the dispatcher script, containing the following:\n/path/to/passwd-file\nvpn.secrets.password:YOUR_PASSWORD\nThe script must be changed accordingly, so that it gets the password from the file:\n/etc/NetworkManager/dispatcher.d/vpn-up\n#!/bin/sh\nVPN_NAME=\"name of VPN connection defined in NetworkManager\"\nESSID=\"Wi-Fi network ESSID (not connection name)\"\ninterface=$1 status=$2\ncase $status in\nup|vpn-down)\nif iwgetid | grep -qs \":\\\"$ESSID\\\"\"; then\nnmcli connection up id \"$VPN_NAME\" passwd-file /path/to/passwd-file\nfi\n;;\ndown)\nif iwgetid | grep -qs \":\\\"$ESSID\\\"\"; then\nif nmcli connection show --active | grep \"$VPN_NAME\"; then\nnmcli connection down id \"$VPN_NAME\"\nfi\nfi\n;;\nesac\n2: Alternatively, change the\npassword-flags\nand put the password directly in the configuration file adding the section\nvpn-secrets\n:\n[vpn]\n....\npassword-flags=0\n[vpn-secrets]\npassword=\nyour_password\nNote\nIt may now be necessary to re-open the NetworkManager connection editor and save the VPN passwords/secrets again.\nUse dispatcher to disable IPv6 on VPN provider connections\nMany\ncommercial VPN providers\nsupport only IPv4. That means all IPv6 traffic bypasses the VPN and renders it virtually useless. To avoid this, dispatcher can be used to disable all IPv6 traffic for the time a VPN connection is up.\n/etc/NetworkManager/dispatcher.d/10-vpn-ipv6\n#!/bin/sh\ncase \"$2\" in\nvpn-up)\necho 1 > /proc/sys/net/ipv6/conf/all/disable_ipv6\n;;\nvpn-down)\necho 0 > /proc/sys/net/ipv6/conf/all/disable_ipv6\n;;\nesac\nAs an alternative, dispatcher can be used to temporarily set the IPv6 mode of the device used by the VPN connection to\nlink-local\n. This will avoid NetworkManager log spam about IPv6 being disabled. This script will not work if multiple devices or connections provide IPv6 connectivity, but could be adapted to iterate over multiple devices. Note that any change to the connection (using\nnmcli(1)\nor a\ndesktop environment\n) will reapply the entire connection to the device and re-enable IPv6 (if it is enabled in the connection).\n/etc/NetworkManager/dispatcher.d/10-vpn-ipv6\n#!/bin/sh\ncase \"$2\" in\nvpn-up)\nnmcli device modify \"${DEVICE_IFACE}\" ipv6.method link-local\n;;\nvpn-down)\nnmcli device reapply \"${DEVICE_IFACE}\"\n;;\nesac\nOpenNTPD\nSee\nOpenNTPD#Using NetworkManager dispatcher\n.\nDynamically set NTP servers received via DHCP with systemd-timesyncd\nWhen roaming between different networks (e.g. a company's LAN, Wi-Fi at home, various other Wi-Fi now and then) you might want to set the NTP server(s) used by timesyncd to those provided by DHCP. However, NetworkManager itself is not capable to communicate with systemd-timesyncd to set the NTP server(s).\nThe dispatcher can work around it.\nCreate\nthe overlay directory for your systemd-timesyncd configuration\n/etc/systemd/timesyncd.conf.d\nif it does not already exist. Inside\n/etc/NetworkManager/dispatcher.d\n, put the following:\n/etc/NetworkManager/dispatcher.d/10-update-timesyncd\n#!/bin/sh\n[ -z \"$CONNECTION_UUID\" ] && exit 0\nINTERFACE=\"$1\"\nACTION=\"$2\"\ncase $ACTION in\nup | dhcp4-change | dhcp6-change)\n[ -n \"$DHCP4_NTP_SERVERS\" ] || exit 0\nmkdir -p /etc/systemd/timesyncd.conf.d\ncat <<-THE_END >\"/etc/systemd/timesyncd.conf.d/${CONNECTION_UUID}.conf\"\n[Time]\nNTP=$DHCP4_NTP_SERVERS\nTHE_END\nsystemctl restart systemd-timesyncd.service\n;;\ndown)\nrm -f \"/etc/systemd/timesyncd.conf.d/${CONNECTION_UUID}.conf\"\nsystemctl restart systemd-timesyncd.service\n;;\nesac\nEvery time NetworkManager sets up a new network connection (\nACTION=up\n) or gets some update for an existing connection (\nACTION=dhcp4-change\nor\nACTION=dhcp6-change\n) and the provided connection data contains information about NTP server(s) (\nDHCP4_NTP_SERVERS\n), a connection specific overlay configuration file is written to\n/etc/systemd/timesyncd.conf.d\n, containing the provided NTP server(s). Whenever a connection is taken down (\nACTION=down\n) the connection specific overlay file is removed. After each change to the configuration of systemd-timesyncd, this service is restarted to pick up the updated configuration. The use of connection specific configuration files is intentional so that when two or more connections are managed by NetworkManager in parallel the different NTP server names in the configuration are not overwritten as\nup\n,\ndhcp4-change\n,\ndhcp6-change\nand\ndown\nactions might come in an arbitrary order.\nTesting\nNetworkManager applets are designed to load upon login so no further configuration should be necessary for most users.  If you have already disabled your previous network settings and disconnected from your network, you can now test if NetworkManager will work. The first step is to\nstart\nNetworkManager.service\n.\nSome applets will provide you with a\n.desktop\nfile so that the NetworkManager applet can be loaded through the application menu.  If it does not, you are going to either have to discover the command to use or logout and login again to start the applet.  Once the applet is started, it will likely begin polling network connections with for auto-configuration with a DHCP server.\nTo start the GNOME applet in non-xdg-compliant window managers like\nawesome\n:\nnm-applet --sm-disable &\nFor static IP addresses, you will have to configure NetworkManager to understand them.  The process usually involves right-clicking the applet and selecting something like 'Edit Connections'.\nTips and tricks\nEncrypted Wi-Fi passwords\nBy default, NetworkManager stores passwords in clear text in the connection files at\n/etc/NetworkManager/system-connections/\n. To print the stored passwords, use the following command:\n# grep -r '^psk=' /etc/NetworkManager/system-connections/\nThe passwords are accessible to the root user in the filesystem and to users with access to settings via the GUI (e.g.\nnm-applet\n).\nIt is preferable to save the passwords in encrypted form in a keyring instead of clear text. The downside to this is that the connections have to be set up for each user.\nIn order to read and write to the keyring, there must be a secret agent available. This can be one of:\nnmcli\nwith the\n--ask\noption\nOne of the graphical interfaces from\n#Front-ends\nIf you make neither of these available, then authentication will fail with the error\nno secrets: No agents were available for this request.\nUsing GNOME Keyring\nThe keyring daemon has to be started and the keyring needs to be unlocked for the following to work.\nFurthermore, NetworkManager needs to be configured not to store the password for all users. Using GNOME's\nnetwork-manager-applet\n, run\nnm-connection-editor\nfrom a terminal, select a network connection, click\nEdit\n, select the\nWi-Fi Security\ntab and click on the right icon of password and check\nStore the password only for this user\n.\nUsing KDE Wallet\nUsing KDE's\nplasma-nm\n, click the applet, click on the top right\nSettings\nicon, click on a network connection, in the\nGeneral configuration\ntab, untick\nAll users may connect to this network\n. If the option is ticked, the passwords will still be stored in clear text, even if a keyring daemon is running.\nIf the option was selected previously and you un-tick it, you may have to use the\nreset\noption first to make the password disappear from the file. Alternatively, delete the connection first and set it up again.\nSharing internet connection over Wi-Fi\nYou can share your internet connection (e.g. 3G or wired) with a few clicks.  Please note that a\nfirewall\nmay interfere with internet sharing.\nYou will need a Wi-Fi card which supports AP mode, see\nSoftware access point#Wi-Fi device must support AP mode\nfor details.\nInstall\nthe\ndnsmasq\npackage to be able to actually share the connection. Note that NetworkManager starts its own instance of\ndnsmasq\n, independent of\ndnsmasq.service\n, as a DHCP server. See\n#dnsmasq\nfor the caveats.\nCreate the shared connection:\nClick on applet and choose\nCreate new wireless network\n.\nFollow wizard (choose WPA2 or higher, be sure to use at least 8 character long password, lower lengths will fail).\nChoose either\nHotspot\nor Ad-hoc as Wi-Fi mode.\nThe connection will be saved and remain stored for the next time you need it.\nNote\nAndroid does not support connecting to Ad-hoc networks. To share a connection with Android use infrastructure mode (i.e. set Wi-Fi mode to \"Hotspot\").\nSharing internet connection over Ethernet\nScenario: your device has internet connection over Wi-Fi and you want to share the internet connection to other devices over Ethernet.\nRequirements:\nInstall\nthe\ndnsmasq\nand\nnm-connection-editor\npackages to be able to actually share the connection. Note that NetworkManager starts its own instance of\ndnsmasq\n, independent of\ndnsmasq.service\n, as a DHCP server. See\n#dnsmasq\nfor the caveats.\nYour internet connected device and the other devices are connected over a suitable Ethernet cable (this usually means a cross over cable or a switch in between).\nInternet sharing is not blocked by a\nfirewall\n.\nSteps:\nRun\nnm-connection-editor\nfrom terminal.\nAdd a new Ethernet connection.\nGive it some sensible name. For example \"Shared Internet\"\nGo to \"IPv4 Settings\".\nFor \"Method:\" select \"Shared to other computers\".\nSave\nNow you should have a new option \"Shared Internet\" under the Wired connections in NetworkManager.\nChecking if networking is up inside a cron job or script\nThis article or section is out of date.\nReason:\nnm-tool\nwas removed from NetworkManager for long time now\n[8]\n.\nnmcli\nshould be used instead. (Discuss in\nTalk:NetworkManager\n)\nSome\ncron\njobs require networking to be up to succeed. You may wish to avoid running these jobs when the network is down. To accomplish this, add an\nif\ntest for networking that queries NetworkManager's\nnm-tool\nand checks the state of networking. The test shown here succeeds if any interface is up, and fails if they are all down. This is convenient for laptops that might be hardwired, might be on wireless, or might be off the network.\nif [ $(nm-tool|grep State|cut -f2 -d' ') == \"connected\" ]; then\n#Whatever you want to do if the network is online\nelse\n#Whatever you want to do if the network is offline - note, this and the else above are optional\nfi\nThis is useful for a\ncron.hourly\nscript that runs\nfpupdate\nfor the F-Prot virus scanner signature update, as an example. Another way it might be useful, with a little modification, is to differentiate between networks using various parts of the output from\nnm-tool\n; for example, since the active wireless network is denoted with an asterisk, you could grep for the network name and then grep for a literal asterisk.\nConnect to network with secret on boot\nBy default, NetworkManager will not connect to networks requiring a secret automatically on boot. This is because it locks such connections to the user who makes it by default, only connecting after they have logged in. To change this, do the following:\nRight click on the\nnm-applet\nicon in your panel and select Edit Connections and open the Wireless tab\nSelect the connection you want to work with and click the Edit button\nCheck the boxes “Connect Automatically” and “Available to all users”\nAdditionally, ensure that under \"Wi-Fi Security\", \"Store password for all users (not encrypted)\" is selected\nLog out and log back in to complete.\nOpenConnect with password in KWallet\nWhile you may type both values at connection time,\nplasma-nm\n0.9.3.2-1 and above are capable of retrieving OpenConnect username and password directly from\nKWallet\n.\nOpen \"KDE Wallet Manager\" and look up your OpenConnect VPN connection under \"Network Management|Maps\". Click \"Show values\" and\nenter your credentials in key \"VpnSecrets\" in this form (replace\nusername\nand\npassword\naccordingly):\nform:main:username%SEP%\nusername\n%SEP%form:main:password%SEP%\npassword\nNext time you connect, username and password should appear in the \"VPN secrets\" dialog box.\nIgnore specific devices\nSometimes it may be desired that NetworkManager ignores specific devices and does not try to configure addresses and routes for them. You can quickly and easily ignore devices by MAC or interface-name by using the following in\n/etc/NetworkManager/conf.d/unmanaged.conf\n:\n[keyfile]\nunmanaged-devices=mac:00:22:68:1c:59:b1;mac:00:1E:65:30:D1:C4;interface-name:eth0\nAfter editing the file, run\nnmcli general reload\nas root. Afterwards you should be able to configure interfaces without NetworkManager altering what you have set.\nConfiguring MAC address randomization\nThis article or section is a candidate for merging with\nNetworkManager/Privacy#MAC Randomization\n.\nNotes:\nThere is a dedicated sub-page for Privacy now. (Discuss in\nTalk:NetworkManager\n)\nNote\nDisabling MAC address randomization may be needed to get (stable) link connection\n[9]\nand/or networks that restrict devices based on their MAC Address or have a limit network capacity.\nMAC randomization can be used for increased privacy by not disclosing your real MAC address to the network.\nNetworkManager supports two types MAC Address Randomization: randomization during scanning, and for network connections. Both modes can be configured by modifying\n/etc/NetworkManager/NetworkManager.conf\nor by creating a separate configuration file in\n/etc/NetworkManager/conf.d/\nwhich is recommended since the aforementioned configuration file may be overwritten by NetworkManager.\nRandomization during Wi-Fi scanning is enabled by default, but it may be disabled by adding the following lines to\n/etc/NetworkManager/NetworkManager.conf\nor a dedicated configuration file under\n/etc/NetworkManager/conf.d\n:\n/etc/NetworkManager/conf.d/wifi_rand_mac.conf\n[device]\nwifi.scan-rand-mac-address=no\nMAC randomization for network connections can be set to different modes for both wireless and ethernet interfaces. See the\nGNOME blog post\nfor more details on the different modes.\nIn terms of MAC randomization the most important modes are\nstable\nand\nrandom\n.\nstable\ngenerates a random MAC address when you connect to a new network and associates the two permanently. This means that you will use the same MAC address every time you connect to that network. In contrast,\nrandom\nwill generate a new MAC address every time you connect to a network, new or previously known. You can configure the MAC randomization by adding the desired configuration under\n/etc/NetworkManager/conf.d\n:\n/etc/NetworkManager/conf.d/wifi_rand_mac.conf\n[device-mac-randomization]\n# \"yes\" is already the default for scanning\nwifi.scan-rand-mac-address=yes\n[connection-mac-randomization]\n# Randomize MAC for every ethernet connection\nethernet.cloned-mac-address=random\n# Generate a random MAC for each Wi-Fi and associate the two permanently.\nwifi.cloned-mac-address=stable\nTo configure MAC randomization for a specific connection (for example, if the network does not like random MAC addresses),\nedit the connection\nto set\n802-11-wireless.cloned-mac-address\nto one of the modes (e.g.\nstable\nor\nrandom\n).\nSee the following\nGNOME blog post\nfor more details.\nEnable IPv6 Privacy Extensions\nSee\nIPv6#NetworkManager\n.\nConfigure a unique DUID per connection\nThe DHCPv6 Unique Identifier (DUID) is a value used by the DHCPv6 client to identify itself to DHCPv6 servers. NetworkManager supports 3 types of DUID:\nDUID-UUID (\nRFC 6355\n): generated from an Universally Unique IDentifier (UUID).\nDUID-LL (\nRFC 3315\n): generated from the Link-Layer address (a.k.a. MAC address).\nDUID-LLT (\nRFC 3315\n): generated from the Link-Layer address plus a timestamp.\nIf the internal NetworkManager's DHCP client is in use (the default) it will identify itself with a global and permanent DUID-UUID generated from the machine-id (\n/etc/machine-id\n). This means that all connections share the same UUID, which may be a privacy breach.\nFortunately, NetworkManager is able to provide unique DUIDs per connection, derived from the connection's stable-id and a per-host unique key. You can enable that by adding the following configuration under\n/etc/NetworkManager/conf.d\n:\n/etc/NetworkManager/conf.d/duid.conf\n[connection]\nipv6.dhcp-duid=stable-uuid\nThe\nstable-ll\nand\nstable-llt\nvalues are also supported. For further information read the description for\ndhcp-duid\nin\nnm-settings(5) § ipv6 setting\n.\nWorking with wired connections\nBy default, NetworkManager generates a connection profile for each wired ethernet connection it finds. At the point when generating the connection, it does not know whether there will be more Ethernet adapters available. Hence, it calls the first wired connection \"Wired connection 1\". You can avoid generating this connection, by configuring\nno-auto-default\n(see\nNetworkManager.conf(5)\n), or by simply deleting it. Then NetworkManager will remember not to generate a connection for this interface again.\nYou can also edit the connection (and persist it to disk) or delete it. NetworkManager will not re-generate a new connection. Then you can change the name to whatever you want. You can use something like\nnm-connection-editor\nfor this task.\nUsing iwd as the Wi-Fi backend\nNote\nDo not enable\niwd.service\nor manually configure\niwd\n. NetworkManager will start and manage it itself.\nConsider\nexisting issues\nbefore switching to\niwd\n.\nTo enable the\nexperimental iwd backend\n, first\ninstall\niwd\nand then create the following configuration file:\n/etc/NetworkManager/conf.d/wifi_backend.conf\n[device]\nwifi.backend=iwd\nAlternatively, you can install\nnetworkmanager-iwd\nAUR\n, a modified package configured to build\nNetworkManager\nworking exclusively with\niwd\n, with the main difference being that\niwd\nis required and\nwpa_supplicant\ncan be uninstalled after building.\nNote\nYou may need to\nconvert existing NetworkManager network profiles\nafter switching to\niwd\n.\nRunning in a network namespace\nIf you would like to run NetworkManager inside a network namespace (e.g., to manage a specific device which should be used by selected applications), bring the device down before moving it to the namespace:\n$ ip link set dev\nMY_DEVICE\ndown\n$ ip link set dev\nMY_DEVICE\nnetns\nMY_NAMESPACE\n$ ip netns exec\nMY_NAMESPACE\nNetworkManager\n...\n$ ip netns exec\nMY_NAMESPACE\nkillall NetworkManager\notherwise NetworkManager will later fail to establish the connection with a\ndevice is strictly unmanaged\nerror.\nAutomatically connect to VPN\nNetworkManager can be set to automatically connect to a VPN when connecting to the internet, on a per network basis. The VPN connection itself can be added in GNOME's NetworkManager front-end, but to make it automatically use the VPN\nnmcli\nmust be used. Other front-ends might not have this limitation.\nFirst, make sure to make the VPN connection available to all users. In the GNOME this is a matter of checking a box under the\ndetails\ntab. Under the\nIdentity\ntab, in the password field, click the icon on the right side in the field, and set it to\nStore the password for all users\n.\nThen find the UUID of the VPN connection, and add that to\nconnection.secondaries\nof the Internet connection:\n# UUID=$(nmcli --get-values connection.uuid connection show\nname-of-VPN-connection\n)\n# nmcli connection modify\nname-of-Internet-connection\nconnection.secondaries \"$UUID\"\nNow when NetworkManager is restarted and you connect to the Internet connection you have configured, you should automatically get connected to the VPN.\nTroubleshooting\nNo prompt for password of secured Wi-Fi networks\nWhen trying to connect to a secured Wi-Fi network, no prompt for a password is shown and no connection is established. This happens when no keyring package is installed. An easy solution is to install\ngnome-keyring\n. If you want the passwords to be stored in encrypted form, follow\nGNOME Keyring\nto set up the\ngnome-keyring-daemon\n.\nNetwork management disabled\nWhen NetworkManager shuts down but the pid (state) file is not removed, you will see a\nNetwork management disabled\nmessage. If this happens, remove the file manually:\n# rm /var/lib/NetworkManager/NetworkManager.state\nProblems with internal DHCP client\nIf you have problems with getting an IP address using the internal DHCP client, consider using another DHCP client, see\n#DHCP client\nfor instructions. This workaround might solve problems in big wireless networks like eduroam.\nDHCP problems with dhclient\nIf you have problems with getting an IP address via DHCP, try to add the following to your\n/etc/dhclient.conf\n:\ninterface \"eth0\" {\nsend dhcp-client-identifier 01:\naa:bb:cc:dd:ee:ff\n;\n}\nWhere\naa:bb:cc:dd:ee:ff\nis the MAC address of this NIC. The MAC address can be found using the\nip link show\ninterface\ncommand from the\niproute2\npackage.\n3G modem not detected\nSee\nMobile broadband modem#NetworkManager\n.\nSwitching off WLAN on laptops\nSometimes NetworkManager will not work when you disable your Wi-Fi adapter with a switch on your laptop and try to enable it again afterwards. This is often a problem with\nrfkill\n. To check if the driver notifies\nrfkill\nabout the wireless adapter's status, use:\n$ watch -n1 rfkill list all\nIf one identifier stays blocked after you switch on the adapter you could try to manually unblock it with (where X is the number of the identifier provided by the above output):\n# rfkill event unblock X\nStatic IP address settings revert to DHCP\nThis article or section is out of date.\nReason:\nThis section is\nadded in 2010\nand describes an ancient version of\nnm-applet\n. Is this still relevant in 2024? (Discuss in\nTalk:NetworkManager\n)\nDue to an unresolved bug, when changing default connections to a static IP address,\nnm-applet\nmay not properly store the configuration change, and will revert to automatic DHCP.\nTo work around this issue you have to edit the default connection (e.g. \"Auto eth0\") in\nnm-applet\n, change the connection name (e.g. \"my eth0\"), uncheck the \"Available to all users\" checkbox, change your static IP address settings as desired, and click\nApply\n.  This will save a new connection with the given name.\nNext, you will want to make the default connection not connect automatically.  To do so, run\nnm-connection-editor\n(\nnot\nas root). In the connection editor, edit the default connection (e.g. \"Auto eth0\") and uncheck \"Connect automatically\".  Click\nApply\nand close the connection editor.\nCannot edit connections as normal user\nSee\n#Set up PolicyKit permissions\n.\nForget hidden wireless network\nSince hidden networks are not displayed in the selection list of the Wireless view, they cannot be forgotten (removed) with the GUI. You can delete one with the following command:\n# rm /etc/NetworkManager/system-connections/\nSSID\n.nmconnection\nThis also works for any other connection.\nVPN not working in GNOME\nWhen setting up OpenConnect or vpnc connections in NetworkManager while using GNOME, you will sometimes never see the dialog box pop up and the following error appears in\n/var/log/errors.log\n:\nlocalhost NetworkManager[399]: <error> [1361719690.10506] [nm-vpn-connection.c:1405] get_secrets_cb(): Failed to request VPN secrets #3: (6) No agents were available for this request.\nThis is caused by the GNOME NetworkManager Applet expecting dialog scripts to be at\n/usr/lib/gnome-shell\n, when NetworkManager's packages put them in\n/usr/lib/networkmanager\n.\nAs a \"temporary\" fix (this bug has been around for a while now), make the following symlink(s):\nFor OpenConnect:\nln -s /usr/lib/nm-openconnect-auth-dialog /usr/lib/gnome-shell/\nFor VPNC (i.e. Cisco VPN):\nln -s /usr/lib/nm-vpnc-auth-dialog /usr/lib/gnome-shell/\nThis may need to be done for any other NetworkManager VPN plugins as well, but these are the two most common.\nUnable to connect to visible European wireless networks\nWLAN chips are shipped with a default\nregulatory domain\n. If your access point does not operate within these limitations, you will not be able to connect to the network. Fixing this is easy:\nInstall\nwireless-regdb\n.\nUncomment the correct country code in\n/etc/conf.d/wireless-regdom\n.\nReboot the system, because the setting is only read on boot.\nAutomatic connect to VPN on boot is not working\nThe problem occurs when the system (i.e. NetworkManager running as the root user) tries to establish a VPN connection, but the password is not accessible because it is stored in the GNOME Keyring of a particular user.\nA solution is to keep the password to your VPN in plaintext, as described in step (2.) of\n#Use dispatcher to connect to a VPN after a network connection is established\n.\nYou do not need to use the dispatcher described in step (1.) to auto-connect anymore, if you use the new \"auto-connect VPN\" option from the\nnm-applet\nGUI.\nsystemd bottleneck\nOver time the log files (\n/var/log/journal\n) can become very large. This can have a big impact on boot performance when using NetworkManager, see:\nsystemd#Boot time increasing over time\n.\nRegular network disconnects, latency and lost packets (Wi-Fi)\nNetworkManager does a scan every 2 minutes.\nSome Wi-Fi drivers have issues when scanning for base stations whilst connected/associated. Symptoms include VPN disconnects/reconnects and lost packets, web pages failing to load and then refresh fine.\nRunning\njournalctl -f\nas root will indicate that this is taking place, messages like the following will be contained in the logs at regular intervals.\nNetworkManager[410]: <info>  (wlp3s0): roamed from BSSID 00:14:48:11:20:CF (my-wifi-name) to (none) ((none))\nIf roaming is not important, the periodic scanning behavior can be disabled by locking the BSSID of the access point in the Wi-Fi connection profile.\nUnable to turn on Wi-Fi with Lenovo laptop (IdeaPad, Legion, etc.)\nThere is an issue with the\nideapad_laptop\nmodule on some Lenovo models due to the Wi-Fi driver incorrectly reporting a soft block. The card can still be manipulated with\nnetctl\n, but managers like NetworkManager break. You can verify that this is the problem by checking the output of\nrfkill list\nafter toggling your hardware switch and seeing that the soft block persists.\nThe factual accuracy of this article or section is disputed.\nReason:\nTry to use\nrfkill.default_state\nand\nrfkill.master_switch_mode\n(see\nkernel-parameters.html\n) to fix the rfkill problem. (Discuss in\nTalk:NetworkManager\n)\nUnloading\nthe\nideapad_laptop\nmodule should fix this. (\nwarning\n: this may disable the laptop keyboard and touchpad also!).\nTurn off hostname sending\nNetworkManager by default sends the hostname to the DHCP server.\nTo disable sending your hostname to the DHCP server globally, set the\nipv4.dhcp-send-hostname=0\nand\nipv6.dhcp-send-hostname=0\noptions with a configuration file in\n/etc/NetworkManager/conf.d/\n. E.g.:\n/etc/NetworkManager/conf.d/dhcp-send-hostname.conf\n[connection]\nipv4.dhcp-send-hostname=0\nipv6.dhcp-send-hostname=0\nTo disable sending your hostname to the DHCP server for a specific connection (or alternatively, enable it for a connection if it is disabled globally), add the following to your network connection file:\n/etc/NetworkManager/system-connections/\nyour_connection_file\n.nmconnection\n...\n[ipv4]\ndhcp-send-hostname=false\n...\n[ipv6]\ndhcp-send-hostname=false\n...\nNote\nThese options are only honored by the default\ninternal DHCP client\n. To omit sending the hostname when using NetworkManager with dhcpcd, edit\n/etc/dhcpcd.conf\nand insert\nanonymous\nas the last line.\nnm-applet disappears in i3wm\nIf you use the\nxfce4-notifyd.service\nfor notifications you must\nedit\nthe unit and add the following:\n/etc/systemd/user/xfce4-notifyd.service.d/display_env.conf\n[Service]\nEnvironment=\"DISPLAY=:0.0\"\nAfter reloading the daemons\nrestart\nxfce4-notifyd.service\n. Exit i3 and start it back up again and the applet should show on the tray.\nUnit dbus-org.freedesktop.resolve1.service not found\nIf\nsystemd-resolved.service\nis not started, NetworkManager will try to start it using D-Bus and fail:\ndbus-daemon[991]: [system] Activating via systemd: service name='org.freedesktop.resolve1' unit='dbus-org.freedesktop.resolve1.service' requested by ':1.23' (uid=0 pid=1012 comm=\"/usr/bin/NetworkManager --no-daemon \")\ndbus-daemon[991]: [system] Activation via systemd failed for unit 'dbus-org.freedesktop.resolve1.service': Unit dbus-org.freedesktop.resolve1.service not found.\ndbus-daemon[991]: [system] Activating via systemd: service name='org.freedesktop.resolve1' unit='dbus-org.freedesktop.resolve1.service' requested by ':1.23' (uid=0 pid=1012 comm=\"/usr/bin/NetworkManager --no-daemon \")\nThis is because NetworkManager will try to send DNS information to\nsystemd-resolved\nregardless of the\nmain.dns=\nsetting in\nNetworkManager.conf(5)\n.\n[10]\nThis can be disabled with a configuration file in\n/etc/NetworkManager/conf.d/\n:\n/etc/NetworkManager/conf.d/no-systemd-resolved.conf\n[main]\nsystemd-resolved=false\nSee\nFS#62138\n.\nSecrets were required, but not provided\nIf you received the following error when attempting to connect to a network:\n$ nmcli device wifi connect\nSSID\npassword\npassword\nError: Connection activation failed: (7) Secrets were required, but not provided\nThis error can have numerous causes and you should read the\njournal\n(filter it with\n-u NetworkManager\n). For example, if NetworkManager took too long to establish connection, it will believe that the password is incorrect:\nNetworkManager[1372]: <warn>  [1643991888.3808] device (wlan0): Activation: (wifi) association took too long\nNetworkManager[1372]: <info>  [1643991888.3809] device (wlan0): state change: config -> need-auth (reason 'none', sys-iface-state: 'managed')\nNetworkManager[1372]: <warn>  [1643991888.3838] device (wlan0): Activation: (wifi) asking for new secrets\nYou can try deleting the connection profile and creating a new one:\n$ nmcli connection delete\nSSID\n$ nmcli device wifi connect\nSSID\npassword\npassword\nYou can also try disabling MAC address randomization:\n/etc/NetworkManager/conf.d/wifi_rand_mac.conf\n[device]\nwifi.scan-rand-mac-address=no\nWPA Enterprise connection with iwd\nIf you try to connect to an WPA Enterprise network like 'eduroam' with NetworkManager with the\niwd backend\nthen you will get the following error from NetworkManager:\nConnection 'eduroam' is not avialable on device wlan0 because profile is not compatible with device (802.1x connections must have IWD provisioning files)\nThis is because NetworkManager can not configure a WPA Enterprise network. Therefore you have to configure it using an iwd configuration file\n/var/lib/iwd/\nessid\n.8021x\nlike described in\niwd#WPA Enterprise\n.\nFailed to request VPN secrets\nIf you get this error:\nFailed to request VPN secrets #1: No agents were available for this request.\nIt is either because the password is empty or you have to\nset up PolicyKit permissions\n.\nOpenVPN connections fail with \"secrets: failed to request VPN secrets\" warn\nThis article or section is being considered for removal.\nReason:\nThis does not warrant a troubleshooting section. Optional dependencies are pointed out by pacman, if this is not clear enough it should be covered in\n#VPN support\n. (Discuss in\nTalk:NetworkManager#Remove unnecessary section 8.22\n)\nThe package\nnetworkmanager-openvpn\nrequires\nlibnma-gtk4\nand optionally\nlibnma\n(Gtk3) when integrated within the GNOME-Shell. If\nlibnma\nis required but not installed a message will be  printed to the system log:\nNetworkManager[642]: <warn>  [...] vpn[...\"name_of_vpn_profile VPN\"]: secrets: failed to request VPN secrets #3: No agents were available for this request.\nOpenVPN connections fail with OpenSSL \"ca md too weak\" error\nSince\nopenssl\nwas updated to version 3, certificates generated with legacy cryptographic algorithms are rejected by default. Attempting to use\nnetworkmanager-openvpn\nwith such a setup can result in the following error in the logs:\nnm-openvpn[14359]: OpenSSL: error:0A00018E:SSL routines::ca md too weak\nnm-openvpn[14359]: Cannot load certificate file /home/archie/.local/share/networkmanagement/certificates/my_issued_cert.crt\nnm-openvpn[14359]: Exiting due to fatal error\nThe correct approach is to have the OpenVPN server administrator generate and re-issue more secure certificates. However, as an immediate work-around, OpenVPN requires\ntls-cipher \"DEFAULT:@SECLEVEL=0\"\n. This may not be possible through the plugin GUI, but it is possible with\nnmcli\n. Separately, you will also need to enable the\nlegacy\nprovider in OpenSSL.\nFirstly, obtain the name of the VPN connection with the issue, from the output of the following:\n$ nmcli connection show\nAssuming the connection name is\nvpn.example.com\n, use\nnmcli\nlike so:\n$ nmcli connection modify vpn.example.com +vpn.data tls-cipher=DEFAULT:@SECLEVEL=0\nThe change should instantly be reflected in\n/etc/NetworkManager/system-connections/vpn.example.com.nmconnection\n.\nAs for OpenSSL, edit\n/etc/ssl/openssl.cnf\nas described on the\nOpenSSL wiki\n.\nSpecifically, at the end of the\n[provider_sect]\nsection add\nlegacy = legacy_sect\n. Under\n[default_sect]\nuncomment\nactivate = 1\n. Lastly, add a new section\n[legacy_sect]\nthat also contains the line\nactivate = 1\n. Excluding most other preexisting configuration sections, the end result will look something like:\n/etc/ssl/openssl.cnf\nopenssl_conf = openssl_init\n[openssl_init]\nproviders = provider_sect\n[provider_sect]\ndefault = default_sect\nlegacy = legacy_sect\n[default_sect]\nactivate = 1\n[legacy_sect]\nactivate = 1\nFinally,\nrestart\nthe\nNetworkManager.service\nto have the new OpenSSL configuration take effect.\nWPA Enterprise connections fail to authenticate with OpenSSL \"unsupported protocol\" error\nSince\nopenssl\nwas updated to version 3, \"SSL 3, TLS 1.0, TLS 1.1, and DTLS 1.0 only work at security level 0\"\nby default\n. Attempting to authenticate to a Wi-Fi network only supporting older standards results in the following error in the logs:\nwpa_supplicant[3320]: SSL: SSL3 alert: write (local SSL3 detected an error):fatal:protocol version\nwpa_supplicant[3320]: OpenSSL: openssl_handshake - SSL_connect error:0A000102:SSL routines::unsupported protocol\nwpa_supplicant[3320]: wlp3s0: CTRL-EVENT-EAP-FAILURE EAP authentication failed\nThe correct approach is to convince the institution's administrator to upgrade the encrypted networking tunnel protocol to TLS 1.3 and optionally drop support for deprecated security standards, including TLS 1.0/1.1, DTLS 1.0 and SSL 1-3. However, as an immediate workaround, there are multiple ways to allow TLS 1.0 and/or 1.1 by default. One way would be to manually patch or revert the breaking changes in OpenSSL (\n[11]\n). As this also lowers security for all other programs using OpenSSL level 1, it is not recommended. Instead, one can directly set the level used by wpa_supplicant, like described in\nBBS#286417\n. To only change the affected connection, it is possible to set\nphase1-auth-flags=32\nor\nphase1-auth-flags=64\nin the\n[802-1x]\nsection of the connection's configuration file. This may not be possible through GUIs, but it is possible with\nnmcli\n.\nFirstly, obtain the name of the Wi-Fi connection with the issue, from the output of the following:\n$ nmcli connection show\nAssuming the connection uses TLS 1.0 and its name is\nExample Wi-Fi\n, use\nnmcli\nlike so:\n$ nmcli connection modify 'Example Wi-Fi' 802-1x.phase1-auth-flags 32\nAnd for a TLS 1.1 connection, type \"64\" instead:\n$ nmcli connection modify 'Example Wi-Fi' 802-1x.phase1-auth-flags 64\nNote\nThe number you type in refers to the number you get from raising 2 to the power of\nn\n. Here,\nn\nis the index of the network authentication bit octet, read from right to left. Flipping the fifth bit enables TLS 1.0\n[log(2) 32]\nand flipping the sixth bit enables TLS 1.1\n[log(2) 64]\n.\nThe change should instantly be reflected in\n/etc/NetworkManager/system-connections/Example Wi-Fi.nmconnection\n.\nFinally,\nrestart\nthe\nNetworkManager.service\nto have the new OpenSSL configuration take effect.\nSee also\nNetworkManager for Administrators Part 1\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=NetworkManager&oldid=853687\n\"\nCategories\n:\nNetwork managers\nDHCP\nHidden categories:\nPages or sections flagged with Template:Style\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Out of date\nPages or sections flagged with Template:Merge\nSections flagged with Template:Remove\nSearch\nSearch\nNetworkManager\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/NetworkManager"}}
{"text": "systemd-networkd - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nsystemd-networkd\n7 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nsystemd\nsystemd-resolved\nsystemd-nspawn\nNetwork bridge\nNetwork configuration\nWireless network configuration\nCategory:Network configuration\nsystemd-networkd\nis a system daemon that manages network configurations. It detects and configures network devices as they appear; it can also create virtual network devices. This service can be especially useful to set up complex network configurations for a container managed by\nsystemd-nspawn\nor for virtual machines. It also works fine on simple connections.\nInstallation\nsystemd\nis part of the default Arch installation and contains all needed files to operate a wired network.  Wireless adapters, covered later in this article, can be set up by services, such as\nwpa_supplicant\nor\niwd\n.\nRequired services and setup\nTo use\nsystemd-networkd\n,\nstart/enable\nsystemd-networkd.service\n.\nNote\nEach network interface should be managed by only one\nDHCP client or network manager\n, so it is advised to run only one DHCP client or network manager on the system. Find a list of the currently running services with\nsystemctl --type=service\nand then\nstop\nor reconfigure those that conflict.\nIt is optional to also configure\nsystemd-resolved\n, which is a network name resolution service to local applications, considering the following points:\nIt is important to understand how\nresolv.conf\nand\nsystemd-resolved\ninteract to properly configure the DNS that will be used, some explanations are provided in\nsystemd-resolved\n.\nsystemd-resolved\nis required if DNS entries are specified in\n.network\nfiles.\nsystemd-resolved\nis also required to obtain DNS addresses from DHCP servers or IPv6 router advertisements.\n(by setting (\nDHCP=\nand/or\nIPv6AcceptRA=\nin the\n[Network]\nsection, and\nUseDNS=yes\n(the default) in the corresponding section(s)\n[DHCPv4]\n,\n[DHCPv6]\n,\n[IPv6AcceptRA]\n, see\nsystemd.network(5)\n).\nNote that\nsystemd-resolved\ncan also be used without\nsystemd-networkd\n.\nsystemd-networkd-wait-online\nEnabling\nsystemd-networkd.service\nalso enables\nsystemd-networkd-wait-online.service\n, which is a oneshot system service that waits for the network to be configured. The latter has\nWantedBy=network-online.target\n, so it will be started only when\nnetwork-online.target\nitself is enabled or pulled in by some other unit. See also\nsystemd#Running services after the network is up\n.\nBy default,\nsystemd-networkd-wait-online.service\nwaits for all links managed by\nsystemd-networkd\nto be fully configured or failed, and for at least one link to be online.\nSee\nsystemd-networkd-wait-online(8)\nfor details.\nConfiguration\nsystemd example network files\nA quick way to enable a network interface is to use one of the provided\n.example\nfiles located in\n/usr/lib/systemd/network/\n. For instance, to enable Wi-Fi and Ethernet, you can create symbolic links to the example files:\n# ln -s /usr/lib/systemd/network/80-wifi-station.network.example /etc/systemd/network/80-wifi-station.network\n# ln -s /usr/lib/systemd/network/89-ethernet.network.example /etc/systemd/network/89-ethernet.network\nYou can use\nnetworkctl\nto add any additional custom configuration. See the\n#networkctl\nsection.\nMultiple interfaces that are not connected all the time\nFor system with multiple network interfaces that are not expected to be connected all the time (e.g. if a dual-port Ethernet card, but only one cable plugged in), starting\nsystemd-networkd-wait-online.service\nwill fail after the default timeout of 2 minutes. This may cause an unwanted delay in the startup process. To change the behaviour to wait for\nany\ninterface rather than\nall\ninterfaces to become online,\nedit\nthe service and add the\n--any\nparameter to the\nExecStart\nline:\n/etc/systemd/system/systemd-networkd-wait-online.service.d/wait-for-only-one-interface.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/systemd/systemd-networkd-wait-online --any\nAlternatively, use\nsystemd-networkd-wait-online@.service\nto wait for a specific interface. For example, to wait for\nenp1s0\n,\ndisable\nsystemd-networkd-wait-online.service\nand\nenable\nsystemd-networkd-wait-online@enp1s0.service\n.\nTip\nIf you know which interface might not be up all the time, you can use\nRequiredForOnline=no\nin the\nLink\nsection of your\n.network\nconfiguration file instead. See\nsystemd.network(5) § [LINK] SECTION OPTIONS\n.\nWait until network interfaces have a routable address\nPer\nsystemd-networkd-wait-online.service(8)\n, \"online means that the link's operational state is equal or higher than \"degraded\".\" (see\nnetworkctl(1)\nfor the definition of \"degraded\" and other operational statuses).\nTo prevent\nsystemd-networkd-wait-online.service\nfrom exiting before network interfaces have a routable IP address (and thus having other services that require a working network connection starting too early), add\nRequiredForOnline=routable\nto the\n[Link]\nsection in\n.network\nfiles:\n[Link]\nRequiredForOnline=routable\nWait until DNS servers are reachable\nsystemd-networkd-wait-online.service(8)\ncan be delayed until all configured interfaces can connect to their DNS servers. This improves the chances that DNS is operational when\nnetwork-online.target\nis reached and units ordered after it begin to start.\nTo enable this feature,\nedit\nsystemd-networkd-wait-online.service\nand add the\n--dns\noption to the\nExecStart\nline:\n/etc/systemd/system/systemd-networkd-wait-online.service.d/wait-for-dns.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/systemd/systemd-networkd-wait-online --dns\nUsage\nThis article or section is a candidate for merging with\n#Configuration\n.\nNotes:\nExplaining how configuration files work belongs to the configuration section. (Discuss in\nTalk:Systemd-networkd\n)\nThis article or section needs expansion.\nReason:\nAdd networkctl commands and simplify content merged from former Configuration Files section (Discuss in\nTalk:Systemd-networkd\n)\nThe global configuration file in\n/etc/systemd/networkd.conf\nmay be used to override some defaults only. The main configuration is performed per network device. Configuration files are located in\n/usr/lib/systemd/network/\n, the volatile runtime network directory\n/run/systemd/network/\nand the local administration network directory\n/etc/systemd/network/\n. Files in\n/etc/systemd/network/\nhave the highest priority.\nThere are three types of configuration files. They all use a format similar to\nsystemd unit files\n.\n.network\nfiles\nThey will apply a network configuration for a\nmatching\ndevice. See the\nsystemd.network(5)\nman page.\n.netdev\nfiles\nThey will create a\nvirtual network device\nfor a\nmatching\nenvironment. See the\nsystemd.netdev(5)\nman page.\n.link\nfiles\nWhen a network device appears,\nudev\nwill look for the first\nmatching\n.link\nfile. See the\nsystemd.link(5)\nman page.\nThey all follow the same rules:\nIf\nall\nconditions in the\n[Match]\nsection are matched, the profile will be activated\nan empty\n[Match]\nsection means the profile will apply in any case (can be compared to the\n*\nwildcard)\nall configuration files are collectively sorted and processed in lexical order, regardless of the directory in which they live\nfiles with identical name replace each other\nAfter making changes to a configuration file,\nrestart\nsystemd-networkd.service\n.\nNote\nThe options specified in the configuration files are case sensitive.\nIn the examples below,\nenp1s0\nis the wired adapter and\nwlp2s0\nis the wireless adapter. These names can be different on different systems. See\nNetwork configuration#Network interfaces\nand\nNetwork configuration#Change interface name\n.\nIt is also possible to use a wildcard, e.g.\nName=en*\nor\nName=wl*\n.\nDevices can also be matched by their type. E.g.\nType=ether\nfor Ethernet,\nType=wlan\nfor Wi-Fi and\nType=wwan\nfor WWAN.\nNote that\nType=ether\nwill also match virtual Ethernet interfaces. To exclude them, use\nType=ether\nin combination with\nKind=!*\n.\nTip\nFiles in\n/etc/systemd/network/\noverride the corresponding system-supplied file in\n/usr/lib/systemd/network/\n. Optionally use a symlink to\n/dev/null\nto \"mask\" a system file.\nsystemd accepts the values\n1\n,\ntrue\n,\nyes\n,\non\nfor a true boolean, and the values\n0\n,\nfalse\n,\nno\n,\noff\nfor a false boolean. See\nsystemd.syntax(7)\n.\nsystemd-networkd will alter routing tables also for other network software. If this is undesired, configure\nManageForeignRoutingPolicyRules=\nin\nnetworkd.conf(5)\naccordingly. For example, see\nWireGuard#Connection lost after sleep using systemd-networkd\n.\nnetworkctl\nYou can use\nnetworkctl\nto query or modify the status of network links:\n$ networkctl\nIDX LINK        TYPE     OPERATIONAL SETUP\n1 lo          loopback carrier     unmanaged\n2 wlo1        wlan     routable    unmanaged\n3 tailscale0  none     routable    unmanaged\n4 enp0s20f0u1 ether    routable    unmanaged\nFor example, to enable Multicast DNS for the Wi-Fi interface:\n# networkctl edit @\nwlan0\n--drop-in mdns\n[Network]\nMulticastDNS=true\nReplace\nwlan0\nwith your stable interface name or specify the full path instead. See\nnetworkctl(1)\n.\nWired adapter using DHCP\n/etc/systemd/network/20-wired.network\n[Match]\nName=enp1s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\nWired adapter using a static IP\n/etc/systemd/network/20-wired.network\n[Match]\nName=enp1s0\n[Network]\nAddress=10.1.10.9/24\nAddress=2001:db8:1234:5678::1/64\nGateway=10.1.10.1\nGateway=fe80::1\nDNS=10.1.10.1\nDNS=2001:db8:1122::3344:1\nAddress=\ncan be used more than once to configure multiple IPv4 or IPv6 addresses. See\nsystemd.network(5)\nfor more options.\nWireless adapter\nIn order to connect to a wireless network with\nsystemd-networkd\n, a wireless adapter configured with another application such as\nwpa_supplicant\nor\niwd\nis required.\n/etc/systemd/network/25-wireless.network\n[Match]\nName=wlp2s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\nIgnoreCarrierLoss=3s\nIf the wireless adapter has a static IP address, the configuration is the same (except for the interface name) as in a\nwired adapter\n.\nTip\nIgnoreCarrierLoss=3s\nensures that\nsystemd-networkd\nwill not re-configure the interface (e.g., release and re-acquire a DHCP lease) for a short period (3 seconds in this example) while the wireless interface roams to another access point within the same wireless network (SSID), which translates to shorter downtime when roaming.\nTo authenticate to the wireless network, use e.g.\nwpa_supplicant\nor\niwd\n.\nWired and wireless adapters on the same machine\nThis setup will enable a DHCP IP for both a wired and wireless connection making use of the metric directive to allow the kernel to decide on-the-fly which one to use.  This way, no connection downtime is observed when the wired connection is unplugged.\nThe kernel's route metric (same as configured with\nip\n) decides which route to use for outgoing packets, in cases when several match. This will be the case when both wireless and wired devices on the system have active connections. To break the tie, the kernel uses the metric. If one of the connections is terminated, the other automatically wins without there being a gap with nothing configured (ongoing transfers may still not deal with this nicely but that is at a different OSI layer).\nsystemd-networkd\ndoes not set per-interface-type default route metrics\n, so it needs to be configured manually:\nNote\nThe\nMetric\noption is for static routes while the\nRouteMetric\noption is for setups not using static routes. See\nsystemd.network(5)\nfor more details.\n/etc/systemd/network/20-wired.network\n[Match]\nName=enp1s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\n[DHCPv4]\nRouteMetric=100\n[IPv6AcceptRA]\nRouteMetric=100\n/etc/systemd/network/25-wireless.network\n[Match]\nName=wlp2s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\n[DHCPv4]\nRouteMetric=600\n[IPv6AcceptRA]\nRouteMetric=600\nDHCP server\nThis is an example of a DHCP server configuration which works well with\nhostapd\nto create a wireless hotspot.\nIPMasquerade\nadds the firewall rules for\nNAT\nand implies\nIPv4Forwarding=yes\nto enable\npacket forwarding\n.\nThe factual accuracy of this article or section is disputed.\nReason:\nIPMasquerade=ipv4\ndoes not add the rules for the\nfilter\ntable, they have to be added manually. See\nsystemd-nspawn#Use a virtual Ethernet link\n. (Discuss in\nTalk:Systemd-networkd\n)\n/etc/systemd/network/\nwlan0\n.network\n[Match]\nName=wlan0\n[Network]\nAddress=10.1.1.1/24\nDHCPServer=true\nIPMasquerade=ipv4\n[DHCPServer]\nPoolOffset=100\nPoolSize=20\nEmitDNS=yes\nDNS=9.9.9.9\nSee\nsystemd.network(5) § [DHCPSERVER] SECTION OPTIONS\nfor all available options.\nUsage with containers\nsystemd-networkd\ncan provide fully automatic configuration of networking for\nsystemd-nspawn\ncontainers using private networking when it is used on the host system as well as inside the container. See\nsystemd-nspawn#Networking\nfor a comprehensive overview.\nTip\nStarting\nsystemd-networkd.service\nis\nall that is needed\non the host to provide the described network auto-configuration for containers which use the default\nvirtual Ethernet link\nsetup. The following is only needed for other private networking scenarios.\nFor the examples below,\nwe will limit the output of the\nip a\ncommand to the concerned interfaces,\nwe assume the\nhost\nis the main operating system running on real hardware and the\ncontainer\nis the guest system,\nall interface names and IP addresses are only examples.\nNetwork bridge with DHCP\nBridge interface\nFirst, create a virtual\nbridge\ninterface with a\n.netdev\nunit file which tells\nsystemd-networkd\nto create a device named\nbr0\nthat functions as an Ethernet bridge.\n/etc/systemd/network/25-br0.netdev\n[NetDev]\nName=br0\nKind=bridge\nOptionally add\nMACAddress=none\nto the\nNetDev\nsection for the bridge to inherit MAC address from one of the bridged interfaces. This also requires a creation of\n25-br0.link\nfile.\nTip\nsystemd-networkd\nassigns a MAC address generated based on the interface name and the machine ID to the bridge. This may cause connection issues, for example in case of routing based on MAC filtering. To circumvent such problems, assign a MAC address to your bridge, probably the same as your physical device, adding the line\nMACAddress=\nxx\n:\nxx\n:\nxx\n:\nxx\n:\nxx\n:\nxx\nin the\nNetDev\nsection above.\nRestart\nsystemd-networkd.service\nto have\nsystemd-networkd\ncreate the bridge.\nTo see the newly created bridge on the host and on the container, type:\n$ ip a\n3: br0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default\nlink/ether ae:bd:35:ea:0c:c9 brd ff:ff:ff:ff:ff:ff\nNote that the interface\nbr0\nis listed but is still DOWN at this stage.\nBind Ethernet to bridge\nThe next step is to add a network interface to the newly created bridge. The configuration file of the bridge must be loaded before those of the bridged interfaces, so its configuration file should be alphanumerically prior to those. In the example below, we add any interface that matches the name\nen*\ninto the bridge\nbr0\n.\n/etc/systemd/network/25-br0-en.network\n[Match]\nName=en*\n[Network]\nBridge=br0\nThe Ethernet interface must not have DHCP or an IP address associated, as the bridge requires an interface to bind to with no IP address.\nNote\nEnsure that no other\n.network\nfile attempts to match interfaces by\nName=en*\n. Only the first file that matches an interface is applied.\nBridge network\nNow that the bridge has been created and has been bound to an existing network interface, the IP configuration of the bridge interface must be specified. This is defined in a third\n.network\nfile, the example below uses DHCP.\n/etc/systemd/network/25-br0.network\n[Match]\nName=br0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\nInherit MAC address (optional)\nFor the bridge to inhering MAC address from one of the bridged interfaces, set\nMACAddress=none\nand\nMACAddressPolicy=none\n.\n/etc/systemd/network/25-br0.netdev\n[NetDev]\nName=br0\nKind=bridge\nMACAddress=none\n/etc/systemd/network/25-br0.link\n[Match]\nOriginalName=br0\n[Link]\nMACAddressPolicy=none\nConfigure the container\nUse the\n--network-bridge=br0\noption when starting the container. See\nsystemd-nspawn#Use a network bridge\nfor details.\nResult\non host\n$ ip a\n3: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\nlink/ether 14:da:e9:b5:7a:88 brd ff:ff:ff:ff:ff:ff\ninet 192.168.1.87/24 brd 192.168.1.255 scope global br0\nvalid_lft forever preferred_lft forever\ninet6 fe80::16da:e9ff:feb5:7a88/64 scope link\nvalid_lft forever preferred_lft forever\n6: vb-\nMyContainer\n: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master br0 state UP group default qlen 1000\nlink/ether d2:7c:97:97:37:25 brd ff:ff:ff:ff:ff:ff\ninet6 fe80::d07c:97ff:fe97:3725/64 scope link\nvalid_lft forever preferred_lft forever\non container\n$ ip a\n2: host0: <BROADCAST,MULTICAST,ALLMULTI,AUTOMEDIA,NOTRAILERS,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\nlink/ether 5e:96:85:83:a8:5d brd ff:ff:ff:ff:ff:ff\ninet 192.168.1.73/24 brd 192.168.1.255 scope global host0\nvalid_lft forever preferred_lft forever\ninet6 fe80::5c96:85ff:fe83:a85d/64 scope link\nvalid_lft forever preferred_lft forever\nNotice\nwe have now one IP address for\nbr0\non the host, and one for\nhost0\nin the container\ntwo new interfaces have appeared:\nvb-\nMyContainer\nin the host and\nhost0\nin the container. This comes as a result of the\n--network-bridge=br0\noption as explained in\nsystemd-nspawn#Use a network bridge\nfor details.\nthe DHCP address on\nhost0\ncomes from the system\n/usr/lib/systemd/network/80-container-host0.network\nfile.\non host\nThis article or section is out of date.\nReason:\nbrctl\nis deprecated, use\nbridge link\n. See\nNetwork bridge#With iproute2\n. (Discuss in\nTalk:Systemd-networkd\n)\n$ brctl show\nbridge name\tbridge id\t\tSTP enabled\tinterfaces\nbr0\t\t8000.14dae9b57a88\tno\t\tenp7s0\nvb-\nMyContainer\nthe above command output confirms we have a bridge with two interfaces binded to.\non host\n$ ip route\ndefault via 192.168.1.254 dev br0\n192.168.1.0/24 dev br0  proto kernel  scope link  src 192.168.1.87\non container\n$ ip route\ndefault via 192.168.1.254 dev host0\n192.168.1.0/24 dev host0  proto kernel  scope link  src 192.168.1.73\nthe above command outputs confirm we have activated\nbr0\nand\nhost0\ninterfaces with an IP address and Gateway 192.168.1.254. The gateway address has been automatically grabbed by\nsystemd-networkd\n.\nNetwork bridge with static IP addresses\nSetting a static IP address for each device can be helpful in case of deployed web services (e.g. FTP, HTTP, SSH). Each device will keep the same MAC address across reboots if your system\n/usr/lib/systemd/network/99-default.link\nfile has the\nMACAddressPolicy=persistent\noption (it has by default). This setup routes any service on the gateway to the desired device.\nThe following configuration needs to be done for this setup:\non host\nThe configuration is very similar to the\n#Network bridge with DHCP\nsection. First, a virtual bridge interface needs to be created and the main physical interface needs to be bound to it. This task can be accomplished with the following two files, with contents equal to those available in the DHCP section.\n/etc/systemd/network/\nMyBridge\n.netdev\n/etc/systemd/network/\nMyEth\n.network\nNext, you need to configure the IP and DNS of the newly created virtual bridge interface. For example:\n/etc/systemd/network/\nMyBridge\n.network\n[Match]\nName=br0\n[Network]\nDNS=192.168.1.254\nAddress=192.168.1.87/24\nGateway=192.168.1.254\non container\nTo get configure a static IP address on the container, we need to override the system\n/usr/lib/systemd/network/80-container-host0.network\nfile, which provides a DHCP configuration for the\nhost0\nnetwork interface of the container. This can be done by placing the configuration into\n/etc/systemd/network/80-container-host0.network\n. For example:\n/etc/systemd/network/80-container-host0.network\n[Match]\nName=host0\n[Network]\nDNS=192.168.1.254\nAddress=192.168.1.94/24\nGateway=192.168.1.254\nMake sure that\nsystemd-networkd.service\nis\nenabled\nin the container.\nMACVLAN bridge\nFor the host to be able to reach containers connected via MACVLAN, the host itself also needs to connect via MACVLAN and not directly to the underlying Ethernet network interface.\nOn the host, attach the underlying Ethernet network interface to MACVLAN and make sure it does not get assigned IP addresses. For example, using\nmv-0\nas the MACVLAN interface name and with\nenp1s0\nas the host's Ethernet interface:\n/etc/systemd/network/30-enp1s0.network\n[Match]\nName=enp1s0\n[Link]\nRequiredForOnline=carrier\n[Network]\nMACVLAN=mv-0\nDHCP=no\nIPv6AcceptRA=false\nLinkLocalAddressing=no\nMulticastDNS=false\nLLMNR=false\nTip\nRequiredForOnline=carrier\nprevents\nsystemd-networkd-wait-online.service\nfrom waiting (and eventually failing) for the connection to acquire an IP address, which will never happen.\nThe underlying network interface does not necessarily need to be a physical Ethernet interface. For example, a MACVLAN bridge can be attached to a bond.\nCreate the MACVLAN bridge\nmv-0\n:\n/etc/systemd/network/25-mv-0.netdev\n[NetDev]\nName=mv-0\nKind=macvlan\n[MACVLAN]\nMode=bridge\nConfigure the host's network connection on the MACVLAN bridge (\nmv-0\n). The following example uses DHCP, replace the options as necessary.\n/etc/systemd/network/35-mv-0.network\n[Match]\nName=mv-0\n[Link]\nRequiredForOnline=routable\n[Network]\nBindCarrier=enp1s0\nDHCP=yes\nFor the container, attach a MACVLAN to the\nunderlying Ethernet network interface\n(\nenp1s0\nin the examples above). For example, in\n/etc/systemd/nspawn/\ncontainer_name\n.nspawn\nspecify:\n[Network]\nMACVLAN=enp1s0\nFor containers started from the command line, pass them the\n--network-macvlan=enp1s0\noption.\nIn the container, the MACVLAN interface will have the name\nmv-\nunderlying_interface_name\n(e.g.\nmv-enp1s0\n). Configure the network connection as necessary (just like in the host) by matching the interface name. For example, using DHCP:\n/etc/systemd/network/30-mv-enp1s0.network\n[Match]\nName=mv-enp1s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\nTips and tricks\nInterface and desktop integration\nsystemd-networkd\ndoes not have a proper interactive graphical management interface. Still, some tools are available to either display or modify the current state of the network, receive notifications or interact with the wireless configuration:\nnetworkctl\nprovides a\ncommand-line shell\ninterface to query or modify the network interface states. It is worth noting that in order to change only some aspects of an interface behavior, one is required to first\nedit\none or more configuration files in\n/etc/systemd/network/\n.\nWhen\nnetworkd\nis configured with\nwpa_supplicant\n, both\nwpa_cli\nand\nwpa_gui\noffer the ability to associate and configure WLAN interfaces dynamically.\nThe\nnetworkd-dispatcher\nAUR\ndaemon allows executing scripts in response to network interface state changes, similar to\nNetworkManager-dispatcher\n.\nThe\nnetworkd-notify-git\nAUR\ncreates simple notification messages on interface changes.\nAs for the DNS resolver\nsystemd-resolved\n, information about current DNS servers can be visualized with\nresolvectl status\n.\nConfiguring static IP or DHCP based on SSID (location)\nOften there is a situation where your home wireless network uses DHCP and office wireless network uses static IP. This mixed setup can be configured as follows:\nNote\nNumber in the file name decides the order in which the files are processed. Users can\n[Match]\nbased on SSID or BSSID, or both.\n/etc/systemd/network/24-wireless-office.network\n# special configuration for office Wi-Fi network\n[Match]\nName=wlp2s0\nSSID=office_ap_name\n#BSSID=aa:bb:cc:dd:ee:ff\n[Network]\nAddress=10.1.10.9/24\nGateway=10.1.10.1\nDNS=10.1.10.1\n#DNS=8.8.8.8\n/etc/systemd/network/25-wireless-dhcp.network\n# use DHCP for any other Wi-Fi network\n[Match]\nName=wlp2s0\n[Link]\nRequiredForOnline=routable\n[Network]\nDHCP=yes\nBonding a wired and wireless interface\nSee also\nWireless bonding\n.\nBonding allows connection sharing through multiple interfaces, so if e.g. the wired interface is unplugged, the wireless is still connected and the network connectivity remains up seamlessly.\nCreate a bond interface. In this case the mode is\nactive-backup\n, which means packets are routed through a secondary interface if the primary interface goes down.\n/etc/systemd/network/30-bond0.netdev\n[NetDev]\nName=bond0\nKind=bond\n[Bond]\nMode=active-backup\nPrimaryReselectPolicy=always\nMIIMonitorSec=1s\nSet the wired interface as the primary:\n/etc/systemd/network/30-ethernet-bond0.network\n[Match]\nName=enp0s25\n[Network]\nBond=bond0\nPrimarySlave=true\nSet the wireless as the secondary:\n/etc/systemd/network/30-wifi-bond0.network\n[Match]\nName=wlan0\n[Network]\nBond=bond0\nNote\nWhen using MAC addresses in the\n[Match]\nsection, use of\nPermanentMACAddress\nis recommended over\nMACAddress\n, see\nthis upstream discussion\n.\nConfigure the bond interface just like a normal interface:\n/etc/systemd/network/30-bond0.network\n[Match]\nName=bond0\n[Link]\nRequiredForOnline=routable\n[Network]\nBindCarrier=enp0s25 wlan0\nDHCP=yes\nNow if the wired network is unplugged, the connection should remain through the wireless:\n$ networkctl\nIDX LINK    TYPE     OPERATIONAL      SETUP\n1 lo      loopback carrier          unmanaged\n2 enp0s25 ether    no-carrier       configured\n3 bond0   bond     degraded-carrier configured\n5 wlan0   wlan     enslaved         configured\n4 links listed.\nSpeeding up TCP slow-start\nOn a higher bandwidth link with moderate latency (typically a home Internet connection that is above 10 Mbit/s) the default settings for the TCP Slow Start algorithm are somewhat conservative.  This issue exhibits as downloads starting slowly and taking a number of seconds to speed up before they reach the connection's full bandwidth.  It is particularly noticeable with a pacman upgrade, where each package downloaded starts off slowly and often finishes before it has reached the connection's full speed.\nThese settings can be adjusted to make TCP connections start with larger window sizes than the defaults, avoiding the time it takes for them to automatically increase on each new TCP connection\n[1]\n.  While this will usually decrease performance on slow connections (or if the values are increased too far) due to having to retransmit a larger number of lost packets, they can substantially increase performance on connections with sufficient bandwidth.\nIt is important to benchmark before and after changing these values to ensure it is improving network speed and not reducing it.  If you are not seeing downloads begin slowly and gradually speed up, then there is no need to change these values as they are already optimal for your connection speed.  When benchmarking, be sure to test against both a high speed and low speed remote server to ensure you are not speeding up access to fast machines at the expense of making access to slow servers even slower.\nTo adjust these values, edit the\n.network\nfile for the connection:\n/etc/systemd/network/eth0.network\n[Match]\nName=eth0\n#[Network]\n#Gateway=...  <-- Remove this if you have it, and put it in the Gateway= line below\n[Route]\n# This will apply to the gateway supplied via DHCP.  If you manually specify\n# your gateway, put it here instead.\nGateway=_dhcp4\n# The defaults for these values is 10.  They are a multiple of the MSS (1460 bytes).\nInitialCongestionWindow=10\nInitialAdvertisedReceiveWindow=10\nThe defaults of\n10\nwork well for connections slower than 10 Mbit/s.  For a 100 Mbit/s connection, a value of\n30\nworks well.  The manual page\nsystemd.network(5) § [ROUTE] SECTION OPTIONS\nsays a value of\n100\nis considered excessive.\nIf the\nsysctl\nsetting\nnet.ipv4.tcp_slow_start_after_idle\nis enabled then the connection will return to these initial settings after it has been idle for some time (and often a very small amount of time).  If this setting is disabled then the connection will maintain a higher window if a larger one was negotiated during packet transfer.  Regardless of the setting, each new TCP connection will begin with the\nInitial*\nsettings set above.\nThe sysctl setting\nnet.ipv4.tcp_congestion_control\nis not directly related to these values, as it controls how the congestion and receive windows are adjusted while a TCP link is active, and particularly when the path between the two hosts is congested and throughput must be reduced.  The above\nInitial*\nvalues simply set the default window values selected for each new connection, before any congestion algorithm takes over and adjusts them as needed.  Setting higher initial values simply shortcuts some negotiation while the congestion algorithm tries to find the optimum values (or, conversely, setting the wrong initial values adds additional negotiation time while the congestion algorithm works towards correcting them, slowing down each newly established TCP connection for a few seconds extra).\nPrevent multiple default routes\nsystemd-networkd\ndoes not set per-interface-type default route metrics\n, i.e. they need to be configured manually when using multiple network devices. For example, the following\nip route\nshows multiple default routes:\nip route\ndefault via 10.30.1.1 dev eno2 proto dhcp src 10.30.1.15 metric 1024\ndefault via 192.168.1.254 dev eno1 proto dhcp src 172.18.105.104 metric 1024\nSince the same default\nmetric\nvalue\n1024\nis assigned, there is a race condition which of both is chosen as default route. Since the\neno2\ndevice came up first, it is preferred and thus, access available via\neno1\nmay be ignored.\nTo prevent the race condition, assign different\nRouteMetric=\nvalues for the devices. See\n#Wired and wireless adapters on the same machine\nfor a corresponding example.\nIf instead one device should not provide a default route, the\nUseGateway=false\noption in\n[DHCPv4]\nand\n[IPv6AcceptRA]\nsections can be used to omit creating the default route provided by the DHCP/RA server while keeping other classless static routes. This may be useful, for example, if the device provides a connection to a single other machine.\nConfiguring a second static IP with its own MAC address on an existing interface\nTo make your computer appear as two completely separate devices to your router, you can create a virtual interface not just with a different IP but also with a different MAC address.\nTo achieve this, create a virtual interface (\nmacvlan\n) on top of your physical interface with a unique MAC address:\n/etc/systemd/network/\n25-eth210\n.netdev\n[NetDev]\nName=\neth210\nKind=macvlan\nMACAddress=\n00:11:22:33:44:55\n[MACVLAN]\nMode=bridge\nThen add a network file as usual, using the same subnet and gateway, and avoiding the range of IP numbers used for DHCP if you configure a static IP. For example:\n/etc/systemd/network/\n25-eth210\n.network\n[Match]\nName=\neth210\n[Network]\nAddress=\n192.168.132.210/24\nGateway=\n192.168.132.1\n[Route]\nDestination=\n192.168.132.0/24\nMetric=2\nThe\nmacvlan\ninterface route has metric 2. This ensures that traffic will prefer going through the main interface, since that (implicitly) has a default route with metric 1, unless specifically directed to use the\nmacvlan\ninterface.\nFinally, add\nMACVLAN=eth210\nto the\n[Network]\nsection of the\n.network\nfile of your main interface!\nAt this point, a fast way to make your router aware of the new MAC (and configure it to accept that MAC) you can for example run\narping -I eth210 192.168.132.1\nas root. After configuring your router for the \"new device\" you can test if the new interface has internet access with for example\ncurl --interface 192.168.132.210 ifconfig.me\nthat should then print your public IP number.\nSee also\nsystemd-networkd(8)\nTom Gundersen posts on Core OS blog\nHow to set up systemd-networkd with wpa_supplicant\n(WonderWoofy's walkthrough on Arch forums)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Systemd-networkd&oldid=850348\n\"\nCategories\n:\nNetwork managers\nVirtualization\nHidden categories:\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nsystemd-networkd\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Systemd-networkd"}}
{"text": "iwd - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\niwd\n5 languages\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nNetwork configuration\nWireless network configuration\nwpa_supplicant\niwd\n(iNet wireless daemon) is a wireless daemon for Linux written by Intel. The core goal of the project is to optimize resource utilization by not depending on any external libraries and instead utilizing features provided by the Linux Kernel to the maximum extent possible.\niwd can work in standalone mode or in combination with comprehensive network managers like\nConnMan\n,\nsystemd-networkd\nand\nNetworkManager\n.\nNote\nDo not follow the instructions on this page when using iwd via a\nnetwork manager\nunless it is explicitly stated otherwise in that network manager's article.\nInstallation\nInstall\nthe\niwd\npackage.\nOptionally, third-party graphical and terminal user interface front-ends can be installed:\nimpala\n— A TUI (Terminal User Interface) for iwd.\nhttps://github.com/pythops/impala\n||\nimpala\niwdgui\n— A graphical front-end for iwd.\nhttps://gitlab.com/hfernh/iwdgui\n||\niwdgui\nAUR\niwgtk\n— A graphical front-end for iwd and an indicator (tray) icon.\nhttps://github.com/J-Lentz/iwgtk\n||\niwgtk\nAUR\niwmenu\n— A menu-driven interface for iwd.\nhttps://github.com/e-tho/iwmenu\n||\niwmenu-git\nAUR\niwqt\n— An iwd network applet for linux systems.\nhttps://github.com/fingu/iwqt\n||\niwqt\nAUR\nUsage\nThe\niwd\npackage provides the client program\niwctl\n, the daemon\niwd\nand the Wi-Fi monitoring tool\niwmon\n.\nStart/enable\niwd.service\nso it can be controlled through the\niwctl\ncommand or through your\npreferred iwd front-end\n.\nNote\nOnly root and members of the\nnetwork\nor the\nwheel\nuser group\nare allowed to interact with\niwd\n. In order to use\niwctl\nor other front-ends, you need to\nadd your user to one of those groups\n.\niwctl\nTo get an interactive prompt do:\n$ iwctl\nThe interactive prompt is then displayed with a prefix of\n[iwd]#\n.\nTip\nIn the\niwctl\nprompt you can auto-complete commands, device names, and SSIDs by hitting\nTab\n.\nTo exit the interactive prompt, send\nEOF\nby pressing\nCtrl+d\n.\nYou can use all commands as command line arguments without entering an interactive prompt. For example:\niwctl device wlan0 show\n.\nTo list all available commands:\n[iwd]# help\nConnect to a network\nFirst, if you do not know your wireless device name, list all Wi-Fi devices:\n[iwd]# device list\nIf the device or its corresponding adapter is turned off, turn it on:\n[iwd]# device\nname\nset-property Powered on\n[iwd]# adapter\nadapter\nset-property Powered on\nThen, to initiate a scan for networks (note that this command will not output anything):\n[iwd]# station\nname\nscan\nYou can then list all available networks:\n[iwd]# station\nname\nget-networks\nFinally, to connect to a network:\n[iwd]# station\nname\nconnect\nSSID\nIf network is hidden:\n[iwd]# station\nname\nconnect-hidden\nSSID\nNote\nFor automatic IP and DNS configuration via DHCP, you have to\nmanually enable\nthe built-in DHCP client or configure a\nstandalone DHCP client\n.\nIf a passphrase is required (and it is not already stored in one of the profiles that iwd automatically checks), you will be prompted to enter it. Alternatively, you can supply it as a command line argument:\n$ iwctl --passphrase\npassphrase\nstation\nname\nconnect\nSSID\nNote\niwd\nautomatically stores network passphrases in the\n/var/lib/iwd\ndirectory and uses them to auto-connect in the future. See\n#Network configuration\n.\nTo connect to a network with spaces in the SSID, the network name should be double quoted when connecting.\niwd only supports PSK pass-phrases from 8 to 63 ASCII-encoded characters. The following error message will be given if the requirements are not met:\nPMK generation failed.  Ensure Crypto Engine is properly configured\n.\nConnect to a network using WPS/WSC\nIf your network is configured such that you can connect to it by pressing a button (\nWikipedia:Wi-Fi Protected Setup\n), check first that your network device is also capable of using this setup procedure.\n[iwd]# wsc list\nThen, provided that your device appeared in the above list,\n[iwd]# wsc\ndevice\npush-button\nand push the button on your router. The procedure works also if the button was pushed beforehand, less than 2 minutes earlier.\nIf your network requires to validate a PIN number to connect that way, check the\nhelp\ncommand output to see how to provide the right options to the\nwsc\ncommand.\nDisconnect from a network\nTo disconnect from a network:\n[iwd]# station\ndevice\ndisconnect\nShow device and connection information\nTo display the details of a Wi-Fi device, like MAC address:\n[iwd]# device\ndevice\nshow\nTo display the connection state, including the connected network of a Wi-Fi device:\n[iwd]# station\ndevice\nshow\nManage known networks\nTo list networks you have connected to previously:\n[iwd]# known-networks list\nTo forget a known network:\n[iwd]# known-networks\nSSID\nforget\niwgtk\nAlternatively,\niwgtk\nAUR\nprovides a GUI front-end through which iwd can be controlled.\nRunning\niwgtk\nwithout any arguments launches the application window, which can be used to toggle your adapters and devices on/off, change their operating modes, view available networks, connect to available networks, and manage known networks.\nIndicator icon\nTo launch iwgtk's indicator (tray) icon daemon, run:\n$ iwgtk -i\nIf the indicator icon does not appear, then your system tray most likely lacks support for the StatusNotifierItem API, in which case you need to run a compatibility layer such as\nsnixembed-git\nAUR\n.\nThe following system trays support StatusNotifierItem, and therefore work out of the box:\nKDE Plasma\nswaybar\nlxqt-panel\nxfce4-panel\nThe following trays only support XEmbed, and therefore require\nsnixembed-git\nAUR\n:\nAwesomeWM\ni3bar\nstalonetray\nAutostart\nThe most common use case for iwgtk is to start the indicator daemon every time you log into your desktop. If your desktop environment supports the\nXDG Autostart\nstandard, this should happen automatically due to the\niwgtk-indicator.desktop\nfile which is placed in\n/etc/xdg/autostart/\nby the AUR package.\nAlternatively, a systemd unit file to start the indicator daemon is provided by the AUR package. If your desktop environment supports systemd's\ngraphical-session.target\nunit, then iwgtk can be autostarted via systemd by\nenabling\nthe\niwgtk.service\nuser unit\n.\nNetwork configuration\nBy default,\niwd\nstores the network configuration in the directory\n/var/lib/iwd\n. The configuration file is named as\nnetwork\n.\ntype\n, where\nnetwork\nis the network SSID and\n.type\nis the network type, either\n.open\n,\n.psk\nor\n.8021x\n. The file is used to store the encrypted\nPreSharedKey\nand optionally the cleartext\nPassphrase\nand can also be created by the user without invoking\niwctl\n. The file can be used for other configuration pertaining to that network SSID as well. For more settings, see\niwd.network(5)\n.\nNote\nIn string values, including identities and passwords, certain characters may be backslash-escaped.  Leading spaces, \\n, \\r, and literal backslashes must be escaped.  See\niwd.network(5)\n.\nWPA-PSK\nA minimal example file to connect to a WPA-PSK or WPA2-PSK secured network with SSID \"spaceship\" and passphrase \"test1234\":\n/var/lib/iwd/spaceship.psk\n[Security]\nPreSharedKey=aafb192ce2da24d8c7805c956136f45dd612103f086034c402ed266355297295\nNote\nThe SSID of the network is used as a filename only when it contains only alphanumeric characters or one of\n- _\n. If it contains any other characters, the name will instead be an\n=\n-character followed by the hex-encoded (with lower case letters for the hex-numbers) version of the SSID.\nTo calculate the pre-shared key from the passphrase, one of these two methods can be used:\nEnter the passphrase in cleartext in the configuration file:\n/var/lib/iwd/spaceship.psk\n[Security]\nPassphrase=test1234\nThe pre-shared key will be appended to the file at the first connect:\n/var/lib/iwd/spaceship.psk\n[Security]\nPassphrase=test1234\nPreSharedKey=aafb192ce2da24d8c7805c956136f45dd612103f086034c402ed266355297295\nOr the pre-shared key can be calculated from the SSID and the passphrase using\nwpa_passphrase\n(from\nwpa_supplicant\n) or\nwpa-psk\nAUR\n. See\nwpa_supplicant#Connecting with wpa_passphrase\nfor more details.\nWPA Enterprise\nEAP-PWD\nFor connecting to a EAP-PWD protected enterprise access point you need to create a file called:\nessid\n.8021x\nin the\n/var/lib/iwd\ndirectory with the following content:\n/var/lib/iwd/\nessid\n.8021x\n[Security]\nEAP-Method=PWD\nEAP-Identity=\nyour_enterprise_email\nEAP-Password=\nyour_password\n[Settings]\nAutoConnect=true\nIf you do not want autoconnect to the AP you can set the option to False and connect manually to the access point via\niwctl\n. The same applies to the password, if you do not want to store it plaintext leave the option out of the file and just connect to the enterprise AP.\nNote\nThere is no way to change priorities of different SSIDs, you may want to set\nAutoConnect=false\nas a workaround.\nEAP-PEAP\nLike EAP-PWD, you also need to create a\nessid\n.8021x\nfile in the directory. Before you proceed to write the configuration file, this is also a good time to find out which CA certificate your organization uses. This is an example configuration file that uses MSCHAPv2 password authentication:\n/var/lib/iwd/\nessid\n.8021x\n[Security]\nEAP-Method=PEAP\nEAP-Identity=anonymous@realm.edu\nEAP-PEAP-CACert=/path/to/root.crt\nEAP-PEAP-ServerDomainMask=radius.realm.edu\nEAP-PEAP-Phase2-Method=MSCHAPV2\nEAP-PEAP-Phase2-Identity=johndoe@realm.edu\nEAP-PEAP-Phase2-Password=hunter2\n[Settings]\nAutoConnect=true\nMsCHAPv2 passwords can also be stored as an encrypted hash. The correct md4 hash can be calculated with:\n$ iconv -t utf16le | openssl md4 -provider legacy\nInsert an EOF after your password by pressing\nCtrl+d\n, do not hit\nEnter\n. The resulting hash needs to be stored inside the\nEAP-PEAP-Phase2-Password-Hash\nkey.\nTip\nIf you are planning on using\neduroam\n, see also\n#eduroam\n.\nTTLS-PAP\nLike EAP-PWD, you also need to create a\nessid\n.8021x\nfile in the directory. Before you proceed to write the configuration file, this is also a good time to find out which CA certificate your organization uses. This is an example configuration file that uses PAP password authentication:\n/var/lib/iwd/\nessid\n.8021x\n[Security]\nEAP-Method=TTLS\nEAP-Identity=anonymous@uni-beispiel.de\nEAP-TTLS-CACert=cert.pem\nEAP-TTLS-ServerDomainMask=*.uni-beispiel.de\nEAP-TTLS-Phase2-Method=Tunneled-PAP\nEAP-TTLS-Phase2-Identity=user\nEAP-TTLS-Phase2-Password=password\n[Settings]\nAutoConnect=true\nEAP-TLS\nEAP-TLS uses x509\nclient certificates\nto authenticate you. Like ssh keys, these use public-key cryptography, so the Wi-Fi authentication server never needs to be sent a secret, and you do not need to copy and reuse a password between devices. Usually each device will use a distinct cert, one that can, in theory at least, be revoked without forcing you to change a password or disrupt your other devices.\nAs with the other enterprise methods you need to know the CA cert your organization uses (\ncacert.pem\n), which is used to prove to your device it is connecting to the right place. You also need to have the client certificate, which represents you and will be uploaded on each connection (\nclient-cert.pem\n), and the private key that goes with it (\nclient-key.pem\n), which is used to prove you own that client certificate.\nYou can either provide a path to the required certificate or you can\nembed them inside your configuration\n.\nWhen you have collected the credentials, put this in your\n/var/lib/iwd/\nessid\n.8021x\nfile:\n/var/lib/iwd/\nessid\n.8021x\n[Security]\nEAP-Method=TLS\nEAP-TLS-CACert=/path/to/cacert.pem\nEAP-Identity=\nyour_enterprise_email\nEAP-TLS-ClientCert=/path/to/client-cert.pem\nEAP-TLS-ClientKey=/path/to/client-key.pem\n#EAP-TLS-ClientKeyPassphrase=key-passphrase  # if client-key.pem is encrypted, provide its passphrase\n[Settings]\nAutoConnect=true\neduroam\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThe first part duplicates\n#EAP-PEAP\n. (Discuss in\nTalk:Iwd\n)\nOne possible method of connecting to eduroam via iwd is provided\nhere\n. Create the following file, filling in the necessary values:\n/var/lib/iwd/eduroam.8021x\n[Security]\nEAP-Method=PEAP\nEAP-Identity=anonymous@\nuniversity.domain\nEAP-PEAP-Phase2-Method=MSCHAPV2\nEAP-PEAP-Phase2-Identity=\nusername@university.domain\nEAP-PEAP-Phase2-Password=\npassword\n[Settings]\nAutoConnect=true\nThe factual accuracy of this article or section is disputed.\nReason:\niwd support in CAT does not work (Discuss in\nTalk:Iwd#eduroam and iwd section wrong?\n)\nIf that does not work, eduroam also offers a\nconfiguration assistant tool (CAT)\n. If your organisation has a profile within the CAT, getting connected to eduroam can be done by downloading the Linux script and running it using\npython\n. If your organisation does not support CAT, you will have to create the configuration file manually using parameters provided to you by the administrators (the below table can be helpful in doing so). It is possible to extract the necessary configuration options from the generated configuration, including the certificate and server domain mask. Additionally, some institutions are upgrading to EAP-TLS, and outsourcing the generation of\nclient-cert.pem\nto\nSecureW2\n, in which case you will need to use their tool as well to generate a client cert.\nThe following table contains a mapping of iwd configuration options to eduroam CAT install script variables.\nIwd Configuration Option\nCAT Script Variable\nessid\none of\nConfig.ssids\nEAP-Method\nConfig.eap_outer\nEAP-Identity\nConfig.anonymous_identity\nEAP-\nmethod\n-CACert\nthe content of\nConfig.CA\n, an absolute path to a\n.pem\nfile containing\nConfig.CA\nor an\nembedded certificate\n.\nEAP-\nmethod\n-ServerDomainMask\none of\nConfig.servers\nEAP-\nmethod\n-Phase2-Method\nConfig.eap_inner\nunless it is equal to\nPAP\n, in that case use instead\nTunneled-PAP\nEAP-\nmethod\n-Phase2-Identity\nusername\n@Config.user_realm\nwhere\nmethod\nis the content of\nEAP-Method\nand should be either\nTLS\n,\nTTLS\nor\nPEAP\n.  Once you have extracted all necessary information and converted them to their iwd configuration equivalent you can put them in a configuration file called\nessid\n.8021x\nas explained in the preceding methods.\nNote\nEAP-Identity\nmay not be required by your eduroam provider, in which case you might have to use\nanonymous@\nConfig.user_realm\nin this field.\nIf your\nEAP-\nmethod\n-ServerDomainMask\nstarts with\nDNS:\n, use only the part after\nDNS:\n.\nOther cases\nMore example tests can be\nfound in the test cases\nof the upstream repository.\nEmbedded certificates\nInstead of including an absolute path to a PEM file (for certificates and keys), the PEM itself can be included inside the network configuration file.\nAn embedded PEM can appear anywhere in the settings file using the following format:\n[@pem@\nmy_ca_cert\n]\n----- BEGIN CERTIFICATE -----\nPEM data\n----- END CERTIFICATE -----\nwhere\nmy_ca_cert\nis any name you can use to identify the certificate inside the configuration file.\nThen the embedded certificate can be used anywhere in the settings file a certificate path is required by prefixing the value with\nembed:\nEAP-TTLS-CACert=embed:\nmy_ca_cert\nThis  is not limited to CA certificates either. Client certificates, client keys (encrypted or not), and certificate chains can be included.\nWPA over wired ethernet\nFor WPA on a wired ethernet connection create a config as above,\nbut place it in the\n/var/lib/ead\ndirectory instead.\nAfterwards\nStart/enable\nead.service\n.\nOptional configuration\nFile\n/etc/iwd/main.conf\ncan be used for main configuration. See\niwd.config(5)\n.\nDisable auto-connect for a particular network\nCreate\nor\nedit\nthe file\n/var/lib/iwd/\nnetwork\n.\ntype\n. Add the following section to it:\n/var/lib/iwd/spaceship.psk (for example)\n[Settings]\nAutoConnect=false\nDisable periodic scan for available networks\nBy default when\niwd\nis in disconnected state, it periodically scans for available networks. To disable periodic scan (so as to always scan manually), create / edit file\n/etc/iwd/main.conf\nand add the following section to it:\n/etc/iwd/main.conf\n[Scan]\nDisablePeriodicScan=true\nEnable built-in network configuration\nSince version 0.19, iwd can assign IP address(es) and set up routes using a built-in DHCP client or with static configuration. It is a good alternative to\nstandalone DHCP clients\n.\nTo activate iwd's network configuration feature, create/edit\n/etc/iwd/main.conf\nand add the following section to it:\n/etc/iwd/main.conf\n[General]\nEnableNetworkConfiguration=true\nThere is also ability to set route metric with\nRoutePriorityOffset\n:\n/etc/iwd/main.conf\n[Network]\nRoutePriorityOffset=300\nIPv6 support\nSince version 1.10, iwd supports IPv6, but it is disabled by default in versions below 2.0.\nSince version\n2.0\n, it is enabled by default.\nTo disable it, add the following to the configuration file:\n/etc/iwd/main.conf\n[Network]\nEnableIPv6=false\nTo enable it in version below 2.0 and higher than 1.10:\n/etc/iwd/main.conf\n[Network]\nEnableIPv6=true\nThis setting is required to be enabled whether you want to use DHCPv6 or static IPv6 configuration.  It can also be set on a per-network basis.\nSetting static IP address in network configuration\nAdd the following section to\n/var/lib/iwd/\nnetwork\n.\ntype\nfile. For example:\n/var/lib/iwd/spaceship.psk\n[IPv4]\nAddress=192.168.1.10\nNetmask=255.255.255.0\nGateway=192.168.1.1\nBroadcast=192.168.1.255\nDNS=192.168.1.1\nSelect DNS manager\nAt the moment, iwd supports two DNS managers—\nsystemd-resolved\nand\nresolvconf\n.\nAdd the following section to\n/etc/iwd/main.conf\nfor\nsystemd-resolved\n:\n/etc/iwd/main.conf\n[Network]\nNameResolvingService=systemd\nFor\nresolvconf\n:\n/etc/iwd/main.conf\n[Network]\nNameResolvingService=resolvconf\nNote\nIf not specified,\nsystemd-resolved\nis used as default and recommended for\nsystemd use\n.\nAllow any user to read status information\nIf you want to allow any user to read the status information, but not modify the settings, you can create the following\nD-Bus\nconfiguration file:\n/etc/dbus-1/system.d/iwd-allow-read.conf\n<!-- Allow any user to read iwd status information. Overrides some part\nof /usr/share/dbus-1/system.d/iwd-dbus.conf. -->\n<!DOCTYPE busconfig PUBLIC \"-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN\"\n\"http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd\">\n<busconfig>\n<policy context=\"default\">\n<deny send_destination=\"net.connman.iwd\"/>\n<allow send_destination=\"net.connman.iwd\" send_interface=\"org.freedesktop.DBus.Properties\" send_member=\"GetAll\" />\n<allow send_destination=\"net.connman.iwd\" send_interface=\"org.freedesktop.DBus.Properties\" send_member=\"Get\" />\n<allow send_destination=\"net.connman.iwd\" send_interface=\"org.freedesktop.DBus.ObjectManager\" send_member=\"GetManagedObjects\" />\n<allow send_destination=\"net.connman.iwd\" send_interface=\"net.connman.iwd.Device\" send_member=\"RegisterSignalLevelAgent\" />\n<allow send_destination=\"net.connman.iwd\" send_interface=\"net.connman.iwd.Device\" send_member=\"UnregisterSignalLevelAgent\" />\n</policy>\n</busconfig>\nEncrypted network profiles\nThis article or section needs expansion.\nReason:\nEncrypted network profiles may not work in certain setups. (Discuss in\nTalk:Iwd\n)\nBy default, iwd stores network credentials to the system unencrypted. Since iwd version 1.25, iwd provides experimental support for creating\nencrypted profiles\nfor systems using systemd.\nFirst, create an encrypted credential. The following example uses\nsystemd-creds\nand creates an encrypted credential called\niwd-secret\nthat is bound to the system's\nTrusted Platform Module\nwhich will be used to create encrypted profiles:\n# systemd-ask-password -n | systemd-creds --tpm2-device=auto --name=iwd-secret encrypt - /etc/credstore.encrypted/iwd-secret.cred\nNext, add the\nLoadCredentialEncrypted\noption by creating a\ndrop-in file\nfor the iwd service.\n/etc/systemd/system/iwd.service.d/use-creds.conf\n[Service]\nLoadCredentialEncrypted=iwd-secret:/etc/credstore.encrypted/iwd-secret.cred\nFinally, add the\nSystemdEncrypt\noption with the value being the named credential to the iwd configuration file,\nreload\nthe systemd manager, and\nrestart\nthe iwd service.\n/etc/iwd/main.conf\n[General]\n...\nSystemdEncrypt=iwd-secret\nNote\nAny profiles currently on the system will be encrypted automatically. At this point there is nothing else needed, and any future profiles will be encrypted automatically.\nIn the above example, the encrypted credential is implicitly bound to TPM PCR 7. Therefore, if the secure boot state or firmware certificates change then connecting to networks will not be possible for that booted session.\nTroubleshooting\nVerbose TLS debugging\nThis can be useful, if you have trouble setting up MSCHAPv2 or TTLS. You can set the following\nenvironment variable\nvia a\ndrop-in snippet\n:\n/etc/systemd/system/iwd.service.d/tls-debug.conf\n[Service]\nEnvironment=IWD_TLS_DEBUG=TRUE\nCheck the iwd logs afterwards by running\njournalctl -u iwd.service\nas root.\nRestarting iwd.service after boot\nOn some machines, it is reported that\niwd.service\nhas to be restarted to work after boot. See\nFS#63912\nand\nthread 251432\n. This probably occurs because\niwd\nstarts before wireless network card powers on.\nAs a workaround, find the unit needed to wait for by\nsystemctl list-units --type=device | grep\nwlan0\nand\nextend the unit\naccordingly:\n/etc/systemd/system/iwd.service.d/override.conf\n[Unit]\nAfter=sys-\nXXXX\n-net-\nwlan0\n.device\nWants=sys-\nXXXX\n-net-\nwlan0\n.device\nThen\nreload\nthe\nsystemd\nmanager configuration.\nIf it does not work, try also\n[Service]\nExecStartPre=ip link set wlan0 up\nWireless device is not renamed by udev\nSince version 1.0, iwd disables\nnetwork interface\nrenaming to\npredictable network interface names\n. It installs the following\nsystemd.link(5)\nconfiguration file which prevents udev from renaming the interface to a predictable, stable name (e.g.\nwlp\n#\ns\n#\n):\n/usr/lib/systemd/network/80-iwd.link\n[Match]\nType=wlan\n[Link]\nNamePolicy=keep kernel\nAs a result the wireless link name\nwlan\n#\nis kept after boot. This resolved a race condition between\niwd\nand\nudev\non interface renaming as explained in\niwd udev interface renaming\n.\nIf this results in issues try masking it with:\n# ln -s /dev/null /etc/systemd/network/80-iwd.link\nNo DHCP in AP mode\nClients may not receive an IP address via DHCP when connecting to\niwd\nin AP mode. It is therefore necessary to enable network configuration by\niwd\non managed interfaces:\n/etc/iwd/main.conf\n[General]\nEnableNetworkConfiguration=True\nThe mentioned file has to be created if it does not already exist.\nWi-Fi keeps disconnecting due to iwd crash\nSome users experience disconnections with Wi-Fi, re-connecting continuously but stabilizing eventually and managing to connect.\nUsers report crashes (\n[1]\n) of\niwd.service\nin their\njournal\n.\nThe core issue is having multiple conflicting services for managing their network connections. Check that you do not have\nenabled\nthem at the same time to fix this issue.\nError loading client private key\nTo load key files\niwd\nrequires the\npkcs8_key_parser\nkernel module\n. While on boot it gets loaded by\nsystemd-modules-load.service(8)\nusing\n/usr/lib/modules-load.d/pkcs8.conf\n, that will not be the case if\niwd\nhas just been installed.\nIf messages such as\nError loading client private key\n/path/to/key\nshow up in the\njournal\nwhen trying to connect to WPA Enterprise networks, manually load the module:\n# modprobe pkcs8_key_parser\niwd keeps roaming\niwd will roam to other known APs if the connection is too bad.\nThis will show up in the system log as\nwlan0: deauthenticating from xx:xx:xx:xx:xx:xx by local choice (Reason: 3=DEAUTH_LEAVING)\nYou can see the connection signal strength with\niwctl station wlan0 show | grep RSSI\nYou can increase the threshold to allow a worse connection. RoamThreshold defaults to -70 and RoamThreshold5G to -76.\n/etc/iwd/main.conf\n[General]\nRoamThreshold=-75\nRoamThreshold5G=-80\nHostname not sent in DHCP request\nSet\nSendHostname\nin the network's configuration file, not in\n/etc/iwd/main.conf\n.\n/var/lib/iwd/SomeNetwork.psk\n...\n[IPv4]\nSendHostname=true\n/etc/resolv.conf: Read-only file system\nWhen using\nresolvconf\nas DNS resolution method, it may have trouble writing to\n/etc/resolv.conf\ncomplaining about read-only file system:\n$ journalctl -u iwd.service\nJun 14 14:08:12 host iwd[1170270]: event: state, old: disconnected, new: autoconnect_quick\nJun 14 14:08:12 host iwd[1170270]: udev interface=wlan0 ifindex=6\nJun 14 14:08:13 host iwd[1170270]: event: connect-info, ssid: <redacted>, bss: <redacted>, signal: -63, load: 0/255\nJun 14 14:08:13 host iwd[1170270]: event: state, old: autoconnect_quick, new: connecting (auto)\nJun 14 14:08:13 host iwd[1170270]: event: state, old: connecting (auto), new: connecting (netconfig)\nJun 14 14:08:14 host iwd[1170315]: cp: cannot create regular file '/etc/resolv.conf.bak': Read-only file system\nJun 14 14:08:14 host iwd[1170316]: /usr/lib/resolvconf/libc: line 257: /etc/resolv.conf: Read-only file system\nJun 14 14:08:16 host iwd[1170366]: cp: cannot create regular file '/etc/resolv.conf.bak': Read-only file system\nJun 14 14:08:16 host iwd[1170367]: /usr/lib/resolvconf/libc: line 257: /etc/resolv.conf: Read-only file system\nJun 14 14:08:16 host iwd[1170270]: event: state, old: connecting (netconfig), new: connected\nTo fix this problem, extend the configuration of the\niwd.service\nsystemd unit by adding\ndrop-in file\n:\n/etc/systemd/system/iwd.service.d/50-resolvconf.conf\n[Service]\nRuntimeDirectory=resolvconf\nReadWritePaths=/etc/resolv.conf\nThis will allow the\niwd.service\nsystem unit to update\n/etc/resolv.conf\n.\nRestart\niwd.service\nto make the change effective.\nNote\nThere is a discussion about this issue at the upstream mailing list:\nRe: iwd doesn't work with openresolv\nSee also\nGetting Started with iwd\nNetwork Configuration Settings\nMore Examples for WPA Enterprise\nThe IWD thread on the Arch Linux Forums\n2017 Update on new WiFi daemon for Linux by Marcel Holtmann - YouTube\nThe New Wi-Fi Experience for Linux - Marcel Holtmann, Intel - YouTube\nHow to set up a simple access point with iwd\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Iwd&oldid=847035\n\"\nCategories\n:\nWireless networking\nNetwork configuration\nHidden categories:\nPages or sections flagged with Template:Style\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Expansion\nSearch\nSearch\niwd\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Iwd"}}
{"text": "Domain name resolution - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nDomain name resolution\n7 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\n(Redirected from\nDNS\n)\nRelated articles\nNetwork configuration\nDNS over HTTPS servers\nIn general, a\ndomain name\nrepresents an IP address and is associated to it in the\nDomain Name System\n(DNS).\nThis article explains how to configure domain name resolution and resolve domain names.\nName Service Switch\nThis article or section needs expansion.\nReason:\nMention\nnss-mdns\n,\nnss-tls-git\nAUR\nand others. (Discuss in\nTalk:Domain name resolution\n)\nThe\nName Service Switch\n(NSS) facility is part of the GNU C Library (\nglibc\n) and backs the\ngetaddrinfo(3)\nAPI, used to resolve domain names. NSS allows system databases to be provided by separate services, whose search order can be configured by the administrator in\nnsswitch.conf(5)\n. The database responsible for domain name resolution is the\nhosts\ndatabase, for which glibc offers the following services:\nfiles\n: reads the\n/etc/hosts\nfile, see\nhosts(5)\ndns\n: the\nglibc resolver\nwhich reads\n/etc/resolv.conf\n, see\nresolv.conf(5)\nsystemd\nprovides three NSS services for hostname resolution:\nnss-resolve(8)\n— a caching DNS stub resolver, described in\nsystemd-resolved\nnss-myhostname(8)\n— provides local hostname resolution without having to edit\n/etc/hosts\nnss-mymachines(8)\n— provides hostname resolution for the names of local\nsystemd-machined(8)\ncontainers\nResolve a domain name using NSS\nNSS databases can be queried with\ngetent(1)\n. A domain name can be resolved through NSS using:\n$ getent ahosts\ndomain_name\nNote\nWhile most programs resolve domain names using NSS, some may read\n/etc/resolv.conf\nand/or\n/etc/hosts\ndirectly. See\nNetwork configuration#local hostname is resolved over the network\n.\nGlibc resolver\nThe glibc resolver reads\n/etc/resolv.conf\nfor every resolution to determine the nameservers and options to use.\nresolv.conf(5)\nlists nameservers together with some configuration options.\nNameservers listed first are tried first, up to three nameservers may be listed. Lines starting with a number sign (\n#\n) are ignored.\nNote\nThe glibc resolver does not cache queries. To improve query lookup time you can set up a caching resolver. The glibc resolver also can not validate DNSSEC. A DNSSEC validating resolver is required for that. See\n#DNS servers\nfor more information.\nOverwriting of /etc/resolv.conf\nNetwork managers\ntend to overwrite\n/etc/resolv.conf\n, for specifics see the corresponding section:\ndhcpcd#/etc/resolv.conf\nNetctl#/etc/resolv.conf\nNetworkManager#/etc/resolv.conf\nConnMan#/etc/resolv.conf\nTo prevent programs from overwriting\n/etc/resolv.conf\n, it is also possible to write-protect it by setting the immutable\nfile attribute\n:\n# chattr +i /etc/resolv.conf\nTip\nIf you want multiple processes to write to\n/etc/resolv.conf\n, you can use\nresolvconf\n.\nAlternative using nmcli\nThis article or section is a candidate for merging with\nNetworkManager#/etc/resolv.conf\n.\nNotes:\nNetworkManager has a dedicated section for this topic. (Discuss in\nTalk:Domain name resolution\n)\nIf you use\nNetworkManager\n,\nnmcli(1)\ncan be used to set persistent options for\n/etc/resolv.conf\n. Change \"Wired\" to the name of your connection. Example:\n# nmcli con mod Wired +ipv4.dns-options 'rotate,single-request,timeout:1'\nFor more options have a look at the man pages of\nnmcli(1)\n,\nnm-settings-nmcli(5)\nand\nresolv.conf(5)\n.\nLimit lookup time\nIf you are confronted with a very long hostname lookup (may it be in\npacman\nor while browsing), it often helps to define a small timeout after which an alternative nameserver is used. To do so, put the following in\n/etc/resolv.conf\n.\n/etc/resolv.conf\noptions timeout:1\nHostname lookup delayed with IPv6\nIf you experience a 5 second delay when resolving hostnames it might be due to a DNS-server/Firewall misbehaving and only giving one reply to a parallel A and AAAA request.\n[1]\nYou can fix that by setting the following option in\n/etc/resolv.conf\n:\n/etc/resolv.conf\noptions single-request\nLocal domain names\nTo be able to use the hostname of local machine names without the fully qualified domain name, add a line to\n/etc/resolv.conf\nwith the local domain such as:\n/etc/resolv.conf\nsearch\nexample.org\nThat way you can refer to local hosts such as\nmainmachine1.example.org\nas simply\nmainmachine1\nwhen using the\nssh\ncommand, but the\ndrill\ncommand still requires the fully qualified domain names in order to perform lookups.\nLookup utilities\nTo query specific DNS servers and DNS/\nDNSSEC\nrecords you can use dedicated DNS lookup utilities or those shipped with DNS servers. These tools implement DNS themselves and do not use\nNSS\n.\ndrill(1)\n— A tool designed to retrieve information out of the DNS. It only supports unencrypted DNS.\nhttps://nlnetlabs.nl/projects/ldns/\n||\nldns\nFor example, to query a specific nameserver with\ndrill\nfor the TXT records of a domain:\n$ drill\ndomain\n@\nnameserver\nTXT\nUnless a DNS server is specified,\ndrill\nwill use the nameservers defined in\n/etc/resolv.conf\n.\nadig(1)\n— Send queries to DNS servers about name and print received information.\nhttps://c-ares.org/\n||\nc-ares\ndnsi\n— A command line tool to investigate various aspects of the DNS.\nhttps://github.com/NLnetLabs/dnsi\n||\ndnsi\nAUR\ndnslookup\n— A simple command line utility to make DNS lookups. Supports all known DNS protocols.\nhttps://github.com/ameshkov/dnslookup\n||\ndnslookup\nAUR\ndog(1)\n— A command-line DNS client like dig.\nhttps://github.com/ogham/dog\n||\ndog\ndoggo\n— Command-line DNS client for humans.\nhttps://github.com/mr-karan/doggo\n||\ndoggo\nAUR\nq\n— A tiny command line DNS client.\nhttps://github.com/natesales/q\n||\nq-dns\nAUR\nSome DNS server packages ship with DNS lookup utilities that can be used without running the DNS server:\nknot\nprovides\nkhost(1)\nand\nkdig(1)\n.\nunbound\nprovides\nunbound-host(1)\n.\nbind\nprovides\ndig(1)\n,\nhost(1)\nand\nnslookup(1)\n.\npowerdns\nprovides\nsdig(1)\n.\nTip\nsystemd-resolved\nhas\nresolvectl(1)\n, which provides a\nquery\nsub-command for DNS lookup. It can only be used with\nsystemd-resolved\n.\nResolver performance\nThe Glibc resolver does not cache queries. To implement local caching, use\nsystemd-resolved\nor set up a local caching\nDNS server\nand use it as the name server by setting\n127.0.0.1\nand\n::1\nas the name servers in\n/etc/resolv.conf\nor in\n/etc/resolvconf.conf\nif using\nopenresolv\n.\nTip\nThe\ndrill\n,\ndig\nand\nkdig\nlookup utilities\nreport the query time.\nA router usually sets its own caching resolver as the network's DNS server thus providing DNS cache for the whole network.\nIf it takes too long to switch to the next DNS server you can try\ndecreasing the timeout\n.\nPrivacy and security\nThis article or section needs expansion.\nReason:\nDocument DNS filtering, a.k.a.\nDNS sinkholing\n. Link to\nUnbound#Domain blacklisting\nand\ndnsmasq#Domain blocklisting\nas examples. (Discuss in\nTalk:Domain name resolution\n)\nThe\nDNS protocol\n(Do53) is unencrypted and does not account for confidentiality, integrity or authentication, so if you use an untrusted network or a malicious ISP, your DNS queries can be eavesdropped and the responses\nmanipulated\n. Furthermore, DNS servers can conduct\nDNS hijacking\n.\nYou need to trust your DNS server to treat your queries confidentially. DNS servers are provided by ISPs and\nthird-parties\n. Alternatively you can run your own\nrecursive name server\n(a.k.a. recursive resolver, a.k.a. DNS recursor), which however takes more effort. If you use a\nDHCP\nclient in untrusted networks, be sure to set static name servers to avoid using and being subject to arbitrary DNS servers, or alternatively, use a\nVPN\nto connect to a secure network and use its DNS servers. To secure your communication with a remote DNS server you can use an encrypted protocol, provided that both the upstream server and your\nlocal resolver\nsupport the protocol. Common encrypted DNS protocols are:\nDNS over TLS\n(DoT)—\nRFC 7858\n,\nDNS over HTTPS\n(DoH)—\nRFC 8484\n,\nDNS over QUIC\n(DoQ)—\nRFC 9250\n,\nDNSCrypt\n.\nTo verify that responses are actually from\nauthoritative name servers\n, you can validate\nDNSSEC\n, provided that both the upstream server(s) and your local resolver support it.\nTLS Server Name Indication\nAlthough one may use an encrypted DNS resolver, a TLS connection still leaks the domain names in the\nServer Name Indication\n(SNI) when requesting the domain certificate. This leak can be checked using the\nWireshark\nfilter\ntls.handshake.extensions_server_name_len > 0\n, or using the following\ntshark\ncommand:\n# tshark -p -Tfields -e tls.handshake.extensions_server_name -Y 'tls.handshake.extensions_server_name_len>0'\nA proposed solution is to use the\nEncrypted Client Hello (ECH)\n, a TLS 1.3 protocol extension.\nApplication-level DNS\nBe aware that some client software, such as major web browsers\n[2]\n[3]\n, are starting to implement DNS over HTTPS. While the encryption of queries may often be seen as a bonus, it also means the software sidetracks queries around the system resolver configuration.\n[4]\nFirefox\nprovides\nconfiguration options\nto enable or disable DNS over HTTPS and select a DNS server. Mozilla has setup a\nTrusted Recursive Resolver (TRR)\nprogramme with transparency information on their default providers. It is notable that Firefox supports and automatically enables the Encrypted Client Hello (ECH) for TRR providers, see\nFirefox/Privacy#Encrypted Client Hello\n.\nChromium\nwill examine the user's system resolver and enable DNS over HTTPS if the system resolver addresses are known to also provide DNS over HTTPS. See\nthis blog post\nfor more information and how DNS over HTTPS can be disabled.\nMozilla\nhas proposed\nuniversally disabling application-level DNS if the system resolver cannot resolve the domain\nuse-application-dns.net\n. Currently, this is only implemented in Firefox.\nOblivious DNS over HTTPS\nOblivious DNS over HTTPS (ODoH)—\nRFC 9230\n—is a system which addresses a number of DNS privacy concerns. See\nCloudflare's article\nfor more information. It added DNS over HTTPS to the academic\nOblivious DNS\ndesign. See the\nImproving the privacy of DNS and DoH with oblivion\narticle for a discussion of the differences.\nRecursive resolver\nThis article or section needs expansion.\nReason:\nExplain\nQNAME minimization\n. (Discuss in\nTalk:Domain name resolution\n)\nCommunication between recursive resolvers and root servers is not encrypted and the root server operators\nare against implementing it\n. For encrypted communication with authoritative servers there is the experimental\nRFC 9539\nwhich allows the opportunistic use of DNS over TLS and DNS over QUIC.\nThird-party DNS services\nNote\nBefore using a third-party DNS service, check its privacy policy for information on how user data is handled. User data has value and can be sold to other parties.\nIt is highly advised to use an\nencrypted protocol\nwhen connecting to third-party DNS services.\nThere are various third-party DNS services. Wikipedia has a list of\n\"notable\" public DNS service operators\nwhile the curl project's wiki has a more extensive list of\npublicly available DNS over HTTPS servers\n(a lot of which also support DNS over TLS). The\nsystemd\npackage\nconfigures fallback\nDNS for\nsystemd-resolved\nwhen no DNS servers are configured (manually or via DHCP/RA).\nYou can use\ndnsperftest\nto test the performance of the most popular DNS resolvers from your location.\ndnsperf.com\nprovides global benchmarks between providers.\nThird-party DNS client software\nSome DNS services also provide dedicated software:\ncloudflared\n— A DNS client for Cloudflare DNS over HTTPS\nhttps://developers.cloudflare.com/1.1.1.1/dns-over-https/cloudflared-proxy\n||\ncloudflared\nopennic-up\n— Automates the renewal of the DNS servers with the most responsive OpenNIC servers\nhttps://github.com/kewlfft/opennic-up\n||\nopennic-up\nAUR\nnextdns\n— A DNS-over-HTTPS CLI client for NextDNS\nhttps://github.com/nextdns/nextdns\n||\nnextdns\nAUR\nDNS servers\nDNS servers can be\nauthoritative\nand\nrecursive\n. If they are neither, they are called\nstub resolvers\nand simply forward all queries to another recursive name server. Stub resolvers are typically used to introduce DNS caching on the local host or network. Note that the same can also be achieved with a fully-fledged name server. This section compares the available DNS servers, for a more detailed comparison, refer to\nWikipedia:Comparison of DNS server software\n.\nName\nPackage\nCapabilities\nresolvconf\nSupported protocols\nAuthoritative\nRecursive\nCache\nValidates\nDNSSEC\nDNS\nDNSCrypt\nDNS\nover TLS\nDNS\nover HTTPS\nDNS\nover QUIC\nBIND\nbind\nYes\nYes\nYes\nYes\nYes\nYes\nNo\nYes\nServer\nNo\nCoreDNS\ncoredns\nAUR\nYes\nNo\nYes\nNo\nNo\nYes\nNo\nYes\nServer\nNo\nDNS-over-HTTPS\ndns-over-https\nNo\nNo\nNo\nNo\nNo\nServer\nNo\nNo\nYes\nNo\nDeadwood\n(\nMaraDNS\nrecursor)\nmaradns\nAUR\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nNo\nNo\nNo\ndnscrypt-proxy\ndnscrypt-proxy\nNo\nNo\nYes\nNo\nNo\nServer\nResolver\nNo\nYes\nNo\ndnsmasq\ndnsmasq\nPartial\n1\nNo\nYes\nYes\n2\nYes\nYes\nNo\nNo\nNo\nNo\ndnsproxy\ndnsproxy\nNo\nNo\nYes\nNo\nNo\nYes\nYes\nYes\nYes\nYes\nKnot Resolver\nknot-resolver\nNo\nYes\nYes\nYes\nNo\nYes\nNo\nYes\nServer\nNo\npdnsd\npdnsd\nPartial\n1\nYes\nPermanent\nNo\nYes\nYes\nNo\nNo\nNo\nNo\nPowerDNS Recursor\npowerdns-recursor\nNo\nYes\nYes\nYes\n2\nYes\nYes\nNo\nPartial\nNo\nNo\nRescached\nrescached-git\nAUR\nNo\nNo\nYes\nNo\nYes\nYes\nNo\nYes\nYes\nNo\nRouteDNS\nroutedns-git\nAUR\nNo\nNo\nYes\n3\nNo\nNo\nYes\nNo\nYes\nYes\nYes\nSmartDNS\nsmartdns\nNo\nNo\nYes\nNo\nNo\nYes\nNo\nResolver\nResolver\nNo\nStubby\nstubby\nNo\nNo\nNo\nYes\n2\nNo\nServer\nNo\nResolver\nNo\nNo\nsystemd-resolved\nsystemd\nNo\nNo\nYes\nExperimental\n2\nYes\nResolver and\nlimited server\nNo\nResolver\nNo\nNo\nUnbound\nunbound\nPartial\nYes\nYes\n3\nYes\nYes\nYes\nServer\nYes\nServer\nServer\nFrom\nWikipedia\n: limited authoritative support, intended for internal network use rather than public Internet use.\nDNSSEC validation is disabled by default and must be enabled in the configuration file.\nSupports persistent cache using the\nRedis\nbackend.\nTip\nDNS servers that do not support DNS over TLS can use\nstunnel\nto add TLS encryption. For resolver functionality this requires the ability to force using TCP when forwarding.\nAuthoritative-only servers\nName\nPackage\nDNSSEC\nsigning\nGeographic\nbalancing\ngdnsd\ngdnsd\nNo\nYes\nKnot DNS\nknot\nYes\nYes\nMaraDNS\nmaradns\nAUR\nNo\nNo\nNSD\nnsd\nYes\nNo\nPowerDNS\npowerdns\nYes\nYes\nConditional forwarding\nIt is possible to use specific DNS resolvers when querying specific domain names. This is particularly useful when connecting to a VPN, so that queries to the VPN network are resolved by the VPN's DNS, while queries to the internet will still be resolved by your standard DNS resolver. It can also be used on local networks.\nTo implement it, you need to use a\nlocal resolver\nbecause glibc does not support it.\nIn a dynamic environment (laptops and to some extents desktops), you need to configure your resolver based on the network(s) you are connected to. The best way to do that is to use\nopenresolv\nbecause it supports\nmultiple subscribers\n. Some\nnetwork managers\nsupport it, either through openresolv, or by configuring the resolver directly. NetworkManager\nsupports conditional forwarding without openresolv\n.\nNote\nAlthough you could use other conditions for forwarding (for example, source IP address), \"conditional forwarding\" appears to be the name used for the \"domain queried\" condition.\nSee also\nLinux Network Administrators Guide\nDebian Handbook\nRFC:7706\n- Decreasing Access Time to Root Servers by Running One on Loopback\nDomain name system overview\n- Diagram about DNS\nWhat does DNS stand for\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Domain_name_resolution&oldid=850368\n\"\nCategories\n:\nDomain Name System\nNetwork configuration\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Merge\nSearch\nSearch\nDomain name resolution\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/DNS"}}
{"text": "Firewalld - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nFirewalld\n2 languages\n日本語\n中文（简体）\nFrom ArchWiki\nRelated articles\nnftables\nfirewalld\nis a firewall daemon developed by Red Hat. It uses\nnftables\nby default. From project home page:\nFirewalld provides a dynamically managed firewall with support for network/firewall zones that define the trust level of network connections or interfaces. It has support for IPv4, IPv6 firewall settings, ethernet bridges and IP sets. There is a separation of runtime and permanent configuration options. It also provides an interface for services or applications to add firewall rules directly.\nInstallation\nInstall\nthe\nfirewalld\npackage.\nUsage\nEnable\nand\nstart\nfirewalld.service\n.\nYou can control the firewall rules with the\nfirewall-cmd\nconsole utility.\nfirewall-offline-cmd\nutility can be used to configure when firewalld is not running. It features similar syntax to\nfirewall-cmd\n.\nGUI is available as\nfirewall-config\nwhich comes with\nfirewalld\npackage.\nWith the\nnftables backend\n, firewalld does not assume complete control over the hosts firewalling. Since nftables allows multiple \"namespaces\" via tables, firewalld will scope all of its rules, sets, and chains to the\nfirewalld\ntable. Firewalld does not do a complete flush of firewall rules, it will only flush rules in the\nfirewalld\ntable.\nnftables allows multiple chains to hook into netfilter at the same point. Packets that are\naccepted\nby a chain are still subject to the rules of other chains hooked into the hook type and in the\ndrop\ncase processing always stops immediately and no other hooks will process the packet. To ensure predictability of the execution order of chains, firewalld gives its rules slightly lower precedence than default nftables hook priority values. Consequently, firewall rules created outside of firewalld (e.g. by\nlibvirt\n,\nDocker\n,\nPodman\n,\nsystemd-nspawn\n, etc.) will be processed before firewalld rules and packets accepted by them will still be subject to firewalld rules.\nConfiguration\nConfiguration at run time can be changed using\nfirewall-cmd\n.\nNote\nMost commands will only change runtime configuration and will not persist through restart. To make changes permanent there are two options:\nUse\n--permanent\noption. This will\nnot\nchange runtime configuration until the firewall service is restarted or rules are reloaded with\n--reload\ncommand.\nChange the runtime configuration and make it permanent as described in\n#Converting runtime configuration to permanent\nZones\nZone is a collection of rules that can be applied to a specific interface.\nTo have an overview of the current zones and interfaces they are applied to:\n# firewall-cmd --get-active-zones\nSome commands (such as adding/removing ports/services) require a zone to specified.\nZone can be specified by name by passing\n--zone=\nzone_name\nparameter.\nIf no zone is specified default zone is assumed.\nZone information\nYou can list all the zones with entirety their configuration:\n# firewall-cmd --list-all-zones\nor just a specific zone\n# firewall-cmd --info-zone=\nzone_name\nChanging zone of an interface\n# firewall-cmd --zone=\nzone\n--change-interface=\ninterface_name\nThere\nzone\nis a new zone that you want to assign interface to.\nUsing NetworkManager to manage zones\nNetworkManager\ncan assign different connection profiles to different zones. This allows for example, adding a home Wi-Fi connection to the \"home\" zone, a work Wi-Fi connection to the \"work\" zone, and all other Wi-Fi connections to the default \"public\" zone.\nList connection profiles:\n$ nmcli connection show\nAssign the \"myssid\" profile to the \"home\" zone:\n$ nmcli connection modify\nmyssid\nconnection.zone\nhome\nDefault zones\nWhen a new interface is connected the default zone will be applied. You can query the name of the default zone using:\n# firewall-cmd --get-default-zone\nThe default zone can be changed using following command.\n# firewall-cmd --set-default-zone=\nzone\nNote\nThis change is always permanent.\nServices\nServices are pre-made rules corresponding to a specific daemon. For example, the\nssh\nservice corresponds to\nSSH\nand opens ports 22 when assigned to a zone.\nTo get a list of available services, enter the following command:\n# firewall-cmd --get-services\nYou can query information about a particular service:\n# firewall-cmd --info-service\nservice_name\nAdding or removing services from a zone\nTo add a service to a zone:\n# firewall-cmd --zone=\nzone_name\n--add-service\nservice_name\nRemoving a service:\n# firewall-cmd --zone=\nzone_name\n--remove-service\nservice_name\nPorts\nPorts can be directly opened on a specific zone.\n# firewall-cmd --zone=\nzone_name\n--add-port\nport_num\n/\nprotocol\nThere\nprotocol\nis either\ntcp\nor\nudp\n.\nTo close the port use\n--remove-port\noption with same port number and protocol.\nNAT masquerade\nMasquerading is a form of\nsource NAT\nwhere the source address is unknown at the time the firewall rule created in the kernel, and instead the source address of a packet is dynamically modified to the primary IP address of the outgoing interface\n[1]\n.\n# firewall-cmd --permanent --zone=public --add-masquerade\nSince version 1.0.0, to make NAT masquerade work between different firewall zones, you have to create a new policy object which is used to filter traffic between them:\n# firewall-cmd --new-policy internal-to-public --permanent\n# firewall-cmd --permanent --policy internal-to-public --add-ingress-zone internal\n# firewall-cmd --permanent --policy internal-to-public --add-egress-zone public\n# firewall-cmd --permanent --policy internal-to-public --set-target ACCEPT\nPort forwarding\nThis article or section needs expansion.\nReason:\nAdd a note about\nStrictForwardPorts\n. (Discuss in\nTalk:Firewalld\n)\nIf you have firewalld configured on a router, and you have enabled NAT masquerading as above, it is simple to set up port forwarding through firewalld:\n# firewall-cmd --zone=public --add-forward-port=port=12345:proto=tcp:toport=22:toaddr=10.20.30.40\nThis will forward port\n12345/tcp\non the firewall's public interface to port\n22\n(standard SSH) on the internal system at IP address\n10.20.30.40\n. To remove this forwarded port:\n# firewall-cmd --zone=public --remove-forward-port=port=12345:proto=tcp:toport=22:toaddr=10.20.30.40\nUnfortunately you have to type the entire forward declaration in order to remove it, specifying only the port and the protocol is not enough.\nRich rules\nWith rich rules/rich language syntax more complex firewall rules can be created in an easy to understand way.\nTo add a rich rule:\n# firewall-cmd [--zone=\nzone_name\n] [--permanent] --add-rich-rule='\nrich_rule\n'\nwhere\nrich_rule\nis a rich language rule.\nFor example, to allow all connection from network\n192.168.1.0/24\nto the\nNFS\nservice\n:\n# firewall-cmd --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"nfs\" accept'\nTo allow connection from\n192.168.2.3\nto port\n1234/tcp\n:\n# firewall-cmd --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.2.3\" port port=\"1234\" protocol=\"tcp\" accept'\nFor more rich language syntax, see\nfirewalld.richlanguage(5)\n.\nTo remove a rich rule:\n# firewall-cmd  [--zone=\nzone_name\n] [--permanent] --remove-rich-rule='\nrich_rule\n'\nTips and tricks\nPort or service timeout\nService or port can be added for a limited amount of time using\n--timeout=\nvalue\noption passed during addition command. Value is either number of seconds, minutes if postfixed with\nm\nor hours\nh\n.\nFor example, adding\nSSH\nservice for 3 hours:\n# firewall-cmd --add-service ssh --timeout=3h\nNote\nTimeouts are mutually exclusive with --permanent changes to the firewall configuration.  I.e., timeouts can only be applied to the runtime configuration, and are never permanent.\nConverting runtime configuration to permanent\nYou can make the runtime (current temporary) configuration permanent (meaning it persists through restarts)\n# firewall-cmd --runtime-to-permanent\nCheck services details\nThe configuration files for the default supported services are located at\n/usr/lib/firewalld/services/\nand user-created service files would be in\n/etc/firewalld/services/\n.\nRemoving the applet/tray icon\nThe applet is not packaged separately from\nfirewalld\n. The auto start script located at\n/etc/xdg/autostart/firewall-applet.desktop\ncan be hidden, however: see\nXDG Autostart#Directories\n. Alternatively, exclude the file from being installed by adding it to\nNoExtract\nin\n/etc/pacman.conf\n.\nTroubleshooting\nIPv6 reverse packet filter dropping legitimate packages\nfirewalld\nimplements an IPv6 reverse packet filter that by default is set to strict. Unfortunately if there are multiple interfaces connected to the same network (e.g. a laptop with both wired and wireless connected) only one of those interfaces, chosen at random, are returned by the reverse path lookup. Incoming packets on other interfaces on the same network are dropped. Because IPv4 and one of the IPv6-enabled interfaces still work this tends to show up as intermittent connectivity issues like hanging connection attempts or a preference for the worse interface. This issue can be verified by running\nping -6 archlinux.org -I\ninterface\non each interface and seeing that only one of them gets any replies.\nThe workaround is to change the reverse path filter setting to loose. This setting only checks that a reverse path exists at all, and matches the default IPv4 reverse path filter setting (not implemented by firewalld, but implemented in the kernel and configured by systemd).\n/etc/firewalld/firewalld.conf\n...\nIPv6_rpfilter=loose\n...\nSee also\nfirewall-cmd(1)\nOfficial documentation\nFedora:Firewalld\nFedora:Features/FirewalldRichLanguage\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Firewalld&oldid=847598\n\"\nCategory\n:\nFirewalls\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nFirewalld\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Firewalld"}}
{"text": "Security - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSecurity\n7 languages\nDeutsch\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nArch Security Team\nGeneral recommendations\nIdentity management\nCapabilities\nList of Applications/Security\nArch package guidelines/Security\nThis article contains recommendations and best practices for\nhardening\nan Arch Linux system.\nConcepts\nIt\nis\npossible to tighten security to the point where the system is unusable. Security and convenience must be balanced. The trick is to create a secure\nand\nuseful system.\nThe biggest threat is, and will always be, the user.\nThe\nprinciple of least privilege\n: Each part of a system should only be able to access what is strictly required, and nothing more.\nDefense in depth: Security works better in independent layers. When one layer is breached, another should stop the attack.\nBe a little paranoid. And be suspicious. If anything sounds too good to be true, it probably is!\nYou can never make a system 100% secure unless you unplug the machine from all networks, turn it off, lock it in a safe, smother it in concrete and never use it.\nPrepare for failure. Create a plan ahead of time to follow when your security is broken.\nPasswords\nPasswords are key to a secure system. They secure your\nuser accounts\n,\nencrypted filesystems\n, and\nSSH\n/\nGPG\nkeys. They are the main way a computer chooses to trust the person using it, so a big part of security is just about picking secure passwords and protecting them.\nChoosing secure passwords\nPasswords must be complex enough to not be easily guessed from e.g. personal information, or\ncracked\nusing methods like social engineering or brute-force attacks. The tenets of strong passwords are based on\nlength\nand\nrandomness\n. In cryptography the quality of a password is often referred to as its\nentropy\n.\nInsecure passwords include those containing or those using as a base before substitution/variation:\nPersonally identifiable information (e.g., your dog's name, date of birth, area code, favorite video game)\nSimple character substitutions on words (e.g.,\nk1araj0hns0n\n), as modern dictionary attacks can easily work with these\nRoot \"words\" or common strings followed or preceded by added numbers, symbols, or characters (e.g.,\nDG091101%\n)\nCommon phrases or short strings of common dictionary words (e.g.\nphotocopyhauntbranchexpose\n) including with character substitution (e.g.\nPh0toc0pyh4uN7br@nch3xp*se\n) (See Diceware below for when a combination of dictionary words can be secure)\nAny of the\nmost common passwords\nThe best choice for a password is something long (the longer, the better) and generated from a random source. It is important to use a long password.\nWeak hash algorithms allow an 8-character password hash to be compromised in just a few hours.\nTools like\npwgen\nor\napg\nAUR\ncan generate random passwords. However, these passwords can be difficult to memorize. One memorization technique (for ones often typed) is to generate a long password and memorize a minimally secure number of characters, temporarily writing down the full generated string. Over time, increase the number of characters typed - until the password is ingrained in muscle memory and need not be remembered. This technique is more difficult, but can provide confidence that a password will not turn up in wordlists or \"intelligent\" brute force attacks that combine words and substitute characters.\nApart from password management,\nkeepassxc\noffers password/passphrase generation. It is possible to customize the generation in a GUI. Dictionary based passphrases are also supported.\nOne technique for memorizing a password is to use a mnemonic phrase, where each word in the phrase reminds you of the next character in the password.\nTake for instance “the girl is walking down the rainy street” could be translated to\nt6!WdtR5\nor, less simply,\nt&6!RrlW@dtR,57\n.\nThis approach could make it easier to remember a password, but note that the various letters have very different probabilities of being found at the start of words (\nWikipedia:Letter frequency\n).\nAnother effective technique can be to write randomly generated passwords down and store them in a\nsafe\nplace, such as in a wallet, purse, or document safe. Most people do a generally good job of protecting their physical valuables from attack, and it is easier for most people to understand physical security best practices compared to digital security practices.\nIt is also very effective to combine the mnemonic and random technique by saving long randomly generated passwords with a\npassword manager\n, which will be in turn accessed with a memorable \"master password\"/primary password that must be used only for that purpose. The master password must be memorized and never saved. This requires the password manager to be installed on a system to easily access the password (which could be seen as an inconvenience or a security feature, depending on the situation). Some password managers also have smartphone apps which can be used to display passwords for manual entry on systems without that password manager installed (if that is a common use case, you could still use easily typeable but secure passwords for each service instead of completely random ones, see below). Note that a password manager introduces a single point of failure if you ever forget the master password.\nSome password managers compute the contained passwords based on the master password and the service name where you want to log in instead of encrypting them, making it possible to use it on a new system without syncing any data.\nIt can be effective to use a memorable long series of unrelated words as a password. The theory is that if a sufficiently long phrase is used, the gained entropy from the password's length can counter the lost entropy from the use of dictionary words. This\nxkcd comic\ndemonstrates the entropy tradeoff of this method, taking into account the limited set of possible words for each word in the passphrase. If the set of words you choose from is large (multiple thousand words) and you choose 5-7 or even more random words from it, this method provides great entropy, even assuming the attacker knows the set of possible words chosen from and the number of words chosen. The number of possible passphrases after settling on a set of words and number of words is: (number of words in the set of words to select from) to the power of (the number of words chosen for the passphrase). See e.g.\nDiceware\nfor more.\nSee\nThe passphrase FAQ\nor\nWikipedia:Password strength\nfor some additional background.\nMaintaining passwords\nOnce you pick a strong password, be sure to keep it safe. Watch out for\nkeyloggers\n(software and hardware), screen loggers,\nsocial engineering\n,\nshoulder surfing\n, and avoid reusing passwords so insecure servers cannot leak more information than necessary.\nPassword managers\ncan help manage large numbers of complex passwords: if you are copy-pasting the stored passwords from the manager to the applications that need them, make sure to clear the copy buffer every time, and ensure they are not saved in any kind of log (e.g. do not paste them in plain terminal commands, which would store them in files like\n.bash_history\n). Note that password managers that are implemented as browser extensions may be vulnerable to\nside channel attacks\n. These can be mitigated by using password managers that run as separate applications.\nAs a rule, do not pick insecure passwords just because secure ones are harder to remember. Passwords are a balancing act. It is better to have an encrypted database of secure passwords, guarded behind a key and one strong master password, than it is to have many similar weak passwords. Writing passwords down is perhaps equally effective\n[1]\n, avoiding potential vulnerabilities in software solutions while requiring physical security.\nAnother aspect of the strength of the passphrase is that it must not be easily recoverable from other places.\nIf you use the same passphrase for disk encryption as you use for your login password (useful e.g. to auto-mount the encrypted partition or folder on login), make sure that\n/etc/shadow\nends up on an encrypted partition or/and uses a strong key derivation function (i.e. yescrypt/argon2 or sha512 with PBKDF2, but not md5 or low iterations in PBKDF2) for the stored password hash (see\nSHA password hashes\nfor more information).\nTip\nArch Linux switched the\ndefault hashing\nalgorithm to yescrypt. If you have not customized the default, executing a password change with\npasswd\nis necessary (and sufficient) to apply the new default.\nIf you are backing up your password database, make sure that each copy is not stored behind any other passphrase which in turn is stored in it, e.g. an encrypted drive or an authenticated remote storage service, or you will not be able to access it in case of need; a useful trick is to protect the drives or accounts where the database is backed up using a simple cryptographic hash of the master password. Maintain a list of all the backup locations: if one day you fear that the master passphrase has been compromised you will have to change it immediately on all the database backups and the locations protected with keys derived from the master password.\nVersion-controlling the database in a secure way can be very complicated: if you choose to do it, you must have a way to update the master password of all the database versions. It may not always be immediately clear when the master password is leaked: to reduce the risk of somebody else discovering your password before you realize that it leaked, you may choose to change it on a periodical basis. If you fear that you have lost control over a copy of the database, you will need to change all the passwords contained in it within the time that it may take to brute-force the master password, according to its entropy.\nPassword hashes\nA hash is a one-way function, i.e. it is designed to make it impossible to deduct the input without computing the hash function with it (example: MD5, SHA).\nA password-hash function is designed to make deducting a user-input (password) impossible without computing the hash function with it (example: bcrypt). A\nkey derivation function\n(KDF; examples: yescrypt, scrypt, PBKDF2) is a cryptographic algorithm designed to derive secret keys (e.g. an AES key, a password hash) from an input (a master key, a password). Hence, a KDF can serve multiple applications, including those of a password-hash function.\nBy default, Arch stores the hashed user passwords in the root-only-readable\n/etc/shadow\nfile, separated from the other user parameters stored in the world-readable\n/etc/passwd\nfile, see\nUsers and groups#User database\n. See also\n#Restricting root\n.\nPasswords are set with the\npasswd\ncommand, which\nstretches\nthem with the system's crypt function and then saves them in\n/etc/shadow\n. The passwords are also\nsalted\nin order to defend them against\nrainbow table\nattacks. See also\nHow are passwords stored in Linux (Understanding hashing with shadow utils)\n.\nSince password hashes follow a defined format, the method and parameter can be configured for subsequent new invocations of the\npasswd\ncommand. Hence, the individual hashes stored in the\n/etc/shadow\nfile can be a heterogeneous mix of the hash functions supported by the system.\nSee\ncrypt(5)\nfor more information on the format, hashing methods and parameters.\nThe\n/etc/login.defs\nfile configures the\ndefault password hashing\nmethod\nENCRYPT_METHOD YESCRYPT\nand its parameter\nYESCRYPT_COST_FACTOR\n.\nFor example, an increment of the default\nYESCRYPT_COST_FACTOR\nparameter will lead to a logarithmic increase of the compute time required to deduce the hash from a password. This applies, likewise, to a third-party trying to obtain the password secret, and the system to authenticate a user log-in.\nIn contrast, the compute time for the SHA-512 hash function is configured by a parameter with a linear influence. See\nSHA password hashes\nfor information on the previous Arch default. Note the yescrypt algorithm internally uses SHA-256, HMAC and PBKDF2 to compute its password-hash. The main reason is to combine positive attributes of these widely used and tested functions for an enhanced resistance to attacks. For example, the usability of SHA for various purposes has resulted in hardware support for the function, i.e. the performance to compute a pure SHA hash has accelerated considerably, making its application as a password-hash function more and more derelict.\nEnforcing strong passwords with pam_pwquality\npam_pwquality\nprovides protection against\nDictionary attacks\nand helps configure a password policy that can be enforced throughout the system. It is based on\npam_cracklib\n, so it is backwards compatible with its options.\nInstall\nthe\nlibpwquality\npackage.\nWarning\nThe\nroot\naccount is not affected by this policy by default.\nNote\nYou can use the\nroot\naccount to set a password for a user that bypasses the desired/configured policy. This is useful when setting temporary passwords.\nCurrent security guidelines around passwords, e.g. from NIST, but also from others, do not recommend enforcing special characters, since they often only lead to predictable alterations.\nIf for example you want to enforce this policy:\nprompt 2 times for password in case of an error (retry option)\n10 characters minimum length (minlen option)\nat least 6 characters should be different from old password when entering a new one (difok option)\nat least 1 digit (dcredit option)\nat least 1 uppercase (ucredit option)\nat least 1 lowercase (lcredit option)\nat least 1 other character (ocredit option)\ncannot contain the words \"myservice\" and \"mydomain\"\nenforce the policy for root\nEdit the\n/etc/pam.d/passwd\nfile to read as:\n#%PAM-1.0\npassword required pam_pwquality.so retry=2 minlen=10 difok=6 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1 [badwords=myservice mydomain] enforce_for_root\npassword required pam_unix.so use_authtok sha512 shadow\nThe\npassword required pam_unix.so use_authtok\ninstructs the\npam_unix\nmodule to not prompt for a password but rather to use the one provided by\npam_pwquality\n.\nYou can refer to the\npam_pwquality(8)\nand\npam_unix(8)\nman pages for more information.\nCPU\nMicrocode\nSee\nmicrocode\nfor information on how to install important security updates for your CPU's microcode.\nHardware vulnerabilities\nSome CPUs contain hardware vulnerabilities. See the\nkernel documentation on hardware vulnerabilities\nfor a list of these vulnerabilities, as well as mitigation selection guides to help customize the kernel to mitigate these vulnerabilities for specific usage scenarios.\nTo check if you are affected by a known vulnerability, run the following:\n$ grep -r . /sys/devices/system/cpu/vulnerabilities/\nIn most cases, updating the kernel and microcode will mitigate vulnerabilities.\nSimultaneous multithreading (hyper-threading)\nSimultaneous multithreading\n(SMT), also called hyper-threading on Intel CPUs, is a hardware feature that may be a source of\nL1 Terminal Fault\nand\nMicroarchitectural Data Sampling\nvulnerabilities. The Linux kernel and microcode updates contain mitigations for known vulnerabilities, but\ndisabling SMT may still be required on certain CPUs if untrusted virtualization guests are present\n.\nNote\nDisabling SMT is something mostly hypervisors benefit from.\n[2]\nOn an ordinary system it has very little to no security benefits.\nSMT can often be disabled in your system's firmware. Consult your motherboard or system documentation for more information. You can also disable SMT in the kernel by adding the following\nkernel parameter\n:\nmitigations=auto,nosmt\nMemory\nHardened malloc\nhardened_malloc\nAUR\nis a hardened replacement for\nglibc\n's malloc(). The project was originally developed for integration into Android's\nBionic\nand\nmusl\nby Daniel Micay, of\nGrapheneOS\n, but he has also built in support for standard Linux distributions on the x86_64 architecture.\nWhile hardened_malloc is not yet integrated into glibc (assistance and pull requests welcome) it can be used easily with LD_PRELOAD. In testing so far, it only causes issues with a handful of applications if enabled globally in\n/etc/ld.so.preload\n. Since hardened_malloc has a performance cost, you may want to decide which implementation to use on a case-by-case basis based on attack surface and performance needs.\nThe factual accuracy of this article or section is disputed.\nReason:\nFirefox may require a rebuild for use with hardened-malloc to be effective (Discuss in\nTalk:Security#Use of hardened-malloc with Firefox\n)\nTo try it out in a standalone manner, use the hardened-malloc-preload wrapper script, or manually start an application with the proper preload value:\nLD_PRELOAD=\"/usr/lib/libhardened_malloc.so\" /usr/bin/firefox\nProper usage with\nFirejail\ncan be found on its wiki page, and some configurable build options for hardened_malloc can be found on the github repo.\nStorage\nData-at-rest encryption\nData-at-rest encryption\n, preferably full-disk encryption with a\nstrong passphrase\n, is the only way to guard data against physical recovery. This provides data confidentiality when the computer is turned off or the disks in question are unmounted.\nOnce the computer is powered on and the drive is mounted, however, its data becomes just as vulnerable as an unencrypted drive. It is therefore best practice to unmount data partitions as soon as they are no longer needed.\nYou may also\nencrypt a drive with the key stored in a TPM\n, although it has had\nvulnerabilites in the past\nand the key can be extracted by a\nbus sniffing attack\n.\nCertain programs, like\ndm-crypt\n, allow the user to encrypt a loop file as a virtual volume. This is a reasonable alternative to full-disk encryption when only certain parts of the system need to be secure.\nWhile the block-device or filesystem-based encryption types compared in the\ndata-at-rest encryption\narticle are useful at protecting data on physical media, most can not be used to protect data on a remote system that you can not control (such as\ncloud storage\n). In some cases, individual file encryption will be useful.\nThese are some methods to encrypt files:\nSome\narchiving and compressing\ntools also provide basic encryption. Some examples are\n7-Zip\n(\n-p\nflag),\nzip\n(\n-e\nflag). The encryption should only be relied on particular care, because the tools may use custom algorithms for cross-platform compatibility.\n[3]\nGnuPG\ncan be used to\nencrypt files\n.\nage\nis a simple and easy to use file encryption tool. It also supports multiple recipients and encryption using SSH keys, which is useful for secure file sharing.\nFile systems\nThe kernel now prevents security issues related to hardlinks and symlinks if the\nfs.protected_hardlinks\nand\nfs.protected_symlinks\nsysctl switches are enabled, so there is no longer a major security benefit from separating out world-writable directories.\nFile systems containing world-writable directories can still be kept separate as a coarse way of limiting the damage from disk space exhaustion. However, filling\n/var\nor\n/tmp\nis enough to take down services. More flexible mechanisms for dealing with this concern exist (like\nquotas\n), and some\nfile systems\ninclude related features themselves (Btrfs has quotas on subvolumes).\nMount options\nFollowing the principle of least privilege, file systems should be mounted with the most restrictive mount options possible (without losing functionality).\nRelevant mount options are:\nnodev\n: Do not interpret character or block special devices on the file system.\nnosuid\n: Do not allow set-user-identifier or set-group-identifier bits to take effect.\nnoexec\n: Do not allow direct execution of any binaries on the mounted file system.\nSetting\nnoexec\non\n/home\ndisallows executable scripts and breaks\nWine\n,\nSteam\n, PyCharm,\n.NET\n, etc.\nWine does not need the\nexec\nflag for opening Windows binaries. It is only needed when Wine itself is installed in\n/home\n.\nTo keep\nSteam\nworking you can mount\n/home/user/.local/share/Steam\nas\nexec\nin\nfstab\nby adding the following:\n/home/user/.local/share/Steam  /home/user/.local/share/Steam  none defaults,bind,user,exec,nofail  0  0\nSome packages (building\nnvidia-dkms\nfor example) may require\nexec\non\n/var\n.\nFile systems used for data should always be mounted with\nnodev\n,\nnosuid\nand\nnoexec\n.\nPotential file system mounts to consider:\n/var\n/home\n/dev/shm\n/tmp\n/boot\nTip\nWhen using\nGPT partition automounting\n, the ESP and XBOOTLDR partitions are\nalways hardened\nwith\nnoexec,nosuid,nodev\n.\nSnapshots\nWhen utilizing file system snapshots, e.g. with\nBtrfs\n,\nLVM\n, or\nZFS\n, it is essential to be aware that snapshots may retain sensitive information that users expect to be deleted. This is especially true when automatic snapshotting tools like\nSnapper\nare configured, as they can capture snapshots at regular intervals or in response to system events. Here are some examples of how sensitive information in\n/home/\ncan persist within snapshots:\nDeleted files and directories\n: Even though files or directories are deleted from the file system, they may still exist within older snapshots. This is expected most of the time, but consider whether files and directories such as\n.local/share/Trash/\n,\n.history\n, etc. should be retained.\nTemporary files and cache\n: Temporary files and cached data generated by applications may be included in snapshots. For example, files kept in encrypted directories might generate thumbnails (\n.cache/thumbnails\n) or work copies when opened, which might in turn be included in snapshots. The same applies e.g. to browsing history (\n.mozilla/\n,\n.config/chromium/\n, etc.), which could have been included in a snapshot before being purged.\nIf this is supported, consider excluding such directories from snapshots altogether. For example, if using\nBtrfs\n, you can create subvolumes for example\n.cache/\n,\n.config/\n,\n.local/\n,\n.var/\nor any other directory according to your use-case.\nNote\nMoving\n.local/share/Trash\nto a separate subvolume might break the trash feature in some cases, e.g. with\nGNOME/Files\n.\nFile access permissions\nThe factual accuracy of this article or section is disputed.\nReason:\nchmod go-r\ndoes not \"take away all permissions\", it only removes the read permission. (Discuss in\nTalk:Security\n)\nThe default\nfile permissions\nallow read access to almost everything and changing the permissions can hide valuable information from an attacker who gains access to a non-root account such as the\nhttp\nor\nnobody\nusers. You can use\nchmod\nto take away all permissions from the group and others:\n# chmod go-r\npath_to_hide\nWarning\nDo not apply this broadly. Try this for one config at a time, ensuring that it is worth hiding, and that it will not break program functionality. You may need to remove the\ng\nfrom the command (or re-add the permission with\nchmod g+r\npath\nif already ran) if the group is relied on.\nSome paths to consider are:\n/boot\n: The\nboot directory\n, which may include traditional\nvmlinuz\nand\ninitramfs\nimages, or a\nUnified kernel image\n. Note that safe permissions are used by default when using\nsystemd#GPT partition automounting\n.\n/etc/nftables.conf\n: The\nnftables\nconfiguration, applicable to\nnftables\nand\niptables-nft\n.\n/etc/iptables\n: The legacy\niptables\nconfiguration, applicable to\niptables\n.\nThe default\numask\n0022\ncan be changed to improve security for newly created files. The\nNSA RHEL5 Security Guide\nsuggests a umask of\n0077\nfor maximum security, which makes new files not readable by users other than the owner. To change this, see\nUmask#Set the mask value\n. If you use\nsudo\n, consider configuring it to use the\ndefault root umask\n.\nSUID and SGID files\nIt is important to be aware of any files with the\nSetuid\nor Setgid bit. Examples of relevant files with the SUID bit set:\nunix_chkpwd\nchage, expiry, gpasswd, groupmems,\npasswd\n, sg (\nshadow\n)\nfusermount3\n, fusermount2\npkexec, polkit-agent-helper-1\n[4]\n(\npolkit\n)\nssh-keysign\nchfn, chsh, mount, newgrp, umount, wall, write (\nutil-linux\n)\nsudo\n,\nsudo-rs\n,\ndoas\n,\nsu\n, su-rs,\nksu\nfirejail\ndbus-daemon-launch-helper\nchromium-sandbox\nXorg.wrap\nThe prominent risks of such executable files include privilege escalation vulnerabilities, see e.g\nWikipedia:Setuid#Security impact\n.\n[5]\n[6]\n[7]\nFiles with the SUID bit set and not owned by root, or files with the SGID bit set\ntypically\nhave less potential impact but can theoretically still do decent damage if vulnerable. It is usually possible to avoid using SUID or SGID by assigning\nCapabilities\ninstead.\nTip\nIt is vital to be vigilant in keeping packages which provide SUID/SGID executables up to date in order to prevent having a vulnerable system.\nTo search for files with either the SUID or SGID bit:\n$ find / -perm \"/u=s,g=s\" -type f 2>/dev/null\nBackups\nThis article or section is a candidate for merging with\nSystem backup\n.\nNotes:\nThere is a dedicated page for system backups. (Discuss in\nTalk:Security\n)\nRegularly create backups of important data. Regularly test the integrity of the backups. Regularly test that the backups can be restored.\nMake sure that at least one copy of the data is stored offline, i.e. not connected to the system under threat in any way.\nRansomware\nand other destructive attacks may also attack any connected backup systems.\nSATA SSD frozen mode\nSee\nSolid state drive#Setting the SATA SSD state to frozen mode after waking up from sleep\n.\nUser setup\nDo not use the root account for daily use\nFollowing the principle of least privilege, do not use the root user for daily use. Create a non-privileged user account for each person using the system. See\nList of applications/Security#Privilege elevation\nfor ways of temporarily gaining privileged access.\nEnforce a delay after a failed login attempt\nAdd the following line to\n/etc/pam.d/system-login\nto add a delay of at least 4 seconds between failed login attempts:\n/etc/pam.d/system-login\nauth optional pam_faildelay.so delay=4000000\n4000000\nis the time in microseconds to delay.\nNote\nOther PAM modules besides\npam_faildelay\ncan also suggest such a delay; if multiple modules do so, PAM will use the longest one.\nIn particular, both\npam_unix\nand\npam_faillock\nset a minimum delay of 2 seconds by default.\nIn order to completely remove this delay, you need to add the\nnodelay\nparameter to any\nauth\nlines of these modules, e.g.\n/etc/pam.d/system-auth\nauth       [success=1 default=bad]     pam_unix.so          try_first_pass nullok nodelay\nLock out user after three failed login attempts\nSince\npambase\n20200721.1-2,\npam_faillock.so\nis enabled by default to lock out users for 10 minutes after 3 failed login attempts in a 15 minute period (see\nFS#67644\n). The lockout only applies to password authentication (e.g. login and\nsudo\n), public key authentication over SSH is still accepted. To prevent complete denial-of-service, this lockout is disabled for the root user by default.\nTo unlock a user, do:\n$ faillock --user\nusername\n--reset\nBy default, the lock mechanism is a file per-user located at\n/run/faillock/\n. Deleting or emptying the file unlocks that user—the directory is owned by root, but the file is owned by the user, so the\nfaillock\ncommand only empties the file, therefore does not require root.\nThe module\npam_faillock.so\ncan be configured with the file\n/etc/security/faillock.conf\n. The lockout parameters:\nunlock_time\n— the lockout time (in seconds, default 10 minutes).\nfail_interval\n— the time in which failed logins can cause a lockout (in seconds, default 15 minutes).\ndeny\n— the number of failed logins before lockout (default 3).\nTip\nThe primary purpose for the lockout is to slow down brute-force attacks so that they become infeasible. Hence, if lockouts due to mistyping of passwords become too frequent, relaxing the number of attempts may be preferred to reducing the lockout time.\nNote\ndeny = 0\nwill disable the lockout mechanism entirely.\nBy default, all user locks are lost after reboot. If your attacker can reboot the machine, it is more secure if locks persist. To make locks persist, change the\ndir\nparameter in\n/etc/security/faillock.conf\nto\n/var/lib/faillock\n.\nNo restart is required for changes to take effect. See\nfaillock.conf(5)\nfor further configuration options, such as enabling lockout for the root account, disabling for centralized login (e.g. LDAP), etc.\nLimit amount of processes\nOn systems with many, or untrusted users, it is important to limit the number of processes each can run at once, therefore preventing\nfork bombs\nand other denial of service attacks. The\n/etc/security/limits.conf\nconfiguration determines how many processes each user, or group can have open, and is empty (except for useful comments) by default. Adding the following lines to this file will limit all users to 100 active processes, unless they use the\nprlimit\ncommand to explicitly raise their maximum to 200 for that session. These values can be changed according to the appropriate number of processes a user should have running, or the hardware of the box you are administrating.\n* soft nproc 100\n* hard nproc 200\nThe current number of threads for each user can be found with\nps --no-headers -Leo user | sort | uniq --count\n. This may help with determining appropriate values for the users' limits; see also\nlimits.conf\n.\nUse Wayland\nPrefer using\nWayland\nover\nXorg\n. Xorg's design predates modern security practices and is\nconsidered insecure\nby many. For example, Xorg applications may record keystrokes while inactive.\nIf you must run Xorg, it is recommended to\navoid running it as root\n. Within Wayland, the Xwayland compatibility layer will automatically use rootless Xorg.\nRestricting root\nThe root user is, by definition, the most powerful user on a system. It is also difficult to\naudit\nthe root user account. It is therefore important to restrict usage of the root user account as much as possible. There are a number of ways to keep the power of the root user while limiting its ability to cause harm.\nUse sudo instead of su\nThis article or section is a candidate for merging with\nsudo\n.\nNotes:\nThere is a dedicated article. (Discuss in\nTalk:Security\n)\nUsing\nsudo\nfor privileged access is preferable to\nsu\nfor a number of reasons.\nIt keeps a log of which normal privilege user has run each privileged command.\nThe root user password need not be given out to each user who requires root access.\nsudo\nprevents users from accidentally running commands as\nroot\nthat do not need root access, because a full root terminal is not created. This aligns with the\nprinciple of least privilege\n.\nIndividual programs may be enabled per user, instead of offering complete root access just to run one command. For example, to give the user\narchie\naccess to a particular program:\n# visudo\n/etc/sudoers\narchie ALL = NOPASSWD: /path/to/program\nOr, individual commands can be allowed for all users. To mount Samba shares from a server as a regular user:\n%users ALL=/sbin/mount.cifs,/sbin/umount.cifs\nThis allows all users who are members of the group users to run the commands\n/sbin/mount.cifs\nand\n/sbin/umount.cifs\nfrom any machine (ALL).\nTip\nTo use restricted version of\nnano\ninstead of\nvi\nwith\nvisudo\n,\n/etc/sudoers\nDefaults editor=/usr/bin/rnano\nExporting\nEDITOR=nano visudo\nis regarded as a severe security risk since everything can be used as an\nEDITOR\n.\nEditing files using sudo\nSee\nSudo#Editing files\n. Alternatively, you can use an editor like\nrvim\nor\nrnano\nwhich has restricted capabilities in order to be safe to run as root.\nRestricting root login\nOnce\nsudo\nis properly configured, full root access can be heavily restricted or denied without losing much usability. To disable root, but still allowing to use\nsudo\n, you can use\npasswd(1)\nwith\npasswd --lock root\n.\nAllow only certain users\nThe\nPAM\npam_wheel.so\nlets you allow only users in the group\nwheel\nto login using\nsu\n. See\nsu#su and wheel\n.\nDenying SSH login\nEven if you do not wish to deny root login for local users, it is always good practice to\ndeny root login via SSH\n. The purpose of this is to add an additional layer of security before a user can completely compromise your system remotely.\nSpecify acceptable login combinations with access.conf\nWarning\nIf you are using GNOME 49 or later, you should make sure the group\ngdm\ncan log in locally. This can be done with a\n+:(gdm):LOCAL\nrule.\n[8]\nWhen someone attempts to log in with\nPAM\n,\n/etc/security/access.conf\nis checked for the first combination that matches their login properties. Their attempt then fails or succeeds based on the rule for that combination.\n+:root:LOCAL\n-:root:ALL\nRules can be set for specific groups and users. In this example, the user archie is allowed to login locally, as are all users in the wheel and adm groups. All other logins are rejected:\n+:archie:LOCAL\n+:(wheel):LOCAL\n+:(adm):LOCAL\n-:ALL:ALL\nRead more at\naccess.conf(5)\nMandatory access control\nMandatory access control\n(MAC) is a type of security policy that differs significantly from the\ndiscretionary access control\n(DAC) used by default in Arch and most Linux distributions. MAC essentially means that every action a program could perform that affects the system in any way is checked against a security ruleset. This ruleset, in contrast to DAC methods, cannot be modified by users. Using virtually any mandatory access control system will significantly improve the security of your computer, although there are differences in how it can be implemented.\nPathname MAC\nPathname-based access control is a simple form of access control that offers permissions based on the path of a given file. The downside to this style of access control is that permissions are not carried with files if they are moved around the system. On the positive side, pathname-based MAC can be implemented on a much wider range of filesystems, unlike labels-based alternatives.\nAppArmor\nis a\nCanonical\n-maintained MAC implementation seen as an \"easier\" alternative to SELinux.\nTOMOYO\nis another simple, easy-to-use system offering mandatory access control. It is designed to be both simple in usage and in implementation, requiring very few dependencies.\nLabels MAC\nLabels-based access control means the extended attributes of a file are used to govern its security permissions. While this system is arguably more flexible in its security offerings than pathname-based MAC, it only works on filesystems that support these extended attributes.\nSELinux\n, based on an\nNSA\nproject to improve Linux security, implements MAC completely separate from system users and roles. It offers an extremely robust multi-level MAC policy implementation that can easily maintain control of a system that grows and changes past its original configuration.\nAccess Control Lists\nAccess Control Lists\n(ACLs) are an alternative to attaching rules directly to the filesystem in some way. ACLs implement access control by checking program actions against a list of permitted behavior.\nKernel hardening\nKernel self-protection / exploit mitigation\nThe\nlinux-hardened\npackage uses a\nbasic kernel hardening patch set\nand more security-focused compile-time configuration options than the\nlinux\npackage. A custom build can be made to choose a different compromise between security and performance than the security-leaning defaults.\nHowever, it should be noted that several packages will not work when using this kernel. For example\nthrottled\n.\nIf you use an out-of-tree driver such as\nNVIDIA\n, you may need to switch to its\nDKMS\npackage.\nUserspace ASLR comparison\nThe\nlinux-hardened\npackage provides an improved implementation of Address Space Layout Randomization for userspace processes. The\npaxtest\ncommand can be used to obtain an estimate of the provided entropy:\n64-bit processes\nlinux-hardened 5.4.21.a-1-hardened\nAnonymous mapping randomization test     : 32 quality bits (guessed)\nHeap randomization test (ET_EXEC)        : 40 quality bits (guessed)\nHeap randomization test (PIE)            : 40 quality bits (guessed)\nMain executable randomization (ET_EXEC)  : 32 quality bits (guessed)\nMain executable randomization (PIE)      : 32 quality bits (guessed)\nShared library randomization test        : 32 quality bits (guessed)\nVDSO randomization test                  : 32 quality bits (guessed)\nStack randomization test (SEGMEXEC)      : 40 quality bits (guessed)\nStack randomization test (PAGEEXEC)      : 40 quality bits (guessed)\nArg/env randomization test (SEGMEXEC)    : 44 quality bits (guessed)\nArg/env randomization test (PAGEEXEC)    : 44 quality bits (guessed)\nOffset to library randomisation (ET_EXEC): 34 quality bits (guessed)\nOffset to library randomisation (ET_DYN) : 34 quality bits (guessed)\nRandomization under memory exhaustion @~0: 32 bits (guessed)\nRandomization under memory exhaustion @0 : 32 bits (guessed)\nlinux 5.5.5-arch1-1\nAnonymous mapping randomization test     : 28 quality bits (guessed)\nHeap randomization test (ET_EXEC)        : 28 quality bits (guessed)\nHeap randomization test (PIE)            : 28 quality bits (guessed)\nMain executable randomization (ET_EXEC)  : 28 quality bits (guessed)\nMain executable randomization (PIE)      : 28 quality bits (guessed)\nShared library randomization test        : 28 quality bits (guessed)\nVDSO randomization test                  : 20 quality bits (guessed)\nStack randomization test (SEGMEXEC)      : 30 quality bits (guessed)\nStack randomization test (PAGEEXEC)      : 30 quality bits (guessed)\nArg/env randomization test (SEGMEXEC)    : 22 quality bits (guessed)\nArg/env randomization test (PAGEEXEC)    : 22 quality bits (guessed)\nOffset to library randomisation (ET_EXEC): 28 quality bits (guessed)\nOffset to library randomisation (ET_DYN) : 28 quality bits (guessed)\nRandomization under memory exhaustion @~0: 29 bits (guessed)\nRandomization under memory exhaustion @0 : 29 bits (guessed)\nlinux-lts 4.19.101-1-lts\nAnonymous mapping randomization test     : 28 quality bits (guessed)\nHeap randomization test (ET_EXEC)        : 28 quality bits (guessed)\nHeap randomization test (PIE)            : 28 quality bits (guessed)\nMain executable randomization (ET_EXEC)  : 28 quality bits (guessed)\nMain executable randomization (PIE)      : 28 quality bits (guessed)\nShared library randomization test        : 28 quality bits (guessed)\nVDSO randomization test                  : 19 quality bits (guessed)\nStack randomization test (SEGMEXEC)      : 30 quality bits (guessed)\nStack randomization test (PAGEEXEC)      : 30 quality bits (guessed)\nArg/env randomization test (SEGMEXEC)    : 22 quality bits (guessed)\nArg/env randomization test (PAGEEXEC)    : 22 quality bits (guessed)\nOffset to library randomisation (ET_EXEC): 28 quality bits (guessed)\nOffset to library randomisation (ET_DYN) : 28 quality bits (guessed)\nRandomization under memory exhaustion @~0: 28 bits (guessed)\nRandomization under memory exhaustion @0 : 28 bits (guessed)\n32-bit processes (on an x86_64 kernel)\nlinux-hardened\nAnonymous mapping randomization test     : 16 quality bits (guessed)\nHeap randomization test (ET_EXEC)        : 22 quality bits (guessed)\nHeap randomization test (PIE)            : 27 quality bits (guessed)\nMain executable randomization (ET_EXEC)  : No randomization\nMain executable randomization (PIE)      : 18 quality bits (guessed)\nShared library randomization test        : 16 quality bits (guessed)\nVDSO randomization test                  : 16 quality bits (guessed)\nStack randomization test (SEGMEXEC)      : 24 quality bits (guessed)\nStack randomization test (PAGEEXEC)      : 24 quality bits (guessed)\nArg/env randomization test (SEGMEXEC)    : 28 quality bits (guessed)\nArg/env randomization test (PAGEEXEC)    : 28 quality bits (guessed)\nOffset to library randomisation (ET_EXEC): 18 quality bits (guessed)\nOffset to library randomisation (ET_DYN) : 16 quality bits (guessed)\nRandomization under memory exhaustion @~0: 18 bits (guessed)\nRandomization under memory exhaustion @0 : 18 bits (guessed)\nlinux\nAnonymous mapping randomization test     : 8 quality bits (guessed)\nHeap randomization test (ET_EXEC)        : 13 quality bits (guessed)\nHeap randomization test (PIE)            : 13 quality bits (guessed)\nMain executable randomization (ET_EXEC)  : No randomization\nMain executable randomization (PIE)      : 8 quality bits (guessed)\nShared library randomization test        : 8 quality bits (guessed)\nVDSO randomization test                  : 8 quality bits (guessed)\nStack randomization test (SEGMEXEC)      : 19 quality bits (guessed)\nStack randomization test (PAGEEXEC)      : 19 quality bits (guessed)\nArg/env randomization test (SEGMEXEC)    : 11 quality bits (guessed)\nArg/env randomization test (PAGEEXEC)    : 11 quality bits (guessed)\nOffset to library randomisation (ET_EXEC): 8 quality bits (guessed)\nOffset to library randomisation (ET_DYN) : 13 quality bits (guessed)\nRandomization under memory exhaustion @~0: No randomization\nRandomization under memory exhaustion @0 : No randomization\nRestricting access to kernel pointers in the proc filesystem\nSetting\nkernel.kptr_restrict\nto 1 will hide kernel symbol addresses in\n/proc/kallsyms\nfrom regular users without\nCAP_SYSLOG\n, making it more difficult for kernel exploits to resolve addresses/symbols dynamically. This will not help that much on a pre-compiled Arch Linux kernel, since a determined attacker could just download the kernel package and get the symbols manually from there, but if you are compiling your own kernel, this can help mitigating local root exploits. This will break some\nperf\ncommands when used by non-root users (but many\nperf\nfeatures require root access anyway). See\nFS#34323\nfor more information.\nSetting\nkernel.kptr_restrict\nto 2 will hide kernel symbol addresses in\n/proc/kallsyms\nregardless of privileges.\n/etc/sysctl.d/51-kptr-restrict.conf\nkernel.kptr_restrict = 1\nNote\nlinux-hardened\nsets\nkptr_restrict=2\nby default rather than\n0\n.\nBPF hardening\nBPF is a system used to load and execute bytecode within the kernel dynamically during runtime. It is used in a number of Linux kernel subsystems such as networking (e.g. XDP, tc), tracing (e.g. kprobes, uprobes, tracepoints) and security (e.g. seccomp). It is also useful for advanced network security, performance profiling and dynamic tracing.\nBPF was originally an acronym of\nBerkeley Packet Filter\nsince the original classic BPF was used for packet capture tools for BSD. This eventually evolved into Extended BPF (eBPF), which was shortly afterwards renamed to just BPF (not an acronym). BPF should not be confused with packet filtering tools like iptables or netfilter, although BPF can be used to implement packet filtering tools.\nBPF code may be either interpreted or compiled using a\nJust-In-Time (JIT) compiler\n. The Arch kernel is built with\nCONFIG_BPF_JIT_ALWAYS_ON\nwhich disables the BPF interpreter and forces all BPF to use JIT compilation. This makes it harder for an attacker to use BPF to escalate attacks that exploit SPECTRE-style vulnerabilities. See\nthe kernel patch which introduced CONFIG_BPF_JIT_ALWAYS_ON\nfor more details.\nThe kernel includes a hardening feature for JIT-compiled BPF which can mitigate some types of JIT spraying attacks at the cost of performance and the ability to trace and debug many BPF programs. It may be enabled by setting\nnet.core.bpf_jit_harden\nto\n1\n(to enable hardening of unprivileged code) or\n2\n(to enable hardening of all code).\nSee the\nnet.core.bpf_*\nsettings in the\nkernel documentation\nfor more details.\nTip\nlinux-hardened\nsets\nnet.core.bpf_jit_harden=2\nby default rather than\n0\n.\nBy default, BPF programs can be run even by unprivileged users. To change that behaviour set\nkernel.unprivileged_bpf_disabled=1\n[9]\n.\nptrace scope\nThe\nptrace(2)\nsyscall provides a means by which one process (the \"tracer\") may observe and control the execution of another process (the \"tracee\"), and examine and change the tracee's memory and registers.\nptrace\nis commonly used by debugging tools including\ngdb\n,\nstrace\n,\nperf\n,\nreptyr\nand other debuggers. However, it also provides a means by which a malicious process can read data from and take control of other processes.\nArch enables the\nYama LSM\nby default, which provides a\nkernel.yama.ptrace_scope\nkernel parameter\n. This parameter is set to\n1\n(restricted) by default which prevents tracers from performing a\nptrace\ncall on traces outside of a restricted scope unless the tracer is privileged or has the\nCAP_SYS_PTRACE\ncapability\n. This is a significant improvement in security compared to the classic permissions. Without this module, there is no separation between processes running as the same user (in the absence of additional security layers such as\npid_namespaces(7)\n).\nNote\nBy default, you can still use tools which require\nptrace\nby running them as privileged processes, e.g. using\nsudo\n.\nIf you do not need to use debugging tools, consider setting\nkernel.yama.ptrace_scope\nto\n2\n(admin-only) or\n3\n(no\nptrace\npossible) to harden the system.\nhidepid\nThis article or section needs expansion.\nReason:\nLinux 5.8 implemented private instances\nand new values for\nhidepid=\n. (Discuss in\nTalk:Security\n)\nThe factual accuracy of this article or section is disputed.\nReason:\nEnabling\nhidepid\nglobally is not a supported way of operation by\nsystemd\n, nor does it have any practical improvements security-wise when systemd is running as service manager.\n[10]\n(Discuss in\nTalk:Security\n)\nWarning\nThis may cause issues for certain applications like an application running in a sandbox and\nXorg\n(see workaround).\nThis causes issues with\nD-Bus\n,\nPolkit\n,\nPulseAudio\nand\nbluetooth\nwhen using\nsystemd\n> 237.64-1.\nThe kernel has the ability to hide other users' processes, normally accessible via\n/proc\n, from unprivileged users by mounting the\nproc\nfilesystem with the\nhidepid=\nand\ngid=\noptions documented in\nhttps://docs.kernel.org/filesystems/proc.html\n.\nThis greatly complicates an intruder's task of gathering information about running processes, whether some daemon runs with elevated privileges, whether other user runs some sensitive program, whether other users run any program at all, makes it impossible to learn whether any user runs a specific program (given the program does not reveal itself by its behaviour), and, as an additional bonus, poorly written programs passing sensitive information via program arguments are now protected against local eavesdroppers.\nThe\nproc\ngroup\n, provided by the\nfilesystem\npackage, acts as a whitelist of users authorized to learn other users' process information. If users or services need access to\n/proc/<pid>\ndirectories beyond their own,\nadd them to the group\n.\nFor example, to hide process information from other users except those in the\nproc\ngroup:\n/etc/fstab\nproc\t/proc\tproc\tnosuid,nodev,noexec,hidepid=2,gid=proc\t0\t0\nFor user sessions to work correctly, an exception needs to be added for\nsystemd-logind\n:\n/etc/systemd/system/systemd-logind.service.d/hidepid.conf\n[Service]\nSupplementaryGroups=proc\nRestricting module loading\nThe default Arch kernel has\nCONFIG_MODULE_SIG_ALL\nenabled, which signs all kernel modules built as part of the\nlinux\npackage. This allows the kernel to only load modules signed with a valid key, i.e. out-of-tree modules compiled locally or provided by packages such as\nvirtualbox-host-modules-arch\ncannot be loaded.\nKernel module loading can be restricted by setting the\nmodule.sig_enforce=1\nkernel parameter\n. More information can be found in the\nkernel documentation\n.\nFurther, unneeded individual modules can be\nblacklisted\n, see\nsecureblue\n[\ndead link\n2025-11-17—HTTP 404]\nfor examples.\nDisable kexec\nKexec allows replacing the current running kernel.\n/etc/sysctl.d/51-kexec-restrict.conf\nkernel.kexec_load_disabled = 1\nTip\nkexec is disabled by default in\nlinux-hardened\n.\nKernel lockdown mode\nSince Linux 5.4 the kernel\nhas gained\nan optional\nlockdown feature\n, intended to strengthen the boundary between UID 0 (root) and the kernel. When enabled some applications may cease to work which rely on low-level access to either hardware or the kernel.\nTo use lockdown, its LSM must be initialized and a lockdown mode must be set.\nAll\nofficially supported kernels\ninitialize the LSM, but none of them enforce any lockdown mode.\nTip\nInitialized LSMs can be verified by running\ncat /sys/kernel/security/lsm\n.\nLockdown has two modes of operation:\nintegrity\n: kernel features that allow userland to modify the running kernel are disabled (e.g. kexec, bpf).\nconfidentiality\n: kernel features that allow userland to extract confidential information from the kernel are also disabled.\nIt is recommended to use\nintegrity\n, unless your specific threat model dictates otherwise.\nTo enable kernel lockdown at runtime, run:\n# echo\nmode\n> /sys/kernel/security/lockdown\nTo enable kernel lockdown on boot, use the\nkernel parameter\nlockdown=\nmode\n.\nNote\nKernel lockdown cannot be disabled at runtime.\nKernel lockdown disables\nhibernation\n.\nThe\nkernel_lockdown(7)\nman page incorrectly states that \"lockdown will be automatically enabled if the system boots in EFI Secure Boot mode\". This is not the behaviour of the upstream kernel, nor Arch's packaged\nkernels\n.\nSee also\nkernel_lockdown(7)\n.\nLinux Kernel Runtime Guard (LKRG)\nLKRG\n(\nlkrg-dkms\nAUR\n) is a kernel module which performs integrity checking of the kernel and detection of exploit attempts.\nDisable emergency shell\nThe factual accuracy of this article or section is disputed.\nReason:\nMasking\nemergency.target\nand\nemergency.service\nwill have no effect on those units being added to the initramfs and run in early userspace. Even with them in the initramfs, mkinitcpio's systemd hook locks the root account\n[11]\n[12]\nfor \"security reasons\" (see\nFS#70408\n). The solution for the issue in the linked article, if even needed, would be to prevent\nrescue.target\n,\nrescue.service\n,\nemergency.target\nand\nemergency.service\nfrom being added to the initramfs image. (Discuss in\nTalk:Security\n)\nThe emergency shell is used to interactively troubleshoot the machine during the boot process. However, it is also a gadget that an attacker can use to access secure resources such as the TPM. See\nthis article\nfor a practical example. The difficulty of attacks can be increased by disabling the emergency shell, at the tradeoff of removing a tool to troubleshoot early boot failures.\nTo disable the emergency shell, See\nsystemd#Disable emergency mode on remote machine\n.\nSandboxing applications\nSee also\nWikipedia:Sandbox (computer security)\n.\nTo improve the security of systemd service units, see\nsystemd/Sandboxing\n.\nNote\nThe user namespace configuration item\nCONFIG_USER_NS\nis currently enabled in\nlinux\n,\nlinux-lts\n,\nlinux-zen\nand\nlinux-hardened\n. Lack of it may prevent certain sandboxing features from being made available to applications.\nWarning\nUnprivileged user namespace usage (\nCONFIG_USER_NS_UNPRIVILEGED\n) is enabled by default in\nlinux\n,\nlinux-lts\nand\nlinux-zen\n, which greatly increases the attack surface for local privilege escalation (see\nAppArmor's Wiki\nand\nFS#36969\n).\nTo mitigate this, either:\nuse the\nlinux-hardened\nkernel which has the safe default, or\nset the\nkernel.unprivileged_userns_clone\nsysctl\nto\n0\n.\nNote that this can break applications such as\nnsjail\n.\nChromium\nbased applications need SUID bit for\nchrome-sandbox\nto work with this setting.\nFirejail\nFirejail\nis an easy to use tool for sandboxing applications and servers alike. It was originally created for browsers and internet facing applications, but supports a large number of applications by now. To establish a sandboxed environment with a variety of features, it is installed as a suid binary and builds a sandboxed runtime environment for the target application based on black and white lists.\nbubblewrap\nbubblewrap\nis a sandbox application developed for unprivileged container tools like\nFlatpak\nwith a significantly smaller resource footprint and complexity than Firejail. While it lacks certain features such as file path whitelisting, bubblewrap does offer bind mounts as well as the creation of user/IPC/PID/network/cgroup namespaces and can support both simple and complex sandboxes. For the\nlinux-hardened\nkernel you will need to to use\nbubblewrap-suid\n.\nBubblejail\nsandbox is based on\nbubblewrap\nand provides a resource oriented permission model with a graphical interface to tweak permissions.\nPortable\nPortable\nis a sandboxing framework which utilizes\nbubblewrap\nand many other tools to lockdown running applications. It is designed to be simple for packagers and efficient for users, yet cuts off security holes and monitors background processes by default.\nSee\nportable-arch\nfor a repository of applications sandboxed by portable.\nIf a sandboxed application does not utilize the Portal file chooser, portable can pass files to the sandbox (by passing\n--actions share-files\n).\nPortable is fully functional on GNOME, while other desktops may lack small amounts of features like advanced background monitoring and ScreenShot portal.\nchroots\nManual\nchroot\njails can also be constructed to build sandboxed process environments. It is much more limited than other sandboxing technologies; the extent of its sandboxing is file path isolation.\nLinux containers\nLinux Containers\nare another good option when you need more separation than the other options (short of\nfull system virtualization\n) provide. LXC is run on top of the existing kernel in a pseudo-chroot with their own virtual hardware.\nFull virtualization options\nUsing full virtualization options such as\nVirtualBox\n,\nKVM\n,\nXen\nor\nQubes OS\n(based on Xen) can also improve isolation and security in the event you plan on running risky applications or browsing dangerous websites.\nNetwork and firewalls\nFirewalls\nWhile the stock Arch kernel is capable of using\nNetfilter\n's\niptables\nand\nnftables\n, the services are not\nenabled\nby default. It is highly recommended to set up some form of firewall to protect the services running on the system. Many resources (including ArchWiki) do not state explicitly which services are worth protecting, so enabling a firewall is a good precaution.\nSee\niptables\nand\nnftables\nfor general information.\nSee\nSimple stateful firewall\nfor a guide on setting up an iptables firewall.\nSee\nCategory:Firewalls\nfor other ways of setting up netfilter.\nSee\nIpset\nfor blocking lists of ip addresses, such as those from Bluetack.\nopensnitch\nis a configurable inbound and outbound firewall with support for configurable rules by application, port, host, etc.\nOpen ports\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\n\"Open ports\" is not a good title since it disregards interfaces and addresses that the application may be bound to. From the firewalls' point of view, ports may be \"open\" even if no application listens on them at the moment. (Discuss in\nTalk:Security\n)\nSome services listen for inbound traffic on open network ports. It is important to only bind these services to the addresses and interfaces that are strictly necessary. It may be possible for a remote attacker to\nexploit flawed network protocols to access exposed services\n. This can even happen with\nprocesses bound to localhost\n.\nIn general, if a service only needs to be accessible to the local system, bind to a Unix domain socket (\nunix(7)\n) or a loopback address such as\nlocalhost\ninstead of a non-loopback address like\n0.0.0.0/0\n.\nIf a service needs to be accessible to other systems via the network, control the access with strict\nfirewall\nrules and configure authentication, authorization and encryption whenever possible.\nYou can list all current open ports with\nss -l\n. To show all\nl\nistening\np\nrocesses and their\nn\numeric\nt\ncp and\nu\ndp port numbers:\n# ss -lpntu\nSee\nss(8)\nfor more options.\nKernel parameters\nKernel parameters which affect networking can be set using\nSysctl\n. For how to do this, see\nSysctl#TCP/IP stack hardening\n.\nSSH\nTo mitigate\nbrute-force attacks\nit is recommended to enforce key-based authentication. For OpenSSH see\nOpenSSH#Protection\nfor more recommendations. Alternatively\nFail2ban\nor\nSshguard\noffer lesser forms of protection by monitoring logs and writing\nfirewall\nrules but open up the potential for a denial of service, since an attacker can\nspoof\npackets as if they came from the administrator after identifying their address. Spoofing IP has lines of defense, such as by\nreverse path filtering\nand\ndisabling ICMP redirects\n.\nYou may want to harden authentication even more by using two-factor authentication.\nGoogle Authenticator\nprovides a two-step authentication procedure using one-time passcodes (OTP).\nDenying root login is also a good practice, both for tracing intrusions and adding an additional layer of security before root access. For OpenSSH, see\nOpenSSH#Deny\n.\nMozilla publishes an\nOpenSSH configuration guide\nwhich configures more verbose audit logging and restricts ciphers.\nDNS\nThe default domain name resolution (DNS) configuration is highly compatible but has security weaknesses. See\nDNS privacy and security\nfor more information.\nProxies\nProxies are commonly used as an extra layer between applications and the network, sanitizing data from untrusted sources. The attack surface of a small proxy running with lower privileges is significantly smaller than a complex application running with the end user privileges.\nFor example the DNS resolver is implemented in\nglibc\n, that is linked with the application (that may be running as root), so a bug in the DNS resolver might lead to a remote code execution. This can be prevented by installing a DNS caching server, such as\ndnsmasq\n, which acts as a proxy.\n[13]\nManaging TLS certificates\nSee\nTLS#Trust management\n.\nPhysical security\nPhysical access to a computer is root access given enough time and resources. However, a high\npractical\nlevel of security can be obtained by putting up enough barriers.\nAn attacker can gain full control of your computer on the next boot by simply attaching a malicious IEEE 1394 (FireWire), Thunderbolt or PCI Express device as they are given full memory access by default.\n[14]\nFor Thunderbolt, you can restrict the direct memory access completely or to known devices, see\nThunderbolt#User device authorization\n. For Firewire and PCI Express, there is little you can do from preventing this, or modification of the hardware itself - such as flashing malicious firmware onto a drive. However, the vast majority of attackers will not be this knowledgeable and determined.\n#Data-at-rest encryption\nwill prevent access to your data if the computer is stolen, but malicious firmware can be installed to obtain this data upon your next log in by a resourceful attacker.\nLocking down BIOS\nAdding a password to the BIOS prevents someone from booting into removable media, which is basically the same as having root access to your computer. You should make sure your drive is first in the boot order and disable the other drives from being bootable if you can.\nBoot loaders\nIt is highly important to protect your\nboot loader\n. An unprotected boot loader can bypass any login restrictions, e.g. by setting the\ninit=/bin/sh\nkernel parameter\nto boot directly to a shell.\nSyslinux\nSyslinux\nsupports\npassword-protecting your boot loader\n. It allows you to set either a per-menu-item password or a global boot loader password.\nGRUB\nGRUB\nsupports boot loader passwords as well. See\nGRUB/Tips and tricks#Password protection of GRUB menu\nfor details. It also has support for\nencrypted /boot\n, which only leaves some parts of the boot loader code unencrypted. GRUB's configuration,\nkernel\nand\ninitramfs\nare encrypted.\nsystemd-boot\nsystemd-boot\ndisables editing of kernel parameters when\n#Secure Boot\nis enabled. Alternatively, see\nsystemd-boot#Kernel parameters editor with password protection\nfor a more traditional password-based option.\nSecure Boot\nSecure Boot\nis a feature of\nUEFI\nthat allows authentication of the files your computer boots. This helps preventing some\nevil maid attacks\nsuch as replacing files inside the boot partition. Normally computers come with keys that are enrolled by vendors (OEM). However these can be removed and allow the computer to enter\nSetup Mode\nwhich allows the user to enroll and manage their own keys.\nThe secure boot page guides you through how to set secure boot up by\nusing your own keys\n.\nTrusted Platform Module (TPM)\nTPMs\nare hardware microprocessors which have cryptographic keys embedded. This forms the fundamental root of trust of most modern computers and allows end-to-end verification of the boot chain. They can be used as internal smartcards, attest the firmware running on the computer and allow users to insert secrets into a tamper-proof and brute-force resistant store.\nBoot partition on removable flash drive\nOne popular idea is to place the boot partition on a flash drive in order to render the system unbootable without it. Proponents of this idea often use\nfull-disk encryption\nalongside, and some also use\ndetached encryption headers\nplaced on the boot partition.\nThis method can also be merged with\nencrypting /boot\n.\nAutomatic logout\nIf you are using\nBash\nor\nZsh\n, you can set\nTMOUT\nfor an automatic logout from shells after a timeout.\nFor example, the following will automatically log out from virtual consoles (but not terminal emulators in X11):\n/etc/profile.d/shell-timeout.sh\nTMOUT=\"$(( 60*10 ))\";\n[ -z \"$DISPLAY\" ] && export TMOUT;\ncase $( /usr/bin/tty ) in\n/dev/tty[0-9]*) export TMOUT;;\nesac\nIf you really want EVERY Bash/Zsh prompt (even within X) to timeout, use:\n$ export TMOUT=\"$(( 60*10 ))\";\nNote that this will not work if there is some command running in the shell (eg.: an SSH session or other shell without\nTMOUT\nsupport). But if you are using VC mostly for restarting frozen GDM/Xorg as root, then this is very useful.\nProtect against rogue USB devices\nThe kernel has\nsettings to deactivate\nUSB ports to protect your computer against rogue USB devices (a.k.a.\nBadUSB\n,\nPoisonTap\nor\nLanTurtle\n). They can be set at runtime and automated via\nsysctl\n.\nFor more control install\nUSBGuard\n, which is a software framework implementing basic whitelisting and blacklisting capabilities based on device attributes.\nVolatile data collection\nA computer that is powered on may be vulnerable to\nvolatile data collection\n. It is a best practice to turn a computer completely off at times it is not necessary for it to be on, or if the computer's physical security is temporarily compromised (e.g. when passing through a security checkpoint).\nPackages\nAuthentication\nAttacks on package managers\nare possible without proper use of package signing, and can affect even package managers with\nproper signature systems\n. Arch uses package signing by default and relies on a web of trust from 5 trusted master keys. See\nPacman-key\nfor details.\nUpgrades\nIt is important to regularly\nupgrade the system\n.\nFollow vulnerability alerts\nSubscribe to the Common Vulnerabilities and Exposure (CVE) Security Alert updates, made available by National Vulnerability Database, and found on the\nNVD Download webpage\n. The\nArch Linux Security Tracker\nserves as a particularly useful resource in that it combines Arch Linux Security Advisory (ASA), Arch Linux Vulnerability Group (AVG) and CVE data sets in tabular format. The tool\narch-audit\ncan be used to check for vulnerabilities affecting the running system. A graphical system tray,\narch-audit-gtk\n, can also be used. See also\nArch Security Team\n.\nYou should also consider subscribing to the release notifications for software you use, especially if you install software through means other than the main repositories or AUR. Some software have mailing lists you can subscribe to for security notifications. Source code hosting sites often offer RSS feeds for new releases.\nRebuilding packages\nPackages can be rebuilt and stripped of undesired functions and features as a means to reduce attack surface. For example,\nbzip2\ncan be rebuilt without\nbzip2recover\nin an attempt to circumvent\nCVE-2016-3189\n. Custom hardening flags can also be applied either manually or via a wrapper.\nThis article or section is a candidate for merging with\nArch package guidelines/Security\n.\nNotes:\nSecurity related build flags have their own article. (Discuss in\nTalk:Security\n)\nThe factual accuracy of this article or section is disputed.\nReason:\nCopy-pasted from a 3 years old blog post. The compiler flags are specific to\nGCC\n, some are hardly security related. (Discuss in\nTalk:Security\n)\nFlag\nPurpose\n-D_FORTIFY_SOURCE=2\nRun-time buffer overflow detection\n-D_GLIBCXX_ASSERTIONS\nRun-time bounds checking for C++ strings and containers\n-fasynchronous-unwind-tables\nIncreased reliability of backtraces\n-fexceptions\nEnable table-based thread cancellation\n-fpie -Wl,-pie\nFull ASLR for executables\n-fpic -shared\nNo text relocations for shared libraries\n-fplugin=annobin\nGenerate data for hardening quality control\n-fstack-clash-protection\nIncreased reliability of stack overflow detection\n-fstack-protector, -fstack-protector-all or -fstack-protector-strong\nStack smashing protector\n-grecord-gcc-switches\nStore compiler flags in debugging information\n-mcet -fcf-protection\nControl flow integrity protection\n-Werror=format-security\nReject potentially unsafe format string arguments\n-Werror=implicit-function-declaration\nReject missing function prototypes\n-Wl,-z,defs\nDetect and reject underlinking\n-Wl,-z,now\nDisable lazy binding\n-Wl,-z,relro\nRead-only segments after relocation\nFlags and info source\nSee also\nArch Linux Security Tracker\nCentOS Wiki: OS Protection\nHardening the Linux desktop\nHardening the Linux server\nLinux Foundation: Linux workstation security checklist\nprivacyguides.org Privacy Resources\nRed Hat Enterprise Linux 7 Security Guide\nSecuring Debian Manual\nThe paranoid #! Security Guide\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Security&oldid=853300\n\"\nCategories\n:\nSecurity\nFile systems\nNetworking\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Expansion\nPages with dead links\nPages or sections flagged with Template:Style\nSearch\nSearch\nSecurity\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Security"}}
{"text": "PAM - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPAM\n4 languages\nEspañol\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nSecurity\npam_mount\npam_usb\npam_abl\npam_oath\nUniversal 2nd Factor\nIdentity management\nThe\nLinux Pluggable Authentication Modules\n(PAM) provides a framework for system-wide user authentication. To quote the\nproject\n:\nPAM provides a way to develop programs that are independent of authentication scheme. These programs need \"authentication modules\" to be attached to them at run-time in order to work. Which authentication module is to be attached is dependent upon the local system setup and is at the discretion of the local system administrator.\nThis article explains the Arch Linux base set-up defaults for PAM to authenticate local and remote users. Applying changes to the defaults is subject of crosslinked specialized per topic articles.\nInstallation\nThe\npam\npackage is a dependency of the\nbase\nmeta package\nand, thereby, normally installed on an Arch system. The PAM modules are installed into\n/usr/lib/security\nexclusively.\nThe repositories contain a number of optional PAM packages, the\n#Configuration How-Tos\nshow examples.\nConfiguration\nA number of\n/etc\npaths are relevant for PAM; execute\npacman --query --list pam | grep /etc\nto see the default configuration files created. They relate to either\n#Security parameters\nfor the modules, or the\n#PAM base-stack\nconfiguration.\nSecurity parameters\nThe path\n/etc/security\ncontains system-specific configuration for variables the authentication methods offer. The base install populates it with default upstream configuration files.\nNote Arch Linux does not provide distribution-specific configuration for these files. For example, the\n/etc/security/pwquality.conf\nfile can be used to define system-wide defaults for password quality. Yet, to enable it, the\npam_pwquality.so\nmodule has to be added to the\n#PAM base-stack\nof modules, which is not the case per default.\nSee\n#Security parameter configuration\nfor some of the possibilities.\nPAM base-stack\nThe\n/etc/pam.d/\npath is exclusive for the PAM configuration to link the applications to the individual systems' authentication schemes. During installation of the system base, it is populated by:\nthe\npambase\npackage, which contains the base-stack of Arch Linux specific PAM configuration to be used by applications, and\nother base packages. For example,\nutil-linux\nadds configuration for the central\nlogin\nand other programs, the\nshadow\npackage adds the Arch Linux defaults to secure and modify the user database (see\nUsers and groups\n).\nThe different configuration files of the base installation link together and are stacked during runtime. For example, on a local user logon, the\nlogin\napplication sources the\nsystem-local-login\npolicy, which in turn sources others:\n/etc/pam.d/\nlogin -> system-local-login -> system-login -> system-auth\nFor a different application, a different path may apply. For example,\nopenssh\ninstalls its\nsshd\nPAM policy:\n/etc/pam.d/\nsshd -> system-remote-login -> system-login -> system-auth\nConsequently, the choice of the configuration file in the stack matters. For the above example, a special authentication method could be required for\nsshd\nonly, or all remote logins by changing\nsystem-remote-login\n; both changes would not affect local logins. Applying the change to\nsystem-login\nor\nsystem-auth\ninstead would affect local and remote logins.\nLike the example of\nsshd\n, any\npam-aware\napplication is required to install its policy to\n/etc/pam.d\nin order to integrate and rely on the PAM stack appropriately. If an application fails to do it, the\n/etc/pam.d/other\ndefault policy to deny and log a warning is applied.\nTip\nPAM is dynamically linked at runtime. For example:\n$ ldd /usr/bin/login | grep pam\nlibpam.so.0 => /usr/lib/libpam.so.0 (0x000003d8c32d6000)\nlibpam_misc.so.0 => /usr/lib/libpam_misc.so.0 (0x000003d8c30d2000)\nthe\nlogin\napplication is pam-aware and\nmust\n, therefore, have a policy.\nThe PAM package manual pages\npam(8)\nand\npam.d(5)\ndescribe the standardized content of the configuration files. In particular, they explain the four PAM groups: account, authentication, password, and session management, as well as the control values that may be used to configure stacking and behavior of the modules.\nAdditionally, extensive documentation is installed to\n/usr/share/doc/Linux-PAM/index.html\nwhich, among various guides, contains browsable man pages for each of the standard modules.\nWarning\nChanges to the PAM configuration fundamentally affect user authentication. Erroneous changes can result in that\nno user\ncan log in, or\nall users\nbeing able to log in.\nTip\nChanges are not effective for already authenticated users; a way to work with PAM is to login preferably locally on the testing machine and develop, keeping the session constantly running, while checking the results from another user on another console.\nExamples\nThe factual accuracy of this article or section is disputed.\nReason:\n(1) the use of nullok (2) the way pam handles optional modules (Discuss in\nTalk:PAM#Accuracy of PAM#Examples\n)\nTwo short examples to illustrate the above warning.\nFirst, we take the following two lines from a\nhistoric Arch default\n:\n/etc/pam.d/system-auth\nauth      required  pam_unix.so     try_first_pass nullok\nauth      optional  pam_permit.so\nFrom\npam_unix(8)\n:\nThe authentication component\npam_unix.so\nperforms the task of checking the users credentials (password). The default action of this module is to not permit the user access to a service if their official password is blank.\n- the latter being what\npam_permit.so\nis used for. Simply swapping the control values\nrequired\nand\noptional\nfor both lines is enough to disable password authentication, i.e. any user may logon without providing a password.\nSecond, as the contrary example, per default configuration of\npam_nologin.so\nin\n/etc/pam.d/login\n, creating the following file:\n# touch /etc/nologin\nresults in that no user other than root may login (if root logins are allowed, see\nSecurity#Restricting root login\n). To allow logins again, remove the file again before your logout from the console you created it with.\nWith that as background, see\n#PAM stack and module configuration\nfor particular use-case configuration.\nConfiguration How-Tos\nThis section provides an overview of content detailing how to apply changes to the PAM configuration and how to integrate special new PAM modules into the PAM stack. Note the man pages for the modules can generally be reached dropping the\n.so\nextension.\nSecurity parameter configuration\nThe following sections describe examples to change the default PAM parameter configuration:\nSecurity#Enforcing strong passwords with pam_pwquality\nshows how to enforce strong passwords with\npam_cracklib.so\n.\nSecurity#Lock out user after three failed login attempts\nshows how to configure the limits on login attempts with\npam_faillock.so\n.\nSecurity#Allow only certain users\nlimits user logons with\npam_wheel.so\n.\nRealtime process management#Configuring PAM\nand\nSecurity#Limit amount of processes\ndetail how to configure system process limits with\npam_limits.so\n.\nEnvironment variables#Using pam_env\nshows examples to set environment variables via\npam_env.so\n.\nPAM stack and module configuration\nThe following articles detail how to change the\n#PAM base-stack\nfor special use-cases.\npam_mount\ndetail examples for using\npam_mount.so\nto automount encrypted directory paths on user login.\nECryptfs#Auto-mounting\nuses\npam_ecryptfs.so\nto automount an encrypted directory.\nDm-crypt/Mounting at login\nshows how to use\npam_exec.so\nto execute a custom script on a user login.\nActive Directory integration#Configuring PAM\nuses\npam_winbind.so\nand\npam_krb5.so\nto let users authenticate via Active Directory (\nLDAP\n,\nKerberos\n) services.\nLDAP authentication\nis an article about integrating LDAP client or server-side authentication with\npam_ldap.so\n.\nYubiKey#Linux user authentication with PAM\ndescribes how to use U2F (\npam_u2f.so\n) and the proprietary Yubico OTP implementation (\npam_yubico.so\n) provided by the YubiKey with PAM\npam_oath\nshows an example to implement software based two-factor authentication with\npam_oath.so\n.\nfprint\nemploys\npam_fprintd.so\nto setup fingerprint authentication.\npam_autologin\nsaves username and password to log in automatically.\npam_usb\nshows how to configure\npam_usb.so\nto use an usb-device for, optionally two-factor, authentication.\nSSH keys#pam_ssh\nuses\npam_ssh.so\nto authenticate as a remote user.\npam_abl\nexplains how\npam_abl.so\ncan be used to limit brute-forcing attacks via ssh.\nEncFS\nmay get automounted via\npam_encfs.so\n.\nGoogle Authenticator\nshows how to set up two-factor authentication with\npam_google_authenticator.so\n.\nVery Secure FTP Daemon#PAM with virtual users\nexplains how to configure a FTP chroot with\npam_pwdfile.so\nto authenticate users without a local system account.\nFurther PAM packages\nOther than those packages mentioned so far, the\nArch User Repository\ncontains a number of additional PAM modules and tools.\nA general purpose utility relating to PAM is:\nPamtester\n— Program to test the pluggable authentication modules (PAM) facility\nhttps://pamtester.sourceforge.net/\n||\npamtester\nAUR\nNote the AUR features a keyword tag for\nPAM\n, but not all available packages are updated to include it. Hence, searching the\npackage description\nmay be necessary.\nTips and tricks\nLocked out\nIf PAM has locked you out, perhaps by typing the wrong password too many times, see\nSecurity#Lock out user after three failed login attempts\n.\nSee also\nlinux-pam.org\n- The project homepage\nUnderstanding and configuring PAM\n- An introductory article\nLogin managers: An introduction\n- Motivates PAM in the context of a\nlogin manager\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=PAM&oldid=822252\n\"\nCategories\n:\nKernel\nAuthentication\nHidden category:\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nPAM\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/PAM"}}
{"text": "Sudo - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSudo\n9 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\nUsers and groups\nsu\ndoas\nSudo\nallows a system administrator to delegate authority to give certain users—or groups of users—the ability to run commands as root or another user while providing an audit trail of the commands and their arguments.\nSudo is an alternative to\nsu\nfor running commands as root. Unlike\nsu\n, which launches a root shell that allows all further commands root access, sudo instead grants temporary privilege elevation to a single command. By enabling root privileges only when needed, sudo usage reduces the likelihood that a typo or a bug in an invoked command will ruin the system.\nSudo can also be used to run commands as other users; additionally, sudo logs all commands and failed access attempts to the\njournal\nfor security auditing.\nInstallation\nInstall\nthe\nsudo\npackage.\nTip\nsudo-rs\nis an alternative memory-safe implementation of\nsudo\n(with\nsome limitations\n).\nUsage\nTo begin using\nsudo\nas a non-privileged user, it must be properly configured. See\n#Configuration\n.\nTo use\nsudo\n, simply prefix a command and its arguments with\nsudo\nand a space:\n$ sudo\ncmd\nFor example, to use pacman:\n$ sudo pacman -Syu\nSee\nsudo(8)\nfor more information.\nLogin shell\nYou cannot run every command as an other user simply by prepending\nsudo\n. In particular when using a\nredirection\nand\ncommand substitution\n, you must use a login shell, which can be easily accessed with\nsudo -iu\nuser\n(one can omit\n-u\nuser\nif the desired user is root).\nIn the following example command substitution would work in a full shell, but fails with prepending\nsudo\n:\n$ sudo wpa_supplicant -B -i\ninterface\n-c\n<(\nwpa_passphrase\nMYSSID passphrase\n)\nSuccessfully initialized wpa_supplicant\nFailed to open config file '/dev/fd/63', error: No such file or directory\nFailed to read or parse configuration '/dev/fd/63'\nConfiguration\nThis article or section needs expansion.\nReason:\nCreate an intro discussing\nDefaults\n, perhaps with a table that lists common settings (Discuss in\nTalk:Sudo\n)\nDefaults skeleton\nsudoers(5) § SUDOERS OPTIONS\nlists all the options that can be used with the\nDefaults\ncommand in the\n/etc/sudoers\nfile.\nSee\n[1]\nfor a list of options (parsed from the version 1.8.7 source code) in a format optimized for\nsudoers\n.\nSee\nsudoers(5)\nfor more information, such as configuring the password timeout.\nView current settings\nRun\nsudo -ll\nto print out the current sudo configuration, or\nsudo -lU\nuser\nfor a specific user.\nUsing visudo\nThe configuration file for sudo is\n/etc/sudoers\n. It should\nalways\nbe edited with the\nvisudo(8)\ncommand.\nvisudo\nlocks the\nsudoers\nfile, saves edits to a temporary file, and checks it for syntax errors before copying it to\n/etc/sudoers\n.\nWarning\nIt is imperative that\nsudoers\nbe free of syntax errors! Any error makes sudo unusable.\nAlways\nedit it with\nvisudo\nto prevent errors.\nvisudo(8)\nwarns that configuring\nvisudo\nto honor the user environment variables for their editor of choice may be a security hole, since it allows the user with\nvisudo\nprivileges to run arbitrary commands as root without logging simply by setting that variable to something else.\nThe default editor for\nvisudo\nis\nvi\n. The\nsudo\npackage is compiled with\n--with-env-editor\nand honors the use of the\nSUDO_EDITOR\n,\nVISUAL\nand\nEDITOR\nvariables.\nEDITOR\nis not used when\nVISUAL\nis set.\nTo establish\nnano\nas the\nvisudo\neditor for the duration of the current shell session, export\nEDITOR=nano\n; to use a different editor just once simply set the variable before calling\nvisudo\n:\n# EDITOR=nano visudo\nAlternatively you may edit a copy of the\n/etc/sudoers\nfile and check it using\nvisudo -c\n/copy/of/sudoers\n. This might come in handy in case you want to circumvent locking the file with\nvisudo\n.\nTo change the editor permanently, see\nEnvironment variables#Per user\n. To change the editor of choice permanently system-wide only for\nvisudo\n, add the following to\n/etc/sudoers\n(assuming\nnano\nis your preferred editor):\n# Set default EDITOR to restricted version of nano, and do not allow visudo to use EDITOR/VISUAL.\nDefaults      editor=/usr/bin/rnano, !env_editor\nExample entries\nTo allow a user to gain full root privileges when they precede a command with\nsudo\n, add the following line:\nUSER_NAME   ALL=(ALL:ALL) ALL\nTo allow a user to run all commands as any user but only on the machine with hostname\nHOST_NAME\n:\nUSER_NAME   HOST_NAME=(ALL:ALL) ALL\nTo allow members of group\nwheel\nsudo access:\n%wheel      ALL=(ALL:ALL) ALL\nTip\nWhen creating new administrators, it is often desirable to enable sudo access for the\nwheel\ngroup and\nadd the user to it\n, since by default\nPolkit\ntreats the members of the\nwheel\ngroup as administrators. If the user is not a member of\nwheel\n, software using Polkit may ask to authenticate using the root password instead of the user password.\nTo disable asking for a password for user\nUSER_NAME\n:\nWarning\nThis will allow any process running with your user name to use sudo without asking for permission.\nDefaults:USER_NAME      !authenticate\nEnable explicitly defined commands only for user\nUSER_NAME\non host\nHOST_NAME\n:\nUSER_NAME HOST_NAME=/usr/bin/halt,/usr/bin/poweroff,/usr/bin/reboot,/usr/bin/pacman -Syu\nNote\nThe most customized option should go at the end of the file, as the later lines overrides the previous ones. In particular such a line should be after the\n%wheel\nline if your user is in this group.\nEnable explicitly defined commands only for user\nUSER_NAME\non host\nHOST_NAME\nwithout password:\nUSER_NAME HOST_NAME= NOPASSWD: /usr/bin/halt,/usr/bin/poweroff,/usr/bin/reboot,/usr/bin/pacman -Syu\nA detailed\nsudoers\nexample is available at\n/usr/share/doc/sudo/examples/sudoers\n. Otherwise, see the\nsudoers(5)\nfor detailed information.\nSudoers default file permissions\nThe owner and group for the\nsudoers\nfile must both be 0. The file permissions must be set to 0440. These permissions are set by default, but if you accidentally change them, they should be changed back immediately or sudo will fail.\n# chown -c root:root /etc/sudoers\n# chmod -c 0440 /etc/sudoers\nTips and tricks\nDisable password prompt timeout\nA common annoyance is a long-running process that runs on a background terminal somewhere that runs with normal permissions and elevates only when needed. This leads to a sudo password prompt which goes unnoticed and times out, at which point the process dies and the work done is lost or, at best, cached. Common advice is to enable passwordless sudo, or extend the timeout of sudo remembering a password. Both of these have negative security implications. The\nprompt\ntimeout can also be disabled and since that does not serve any reasonable security purpose it should be the solution here:\nDefaults passwd_timeout=0\nPassing aliases\nThe following is only relevant if the bash completion is not available (either full or reduced as described above): Aliases in\nZsh\nand\nBash\nare normally only expanded for the first word in a command. This means that your aliases will not normally get expanded when running the\nsudo\ncommand. One way to make the next word expand is to make an alias for sudo ending with a space. Add the following to your\nshell's configuration file\n:\nalias sudo='sudo '\nzshmisc(1) § ALIASING\ndescribes how this works:\nIf the replacement text ends with a space, the next word in the shell input is always eligible for purposes of alias expansions.\nAs well as\nbash(1) § ALIASES\n:\nIf the last character of the alias value is a blank, then the next command word following the alias is also checked for alias expansion.\nAdd terminal bell to the password prompt\nTo draw attention to a sudo prompt in a background terminal, users can simply make it echo a\nbell character\n:\nDefaults passprompt=\"\n^G\n[sudo] password for %p: \"\nNote the\n^G\nis a literal bell character. E.g. in\nvim\n, insert using the sequence\nCtrl+v\nCtrl+g\n. If\nCtrl+v\nis mapped, e.g. for pasting, one can\nusually\nuse\nCtrl+q\ninstead. In\nnano\n,\nAlt+v\nCtrl+g\n.\nThis article or section needs expansion.\nReason:\nIs it possible to preserve the localized prompt while using bell? The same question for the case when SUDO_PROMPT is used. Is there an alternative, for example by using \"-B\" option as default?  (Discuss in\nTalk:Sudo\n)\nAnother option is to set the\nSUDO_PROMPT\nenvironment variable\n. For example, add the following to your shell configuration file:\nexport SUDO_PROMPT=$'\\a[sudo] password for %p: '\nDisable per-terminal sudo\nWarning\nThis will let any process use your sudo session.\nIf you are annoyed by sudo's defaults that require you to enter your password every time you open a new terminal, set\ntimestamp_type\nto\nglobal\n:\nDefaults timestamp_type=global\nReduce the number of times you have to type a password\nIf you are annoyed that you have to re-enter your password every 5 minutes (default), you can change this by setting a longer value for\ntimestamp_timeout\n(in minutes):\nDefaults timestamp_timeout=10\nIf you are using sudo commands in a long script and you do not want to wait for user input when the timeout expires, it is possible to refresh the timeout by separately running\nsudo -v\nin a loop (whereas\nsudo -K\nrevokes it immediately).\nEnvironment variables\nIf you have a lot of environment variables, or you export your proxy settings via\nexport http_proxy=\"...\"\n, when using sudo these variables do not get passed to the root account unless you run sudo with the\n-E\n/\n--preserve-env\noption.\n$ sudo -E pacman -Syu\nThe recommended way of preserving environment variables is to append them to\nenv_keep\n:\n/etc/sudoers\nDefaults env_keep += \"ftp_proxy http_proxy https_proxy no_proxy\"\nRoot password\nUsers can configure sudo to ask for the root password instead of the user password by adding\ntargetpw\n(target user, defaults to root) or\nrootpw\nto the Defaults line in\n/etc/sudoers\n:\nDefaults targetpw\nTo prevent exposing your root password to users, you can restrict this to a specific group:\nDefaults:%wheel targetpw\n%wheel ALL=(ALL) ALL\nDisable root login\nUsers may wish to disable the root login. Without root, attackers must first guess a user name configured as a sudoer as well as the user password. See for example\nOpenSSH#Deny\n.\nWarning\nBe careful, you may lock yourself out by disabling root login. Sudo is not automatically installed and its default configuration allows neither passwordless root access nor root access with your own password. Ensure a user is properly configured as a sudoer\nbefore\ndisabling the root account!\nIf you have changed your sudoers file to use rootpw as default, then do not disable root login with any of the following commands!\nIf you are already locked out, see\nPassword recovery\nfor help.\nThe account can be locked via\npasswd\n:\n# passwd -l root\nA similar command unlocks root.\n$ sudo passwd -u root\nAlternatively, you can use the following command to delete the password and then lock the root account :\n$ sudo passwd -dl root\nTo enable root login again:\n$ sudo passwd root\nNote that this merely disables password-based login. The user may still be able to login using another authentication token (e.g. an SSH key). To disable the account use:\n$ usermod --expiredate 1 root\nThe factual accuracy of this article or section is disputed.\nReason:\nIn most cases when a user ends up in an emergency shell they are using the initramfs, will not use the following configuration, unless added to the\nFILES\nin\nmkinitcpio's configuration\n. (Discuss in\nTalk:Sudo\n)\nIn case of system emergency, the recovery prompt is going to ask you for a root password, making it impossible to log into recovery shell. To automatically unlock the root account in case of emergency add\nSYSTEMD_SULOGIN_FORCE=1\nenvironment variable to\nrescue.service\nusing a\ndrop-in file\n:\n/etc/systemd/system/rescue.service.d/SYSTEMD_SULOGIN_FORCE.conf\n[Service]\nEnvironment=SYSTEMD_SULOGIN_FORCE=1\nTip\nTo get to an interactive root prompt, even after disabling the\nroot\naccount, use\nsudo -i\n.\nkdesu\nkdesu may be used under\nKDE\nto launch GUI applications with root privileges. It is possible that by default kdesu will try to use su even if the root account is disabled. Fortunately one can tell kdesu to use sudo instead of su. Create/edit the file\n~/.config/kdesurc\n:\n[super-user-command]\nsuper-user-command=sudo\nor use the following command:\n$ kwriteconfig6 --file kdesurc --group super-user-command --key super-user-command sudo\nHarden with sudo example\nLet us say you create 3 users: admin, devel, and archie. The user \"admin\" is used for journalctl, systemctl, mount, kill, and iptables; \"devel\" is used for installing packages, and editing configuration files; and \"archie\" is the user you log in with. To let \"archie\" reboot, shutdown, and use netctl we would do the following:\nEdit\n/etc/pam.d/su\nand\n/etc/pam.d/su-l\n. Require user be in the wheel group, but do not put anyone in it.\n#%PAM-1.0\nauth            sufficient      pam_rootok.so\n# Uncomment the following line to implicitly trust users in the \"wheel\" group.\n#auth           sufficient      pam_wheel.so trust use_uid\n# Uncomment the following line to require a user to be in the \"wheel\" group.\nauth            required        pam_wheel.so use_uid\nauth            required        pam_unix.so\naccount         required        pam_unix.so\nsession         required        pam_unix.so\nLimit SSH login to the 'ssh' group. Only \"archie\" will be part of this group.\n# groupadd -r ssh\n# gpasswd -a archie ssh\n# echo 'AllowGroups ssh' >> /etc/ssh/sshd_config\nRestart\nsshd.service\n.\nAdd users to other groups.\n# for g in power network ;do ;gpasswd -a archie $g ;done\n# for g in network power storage ;do ;gpasswd -a admin $g ;done\nSet permissions on configs so devel can edit them.\n# chown -R devel:root /etc/{http,openvpn,cups,zsh,vim,screenrc}\nCmnd_Alias  POWER       =   /usr/bin/shutdown -h now, /usr/bin/halt, /usr/bin/poweroff, /usr/bin/reboot\nCmnd_Alias  STORAGE     =   /usr/bin/mount -o nosuid\\,nodev\\,noexec, /usr/bin/umount\nCmnd_Alias  SYSTEMD     =   /usr/bin/journalctl, /usr/bin/systemctl\nCmnd_Alias  KILL        =   /usr/bin/kill, /usr/bin/killall\nCmnd_Alias  PKGMAN      =   /usr/bin/pacman\nCmnd_Alias  NETWORK     =   /usr/bin/netctl\nCmnd_Alias  FIREWALL    =   /usr/bin/iptables, /usr/bin/ip6tables\nCmnd_Alias  SHELL       =   /usr/bin/zsh, /usr/bin/bash\n%power      ALL         =   (root)  NOPASSWD: POWER\n%network    ALL         =   (root)  NETWORK\n%storage    ALL         =   (root)  STORAGE\nroot        ALL         =   (ALL)   ALL\nadmin       ALL         =   (root)  SYSTEMD, KILL, FIREWALL\ndevel\t    ALL         =   (root)  PKGMAN\narchie\t    ALL         =   (devel) SHELL, (admin) SHELL\nWith this setup, you will almost never need to login as the root user.\n\"archie\" can connect to their home Wi-Fi.\n$ sudo netctl start home\n$ sudo poweroff\n\"archie\" can not use netctl as any other user.\n$ sudo -u admin -- netctl start home\nWhen \"archie\" needs to use journalctl or kill run away process they can switch to that user.\n$ sudo -i -u devel\n$ sudo -i -u admin\nBut \"archie\" cannot switch to the root user.\n$ sudo -i -u root\nIf \"archie\" want to start a gnu-screen session as admin they can do it like this:\n$ sudo -i -u admin\n[admin]$ chown admin:tty `echo $TTY`\n[admin]$ screen\nConfigure sudo using drop-in files in /etc/sudoers.d\nsudo\nparses files contained in the directory\n/etc/sudoers.d/\n. This means that instead of editing\n/etc/sudoers\n, you can change settings in standalone files and drop them in that directory. This has two advantages:\nThere is no need to edit a\nsudoers.pacnew\nfile;\nIf there is a problem with a new entry, you can remove the offending file instead of editing\n/etc/sudoers\n(but see the warning below).\nThe format for entries in these drop-in files is the same as for\n/etc/sudoers\nitself. To edit them directly, use\nvisudo -f /etc/sudoers.d/\nsomefile\n. See\nsudoers(5) § Including other files from within sudoers\nfor details.\nThe files in\n/etc/sudoers.d/\ndirectory are parsed in lexicographical order, file names containing\n.\nor\n~\nare skipped. To avoid sorting problems, the file names should begin with two digits, e.g.\n01_foo\n.\nNote\nThe order of entries in the drop-in files is important: make sure that the statements do not override themselves.\nWarning\nThe files in\n/etc/sudoers.d/\nare just as fragile as\n/etc/sudoers\nitself: any improperly formatted file will prevent\nsudo\nfrom working.  Hence, for the same reason it is strongly advised to use\nvisudo\nEditing files\nsudo\nprovides the\nsudoedit\ncommand (equivalent to\nsudo -e\n). This is useful for editing files which can be edited by root only while still running the editor as a normal user, and using that user’s configuration.\nTo edit a file, set\nSUDO_EDITOR\nto the name of the editor and pass the file name to\nsudoedit\n. For example:\n$ SUDO_EDITOR=vim sudoedit /etc/file\nSee\n#Using visudo\nand\nsudo(8) § e\nfor ways to set the editor, but beware of\npossible security issues\n.\nIf multiple names are passed to\nsudo\n, all files are opened in the editor in a single invocation. A feature useful for merging files:\n$ SUDO_EDITOR=vimdiff sudoedit /etc/file /etc/file.pacnew\nEnable insults\nUsers can enable the insults easter egg in sudo by adding the following line in the\nsudoers\nfile with\nvisudo\n.\n/etc/sudoers\nDefaults insults\nUpon entering an incorrect password, this will replace\nSorry, try again.\nmessage with humorous insults.\nEnable password input feedback\nBy default, there is no visual feedback when you input a password. That is done on purpose for extra security. However, if you wish to have visual input, you can enable it by adding this line:\n/etc/sudoers\nDefaults pwfeedback\nColored password prompt\nTo customize the password prompt with colors and/or bold fonts, set the\nSUDO_PROMPT\nenvironment variable\nin your shell initialization file and use\ntput(1)\n.\nFor example, to set the password prompt to display\nPassword:\nin bold red, use this:\nexport SUDO_PROMPT=\"$(tput setaf 1 bold)Password:$(tput sgr0) \"\nOr use different colors with the default message like so:\nexport SUDO_PROMPT=\"$(tput setab 1 setaf 7 bold)[sudo]$(tput sgr0) $(tput setaf 6)password for$(tput sgr0) $(tput setaf 5)%p$(tput sgr0): \"\nSee more on\nColor output in console\nand\nBash/Prompt customization\nUsing U2F\nU2F is great to use with sudo, as it can effectively eliminate the risk of\nshoulder surfing\nin public areas while still giving you conscious control to approve the prompt with a simple physical touch.\nSee\nUniversal 2nd Factor#Passwordless sudo\n.\nWrite to protected files\nWhen using sudo, you may want to write to protected files. Using\ntee\nallows such a separation:\n$\ninput stream\n| sudo tee\n--option\nprotected_file_1 protected_file_2...\nwhen a simple\n>\n/\n>>\nwould not have worked.\nIn Vim\nA similar concept is useful when you forgot to start\nVim\nwith sudo when editing a file owned by an other user. In this case you can do the following inside\nVim\nto save the file:\n:w !sudo tee %\nYou can add this to your\n~/.vimrc\nto make this trick easy-to-use with\n:w!!\nmapping in command mode:\n~/.vimrc\n\" Allow saving of files as sudo when I forgot to start vim using sudo\ncmap w!! w !sudo tee > /dev/null %\nThe\n> /dev/null\npart explicitly throws away the standard output since we do not need to pass anything to another piped command.\nMore detailed explanation of how and why this works can be found in\nHow does the vim “write with sudo” trick work?\narticle on StackOverflow.\nUsing sudo-rs without the sudo package\nYou can use\nsudo-rs\nas a standalone replacement for\nsudo\n, without requiring the\nsudo\npackage.\nCreate\n/etc/pam.d/sudo\nfollowing\nsudo\n's\ndefault configuration\n.\nAlso create\n/etc/pam.d/sudo-i\nfor\nsudo -i\n:\n# ln -s /etc/pam.d/sudo /etc/pam.d/sudo-i\nCreate or edit\n/etc/sudo-rs/config.toml\n:\n/etc/sudo-rs/config.toml\n[defaults]\naskpass = false\ntimeout = 15\nsudo-rs\nsupports both\n/etc/sudoers\nand\n/etc/sudoers-rs\nand uses the latter if it exists.\nOptionally, you can replace\nsudo\nwith\nsudo-rs\nby symlinking it from a higher priority\nPATH\ndirectory:\n# ln -s /usr/bin/sudo-rs /usr/local/bin/sudo\nTroubleshooting\nSSH problem without TTY\nThis article or section is a candidate for merging with\n#Configuration\n.\nNotes:\nplease use the second argument of the template to provide more detailed indications.\n(Discuss in\nTalk:Sudo\n)\nSSH does not allocate a tty by default when running a remote command. Without an allocated tty, sudo cannot prevent the password from being displayed. You can use ssh's\n-t\noption to force it to allocate a tty.\nThe\nDefaults\noption\nrequiretty\nonly allows the user to run sudo if they have a tty.\n# Disable \"ssh hostname sudo <cmd>\", because it will show the password in clear text. You have to run \"ssh -t hostname sudo <cmd>\".\n#\n#Defaults    requiretty\nPermissive umask\nThis article or section is a candidate for merging with\n#Configuration\n.\nNotes:\nplease use the second argument of the template to provide more detailed indications.\n(Discuss in\nTalk:Sudo\n)\nSudo will union the user's\numask\nvalue with its own umask (which defaults to 0022). This prevents sudo from creating files with more open permissions than the user's umask allows. While this is a sane default if no custom umask is in use, this can lead to situations where a utility run by sudo may create files with different permissions than if run by root directly. If errors arise from this, sudo provides a means to fix the umask, even if the desired umask is more permissive than the umask that the user has specified. Adding this (using\nvisudo\n) will override sudo's default behavior:\nDefaults umask = 0022\nDefaults umask_override\nThis sets sudo's umask to root's default umask (0022) and overrides the default behavior, always using the indicated umask regardless of what umask the user as set.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Sudo&oldid=848803\n\"\nCategories\n:\nSecurity\nCommands\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Merge\nSearch\nSearch\nSudo\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Sudo"}}
{"text": "GnuPG - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nGnuPG\n6 languages\nDeutsch\nMagyar\n日本語\nPolski\nРусский\n中文（简体）\nFrom ArchWiki\n(Redirected from\nGPG\n)\nRelated articles\npacman/Package signing\nData-at-rest encryption\nList of applications/Security#Encryption, signing, steganography\nOpenPGP\nAccording to the\nofficial website\n:\nGnuPG is a complete and free implementation of the\nOpenPGP\nstandard as defined by\nRFC 4880\n(also known as PGP). GnuPG allows you to encrypt and sign your data and communications; it features a versatile key management system, along with access modules for all kinds of public key directories. GnuPG, also known as GPG, is a command line tool with features for easy integration with other applications. A wealth of frontend applications and libraries are available. GnuPG also provides support for S/MIME and Secure Shell (ssh).\nWarning\nGnuPG started out as an implementation of the\nOpenPGP\nformat. However, in recent years its maintainer has actively diverged from the\nOpenPGP standardization effort\nand is separately extending the format in a GnuPG specific way (see\ndraft-koch-librepgp\n). These changes are causing compatibility issues with other implementations since version 2.4. See\n#OpenPGP compatibility\n.\nInstallation\ngnupg\nshould already be installed on your system as it is a dependency of\npacman\n.\nThis will also install\npinentry\n, a collection of simple PIN or passphrase entry dialogs which GnuPG uses for passphrase entry. The shell script\n/usr/bin/pinentry\ndetermines which\npinentry\ndialog is used, in the order described at\n#pinentry\n.\nIf you want to use a graphical frontend or program that integrates with GnuPG, see\nList of applications/Security#Encryption, signing, steganography\n.\nConfiguration\nHome directory\nThe GnuPG home directory is where the GnuPG suite stores its keyrings and private keys, and reads configurations from. By default, the path used is\n~/.gnupg\n. There are two ways to override this:\nSet the\n$GNUPGHOME\nenvironment variable\n.\nUse the\n--homedir\nargument, e.g.\n$ gpg --homedir\npath/to/dir\n[1]\n.\nBy default, the home directory has its\npermissions\nset to\n700\nand the files it contains have their permissions set to\n600\n. Only the owner of the directory has permission to read, write, and access the files. This is for security purposes and should not be changed. In case this directory or any file inside it does not follow this security measure, you will get warnings about unsafe file and home directory permissions.\nConfiguration files\nAll of GnuPG's behavior is configurable via command line arguments. For arguments you would like to be the default, you can add them to the respective configuration file:\ngpg\nchecks\ngnupg_home\n/gpg.conf\n(user) and\n/etc/gnupg/gpg.conf\n(global)\n[2]\n. Since\ngpg\nis the main entrypoint for GnuPG, most configuration of interest will be here. See\nGPG Options\nfor possible options.\ndirmngr\nchecks\ngnupg_home\n/dirmngr.conf\nand\n/etc/gnupg/dirmngr.conf\n.\ndirmngr\nis a program internally invoked by\ngpg\nto access PGP keyservers\n[3]\n. See\nDirmngr Options\nfor possible options.\nThese two configuration files cover the common usecases, but there are more auxiliary programs in the GnuPG suite with their own options. See the\nGnuPG manual\nfor a comprehensive list.\nCreate the desired file(s), and set their permissions to\n600\nas discussed in\n#Home directory\n.\nAdd to these files any long options you want. Do not write the two dashes, but simply the name of the option and required arguments. For example, to make GnuPG always use a keyring at a specific path, as if it was invoked as\ngpg --no-default-keyring --keyring\nkeyring-path\n...\n:\ngnupg_home\n/gpg.conf (or /etc/gnupg/gpg.conf)\nno-default-keyring\nkeyring\nkeyring-path\nOther examples are found in\n#See also\n.\nAdditionally,\npacman\nuses a different set of configuration files for package signature verification. See\nPacman/Package signing\nfor details.\nDefault options for new users\nIf you want to setup some default options for new users, put configuration files in\n/etc/skel/.gnupg/\n. When the new user is added in system, files from here will be copied to its GnuPG home directory. There is also a simple script called\naddgnupghome\nwhich you can use to create new GnuPG home directories for existing users:\n# addgnupghome user1 user2\nThis will add the respective\n/home/user1/.gnupg/\nand\n/home/user2/.gnupg/\nand copy the files from the skeleton directory to it. Users with existing GnuPG home directory are simply skipped.\nUsage\nNote\nWhenever a\nuser-id\nis required in a command, it can be specified with your key ID, fingerprint, a part of your name or email address, etc. GnuPG is flexible on this.\nWhenever a\nkey-id\nis needed, it can be found adding the\n--keyid-format=long\nflag to the command. To show the master secret key for example, run\ngpg --list-secret-keys --keyid-format=long\nuser-id\n, the\nkey-id\nis the hexadecimal hash provided on the same line as\nsec\n.\nCreate a key pair\nGenerate a key pair by typing in a terminal:\n$ gpg --full-gen-key\nWarning\nWhen using\n--full-gen-key\nthe generated key will advertise an AEAD mechanism, which is not understood by other\nOpenPGP\nimplementations. To disable this after key creation see\n#Disable unsupported AEAD mechanism\n.\nAlso add the\n--expert\noption to the command line to access more ciphers and in particular some newer\nelliptic curves\nlike\nCurve448\n.\nThe command will prompt for answers to several questions. For general use most people will want:\nThe default\nECC (sign and encrypt)\nfor signing and encryption keys.\nThe default\nCurve 25519\nto use\nCurve25519\nand\nEd25519\n.\nAn expiration date: a period of one year is good enough for the average user. This way even if access is lost to the keyring, it will allow others to know that it is no longer valid. At a later stage, if necessary, the expiration date can be extended without having to re-issue a new key.\nYour name and email address. You can add multiple identities to the same key later (\ne.g.\n, if you have multiple email addresses you want to associate with this key).\nno\noptional comment. Since the semantics of the comment field are\nnot well-defined\n, it has limited value for identification.\nA secure passphrase, find some guidelines in\nSecurity#Choosing secure passwords\n.\nNote\nThe name and email address you enter here will be seen by anybody who imports your key.\nTip\nThe simpler\n--gen-key\noption uses default parameters for the key cipher, size and expiry and only asks for\nreal name\nand\nemail address\n.\nList keys\nTo list keys in your public key ring:\n$ gpg --list-keys\nTo list keys in your secret key ring:\n$ gpg --list-secret-keys\nExport your public key\nGnuPG's main usage is to ensure confidentiality of exchanged messages via public-key cryptography. With it each user distributes the public key of their keyring, which can be used by others to encrypt messages to the user. The private key must\nalways\nbe kept private, otherwise confidentiality is broken. See\nWikipedia:Public-key cryptography\nfor examples about the message exchange.\nSo, in order for others to send encrypted messages to you, they need your public key.\nTo generate an ASCII version of a user's public key to file\npublic-key\n.asc\n(e.g. to distribute it by e-mail):\n$ gpg --export --armor --output\npublic-key\n.asc\nuser-id\nAlternatively, or in addition, you can\nuse a keyserver\nto share your key.\nTip\nAdd\n--no-emit-version\nto avoid printing the version number, or add the corresponding setting to your\ngpg.conf\n.\nYou can omit the\nuser-id\nto export all public keys within your keyring. This is useful if you want to share multiple identities at once, or for importing in another application, e.g.\nThunderbird\n.\nImport a public key\nIn order to encrypt messages to others, as well as verify their signatures, you need their public key. To import a public key with file name\npublic-key\n.asc\nto your public key ring:\n$ gpg --import\npublic-key\n.asc\nAlternatively, try retrieving their public key\nvia WKD\n(in case the domain of their email address supports it) or\nusing a keyserver\n.\nIf you wish to import a key ID to install a specific Arch Linux package, see\npacman/Package signing#Managing the keyring\nand\nMakepkg#Signature checking\n.\nUse a keyserver\nSending keys\nYou can register your key with a public PGP key server, so that others can retrieve it without having to contact you directly:\n$ gpg --send-keys\nkey-id\nWarning\nThere are keyservers where submitted keys cannot be deleted. Some of the reasons are explained in the\nMIT PGP Public Key Server FAQ\n.\nNote\nThe associated email address, once published publicly, could be the target of spammers and in this case anti-spam filtering may be necessary.\nSearching and receiving keys\nTo find out details of a key on the keyserver, without importing it, do:\n$ gpg --search-keys\nuser-id\nTo import a key from a key server:\n$ gpg --receive-keys\nkey-id\nTo refresh/update the keychain with the latest version from a key server:\n$ gpg --refresh-keys\nWarning\nYou should verify the authenticity of the retrieved public key by comparing its fingerprint with one that the owner published on an independent source(s) (e.g., contacting the person directly). See\nWikipedia:Public key fingerprint\nfor more information.\nIt is recommended to use the long key ID or the full fingerprint when receiving a key. Using a short ID may encounter collisions. All keys will be imported that have the short ID, see\nfake keys found in the wild\nfor such example.\nTip\nAdding\nauto-key-retrieve\nto the\nGPG configuration file\nwill automatically fetch keys from the key server as needed. This is not a compromise on security, but it can be considered a\nprivacy violation\n; see \"web bug\" in\ngpg(1) § auto-key-retrieve\n.\nKey servers\nSee\nOpenPGP#Keyserver\nfor a general overview of OpenPGP keyservers and their features.\nAn alternative key server can be specified with the\nkeyserver\noption in one of the\nconfiguration files\n, for instance:\n~/.gnupg/dirmngr.conf\nkeyserver hkp://keyserver.ubuntu.com\nA temporary use of another server is handy when the regular one does not work as it should. It can be achieved by, for example,\n$ gpg --keyserver\nhkps://keys.openpgp.org/\n--search-keys\nuser-id\nTip\nIf you are experiencing keyserver failures, you may want to check your\nDNS\nand your resolver configurations or its logs beforehand (e.g\nsystemd-resolved\n).\nIf receiving fails with the message\ngpg: keyserver receive failed: Connection refused\n, try using a different DNS server.\nIf connecting to a keyserver fails with\ngpg: keyserver receive failed: Server indicated a failure\n, you may need to configure gpg to use an alternate port. For example, to use port 80 on Ubuntu's keyserver, use\nkeyserver hkp://keyserver.ubuntu.com:80\n.\nYou can connect to the keyserver over\nTor\nwith\nTor#Torsocks\n. Or using the\n--use-tor\ncommand line option. See\n[4]\nfor more information.\nYou can connect to a keyserver using a proxy by setting the\nhttp_proxy\nenvironment variable\nand setting\nhonor-http-proxy\nin\ndirmngr.conf\n. Alternatively, set\nhttp-proxy\nhost[:port]\nin the configuration file to override the environment variable of the same name.\nRestart\nthe\ndirmngr.service\nuser service\nfor the changes to take effect.\nWeb Key Directory\nSee\nOpenPGP#Web Key Directory\nfor a general overview.\nLookup certificates using WKD\nWhen encrypting to an email address (e.g.\nuser@example.org\n), if it is not already in the local keyring, GnuPG, by default, will retrieve the public OpenPGP key using the Web Key Directory protocol (i.e. GnuPG will download the key via HTTPS from the\nexample.org\nweb server). For example:\n$ gpg --recipient\nuser@example.org\n--encrypt\ndoc\nTo retrieve a public key and import it into your keyring, use the\n--locate-keys\nor\n--locate-external-keys\noptions. The former will not do anything if the key already exists in the local keyring, while the later will always refresh the key. For example:\n$ gpg --locate-external-keys\nuser@example.org\nNote\nGnuPG's automatic key retrieval is controlled with the\n--auto-key-locate\noption which defaults to\nlocal,wkd\n; see its description in\ngpg(1)\n. In case you have set\nauto-key-locate\nto a value without\nwkd\nin the\nGPG configuration file\n, you can use the\n--auto-key-locate clear,wkd\ncommand line option to override it.\nCreate a WKD\nIf you control the domain of your email address yourself and have a web server that provides HTTPS with a trusted TLS certificate, you can follow\nthis guide\nto enable WKD for your domain.\nEncrypt and decrypt\nAsymmetric\nYou need to\nimport a public key\nof a user before encrypting (option\n-e\n/\n--encrypt\n) a file or message to that recipient (option\n-r\n/\n--recipient\n). Additionally you need to\ncreate a key pair\nif you have not already done so.\nTo encrypt a file with the name\ndoc\n, use:\n$ gpg --recipient\nuser-id\n--encrypt\ndoc\nTo decrypt (option\n-d\n/\n--decrypt\n) a file with the name\ndoc\n.gpg encrypted with your public key, use:\n$ gpg --output\ndoc\n--decrypt\ndoc\n.gpg\ngpg\nwill prompt you for your passphrase and then decrypt and write the data from\ndoc\n.gpg to\ndoc\n. If you omit the\n-o\n/\n--output\noption,\ngpg\nwill write the decrypted data to stdout.\nTip\nAdd\n--armor\nto encrypt a file using ASCII armor, suitable for copying and pasting a message in text format.\nUse\n-R\nuser-id\nor\n--hidden-recipient\nuser-id\ninstead of\n-r\nto not put the recipient key IDs in the encrypted message. This helps to hide the receivers of the message and is a limited countermeasure against traffic analysis.\nAdd\n--no-emit-version\nto avoid printing the version number, or add the corresponding setting to your configuration file.\nYou can use GnuPG to encrypt your sensitive documents by using your own user-id as recipient or by using the\n--default-recipient-self\nflag; however, you can only do this one file at a time, although you can always tarball various files and then encrypt the tarball. See also\nData-at-rest encryption#Available methods\nif you want to encrypt directories or a whole file-system.\nSymmetric\nSymmetric encryption does not require the generation of a key pair and can be used to simply encrypt data with a passphrase. Simply use\n-c\n/\n--symmetric\nto perform symmetric encryption:\n$ gpg -c\ndoc\nThe following example:\nEncrypts\ndoc\nwith a symmetric cipher using a passphrase\nUses the AES-256 cipher algorithm to encrypt the data\nUses the SHA-512 digest algorithm to mangle the passphrase and generate the encryption key\nMangles the passphrase for 65536 iterations\n$ gpg -c --s2k-cipher-algo AES256 --s2k-digest-algo SHA512 --s2k-count 65536\ndoc\nTo decrypt a symmetrically encrypted\ndoc\n.gpg\nusing a passphrase and output decrypted contents into the same directory as\ndoc\ndo:\n$ gpg --output\ndoc\n--decrypt\ndoc\n.gpg\nDirectory\nEncrypting/decrypting a directory can be done with\ngpgtar(1)\n.\nEncrypt:\n$ gpgtar -c -o\ndir\n.gpg\ndir\nDecrypt:\n$ gpgtar -d\ndir\n.gpg\nKey maintenance\nBackup your private key\nTo backup your private key do the following:\n$ gpg --export-secret-keys --armor --output\nprivate-key\n.asc\nuser-id\nIf the private key is protected by a passphrase, the exported key file will be protected by the same one.\nGnuPG may ask you to enter the passphrase for the key. This is required, because the internal protection method of the secret key is different from the one specified by the OpenPGP protocol.\n[5]\nWarning\nThe passphrase is usually the weakest link in protecting your secret key. Place the private key in a safe place on a different system/device, such as a locked container or encrypted drive. It is the only safety you have to regain control to your keyring in case of, for example, a drive failure, theft or worse.\nThis method of backing up key has some security limitations. See the\nMoving GPG Keys Privately\npost on VHSblog for a potentially more secure way to back up and import keys using\ngpg\n.\nTo import the backup of your private key:\n$ gpg --import\nprivate-key\n.asc\nTip\nPaperkey\ncan be used to export private keys as human readable text or machine readable barcodes that can be printed on paper and archived.\nBackup your revocation certificate\nRevocation certificates are automatically generated for newly generated keys. These are by default located in\n~/.gnupg/openpgp-revocs.d/\n. The filename of the certificate is the fingerprint of the key it will revoke.\nThe revocation certificates can also be generated manually by the user later using:\n$ gpg --gen-revoke --armor --output\nrevcert\n.asc\nuser-id\nThis certificate can be used to\nrevoke a key\nif it is ever lost or compromised. The backup will be useful if you have no longer access to the secret key and are therefore not able to generate a new revocation certificate with the above command. It is short enough to be printed out and typed in by hand if necessary.\nWarning\nAnyone with access to the revocation certificate can revoke the key publicly, this action cannot be undone. Protect your revocation certificate like you protect your secret key.\nEdit your key\nRunning the\ngpg --edit-key\nuser-id\ncommand will present a menu which enables you to do most of your key management related tasks.\nType\nhelp\nin the edit key sub menu to show the complete list of commands. Some useful ones:\n> passwd       # change the passphrase\n> clean        # compact any user ID that is no longer usable (e.g revoked or expired)\n> revkey       # revoke a key\n> addkey       # add a subkey to this key\n> expire       # change the key expiration time\n> adduid       # add additional names, comments, and email addresses\n> addphoto     # add photo to key (must be JPG, 240x288 recommended, enter full path to image when prompted)\nTip\nIf you have multiple email accounts you can add each one of them as an identity, using\nadduid\ncommand. You can then set your favourite one as\nprimary\n.\nExporting subkey\nIf you plan to use the same key across multiple devices, you may want to strip out your master key and only keep the bare minimum encryption subkey on less secure systems.\nFirst, find out which subkey you want to export.\n$ gpg --list-secret-keys --with-subkey-fingerprint\nSelect only that subkey to export.\n$ mktemp -d\n/tmp/tmp.\nXXXXXXXXXX\n$ gpg --armor --export-secret-subkeys --output /tmp/tmp.XXXXXXXXXX/subkey.asc\nsubkey-id\n!\nWarning\nIf you forget to add the exclamation mark (\n!\n), all of your subkeys will be exported.\nAt this point you could stop, but it is most likely a good idea to change the passphrase as well. Import the key into a temporary folder.\n$ gpg --homedir /tmp/tmp.\nXXXXXXXXXX\n--import /tmp/tmp.\nXXXXXXXXXX\n/subkey.asc\n$ gpg --homedir /tmp/tmp.\nXXXXXXXXXX\n--edit-key\nuser-id\n> passwd\n> save\n$ gpg --homedir /tmp/tmp.\nXXXXXXXXXX\n--armor --output /tmp/tmp.\nXXXXXXXXXX\n/subkey.altpass.asc --export-secret-subkeys\nsubkey-id\n!\nNote\nYou will get a warning that the master key was not available and the password was not changed, but that can safely be ignored as the subkey password was.\nAt this point, you can now use\n/tmp/tmp.\nXXXXXXXXXX\n/subkey.altpass.asc\non your other devices.\nExtending expiration date\nWarning\nNever\ndelete your expired or revoked subkeys unless you have a good reason. Doing so will cause you to lose the ability to decrypt files encrypted with the old subkey. Please\nonly\ndelete expired or revoked keys from other users to clean your keyring.\nIt is good practice to set an expiration date on your subkeys, so that if you lose access to the key (e.g. you forget the passphrase) the key will not continue to be used indefinitely by others. When the key expires, it is relatively straight-forward to extend the expiration date:\n$ gpg --edit-key\nuser-id\n> expire\nYou will be prompted for a new expiration date, as well as the passphrase for your secret key, which is used to sign the new expiration date.\nTip\nAn exact expiration date and time can be specified by entering a\nYYYY\n-\nMM\n-\nDD\nformatted date or\nYYYYMMDD\nT\nhhmmss\nformatted timestamp as the expiration value.\nRepeat this for any further subkeys that have expired:\n> key 1\n> expire\nFinally, save the changes and quit:\n> save\nUpdate it to a keyserver.\n$ gpg --keyserver keyserver.ubuntu.com --send-keys\nkey-id\nAlternatively, if you use this key on multiple computers, you can export the public key (with new signed expiration dates) and import it on those machines:\n$ gpg --export --output pubkey.gpg\nuser-id\n$ gpg --import pubkey.gpg\nThere is no need to re-export your secret key or update your backups: the master secret key itself never expires, and the signature of the expiration date left on the public key and subkeys is all that is needed.\nRotating subkeys\nWarning\nNever\ndelete your expired or revoked subkeys unless you have a good reason. Doing so will cause you to lose the ability to decrypt files encrypted with the old subkey. Please\nonly\ndelete expired or revoked keys from other users to clean your keyring.\nAlternatively, if you prefer to stop using subkeys entirely once they have expired, you can create new ones. Do this a few weeks in advance to allow others to update their keyring.\nTip\nYou do not need to create a new key simply because it is expired. You can extend the expiration date, see\n#Extending expiration date\n.\nCreate new subkey (repeat for both signing and encrypting key)\n$ gpg --edit-key\nuser-id\n> addkey\nAnd answer the following questions it asks (see\n#Create a key pair\nfor suggested settings).\nSave changes\n> save\nUpdate it to a keyserver.\n$ gpg --keyserver\npgp.mit.edu\n--send-keys\nuser-id\nYou will also need to export a fresh copy of your secret keys for backup purposes. See\n#Backup your private key\nfor details on how to do this.\nTip\nRevoking expired subkeys is unnecessary and arguably bad form. If you are constantly revoking keys, it may cause others to lack confidence in you.\nRevoke a key\nKey revocation should be performed if the key is compromised, superseded, no longer used, or you forget your passphrase. This is done by merging the key with the revocation certificate of the key.\nIf you have no longer access to your keypair, first\nimport a public key\nto import your own key.\nThen, to revoke the key, import the file saved in\n#Backup your revocation certificate\n:\n$ gpg --import\nrevcert\n.asc\nNow the revocation needs to be made public.\nUse a keyserver\nto send the revoked key to a public PGP server if you used one in the past, otherwise, export the revoked key to a file and distribute it to your communication partners.\nSignatures\nSignatures certify and timestamp documents. If the document is modified, verification of the signature will fail. Unlike encryption which uses the recipient public key to encrypt a document, signatures are created with the sender's private key. The recipient of a signed document then verifies the signature using the sender's public key.\nCreate a signature\nSign a file\nTo sign a file use the\n-s\n/\n--sign\nflag:\n$ gpg --output\ndoc\n.sig --sign\ndoc\ndoc\n.sig\ncontains both the compressed content of the original file\ndoc\nand the signature in a binary format, but the file is not encrypted. However, you can combine signing with\nencrypting\n.\nClearsign a file or message\nTo sign a file without compressing it into binary format use:\n$ gpg --output\ndoc\n.sig --clearsign\ndoc\nHere both the content of the original file\ndoc\nand the signature are stored in human-readable form in\ndoc\n.sig\n.\nMake a detached signature\nTo create a separate signature file to be distributed separately from the document or file itself, use the\n--detach-sig\nflag:\n$ gpg --output\ndoc\n.sig --detach-sig\ndoc\nHere the signature is stored in\ndoc\n.sig\n, but the contents of\ndoc\nare not stored in it. This method is often used in distributing software projects to allow users to verify that the program has not been modified by a third party.\nVerify a signature\nTo verify a signature use the\n--verify\nflag:\n$ gpg --verify\ndoc\n.sig\nwhere\ndoc\n.sig\nis the signed file containing the signature you wish to verify.\nIf you are verifying a detached signature, both the signed data file and the signature file must be present when verifying. For example, to verify Arch Linux's latest iso you would do:\n$ gpg --verify archlinux-\nversion\n.iso.sig\nwhere\narchlinux-\nversion\n.iso\nmust be located in the same directory.\nYou can also specify the signed data file with a second argument:\n$ gpg --verify archlinux-\nversion\n.iso.sig\n/path/to/\narchlinux-\nversion\n.iso\nIf a file has been encrypted in addition to being signed, simply\ndecrypt\nthe file and its signature will also be verified.\ngpg-agent\nThis article or section needs expansion.\nReason:\nDocument\nkeyboxd.socket\nand\nkeyboxd.service\n.\n[6]\n(Discuss in\nTalk:GnuPG\n)\ngpg-agent\nis mostly used as daemon to request and cache the password for the keychain. This is useful if GnuPG is used from an external program like a mail client.\ngnupg\ncomes with\nsystemd user\nsockets which are enabled by default. These sockets are\ngpg-agent.socket\n,\ngpg-agent-extra.socket\n,\ngpg-agent-browser.socket\n,\ngpg-agent-ssh.socket\n, and\ndirmngr.socket\n.\nThe main\ngpg-agent.socket\nis used by\ngpg\nto connect to the\ngpg-agent\ndaemon.\nThe intended use for the\ngpg-agent-extra.socket\non a local system is to set up a Unix domain socket forwarding from a remote system. This enables to use\ngpg\non the remote system without exposing the private keys to the remote system. See\ngpg-agent(1)\nfor details.\nThe\ngpg-agent-browser.socket\nallows web browsers to access the\ngpg-agent\ndaemon.\nThe\ngpg-agent-ssh.socket\ncan be used by\nSSH\nto cache\nSSH keys\nadded by the\nssh-add\nprogram. See\n#SSH agent\nfor the necessary configuration.\nThe\ndirmngr.socket\nstarts a GnuPG daemon handling connections to keyservers.\nNote\nIf you use non-default\nGnuPG home directory\n, you will need to\nedit\nthe\nListenStream\n(see\nsystemd.socket(5) § options\n) of all the socket files to be consistent with\ngpgconf --list-dirs\n. The socket names use the hash of the non-default GnuPG home directory\n[7]\n, so you can hardcode it without worrying about it changing.\nConfiguration\ngpg-agent can be configured via\n~/.gnupg/gpg-agent.conf\nfile. The configuration options are listed in\ngpg-agent(1)\n. For example you can change cache ttl for unused keys:\n~/.gnupg/gpg-agent.conf\ndefault-cache-ttl 3600\nTip\nTo cache your passphrase for the whole session, please run the following command:\n$ /usr/lib/gnupg/gpg-preset-passphrase --preset XXXXX\nwhere XXXXX is the keygrip. You can get its value when running\ngpg --with-keygrip --list-secret-keys\n. The passphrase will be stored until\ngpg-agent\nis restarted. If you set up\ndefault-cache-ttl\nvalue, it will take precedence.\nIt is necessary to allow this passphrase presetting by starting gpg-agent with the\n--allow-preset-passphrase\nor setting\nallow-preset-passphrase\nin\n~/.gnupg/gpg-agent.conf\n.\nReload the agent\nAfter changing the configuration, reload the agent using\ngpg-connect-agent\n:\n$ gpg-connect-agent reloadagent /bye\nThe command should print\nOK\n.\nHowever in some cases only the restart may not be sufficient, like when\nkeep-screen\nhas been added to the agent configuration.\nIn this case you firstly need to kill the ongoing gpg-agent process and then you can restart it as was explained above.\npinentry\ngpg-agent\ncan be configured via the\npinentry-program\nstanza to use a particular\npinentry\nuser interface when prompting the user for a passphrase. For example:\n~/.gnupg/gpg-agent.conf\npinentry-program /usr/bin/pinentry-curses\nThere are other pinentry programs that you can choose from - see\npacman -Ql pinentry | grep /usr/bin/\n. You may need to install the relevant\noptional dependencies\nfor your chosen pinentry program.\nTip\nThe pinentry programs\n/usr/bin/pinentry-gnome3\n(GNOME),\n/usr/bin/pinentry-qt\n,\n/usr/bin/pinentry-qt5\nand\n/usr/bin/pinentry-gtk\n(generic)\n[8]\nsupport the\nDBus Secret Service API\n, which allows for remembering passwords via a compliant manager such as\nGNOME Keyring\n,\nKeePassXC\nor\nKDE Wallet\n.\nAn alternative for\nKDE Wallet\nis\n/usr/bin/pinentry-kwallet\nwhich requires installing the\nkwalletcli\nAUR\npackage.\nNote\nWhen using\nKDE\n, the Secret Service API integration is disabled to\nprevent a deadlock\nin case\nKDE Wallet\nuses GnuPG encryption. If you use KDE Wallet with the classic, blowfish encrypted file instead, re-enable the Secret Service API integration by setting the\nenvironment variable\nPINENTRY_KDE_USE_WALLET\nto a non-empty value. If you installed\nKDE\nfrom the meta packages or package groups, you should already have\nkwallet-pam\ninstalled, in which case your\nKDE Wallet\nwas likely already created using blowfish encryption against your account password, so this\nenvironment variable\nshould be safe to use.\nRemember to\nreload the agent\nafter making changes to the configuration.\nCache passwords\nmax-cache-ttl\nand\ndefault-cache-ttl\ndefines how many seconds gpg-agent should cache the passwords. To enter a password once a session, set them to something very high, for instance:\ngpg-agent.conf\nmax-cache-ttl 60480000\ndefault-cache-ttl 60480000\nFor password caching in SSH emulation mode, set\ndefault-cache-ttl-ssh\nand\nmax-cache-ttl-ssh\ninstead, for example:\ngpg-agent.conf\ndefault-cache-ttl-ssh 60480000\nmax-cache-ttl-ssh 60480000\nUnattended passphrase\nStarting with GnuPG 2.1.0 the use of gpg-agent and pinentry is required, which may break backwards compatibility for passphrases piped in from STDIN using the\n--passphrase-fd 0\ncommandline option. In order to have the same type of functionality as the older releases two things must be done:\nFirst, edit the gpg-agent configuration to allow\nloopback\npinentry mode:\n~/.gnupg/gpg-agent.conf\nallow-loopback-pinentry\nReload the agent\nif it is running to let the change take effect.\nSecond, either the application needs to be updated to include a commandline parameter to use loopback mode like so:\n$ gpg --pinentry-mode loopback ...\n...or if this is not possible, add the option to the configuration:\n~/.gnupg/gpg.conf\npinentry-mode loopback\nNote\nThe upstream author indicates setting\npinentry-mode loopback\nin\ngpg.conf\nmay break other usage, using the commandline option should be preferred if at all possible.\n[9]\nSSH agent\ngpg-agent\nhas OpenSSH agent emulation. If you already use the GnuPG suite, you might consider using its agent to also cache your\nSSH keys\n.  Additionally, some users may prefer the PIN entry dialog GnuPG agent provides as part of its passphrase management.\nNote\nUsing\ngpg-agent\nin place of\nssh-agent\nwill not work if you use\ncoreutils-uutils\nAUR\n. It will always say\nCommunication with agent failed\nSet SSH_AUTH_SOCK\nSet\nthe following variables to communicate with\ngpg-agent\ninstead of the default\nssh-agent\n.\nSSH_AGENT_PID=\"\"\nSSH_AUTH_SOCK=\"${XDG_RUNTIME_DIR}/gnupg/S.gpg-agent.ssh\"\nNote\nIf you are using a script to manage your variables, you may also unset\nSSH_AGENT_PID\nrather than setting it to\n\"\"\n, via\nunset SSH_AGENT_PID\n.\nIf you set your\nSSH_AUTH_SOCK\nmanually, keep in mind that your socket location may be different if you are using a custom\nGNUPGHOME\n. You can use the following bash example, or change\nSSH_AUTH_SOCK\nto the value of\ngpgconf --list-dirs agent-ssh-socket\n.\nIf GNOME Keyring is installed, it is necessary to\ndeactivate\nits ssh component. Otherwise, it will overwrite\nSSH_AUTH_SOCK\n.\nAlternatively, depend on Bash. This works for non-standard socket locations as well:\n~/.bashrc\nunset SSH_AGENT_PID\nif [ \"${gnupg_SSH_AUTH_SOCK_by:-0}\" -ne $$ ]; then\nexport SSH_AUTH_SOCK=\"$(gpgconf --list-dirs agent-ssh-socket)\"\nfi\nNote\nThe test involving the\ngnupg_SSH_AUTH_SOCK_by\nvariable is for the case where the agent is started as\ngpg-agent --daemon /bin/sh\n, in which case the shell inherits the\nSSH_AUTH_SOCK\nvariable from the parent,\ngpg-agent\n[10]\n.\nConfigure pinentry to use the correct TTY\nAlso set the GPG_TTY and refresh the TTY in case user has switched into an X session as stated in\ngpg-agent(1)\n. For example:\n~/.bashrc\nexport GPG_TTY=$(tty)\ngpg-connect-agent updatestartuptty /bye >/dev/null\nIf you use multiple terminals simultaneously and want\ngpg-agent\nto ask for passphrase via\npinentry-curses\nfrom the same terminal where the\nssh\ncommand was run, add the following to the SSH configuration file. This will make the TTY to be refreshed every time an\nssh\ncommand is run\n[11]\n:\n~/.ssh/config\nMatch host * exec \"gpg-connect-agent UPDATESTARTUPTTY /bye\"\nNote that GPG_TTY environment variable has to be set for this to work.\nAdd SSH keys\nOnce\ngpg-agent\nis running you can use\nssh-add\nto approve keys, following the same steps as for\nssh-agent\n. The list of approved keys is stored in the\n~/.gnupg/sshcontrol\nfile.\nOnce your key is approved, you will get a\npinentry\ndialog every time your passphrase is needed. For password caching see\n#Cache passwords\n.\nUsing a PGP key for SSH authentication\nYou can also use your PGP key as an SSH key. This requires a key with the\nAuthentication\ncapability (see\n#Custom capabilities\n). There are various benefits gained by using a PGP key for SSH authentication, including:\nReduced key maintenance, as you will no longer need to maintain an SSH key.\nThe ability to store the authentication key on a smartcard. GnuPG will automatically detect the key when the card is available, and add it to the agent (check with\nssh-add -l\nor\nssh-add -L\n). The comment for the key should be something like:\nopenpgp:\nkey-id\nor\ncardno:\ncard-id\n.\nTo retrieve the public key part of your GPG/SSH key, run\ngpg --export-ssh-key\ngpg-key\n. If your key is authentication-capable but this command still fails with \"Unusable public key\", add a\n!\nsuffix (\n[12]\n).\nUnless you have your GPG key on a keycard, you need to add your key to\n$GNUPGHOME/sshcontrol\nto be recognized as a SSH key. If your key is on a keycard, its keygrip is added to\nsshcontrol\nimplicitly. If not, get the keygrip of your key this way:\n$ gpg --list-keys --with-keygrip\nsub   rsa4096 2018-07-25 [A]\nKeygrip =\n1531C8084D16DC4C36911F1585AF0ACE7AAFD7E7\nThen edit\nsshcontrol\nlike this. Adding the keygrip is a one-time action; you will not need to edit the file again, unless you are adding additional keys.\n$GNUPGHOME/sshcontrol\n1531C8084D16DC4C36911F1585AF0ACE7AAFD7E7\nForwarding gpg-agent and ssh-agent to remote\nThis article or section needs expansion.\nReason:\nWhat about setting\nForwardAgent yes\nas shown in\nOpenSSH#Agent forwarding\n? (Discuss in\nTalk:GnuPG\n)\nIt is possible to forward one's gpg-agent to a remote machine by forwarding gpg sockets to the remote machine, as explained by the\nGnuPG wiki\n.\nFirst, add the following line to\n/etc/ssh/sshd_config\non the remote machine to enable automatic removal of stale sockets on connect. Without this, the socket(s) on the remote machine will need to removed manually before connecting with forwarding enabled for agent forwarding to work:\n/etc/ssh/sshd_config\n...\nStreamLocalBindUnlink yes\n...\nNote\nYou will have to\nreload\nsshd.service\non the remote machine for the new configuration to be loaded by sshd.\nOn the client, use the\nRemoteForward\nSSH directive to forward traffic destined for a remote port, to a port on your local host. As described in\nssh_config(5) § RemoteForward\n, this directive's parameters are the listening socket path on the remote, and then the destination socket path on the local host. Your configuration should look something like this:\n~/.ssh/config\nHost\nremote_name\n...\nRemoteForward\nremote_agent_socket\nlocal_agent_extra_socket\nRemoteForward\nremote_agent_ssh_socket\nlocal_agent_ssh_socket\nThe first line configures gpg-agent forwarding:\nremote_agent_socket\nis the output of\ngpgconf --list-dir agent-socket\non the remote host.\nlocal_agent_extra_socket\nis\ngpgconf --list-dir agent-extra-socket\non the local host.\nThe second line is optional. It configures ssh-agent forwarding:\nremote_agent_ssh_socket\nis\ngpgconf --list-dir agent-ssh-socket\non the remote host.\nlocal_agent_ssh_socket\nis\ngpgconf --list-dir agent-ssh-socket\non the local host.\nNote\nIf using ssh-agent forwarding, the remote should have\nSSH_AUTH_SOCK\nset to the output of\ngpgconf --list-dir agent-ssh-socket\nas mentioned in\n#SSH agent\n).\nSo, with the default paths, it would be:\nRemoteForward /run/user/1000/gnupg/S.gpg-agent /run/user/1000/gnupg/S.gpg-agent.extra\nRemoteForward /run/user/1000/gnupg/S.gpg-agent.ssh /run/user/1000/gnupg/S.gpg-agent.ssh\nWith this configuration in place, invoking\nssh\nremote_name\nshould automatically forward the gpg-agent to the remote, and allow the use of your gpg key(s) for both decryption/signing (and allows the use of ssh-agent with gpg if the second\nRemoteForward\nline is included).\nSmartcards\nThis article or section needs expansion.\nReason:\nGnuPG 2.3+ has a\ngpg-card(1)\ntool. (Discuss in\nTalk:GnuPG\n)\nGnuPG uses\nscdaemon\nas an interface to your smartcard reader, please refer to the\nman page\nscdaemon(1)\nfor details.\nGnuPG's\ngpg-card\ntool can be used to configure\nscdaemon\nand serves as front-end for smartcard configuration, see\ngpg-card(1)\nfor details.\nWarning\nGnuPG 2.4.3 (and 2.2.42, 2.4.2 not packaged by Arch Linux) contained a security regression that may have retained a clear private key backup, if you used it to move a key to a smartcard with the\ngpg --edit-card\ncommand.\n[13]\nSee the\nGnuPG advisory\nfor information and remediation with\ngpg-card checkkeys\n.\nGnuPG only setups\nNote\nTo allow scdaemon direct access to USB smartcard readers the optional dependency\nlibusb-compat\nmust be installed\nIf you do not plan to use other cards but those based on GnuPG, you should check the\nreader-port\nparameter in\n~/.gnupg/scdaemon.conf\n. The value '0' refers to the first available serial port reader and a value of '32768' (default) refers to the first USB reader.\nGnuPG with pcscd (PCSC Lite)\npcscd(8)\nis a daemon which handles access to smartcard (SCard API). In earlier versions, if GnuPG's scdaemon failed to connect to the smartcard directly (e.g. by using its integrated CCID support), it fell back and tried to find a smartcard using the PCSC Lite driver.\nSince version 2.4\nhowever, you will have to add the\ndisable-ccid\noption in\n~/.gnupg/scdaemon.conf\n, to be able to use pcscd.\nTo use pscsd\ninstall\npcsclite\nand\nccid\n. Then\nstart\nand/or\nenable\npcscd.service\n. Alternatively start and/or enable\npcscd.socket\nto activate the daemon when needed.\nAlways use pcscd\nIf you are using any smartcard with an opensc driver (e.g.: ID cards from some countries) you should pay some attention to GnuPG configuration. Out of the box you might receive a message like this when using\ngpg --card-status\ngpg: selecting openpgp failed: ec=6.108\nBy default, scdaemon will try to connect directly to the device. This connection will fail if the reader is being used by another process. For example: the pcscd daemon used by OpenSC. To cope with this situation we should use the same underlying driver as opensc so they can work well together. In order to point scdaemon to use pcscd you should remove\nreader-port\nfrom\n~/.gnupg/scdaemon.conf\n, specify the location to\nlibpcsclite.so\nlibrary and disable ccid so we make sure that we use pcscd:\n~/.gnupg/scdaemon.conf\npcsc-driver /usr/lib/libpcsclite.so\ncard-timeout 5\ndisable-ccid\nPlease check\nscdaemon(1)\nif you do not use OpenSC.\nShared access with pcscd\nGnuPG\nscdaemon\nis the only popular\npcscd\nclient that uses\nPCSC_SHARE_EXCLUSIVE\nflag when connecting to\npcscd\n. Other clients like OpenSC PKCS#11 that are used by browsers and programs listed in\nElectronic identification\nare using\nPCSC_SHARE_SHARED\nthat allows simultaneous access to single smartcard.\npcscd\nwill not give exclusive access to smartcard while there are other clients connected. This means that to use GnuPG smartcard features you must before have to close all your open browser windows or do some other inconvenient operations.\nStarting from version 2.2.28 LTS and 2.3.0 you can enable shared access by modifying your\nscdaemon.conf\nfile and adding the line\npcsc-shared\nto the end of it. Keep in mind that\nscdaemon(1) § --pcsc-shared\ndescribes this flag as a \"somewhat dangerous option\" due to \"certain information being cached from the card\".\nMulti applet smart cards\nWhen using\nYubiKeys\nor other multi applet USB dongles with OpenSC PKCS#11 may run into problems where OpenSC switches your Yubikey from OpenPGP to PIV applet, breaking the\nscdaemon\n.\nYou can hack around the problem by forcing OpenSC to also use the OpenPGP applet. Open\n/etc/opensc.conf\nfile, search for Yubikey and change the\ndriver = \"PIV-II\";\nline to\ndriver = \"openpgp\";\n. If  there is no such entry, use\nopensc-tool --atr\nprovided by\nopensc\n. Search for the Answer to Reset\nATR: 12 34 56 78 90 AB CD ...\n. Then create a new\ncard_atr\nblock referencing your device ATR within the\napp\nblock.\n/etc/opensc.conf\napp default {\n...\ncard_atr 12:23:34:45:67:89:ab:cd:... {\nname = \"YubiKey Neo\";\ndriver = \"openpgp\"\n}\n}\n...\nAfter that you can test with\npkcs11-tool -O --login\nthat the OpenPGP applet is selected by default. Other PKCS#11 clients like browsers may need to be restarted for that change to be applied.\nUsing a smart card on a remote client\nIf for example you log into a machine via SSH or share a smart card to\nWSL\nvia\nusbipd-win\nand try to use an attached device via pcscd, you will notice errors such as:\ngpg: selecting card failed: No such device\ngpg: OpenPGP card not available: No such device\nThis is due to\nPolkit\nrestricting access to local clients. To fix this, you can add a rule to allow certain users in all cases. The below rule allows all users in the\nwheel\ngroup to access devices via\npcscd\n:\n/etc/polkit-1/rules.d/99-pcscd.rules\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.debian.pcsc-lite.access_card\" &&\nsubject.isInGroup(\"wheel\")) {\nreturn polkit.Result.YES;\n}\n});\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.debian.pcsc-lite.access_pcsc\" &&\nsubject.isInGroup(\"wheel\")) {\nreturn polkit.Result.YES;\n}\n});\nAfter creating the file, make sure to\nrestart\npolkit.service\n.\nOpenPGP compatibility\nGnuPG started out as an implementation of the\nOpenPGP\nformat. Currently, the project is based on\nRFC 4880\nand does not support\nRFC 9580\n(which supersedes RFC 4880).\nHowever, beginning with version 2.4.0 (from December 2022) GnuPG has opted to roll out changes and extensions to the format outside of the IETF process (see\ndraft-koch-librepgp\n).\nMost of the GnuPG-proprietary formats (which diverge from the\nOpenPGP standard\n) carry \"version 5\" (this version is not used in the IETF OpenPGP standard) and introduce incompatibilities:\nGnuPG \"version 5\" keys use different fingerprints (longer, due to the use of SHA-256).\nA new symmetrically encrypted data packet format (\nOCB Encrypted Data Packet\n) is added. Support for this format is signalled with a \"feature flag\" which is aggressively enabled by default. See\n#Disable unsupported AEAD mechanism\n.\nA new\nPost-Quantum Cryptography\nformat, again diverging from the IETF process (see\ndraft-ietf-openpgp-pqc\n).\nExternal reviews have raised concerns about the soundness of the format extensions by GnuPG (see\nA Summary of Known Security Issues in LibrePGP\n).\nSee\nA Critique on \"A Critique on the OpenPGP Updates\"\nfor a more in-depth discussion of concerns with regard to the GnuPG-specific format changes and\n\"Comparison of RFC 9580 and LibrePGP\"\nfor a detailed technical comparison.\nArch Linux's position is to prefer compatibility with the\nOpenPGP\nstandard.\nTo this end patches such as the one for\nreverting RFC4880bis by default\nare applied to the\ngnupg\npackage.\nThis ensures the longterm compatibility with other\nOpenPGP\nimplementations and avoids vendor lock-in by default.\nDisable unsupported AEAD mechanism\nWith\ngnupg\n2.4,\ngpg\ngenerates keys, which advertise support for a GnuPG specific\nAEAD\nencryption mechanism (based on\nOCB\n). However, this flavor of AEAD is not supported by other\nOpenPGP\nimplementations!\nAlthough many downstreams attempt to remove this new default by\npatching the GnuPG sources\n, when using\n--full-gen-key\nthe OCB based custom AEAD encryption mechanism is nonetheless set for the new key.\nWhether GnuPG's custom AEAD is set for a key can be inspected with the help of\ngpg\nitself:\n$ gpg --list-secret-keys --list-options=show-pref-verbose\nFINGERPRINT\n...\nuid           [ultimate] Archie <archie@archlinux.example>\nCipher: AES256, AES192, AES, 3DES\nAEAD:\nOCB\nDigest: SHA512, SHA384, SHA256, SHA224, SHA1\nCompression: ZLIB, BZIP2, ZIP, Uncompressed\nFeatures: MDC,\nAEAD\n, Keyserver no-modify\n...\nThis mechanism can be disabled:\n$ gpg --expert --edit-key\nFINGERPRINT\ngpg> setpref AES256 AES192 AES SHA512 SHA384 SHA256 SHA224 ZLIB BZIP2 ZIP\nSet preference list to:\nCipher: AES256, AES192, AES, 3DES\nAEAD:\nDigest: SHA512, SHA384, SHA256, SHA224, SHA1\nCompression: ZLIB, BZIP2, ZIP, Uncompressed\nFeatures: MDC, Keyserver no-modify\nReally update the preferences? (y/N) y\nTips and tricks\nDifferent algorithm\nYou may want to use stronger algorithms:\n~/.gnupg/gpg.conf\n...\npersonal-digest-preferences SHA512\ncert-digest-algo SHA512\ndefault-preference-list SHA512 SHA384 SHA256 SHA224 AES256 AES192 AES CAST5 ZLIB BZIP2 ZIP Uncompressed\npersonal-cipher-preferences TWOFISH CAMELLIA256 AES 3DES\nIn the latest version of GnuPG, the default algorithms used are SHA256 and AES, both of which are secure enough for most people. However, if you are using a version of GnuPG older than 2.1, or if you want an even higher level of security, then you should follow the above step.\nEncrypt a password\nIt can be useful to encrypt some password, so it will not be written in clear on a configuration file. A good example is your email password.\nFirst create a file with your password. You\nneed\nto leave\none\nempty line after the password, otherwise gpg will return an error message when evaluating the file.\nThen run:\n$ gpg -e -a -r\nuser-id\nyour_password_file\n-e\nis for encrypt,\n-a\nfor armor (ASCII output),\n-r\nfor recipient user ID.\nYou will be left with a new\nyour_password_file\n.asc\nfile.\nTip\npass\nautomates this process.\nChange trust model\nBy default GnuPG uses the\nWeb of Trust\nas the trust model. You can change this to\nTrust on first use\nby adding\n--trust-model=tofu\nwhen adding a key or adding this option to your GnuPG configuration file. More details are in\nthis email to the GnuPG list\n.\nHide all recipient id's\nBy default the recipient's key ID is in the encrypted message. This can be removed at encryption time for a recipient by using\nhidden-recipient\nuser-id\n. To remove it for all recipients add\nthrow-keyids\nto your configuration file. This helps to hide the receivers of the message and is a limited countermeasure against traffic analysis (i.e. using a little social engineering, anyone who is able to decrypt the message can check whether one of the other recipients is the one they suspect). On the receiving side, it may slow down the decryption process because all available secret keys must be tried (e.g. with\n--try-secret-key\nuser-id\n).\nUsing caff for keysigning parties\nTo allow users to validate keys on the keyservers and in their keyrings (i.e. make sure they are from whom they claim to be), PGP/GPG uses the\nWeb of Trust\n. Keysigning parties allow users to get together at a physical location to validate keys. The\nZimmermann-Sassaman\nkey-signing protocol is a way of making these very effective.\nHere\nyou will find a how-to article.\nFor an easier process of signing keys and sending signatures to the owners after a keysigning party, you can use the tool\ncaff\n. It can be installed from the AUR with the package\ncaff-git\nAUR\n.\nTo send the signatures to their owners you need a working\nMTA\n. If you do not have already one, install\nmsmtp\n.\nAlways show long ID's and fingerprints\nTo always show long key ID's add\nkeyid-format 0xlong\nto your configuration file. To always show full fingerprints of keys, add\nwith-fingerprint\nto your configuration file.\nCustom capabilities\nFor further customization also possible to set custom capabilities to your keys. The following capabilities are available:\nCertify (only for primary keys) - allows the key to create certifications that the User IDs on other keys are correct.\nSign - allows the key to create cryptographic signatures over data, that others can verify with the public key.\nEncrypt - allows anyone to encrypt data with the public key, that only the private key can decrypt.\nAuthenticate - allows the key to authenticate with various non-GnuPG programs. The key can be used as e.g. an SSH key.\nIt is possible to specify the capabilities of the primary key, by running:\n$ gpg --full-generate-key --expert\nWarning\nWhen using\n--full-generate-key\nthe generated key will advertise an AEAD mechanism, which is not understood by other\nOpenPGP\nimplementations. To disable this after key creation see\n#Disable unsupported AEAD mechanism\n.\nAnd select an option that allows you to set your own capabilities.\nComparably, to specify custom capabilities for subkeys, add the\n--expert\nflag to\ngpg --edit-key\n, see\n#Edit your key\nfor more information.\nTroubleshooting\nsu\nWhen using\npinentry\n, you must have the proper permissions of the terminal device (e.g.\n/dev/tty1\n) in use. However, with\nsu\n(or\nsudo\n), the ownership stays with the original user, not the new one. This means that pinentry will fail with a\nPermission denied\nerror, even as root. If this happens when attempting to use ssh, an error like\nsign_and_send_pubkey: signing failed: agent refused operation\nwill be returned. The fix is to change the permissions of the device at some point before the use of pinentry (i.e. using gpg with an agent). If doing gpg as root, simply change the ownership to root right before using gpg:\n# chown root $(tty)\nand then change it back after\nsu\n(or\nsudo\n) terminated.\nNote\nThe owner of tty\nmust\nmatch with the user for which pinentry is running. Being part of the group\ntty\nis not\nenough.\nTip\nIf you run gpg with\nscript\nit will use a new tty with the correct ownership:\n# script -q -c \"gpg --gen-key\" /dev/null\nAgent complains end of file\nIf the pinentry program is\n/usr/bin/pinentry-gnome3\n, it needs a DBus session bus to run properly. See\nGeneral troubleshooting#Session permissions\nfor details.\nAlternatively, you can use a variety of different options described in\n#pinentry\n.\nKGpg configuration permissions\nThere have been issues with\nkgpg\nbeing able to access the\n~/.gnupg/\noptions. One issue might be a result of a deprecated\noptions\nfile, see the\nbug\nreport.\nGNOME on Wayland overrides SSH agent socket\nFor Wayland sessions,\ngnome-session\nsets\nSSH_AUTH_SOCK\nto the standard gnome-keyring socket,\n$XDG_RUNTIME_DIR/keyring/ssh\n. This overrides any value set elsewhere.\nSee\nGNOME/Keyring#Disabling\non how to disable this behavior.\nmutt\nMutt might not use\ngpg-agent\ncorrectly, you need to set an\nenvironment variable\nGPG_AGENT_INFO\n(the content does not matter) when running mutt. Be also sure to enable password caching correctly, see\n#Cache passwords\n.\nSee\nthis forum thread\n.\n\"Lost\" keys, upgrading to gnupg version 2.1\nWhen\ngpg --list-keys\nfails to show keys that used to be there, and applications complain about missing or invalid keys, some keys may not have been migrated to the new format.\nPlease read\nGnuPG invalid packet workaround\n. Basically, it says that there is a bug with keys in the old\npubring.gpg\nand\nsecring.gpg\nfiles, which have now been superseded by the new\npubring.kbx\nfile and the\nprivate-keys-v1.d/\nsubdirectory and files.  Your missing keys can be recovered with the following commands:\n$ cd\n$ cp -r .gnupg gnupgOLD\n$ gpg --export-ownertrust > otrust.txt\n$ gpg --import .gnupg/pubring.gpg\n$ gpg --import-ownertrust otrust.txt\n$ gpg --list-keys\ngpg hanged for all keyservers (when trying to receive keys)\nIf gpg hanged with a certain keyserver when trying to receive keys, you might need to kill dirmngr in order to get access to other keyservers which are actually working, otherwise it might keeping hanging for all of them.\nSmartcard not detected\nYour user might not have the permission to access the smartcard which results in a\ncard error\nto be thrown, even though the card is correctly set up and inserted.\nOne possible solution is to add a new group\nscard\nincluding the users who need access to the smartcard.\nThen use\nudev rules\n, similar to the following:\n/etc/udev/rules.d/71-gnupg-ccid.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", ENV{ID_VENDOR_ID}==\"1050\", ENV{ID_MODEL_ID}==\"0116|0111\", MODE=\"660\", GROUP=\"scard\"\nOne needs to adapt VENDOR and MODEL according to the\nlsusb\noutput, the above example is for a YubikeyNEO.\nserver 'gpg-agent' is older than us (x < y)\nThis warning appears if\ngnupg\nis upgraded and the old gpg-agent is still running.\nRestart\nthe\nuser'\ns\ngpg-agent.socket\n(i.e., use the\n--user\nflag when restarting).\nIPC connect call failed\nMake sure\ngpg-agent\nand\ndirmngr\nare not running with\nkillall gpg-agent dirmngr\nand the\n$GNUPGHOME/crls.d/\nfolder has permission set to\n700\n.\nBy default, the\ngnupg\npackage uses the directory\n/run/user/$UID/gnupg/\nfor sockets.\nGnuPG documentation\nstates this is the preferred directory (not all file systems are supported for sockets). Validate that your\nagent-socket\nconfiguration specifies a path that has an appropriate file system. You can find your path settings for\nagent-socket\nby running\ngpgconf --list-dirs agent-socket\n.\nTest that\ngpg-agent\nstarts successfully with\ngpg-agent --daemon\n.\nMitigating Poisoned PGP Certificates\nIn June 2019, an unknown attacker spammed several high-profile PGP certificates with tens of thousands (or hundreds of thousands) of signatures (CVE-2019-13050) and uploaded these signatures to keyservers.\nThe existence of these poisoned certificates in a keyring causes gpg to hang with the following message:\ngpg: removing stale lockfile (created by 7055)\nPossible mitigation involves removing the poisoned certificate as per this\nblog post\n.\nInvalid IPC response and Inappropriate ioctl for device\nThe default pinentry program is\n/usr/bin/pinentry-gtk-2\n. If\ngtk2\nAUR\nis unavailable, pinentry falls back to\n/usr/bin/pinentry-curses\nand causes signing to fail:\ngpg: signing failed: Inappropriate ioctl for device\ngpg: [stdin]: clear-sign failed: Inappropriate ioctl for device\nYou need to set the\nGPG_TTY\nenvironment variable for the pinentry programs\n/usr/bin/pinentry-tty\nand\n/usr/bin/pinentry-curses\n.\n$ export GPG_TTY=$(tty)\nKeyblock resource does not exist\nIf you get an error like this when trying to import keys\ngpg: keyblock resource '\ngnupg_home\n/pubring.kbx': No such file or directory\nit is because GnuPG will not create its home directory if it does not yet exist. Simply create it manually\n$ mkdir -m 700\ngnupg_home\nSubkey is created with Restricted capability\nIn some cases creating a subkey with a custom set of capabilities results in the subkey marked as \"Restricted\". This happens in the\naddkey\ncommand with option 7 or 8 (\"set your own capabilities\") when the capabilities are toggled in the interactive prompt. A workaround is to enter the desired capability set directly as a string instead of toggling individual capabilities, when prompted with the capability selection. For example, enter \"=A\" to create a subkey with only the Authentication capability.\nSee also\nGNU Privacy Guard Homepage\nAlan Eliasen's GPG Tutorial\nRFC 4880\n— \"OpenPGP Message Format\"\ngpg.conf recommendations and best practices\nFedora:Creating GPG Keys\nDebian:Subkeys\nProtecting code integrity with PGP\nA more comprehensive gpg Tutorial\n/r/GPGpractice - a subreddit to practice using GnuPG.\nA Summary of Known Security Issues in LibrePGP\non blog.pgpkeys.eu\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=GnuPG&oldid=853688\n\"\nCategories\n:\nEncryption\nOpenPGP\nEmail\nGNU\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nGnuPG\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/GPG"}}
{"text": "SSH keys - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSSH keys\n2 languages\n日本語\n中文（简体）\nFrom ArchWiki\nThis article or section needs expansion.\nReason:\nThe intro and\nBackground\nsection ignore the server perspective. (Discuss in\nTalk:SSH keys#Server perspective is ignored\n)\nSSH keys can serve as a means of identifying yourself to an SSH server using\npublic-key cryptography\nand\nchallenge-response authentication\n. The major advantage of key-based authentication is that, in contrast to password authentication, it is not prone to\nbrute-force attacks\n, and you do not expose valid credentials if the server has been compromised (see\nRFC 4251 9.4.4\n).\nFurthermore, SSH key authentication can be more convenient than the more traditional password authentication. When used with a program known as an SSH agent, SSH keys can allow you to connect to a server, or multiple servers, without having to remember or enter your password for each system.\nKey-based authentication is not without its drawbacks and may not be appropriate for all environments, but in many circumstances it can offer some strong advantages. A general understanding of how SSH keys work will help you decide how and when to use them to meet your needs.\nThis article assumes you already have a basic understanding of the\nSecure Shell\nprotocol and have\ninstalled\nthe\nopenssh\npackage.\nBackground\nSSH keys are always generated in pairs with one known as the private key and the other as the public key.  The private key is known only to you and it should be safely guarded.   By contrast, the public key can be shared freely with any SSH server to which you wish to connect.\nIf an SSH server has your public key on file and sees you requesting a connection, it uses your public key to construct and send you a challenge.  This challenge is an encrypted message and it must be met with the appropriate response before the server will grant you access.  What makes this coded message particularly secure is that it can only be understood by the private key holder.  While the public key can be used to encrypt the message, it cannot be used to decrypt that very same message.  Only you, the holder of the private key, will be able to correctly understand the challenge and produce the proper response.\nThis\nchallenge-response\nphase happens behind the scenes and is invisible to the user.  As long as you hold the private key, which is typically stored in the\n~/.ssh/\ndirectory, your SSH client should be able to reply with the appropriate response to the server.\nA private key is a guarded secret and as such it is advisable to store it on disk in an encrypted form.  When the encrypted private key is required, a passphrase must first be entered in order to decrypt it.  While this might superficially appear as though you are providing a login password to the SSH server, the passphrase is only used to decrypt the private key on the local system.  The passphrase is not transmitted over the network.\nGenerating an SSH key pair\nAn SSH key pair can be generated by running the\nssh-keygen\ncommand, see the\nssh-keygen(1)\nman page for what is \"\ngenerally considered sufficient\n\" and should be compatible with virtually all clients and servers:\n$ ssh-keygen\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/home/\nusername\n/.ssh/id_ed25519):\nCreated directory '/home/\nusername\n/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /home/\nusername\n/.ssh/id_ed25519\nYour public key has been saved in /home/\nusername\n/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:RLy4JBv7jMK5qYhRKwHB3af0rpMKYwE2PBhALCBV3G8\nusername\n@\nhostname\nThe key's randomart image is:\n+--[ED25519 256]--+\n|%oooo. ..        |\n|== ..o.o.        |\n|==  . +o..       |\n|+ o o.ooE        |\n|...  *.oS        |\n| o..o ..         |\n|o=.. +o          |\n|+o*..+o          |\n|+.o+. .          |\n+----[SHA256]-----+\nThe\nrandomart image\nwas\nintroduced in OpenSSH 5.1\nas an easier means of visually identifying the key fingerprint.\nNote\nYou can use the\n-a\nswitch to specify the number of KDF rounds on the password encryption.\nYou can also add an optional comment field to the public key with the\n-C\nswitch, to more easily identify it in places such as\n~/.ssh/known_hosts\n,\n~/.ssh/authorized_keys\nand\nssh-add -L\noutput. For example:\n$ ssh-keygen -C \"$(whoami)@$(uname -n)-$(date -I)\"\nwill add a comment saying which user created the key on which machine and when.\nChoosing the authentication key type\nOpenSSH supports several signing algorithms (for authentication keys) which can be divided in two groups depending on the mathematical properties they exploit:\nEd25519\nand\nECDSA\n, which rely on the elliptic curve\ndiscrete logarithm\nproblem (ECDLP). (\nexample\n)\nRSA\n, which relies on the\npractical difficulty\nof factoring the product of two large prime numbers,\nElliptic curve cryptography\n(ECC) algorithms are a\nmore recent addition\nto public key cryptosystems. One of their main advantages is their ability to provide\nthe same level of security with smaller keys\n, which makes for less computationally intensive operations (\ni.e.\nfaster key creation, encryption and decryption) and reduced storage and transmission requirements.\nDSA keys are\ndeprecated\ndue to their security weaknesses and most SSH implementations do not support them anymore. Dropbear 2022.83 disabled DSA key support while OpenSSH 10.0 and libssh 0.11.0 removed support for DSA keys entirely. Therefore the choice of\ncryptosystem\nlies within RSA or one of the two types of ECC.\nThe default Ed25519 will give you the best security and good performance. ECDSA is slower than Ed25519, but faster than RSA; concerns exist about its security (see below). RSA keys will give you the greatest compatibility with old servers, but it requires a larger key size to provide sufficient security.\nNote\nThese keys are used only to authenticate you; choosing stronger keys will not increase CPU load when transferring data over SSH.\nTip\nTo protect SSH keys against exfiltration from the machine, it is possible to store them in\nFIDO/U2F hardware authenticators\nor\nTrusted Platform Modules\n.\nEd25519 and ECDSA keys can be stored in FIDO/U2F hardware authenticators by using the special \"security key\" key types when generating the keys. See\n#FIDO/U2F\n.\nECDSA and RSA are supported by Trusted Platform Modules making it possible to seal SSH keys inside the TPM. See\nTrusted Platform Module#SSH\n.\nEd25519\nEd25519\nwas introduced in\nOpenSSH 6.5\nof January 2014: \"\nEd25519 is an elliptic curve signature scheme that offers better security than ECDSA and DSA and good performance\n\". Its main strengths are its speed, its constant-time run time (and resistance against side-channel attacks), and its lack of nebulous hard-coded constants.\n[1]\nSee also\nthis blog post\nby a Mozilla developer on how it works.\nIt is implemented in\nmany applications and libraries\nand is the default key type in\nssh-keygen(1)\nand\ndropbearkey(1)\n.\nssh-keygen(1)\ndefaults to Ed25519 therefore there is no need to specify it with the\n-t ed25519\noption. The key pairs can be simply generated with:\n$ ssh-keygen\nThere is no need to set the key size, as all Ed25519 keys are 256 bits.\nKeep in mind that ancient SSH clients and servers may not support these keys.\nECDSA\nThe Elliptic Curve Digital Signature Algorithm (ECDSA) was the preferred algorithm for authentication (key exchange algorithm) from\nOpenSSH 5.7\n(2011-01-24) to OpenSSH 6.5 (2014-01-30).\nThere are two sorts of concerns with it:\nPolitical concerns\n, the trustworthiness of NIST-produced curves\nbeing questioned\nafter revelations that the NSA willingly inserts backdoors into softwares, hardware components and published standards were made; well-known cryptographers\nhave\nexpressed\ndoubts\nabout how the NIST curves were designed, and voluntary tainting has already\nbeen\nproven\nin the past.\nTechnical concerns\n, about the\ndifficulty to properly implement the standard\nand the\nslowness and design flaws\nwhich reduce security in insufficiently precautious implementations.\nBoth of those concerns are best summarized in\nlibssh curve25519 introduction\n. Although the political concerns will always be subject to debate, there is a\nclear consensus\nthat\n#Ed25519\nis technically superior and should therefore be preferred.\nECDSA key pairs can be generated with:\n$ ssh-keygen -t ecdsa\nThree elliptic curve sizes are supported for ECDSA keys: 256, 384 and 521 bits. The default is 256 bits. If you wish to generate a stronger ECDSA key pair, simply specify the\n-b\noption:\n$ ssh-keygen -t ecdsa -b 384\nRSA\nRSA provides the best compatibility of all algorithms but requires the key size to be larger to provide sufficient security. Minimum key size is 1024 bits, default is 3072 (see\nssh-keygen(1)\n) and maximum is 16384.\nRSA key pairs can be generated with:\n$ ssh-keygen -t rsa\nIf you wish to generate a stronger RSA key pair (\ne.g.\nto guard against cutting-edge or unknown attacks and more sophisticated attackers), simply specify the\n-b\noption with a higher bit value than the default:\n$ ssh-keygen -t rsa -b 4096\nBe aware though that there are diminishing returns in using longer keys.\n[2]\n[3]\nThe GnuPG FAQ reads: \"\nIf you need more security than RSA-2048 offers, the way to go would be to switch to elliptical curve cryptography — not to continue using RSA\n.\"\n[4]\nOn the other hand, the latest iteration of the\nNSA Fact Sheet Suite B Cryptography\nsuggests a minimum 3072-bit modulus for RSA while \"\n[preparing] for the upcoming quantum resistant algorithm transition\n\".\n[5]\nFIDO/U2F\nFIDO/\nU2F\nhardware authenticator\nsupport was added in\nOpenSSH version 8.2\nfor both of the elliptic curve signature schemes mentioned above. It allows for a hardware token attached via USB or other means to act a second factor alongside the private key.\nThe\nlibfido2\nis required for hardware token support.\nNote\nBoth the client and server must support the\ned25519-sk\nand\necdsa-sk\nkey types.\nOpenSSH uses a middleware library to communicate with the hardware token and comes with an internal middleware which supports USB tokens. Other middleware may be specified by the\nsshd_config(5) § SecurityKeyProvider\ndirective or the\nSSH_SK_PROVIDER\nenvironment variable for\nssh-keygen\nand\nssh-add\n.\nAfter attaching a compatible FIDO key, a key pair may be generated with:\n$ ssh-keygen -t ed25519-sk\nYou will usually be required to enter your PIN and/or tap your token to confirm the generation.\nresident\nBy default, the generated SSH key consist of two parts: a key handle on disk, and a private key that is unique for each security key. To easily move your FIDO key between machines, generate a key with the\nssh-keygen(1) § resident\noption,\n-O resident\n. This indicates \"that the key handle should be stored on the FIDO authenticator itself.\"\n[6]\n$ ssh-keygen -O resident -t ed25519-sk\nAfterwards, on a new machine, the key can be downloaded using\nssh-keygen(1) § K\n$ ssh-keygen -K\nno-touch-required\nConnecting to a server will usually require tapping your token unless the\n-O no-touch-required\ncommand line option is used during generation and the\nsshd(8) § no-touch-required\nauthorized_keys\noption is set on the server.\nTo create keys that do not require touch events, generate a key pair with the\nno-touch-required\noption. For example:\n$ ssh-keygen -O no-touch-required -t ed25519-sk\nNote\nNot all hardware tokens support this option. If you are using a YubiKey, firmware version 5.2.3 is needed for the ed25519-sk key type.\n[7]\nAdditionally,\nsshd\nrejects\nno-touch-required\nkeys by default. To allow keys generated with this option, either enable it for an individual key in the\nauthorized_keys\nfile:\n~/.ssh/authorized_keys\nno-touch-required sk-ssh-ed25519@openssh.com AAAAInN... user@example.com\nOr for the whole system by editing\n/etc/ssh/sshd_config\nwith:\nPubkeyAuthOptions none\nTip\nGitHub\nand\nGitLab\ndo not support\nno-touch-required\n.\nAn ECDSA-based keypair may also be generated with the\necdsa-sk\nkeytype, but the relevant concerns in the\n#ECDSA\nsection above still apply.\n$ ssh-keygen -t ecdsa-sk\nChoosing the key location and passphrase\nUpon issuing the\nssh-keygen\ncommand, you will be prompted for the desired name and location of your private key.  By default, keys are stored in the\n~/.ssh/\ndirectory and named according to the type of encryption used.  You are advised to accept the default name and location in order for later code examples in this article to work properly.\nWhen prompted for a passphrase, choose something that will be hard to guess if you have the security of your private key in mind.  A longer, more random password will generally be stronger and harder to crack should it fall into the wrong hands.\nIt is also possible to create your private key without a passphrase.  While this can be convenient, you need to be aware of the associated risks.  Without a passphrase, your private key will be stored on disk in an unencrypted form.  Anyone who gains access to your private key file will then be able to assume your identity on any SSH server to which you connect using key-based authentication.  Furthermore, without a passphrase, you must also trust the root user, as they can bypass file permissions and will be able to access your unencrypted private key file at any time.\nNote\nPreviously, the private key password was encoded in an insecure way: only a single round of an MD5 hash. OpenSSH 6.5 and later support a new, more secure format to encode your private key. This format is the default since\nOpenSSH version 7.8\n. Ed25519 keys have always used the new encoding format. To upgrade to the new format, simply change the key's passphrase, as described in the next section.\nChanging the private key's passphrase without changing the key\nIf the originally chosen SSH key passphrase is undesirable or must be changed, one can use the\nssh-keygen\ncommand to change the passphrase without changing the actual key. This can also be used to change the password encoding format to the new standard.\n$ ssh-keygen -f ~/.ssh/id_rsa -p\nManaging multiple keys\nIf you have multiple SSH identities, you can set different keys to be used for different hosts or remote users by using the\nHost\nand\nIdentityFile\ndirectives in your configuration:\n~/.ssh/config\nHost SERVER1\nIdentitiesOnly yes\nIdentityFile ~/.ssh/id_rsa_IDENTITY1\nHost SERVER2 SERVER3\nIdentitiesOnly yes\nIdentityFile ~/.ssh/id_ed25519_IDENTITY2\nSee\nssh_config(5)\nfor full description of these options.\nStoring SSH keys on hardware tokens\nSSH keys can also be stored on a security token like a smart card or a USB token. This has the advantage that the private key is stored securely on the token instead of being stored on disk. When using a security token the sensitive private key is also never present in the RAM of the PC; the cryptographic operations are performed on the token itself. A cryptographic token has the additional advantage that it is not bound to a single computer; it can easily be removed from the computer and carried around to be used on other computers.\nExamples of hardware tokens are described in:\n#FIDO/U2F\nYubiKey#SSH notes\nNative OpenSSH support for FIDO/U2F keys\nYubiKey#SSH keys\nTrusted Platform Module#SSH\nCopying the public key to the remote server\nThis article or section needs expansion.\nReason:\nHow to do this if you\nforce public key authentication\n? (Discuss in\nTalk:SSH keys\n)\nOnce you have generated a key pair, you will need to copy the public key to the remote server so that it will use SSH key authentication.  The public key file shares the same name as the private key except that it is appended with a\n.pub\nextension.  Note that the private key is not shared and remains on the local machine.\nSimple method\nIf your key file is\n~/.ssh/id_rsa.pub\nyou can simply enter the following command.\n$ ssh-copy-id remote-server.org\nIf your username differs on remote machine, be sure to prepend the username followed by\n@\nto the server name.\n$ ssh-copy-id username@remote-server.org\nIf your public key filename is anything other than the default of\n~/.ssh/id_rsa.pub\nyou will get an error stating\n/usr/bin/ssh-copy-id: ERROR: No identities found\n. In this case, you must explicitly provide the location of the public key.\n$ ssh-copy-id -i ~/.ssh/id_ed25519.pub username@remote-server.org\nIf the ssh server is listening on a port other than default of 22, be sure to include it within the host argument.\n$ ssh-copy-id -i ~/.ssh/id_ed25519.pub -p 221 username@remote-server.org\nManual method\nBy default, for OpenSSH, the public key needs to be concatenated with\n~/.ssh/authorized_keys\n.  Begin by copying the public key to the remote server.\n$ scp ~/.ssh/id_ecdsa.pub username@remote-server.org\n:\nThe above example copies the public key (\nid_ecdsa.pub\n) to your home directory on the remote server via\nscp\n.  Do not forget to include the\n:\nat the end of the server address.  Also note that the name of your public key may differ from the example given.\nOn the remote server, you will need to create the\n~/.ssh\ndirectory if it does not yet exist and append your public key to the\nauthorized_keys\nfile.\n$ ssh username@remote-server.org\nusername@remote-server.org's password:\n$ install -dm700 ~/.ssh\n$ cat ~/id_ecdsa.pub >> ~/.ssh/authorized_keys\n$ rm ~/id_ecdsa.pub\n$ chmod 600 ~/.ssh/authorized_keys\nThe last two commands remove the public key file from the server and set the permissions on the\nauthorized_keys\nfile such that it is only readable and writable by you, the owner.\nSSH agents\nIf your private key is encrypted with a passphrase, this passphrase must be entered every time you attempt to connect to an SSH server using public-key authentication.  Each individual invocation of\nssh\nor\nscp\nwill need the passphrase in order to decrypt your private key before authentication can proceed.\nAn SSH agent is a program which caches your decrypted private keys and provides them to SSH client programs on your behalf.  In this arrangement, you must only provide your passphrase once, when adding your private key to the agent's cache.   This facility can be of great convenience when making frequent SSH connections.\nAn agent is typically configured to run automatically upon login and persist for the duration of your login session.  A variety of agents, front-ends, and configurations exist to achieve this effect.  This section provides an overview of a number of different solutions which can be adapted to meet your specific needs.\nssh-agent\nssh-agent\nis the default agent included with OpenSSH.  It can be used directly or serve as the back-end to a few of the front-end solutions mentioned later in this section.  When\nssh-agent\nis run, it forks to background and prints necessary environment variables. E.g.\n$ ssh-agent\nSSH_AUTH_SOCK=/tmp/ssh-vEGjCM2147/agent.2147; export SSH_AUTH_SOCK;\nSSH_AGENT_PID=2148; export SSH_AGENT_PID;\necho Agent pid 2148;\nTo make use of these variables, run the command through the\neval\ncommand. Use\nssh-agent -c\ninstead if using the\nfish\nshell.\n$ eval $(ssh-agent)\nAgent pid 2157\nOnce\nssh-agent\nis running, you will need to add your private key to its cache:\n$ ssh-add ~/.ssh/id_ed25519\nEnter passphrase for /home/user/.ssh/id_ed25519:\nIdentity added: /home/user/.ssh/id_ed25519 (/home/user/.ssh/id_ed25519)\nIf your private key is encrypted,\nssh-add\nwill prompt you to enter your passphrase.  Once your private key has been successfully added to the agent you will be able to make SSH connections without having to enter your passphrase.\nTip\nTo make all\nssh\nclients (including\ngit\n) store keys in the agent on first use, add the configuration setting\nAddKeysToAgent yes\nto\n~/.ssh/config\n. See\nssh_config(5) § AddKeysToAgent\nfor other possible values.\nIn order to start the agent automatically and make sure that only one\nssh-agent\nprocess runs at a time,\ntouch $XDG_RUNTIME_DIR/ssh-agent.env\nand add the following to your\n~/.bashrc\n:\nif ! pgrep -u \"$USER\" ssh-agent > /dev/null; then\nssh-agent -t 1h > \"$XDG_RUNTIME_DIR/ssh-agent.env\"\nfi\nif [ ! -f \"$SSH_AUTH_SOCK\" ]; then\nsource \"$XDG_RUNTIME_DIR/ssh-agent.env\" >/dev/null\nfi\nThis will run an\nssh-agent\nprocess if there is not one already, and save the output thereof. If there is one running already, we retrieve the cached\nssh-agent\noutput and evaluate it which will set the necessary environment variables. The lifetime of the unlocked keys is set to 1 hour.\nThere also exist a number of front-ends to\nssh-agent\nand alternative agents described later in this section which avoid this problem.\nStart ssh-agent with systemd user\nIf you would like your ssh agent to run when you are logged in, regardless of whether X is running, a handy\nssh-agent.service\nis included in\nopenssh\nsince the version 9.4p1-3, which can be\nenabled\nas a\nuser unit\n.\nThen\nset the environment variable\nSSH_AUTH_SOCK\nto\n$XDG_RUNTIME_DIR/ssh-agent.socket\n.\nNote\nIf you use GNOME, this environment variable is overridden by default. See\nGNOME/Keyring#Disabling\n.\nForwarding ssh-agent\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThis is not specific to ssh-agent, e.g. gpg-agent uses the same environment variable:\nGnuPG#Forwarding gpg-agent and ssh-agent to remote\n(Discuss in\nTalk:SSH keys\n)\nWhen\nforwarding\na local\nssh-agent\nto remote (e.g., through command-line argument\nssh -A remote\nor through\nForwardAgent yes\nin the configuration file), it is important for the remote machine not to overwrite the environment variable\nSSH_AUTH_SOCK\n. So if the remote machine uses a\nsystemd unit\nshown previously to start the agent,\nSSH_AUTH_SOCK\nmust not be set in the environment when a user is logged in through SSH. Otherwise, the forwarding may fail, and you may see errors (for example:\nThe agent has no identities\n) when checking the existing keys with\nssh-add -l\non the remote machine.\nFor example, if using bash, the\n.bashrc\ncould be something like:\n~/.bashrc\n...\nif [[ -z \"${SSH_CONNECTION}\" ]]; then\nexport SSH_AUTH_SOCK=\"$XDG_RUNTIME_DIR/ssh-agent.socket\"\nfi\n...\nIn this way,\nSSH_AUTH_SOCK\nis only set when the current session is\nnot\nan SSH login. And when this is a SSH session,\nSSH_AUTH_SOCK\non the remote machine is then set by the local machine to make the forwarding work.\nssh-agent as a wrapper program\nAn alternative way to start ssh-agent (with, say, each X session) is described in\nthis ssh-agent tutorial by UC Berkeley Labs\n. A basic use case is if you normally begin X with the\nstartx\ncommand, you can instead prefix it with\nssh-agent\nlike so:\n$ ssh-agent startx\nAnd so you do not even need to think about it you can put an alias in your\n.bash_aliases\nfile or equivalent:\nalias startx='ssh-agent startx'\nDoing it this way avoids the problem of having extraneous\nssh-agent\ninstances floating around between login sessions. Exactly one instance will live and die with the entire X session.\nNote\nssh-askpass\nrequires the\nDISPLAY\nor\nWAYLAND_DISPLAY\nenvironment variable to work, so you may want to run\nssh-agent\nin\n~/.xinitrc\ninstead of\nssh-agent startx\n, where\nDISPLAY\nis set. For example, you can add\nexec ssh-agent dbus-launch i3\nto\n~/.xinitrc\n. Or as an alternative to using\nssh-agent\nas a wrapper program, you can add\neval $(ssh-agent)\nto\n~/.xinitrc\n.\nSee\nthe notes on using x11-ssh-askpass with ssh-add\nfor an idea on how to immediately add your key to the agent.\nOpenPGP card ssh-agent\nThis ssh-agent specializes on\nOpenPGP\ncard integration. It uses private keys that are stored in\nOpenPGP\ncard authentication slots.\nNote\nWhen also using\nGnuPG\nwhile running this agent, it is required to\nuse it with pcscd\nand configure\nshared access with pcscd\n.\nInstall\nopenpgp-card-ssh-agent\nand\nenable\nand\nstart\nthe\nopenpgp-card-ssh-agent.socket\nuser unit.\nAfterwards add the relevant\nenvironment variable\nfor this agent:\nSSH_AUTH_SOCK=\"$XDG_RUNTIME_DIR/openpgp-card/ssh-agent.sock\"\nUser PIN handling\nThe user PIN for the\nOpenPGP\ncard is persisted via an\norg.freedesktop.secrets\nprovider (such as\nGNOME Keyring\n,\nKeePassXC\nor\nKDE Wallet\n) by default. The PIN storage backend is\nconfigurable and extendable\n.\nThe user PIN needs to be persisted only once for each\nOpenPGP\ncard. Prior to the first SSH connection with this agent, list the available SSH public keys and add their respective card identifiers:\n$ ssh-add -L\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIJUz6VnFprMe33G88Pq8NLw3wnIKOsBg0CDrwFeUVrU6\nFFFE:01234567\n$ ssh-add -s\nFFFE:01234567\nEnter passphrase for PKCS#11:\nNote\nThe prompt mentions\nPKCS#11\nas it is a hardcoded message in\nssh-add(1)\n. However, in this context the OpenPGP card user PIN must be entered.\nGnuPG Agent\nThe\ngpg-agent\nhas OpenSSH Agent protocol emulation. See\nGnuPG#SSH agent\nfor necessary configuration.\nKeychain\nKeychain\nis a program designed to help you easily manage your SSH keys with minimal user interaction. It is implemented as a shell script which drives both\nssh-agent\nand\nssh-add\n. A notable feature of Keychain is that it can maintain a single\nssh-agent\nprocess across multiple login sessions. This means that you only need to enter your passphrase once each time your local machine is booted.\nInstallation\nInstall\nthe\nkeychain\npackage.\nConfiguration\nWarning\nAs of 2015-09-26, the\n-Q, --quick\noption has the unexpected side-effect of making\nkeychain\nswitch to a newly-spawned\nssh-agent\nupon relogin (at least on systems using\nGNOME\n), forcing you to re-add all the previously registered keys.\nAdd a line similar to the following to your\nshell\nconfiguration file,\ne.g.\nif using\nBash\n:\n~/.bashrc\neval $(keychain --eval --quiet id_ed25519 id_rsa ~/.keys/my_custom_key)\nNote\n~/.bashrc\nis used instead of the upstream suggested\n~/.bash_profile\nbecause on Arch it is sourced by both login and non-login shells, making it suitable for textual and graphical environments alike. See\nBash#Invocation\nfor more information on the difference between those.\nIn the above example,\nthe\n--eval\nswitch outputs lines to be evaluated by the opening\neval\ncommand; this sets the necessary environment variables for an SSH client to be able to find your agent.\nthe\n--eval\nswitch generates the commands for the shell specified in the\nSHELL\nenvironent variable. It might save you some trouble to specify it for the command using e.g.\nSHELL=/bin/bash\nbefore the\nkeychain\ncommand.\n--quiet\nwill limit output to warnings, errors, and user prompts.\nMultiple keys can be specified on the command line, as shown in the example. By default keychain will look for key pairs in the\n~/.ssh/\ndirectory, but absolute path can be used for keys in non-standard location. You may also use the\n--confhost\noption to inform keychain to look in\n~/.ssh/config\nfor\nIdentityFile\nsettings defined for particular hosts, and use these paths to locate keys.\nSee\nkeychain --help\nor\nkeychain(1)\nfor details on setting\nkeychain\nfor other shells.\nTo test Keychain, simply open a new terminal emulator or log out and back in your session. It should prompt you for the passphrase of the specified private key(s) (if applicable), either using the program set in\n$SSH_ASKPASS\nor on the terminal.\nBecause Keychain reuses the same\nssh-agent\nprocess on successive logins, you should not have to enter your passphrase the next time you log in or open a new terminal. You will only be prompted for your passphrase once each time the machine is rebooted.\nTips\nkeychain\nexpects public key files to exist in the same directory as their private counterparts, with a\n.pub\nextension. If the private key is a symlink, the public key can be found alongside the symlink or in the same directory as the symlink target (this capability requires the\nreadlink\ncommand to be available on the system).\nTo disable the graphical prompt and always enter your passphrase on the terminal, use the\n--nogui\noption. This allows to copy-paste long passphrases from a password manager for example.\nIf you do not want to be immediately prompted for unlocking the keys but rather wait until they are needed, use the\n--noask\noption.\nNote\nKeychain is able to manage\nGPG\nkeys in the same fashion. For keychain versions up to 2.9.0 the default is to attempt to start\nssh-agent\nonly, but you can modify this behavior using the\n--agents\noption,\ne.g.\n--agents ssh,gpg\n. See\nkeychain(1)\n.\nAs of Keychain 2.9.0, the\n--agents\noption is deprecated. See\nkeychain(1)\n.\nIf you are on Wayland, you might have to add\n--inherit any-once\nas per\nkeychain issue 148\n.\nx11-ssh-askpass\nThe\nx11-ssh-askpass\npackage provides a graphical dialog for entering your passhrase when running an X session.\nx11-ssh-askpass\ndepends only on the\nlibx11\nand\nlibxt\nlibraries, and the appearance of\nx11-ssh-askpass\nis customizable. While it can be invoked by the\nssh-add\nprogram, which will then load your decrypted keys into\nssh-agent\n, the following instructions will, instead, configure\nx11-ssh-askpass\nto be invoked by the aforementioned\nKeychain\nscript.\nInstall the\nkeychain\nand\nx11-ssh-askpass\npackages.\nEdit your\n~/.xinitrc\nfile to include the following lines, replacing the name and location of your private key if necessary. Be sure to place these commands\nbefore\nthe line which invokes your window manager.\n~/.xinitrc\nkeychain ~/.ssh/id_ecdsa\n[ -f ~/.keychain/$HOSTNAME-sh ] && . ~/.keychain/$HOSTNAME-sh 2>/dev/null\n[ -f ~/.keychain/$HOSTNAME-sh-gpg ] && . ~/.keychain/$HOSTNAME-sh-gpg 2>/dev/null\n...\nexec openbox-session\nIn the above example, the first line invokes\nkeychain\nand passes the name and location of your private key. If this is not the first time\nkeychain\nwas invoked, the following two lines load the contents of\n$HOSTNAME-sh\nand\n$HOSTNAME-sh-gpg\n, if they exist. These files store the environment variables of the previous instance of\nkeychain\n.\nCalling x11-ssh-askpass with ssh-add\nThe\nssh-add\nmanual page specifies that, in addition to needing the\nDISPLAY\nor\nWAYLAND_DISPLAY\nvariable defined, you also need\nSSH_ASKPASS\nset to the name of your askpass program (in this case\nx11-ssh-askpass\n). It bears keeping in mind that the default Arch Linux installation places the\nx11-ssh-askpass\nbinary in\n/usr/lib/ssh/\n, which will not be in most people's\nPATH\n. This is a little annoying, not only when declaring the\nSSH_ASKPASS\nvariable, but also when theming. You have to specify the full path everywhere. Both inconveniences can be solved simultaneously by symlinking:\n$ ln -sv /usr/lib/ssh/x11-ssh-askpass ~/bin/ssh-askpass\nThis is assuming that\n~/bin\nis in your\nPATH\n. So now in your\n.xinitrc\n, before calling your window manager, one just needs to export the\nSSH_ASKPASS\nenvironment variable:\n$ export SSH_ASKPASS=ssh-askpass\nand your\nX resources\nwill contain something like:\nssh-askpass*background: #000000\nDoing it this way works well with\nthe above method on using\nssh-agent\nas a wrapper program\n. You start X with\nssh-agent startx\nand then add\nssh-add\nto your window manager's list of start-up programs.\nTheming\nThe appearance of the\nx11-ssh-askpass\ndialog can be customized by setting its associated\nX resources\n. Some examples are the .ad files at\nhttps://github.com/sigmavirus24/x11-ssh-askpass\n. See\nx11-ssh-askpass(1)\nfor full details.\nAlternative passphrase dialogs\nThere are other passphrase dialog programs which can be used instead of\nx11-ssh-askpass\n. The following list provides some alternative solutions.\nseahorse\n(provides\n/usr/lib/seahorse/ssh-askpass\n) uses the\nGTK\nlibrary.\ngnome-ssh-askpass3\nAUR\nuses the\nGTK\nlibrary.\nksshaskpass\nuses the\nKDE Wallet\n.\nopenssh-askpass\nAUR\nuses the\nQt5\nlibrary.\nlxqt-openssh-askpass\npam_ssh\nThe\npam_ssh\nproject exists to provide a\nPluggable Authentication Module\n(PAM) for SSH private keys.  This module can provide single sign-on behavior for your SSH connections.  On login, your SSH private key passphrase can be entered in place of, or in addition to, your traditional system password.  Once you have been authenticated, the pam_ssh module spawns ssh-agent to store your decrypted private key for the duration of the session.\nTo enable single sign-on behavior at the tty login prompt, install the unofficial\npam_ssh\nAUR\npackage.\nNote\npam_ssh 2.0 now requires that all private keys used in the authentication process be located under\n~/.ssh/login-keys.d/\n.\nCreate a symlink to your private key file and place it in\n~/.ssh/login-keys.d/\n.  Replace the\nid_rsa\nin the example below with the name of your own private key file.\n$ mkdir ~/.ssh/login-keys.d/\n$ cd ~/.ssh/login-keys.d/\n$ ln -s ../id_rsa\nEdit the\n/etc/pam.d/login\nconfiguration file to include the text highlighted in bold in the example below.  The order in which these lines appear is significiant and can affect login behavior.\nWarning\nMisconfiguring PAM can leave the system in a state where all users become locked out.  Before making any changes, you should have an understanding of how PAM configuration works as well as a backup means of accessing the PAM configuration files, such as an Arch Live CD, in case you become locked out and need to revert any changes.  An IBM developerWorks\narticle\nis available which explains PAM configuration in further detail.\n/etc/pam.d/login\n#%PAM-1.0\nauth       required     pam_securetty.so\nauth       requisite    pam_nologin.so\nauth       include      system-local-login\nauth       optional     pam_ssh.so        try_first_pass\naccount    include      system-local-login\nsession    include      system-local-login\nsession    optional     pam_ssh.so\nIn the above example, login authentication initially proceeds as it normally would, with the user being prompted to enter their user password.  The additional\nauth\nauthentication rule added to the end of the authentication stack then instructs the pam_ssh module to try to decrypt any private keys found in the\n~/.ssh/login-keys.d\ndirectory.  The\ntry_first_pass\noption is passed to the pam_ssh module, instructing it to first try to decrypt any SSH private keys using the previously entered user password.  If the user's private key passphrase and user password are the same, this should succeed and the user will not be prompted to enter the same password twice.  In the case where the user's private key passphrase user password differ, the pam_ssh module will prompt the user to enter the SSH passphrase after the user password has been entered.  The\noptional\ncontrol value ensures that users without an SSH private key are still able to log in.  In this way, the use of pam_ssh will be transparent to users without an SSH private key.\nIf you use another means of logging in, such as an X11 display manager like\nSLiM\nor\nXDM\nand you would like it to provide similar functionality, you must edit its associated PAM configuration file in a similar fashion.  Packages providing support for PAM typically place a default configuration file in the\n/etc/pam.d/\ndirectory.\nFurther details on how to use pam_ssh and a list of its options can be found in the\npam_ssh(8)\nman page.\nUsing a different password to unlock the SSH key\nIf you want to unlock the SSH keys or not depending on whether you use your key's passphrase or the (different!) login password, you can modify\n/etc/pam.d/system-auth\nto\n/etc/pam.d/system-auth\n#%PAM-1.0\nauth      [success=1 new_authtok_reqd=1 ignore=ignore default=ignore]  pam_unix.so     try_first_pass nullok\nauth      required  pam_ssh.so      use_first_pass\nauth      optional  pam_permit.so\nauth      required  pam_env.so\naccount   required  pam_unix.so\naccount   optional  pam_permit.so\naccount   required  pam_time.so\npassword  required  pam_unix.so     try_first_pass nullok sha512 shadow\npassword  optional  pam_permit.so\nsession   required  pam_limits.so\nsession   required  pam_unix.so\nsession   optional  pam_permit.so\nsession   optional  pam_ssh.so\nFor an explanation, see\n[8]\n.\nKnown issues with pam_ssh\nWork on the pam_ssh project is infrequent and the documentation provided is sparse.  You should be aware of some of its limitations which are not mentioned in the package itself.\nVersions of pam_ssh prior to version 2.0 do not support SSH keys employing the newer option of ECDSA (elliptic curve) cryptography. If you are using earlier versions of pam_ssh you must use RSA keys.\nThe\nssh-agent\nprocess spawned by pam_ssh does not persist between user logins.  If you like to keep a\nGNU Screen\nsession active between logins you may notice when reattaching to your screen session that it can no longer communicate with ssh-agent.  This is because the GNU Screen environment and those of its children will still reference the instance of ssh-agent which existed when GNU Screen was invoked but was subsequently killed in a previous logout.  The\nKeychain\nfront-end avoids this problem by keeping the ssh-agent process alive between logins.\npam_exec-ssh\nAs an alternative to\npam_ssh\nyou can use\npam_exec-ssh-git\nAUR\n. It is a shell script that uses pam_exec. Help for configuration can be found\nupstream\n.\nGNOME Keyring\nThe\nGNOME Keyring\ntool can act as a wrapper around ssh-agent, providing GUI and/or automatic key unlocking. See\nGNOME Keyring#SSH keys\nfor further details.\nStore SSH keys with Kwallet\nFor instructions on how to use kwallet to store your SSH keys, see\nKDE Wallet#Using the KDE Wallet to store ssh key passphrases\n.\nKeePass2 with KeeAgent plugin\nKeeAgent\nis a plugin for\nKeePass\nthat allows SSH keys stored in a KeePass database to be used for SSH authentication by other programs.\nSupports both PuTTY and OpenSSH private key formats.\nWorks with native SSH agent on Linux/Mac and with PuTTY on Windows.\nSee\nKeePass#Plugin installation in KeePass\nor\ninstall\nthe\nkeepass-plugin-keeagent\npackage.\nThis agent can be used directly, by matching KeeAgent socket:\nKeePass -> Tools -> Options -> KeeAgent -> Agent mode socket file -> %XDG_RUNTIME_DIR%/keeagent.socket\nand environment variable:\nexport SSH_AUTH_SOCK=\"$XDG_RUNTIME_DIR\"'/keeagent.socket'\n.\nKeePassXC\nThe KeePassXC fork of KeePass\ncan act as a client for an existing SSH agent\n. SSH keys stored in its database can be automatically (or manually) added to the agent. It is also compatible with KeeAgent's database format.\nTroubleshooting\nKey ignored by the server\nIf it appears that the SSH server is ignoring your keys, ensure that you have the proper permissions set on all relevant files.\nFor the local machine:\n$ chmod 700 ~/.ssh\n$ chmod 600 ~/.ssh/\nkey\nFor the remote machine:\n$ chmod 700 ~/.ssh\n$ chmod 600 ~/.ssh/authorized_keys\nFor the remote machine, also check that the target user's home directory has the correct permissions (it must\nnot\nbe writable by the group and others):\n$ chmod go-w ~\ntarget_user\nIf that does not solve the problem you may try temporarily setting\nStrictModes\nto\nno\nin\n/etc/ssh/sshd_config\n. If authentication with\nStrictModes off\nis successful, it is likely an issue with file permissions persists.\nMake sure keys in\n~/.ssh/authorized_keys\nare entered correctly and only use one single line.\nMake sure the remote machine supports the type of keys you are using: some servers do not support ECDSA keys, try using RSA keys instead, see\n#Generating an SSH key pair\n.\nYou may want to use debug mode and monitor the output while connecting:\n# /usr/bin/sshd -d\nIf you gave another name to your key, for example\nid_rsa_server\n, you need to connect with the\n-i\noption:\n$ ssh -i id_rsa_server user@server\nagent refused operation\nIf your private key requires a password (or, for instance, you have a hardware key with a PIN) but ssh-agent is not provided with one,\nssh\nwill fail:\nsign_and_send_pubkey: signing failed for ECDSA-SK\nuser\n@\nhost\nfrom agent: agent refused operation\nOne potential cause for this is ssh-agent being unable to prompt for a password. Ensure that ssh-agent has access to either a display server (via the\nDISPLAY\nenvironment variable) or a TTY. For some graphical environments you might only need to\ninstall\nx11-ssh-askpass\n, for other setups also follow\n#x11-ssh-askpass\ninstructions.\nAnother cause, if using a hardware authenticator, could be the key malfunctioning or being unplugged.\nThere is currently an open\nbug\nthat triggers with the \"agent refused operation\" error when using authenticator keys like ED25519-sk and ECDSA-SK that were created with the option\n-O verify-required\n. To avoid this issue, use the\n-o IdentityAgent=none -o IdentitiesOnly=yes\noption for the\nssh\ncommand or add it to your\nssh_config\nfile for the relevant hosts:\nHost myserver.tld\nIdentityAgent none\nIdentitiesOnly yes\nSee also\nOpenSSH key management:\nPart 1\n,\nPart 2\n,\nPart 3\nSecure Secure Shell\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=SSH_keys&oldid=852693\n\"\nCategory\n:\nSecure Shell\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Style\nSearch\nSearch\nSSH keys\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/SSH_keys"}}
{"text": "Xorg - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nXorg\n8 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\nAutostarting\nCursor themes\nDesktop environment\nDisplay manager\nFont configuration\nWindow manager\nXDMCP\nxinit\nxrandr\nX.Org Server\n— commonly referred to as simply\nX\n— is the\nX.Org Foundation\nimplementation of the\nX Window System\n(\nX11\n) display server, and it is the most popular display server among Linux users. Its ubiquity has led to making it an ever-present requisite for GUI applications, resulting in massive adoption from most distributions.\nFor the alternative and successor, see\nWayland\n.\nInstallation\nXorg can be\ninstalled\nwith the\nxorg-server\npackage.\nAdditionally, some packages from the\nxorg-apps\ngroup are necessary for certain configuration tasks. They are pointed out in the relevant sections.\nFinally, an\nxorg\ngroup is also available, which includes Xorg server packages, packages from the\nxorg-apps\ngroup and fonts.\nDriver installation\nThis article or section is a candidate for moving to\nGraphics processing unit\n.\nNotes:\nExcept for DDX, nothing else is specific to Xorg. (Discuss in\nArchWiki talk:Requests#GPU article\n)\nThe Linux kernel includes open-source video drivers and support for hardware accelerated framebuffers. However, userland support is required for\nOpenGL\n,\nVulkan\nand 2D acceleration in X11.\nFirst, identify the graphics card (the\nSubsystem\noutput shows the specific model):\n$ lspci -v -nn -d ::03xx\nTip\n::03\nhere means \"\nDisplay controller\nPCI device class\", and\nxx\nstands for \"any subclass of the class\".\nThen, install an appropriate driver. You can search the package database for a complete list of open-source\nDevice Dependent X (DDX)\ndrivers:\n$ pacman -Ss xf86-video\nHowever, hardware-specific DDX is considered legacy nowadays. There is a generic\nmodesetting(4)\nDDX driver in\nxorg-server\n, which uses\nkernel mode setting\nand works well on modern hardware. The modesetting DDX driver uses\nGlamor\n[1]\nfor 2D acceleration, which requires OpenGL.\nIf you want to install another DDX driver, note that Xorg searches for installed DDX drivers automatically:\nIf it cannot find the specific driver installed for the hardware (listed below), it first searches for\nfbdev\n(\nxf86-video-fbdev\n), which does not include any 2D or 3D acceleration.\nIf that is not found, it searches for\nvesa\n(\nxf86-video-vesa\n), the generic driver, which handles a large number of chipsets but does not include any 2D or 3D acceleration.\nIf\nvesa\nis not found, Xorg will fall back to\nmodesetting(4)\nDDX driver.\nIn order for video acceleration to work, and often to expose all the modes that the GPU can set, a proper video driver is required:\nBrand\nType\nDocumentation\nDRM driver\nOpenGL\nOpenGL (\nmultilib\n)\nVulkan\nVulkan (\nmultilib\n)\nDDX driver\nAMD (ex-ATI)\nOpen source\nAMDGPU\nincluded in\nLinux\nmesa\n3\nlib32-mesa\n3\nvulkan-radeon\nlib32-vulkan-radeon\nxf86-video-amdgpu\nATI\nNone\nxf86-video-ati\nIntel\nOpen source\nIntel graphics\nmesa\n3\nlib32-mesa\n3\nvulkan-intel\nlib32-vulkan-intel\nxf86-video-intel\n2\nNVIDIA\nOpen source\nNouveau\n1\nmesa\n3\nlib32-mesa\n3\nvulkan-nouveau\nlib32-vulkan-nouveau\nxf86-video-nouveau\nProprietary\nNVIDIA\n1\nnvidia\nor\nnvidia-open\n4\nnvidia-utils\nlib32-nvidia-utils\nnvidia-utils\nlib32-nvidia-utils\nnvidia-utils\nnvidia-535xx-dkms\nAUR\nnvidia-535xx-utils\nAUR\nlib32-nvidia-535xx-utils\nAUR\nnvidia-535xx-utils\nAUR\nlib32-nvidia-535xx-utils\nAUR\nnvidia-535xx-utils\nAUR\nnvidia-470xx-dkms\nAUR\nnvidia-470xx-utils\nAUR\nlib32-nvidia-470xx-utils\nAUR\nnvidia-470xx-utils\nAUR\nlib32-nvidia-470xx-utils\nAUR\nnvidia-470xx-utils\nAUR\nnvidia-390xx-dkms\nAUR\nnvidia-390xx-utils\nAUR\nlib32-nvidia-390xx-utils\nAUR\nnvidia-390xx-utils\nAUR\nlib32-nvidia-390xx-utils\nAUR\nnvidia-390xx-utils\nAUR\nFor NVIDIA Optimus enabled laptop which uses an integrated video card combined with a dedicated GPU, see\nNVIDIA Optimus\n.\nFor Intel graphics, the\nmodesetting\nDDX driver is recommended. See\nIntel graphics#Installation\nfor details.\nFor older hardware, classic OpenGL (non-Gallium3D) drivers in\nmesa-amber\n/\nlib32-mesa-amber\nmight be useful (Mesa 22.0 and higher have dropped support for non-Gallium3D classic drivers), see\nOpenGL#Installation\n.\nFor the difference between\nnvidia\nand\nnvidia-open\n, see\nNVIDIA#Installation\n.\nOther DDX drivers can be found in the\nxorg-drivers\ngroup.\nXorg should run smoothly without closed source drivers, which are typically needed only for advanced features such as fast 3D-accelerated rendering for games. The exceptions to this rule are recent GPUs (especially NVIDIA GPUs) not supported by open source drivers.\nAMD\nFor a translation of model names (e.g.\nRadeon RX 6800\n) to GPU architectures (e.g.\nRDNA 2\n), see\nWikipedia:List of AMD graphics processing units#Features overview\n.\nGPU architecture\nOpen-source driver\nProprietary driver\nRDNA and later\nAMDGPU\nnot available\nGCN 3 and later\nGCN 1&2\nAMDGPU\n1\n/\nATI\nnot available\nTeraScale\nand older\nATI\nnot available\nExperimental.\nRunning\nThe\nXorg(1)\ncommand is usually not run directly. Instead, the X server is started with either a\ndisplay manager\nor\nxinit\n.\nTip\nYou will typically seek to install a\nwindow manager\nor a\ndesktop environment\nto supplement X.\nConfiguration\nNote\nArch supplies default configuration files in\n/usr/share/X11/xorg.conf.d/\n, and no extra configuration is necessary for most setups.\nXorg uses a configuration file called\nxorg.conf\nand files ending in the suffix\n.conf\nfor its initial setup: the complete list of the folders where these files are searched can be found in\nxorg.conf(5)\n, together with a detailed explanation of all the available options.\nUsing .conf files\nThe\n/etc/X11/xorg.conf.d/\ndirectory stores host-specific configuration. You are free to add configuration files there, but they must have a\n.conf\nsuffix: the files are read in ASCII order, and by convention their names start with\nXX\n-\n(two digits and a hyphen, so that for example 10 is read before 20). These files are parsed by the X server upon startup and are treated like part of the traditional\nxorg.conf\nconfiguration file. Note that on conflicting configuration, the file read\nlast\nwill be processed. For this reason, the most generic configuration files should be ordered first by name. The configuration entries in the\nxorg.conf\nfile are processed at the end.\nFor option examples to set, see\nFedora:Input device configuration#xorg.conf.d\n.\nUsing xorg.conf\nXorg can also be configured via\n/etc/X11/xorg.conf\nor\n/etc/xorg.conf\n. You can also generate a skeleton for\nxorg.conf\nwith:\n# Xorg :0 -configure\nThis should create a\nxorg.conf.new\nfile in\n/root/\nthat you can copy over to\n/etc/X11/xorg.conf\n.\nTip\nIf you are already running an X server, use a different display, for example\nXorg :2 -configure\n.\nAlternatively, your proprietary video card drivers may come with a tool to automatically configure Xorg: see the article of your video driver,\nNVIDIA\n, for more details.\nNote\nConfiguration file keywords are case insensitive, and \"_\" characters are ignored. Most strings (including Option names) are also case insensitive, and insensitive to white space and \"_\" characters.\nInput devices\nFor input devices the X server defaults to the libinput driver (\nxf86-input-libinput\n), but\nxf86-input-evdev\nand related drivers are available as alternative.\n[2]\nUdev\n, which is provided as a systemd dependency, will detect hardware and both drivers will act as hotplugging input driver for almost all devices, as defined in the default configuration files\n10-quirks.conf\nand\n40-libinput.conf\nin the\n/usr/share/X11/xorg.conf.d/\ndirectory.\nAfter starting X server, the log file will show which driver hotplugged for the individual devices (note the most recent log file name may vary):\n$ grep -e \"Using input driver \" Xorg.0.log\nIf both do not support a particular device, install the needed driver from the\nxorg-drivers\ngroup. The same applies, if you want to use another driver.\nTo influence hotplugging, see\n#Configuration\n.\nFor specific instructions, see also the\nlibinput\narticle, the following pages below, or\nFedora:Input device configuration\nfor more examples.\nInput identification\nSee\nKeyboard input#Identifying keycodes in Xorg\n.\nMouse acceleration\nSee\nMouse acceleration\n.\nExtra mouse buttons\nSee\nMouse buttons\n.\nTouchpad\nSee\nlibinput\nor\nSynaptics\n.\nTouchscreen\nSee\nTouchscreen\n.\nKeyboard settings\nSee\nKeyboard configuration in Xorg\n.\nMonitor settings\nManual configuration\nNote\nNewer versions of Xorg are auto-configuring, so manual configuration should not be needed.\nIf Xorg is unable to detect any monitor or to avoid auto-configuring, a configuration file can be used. A common case where this is necessary is a headless system, which boots without a monitor and starts Xorg automatically, either from a\nvirtual console\nat\nlogin\n, or from a\ndisplay manager\n.\nFor a headless configuration, the\nxf86-video-dummy\ndriver is necessary;\ninstall\nit and create a configuration file, such as the following:\n/etc/X11/xorg.conf.d/10-headless.conf\nSection \"Monitor\"\nIdentifier \"dummy_monitor\"\nHorizSync 28.0-80.0\nVertRefresh 48.0-75.0\nModeline \"1920x1080\" 172.80 1920 2040 2248 2576 1080 1081 1084 1118\nEndSection\nSection \"Device\"\nIdentifier \"dummy_card\"\nVideoRam 256000\nDriver \"dummy\"\nEndSection\nSection \"Screen\"\nIdentifier \"dummy_screen\"\nDevice \"dummy_card\"\nMonitor \"dummy_monitor\"\nSubSection \"Display\"\nEndSubSection\nEndSection\nMultiple monitors\nSee main article\nMultihead\nfor general information.\nMore than one graphics card\nYou must define the correct driver to use and put the bus ID of your graphic cards (in decimal notation).\nSection \"Device\"\nIdentifier             \"Screen0\"\nDriver                 \"intel\"\nBusID                  \"PCI:0:2:0\"\nEndSection\nSection \"Device\"\nIdentifier             \"Screen1\"\nDriver                 \"nouveau\"\nBusID                  \"PCI:1:0:0\"\nEndSection\nTo get your bus IDs (in hexadecimal):\n$ lspci -d ::03xx\n00:02.0 VGA compatible controller: Intel Corporation HD Graphics 630 (rev 04)\n01:00.0 3D controller: NVIDIA Corporation GP107M [GeForce GTX 1050 Mobile] (rev a1)\nThe bus IDs here are\n0:2:0\nand\n1:0:0\n.\nDisplay size and DPI\nBy default, Xorg always sets DPI to 96 since\n2009-01-30\n. A change was made with version 21.1 to provide proper DPI auto-detection, but\nreverted\n.\nThe DPI of the X server can be set with the\n-dpi\ncommand line option.\nHaving the correct DPI is helpful where fine detail is required (like font rendering). Previously, manufacturers tried to create a standard for 96 DPI (a 10.3\" diagonal monitor would be 800x600, a 13.2\" monitor 1024x768). These days, screen DPIs vary and may not be equal horizontally and vertically. For example, a 19\" widescreen LCD at 1440x900 may have a DPI of 89x87.\nTo see if your display size and DPI are correct:\n$ xdpyinfo | grep -B2 resolution\nCheck that the dimensions match your display size.\nIf you have specifications on the physical size of the screen, they can be entered in the Xorg configuration file so that the proper DPI is calculated (adjust identifier to your xrandr output):\nSection \"Monitor\"\nIdentifier             \"DVI-D-0\"\nDisplaySize             286 179    # In millimeters\nEndSection\nIf you only want to enter the specification of your monitor\nwithout\ncreating a full xorg.conf, create a new configuration file. For example (\n/etc/X11/xorg.conf.d/90-monitor.conf\n):\nSection \"Monitor\"\nIdentifier             \"<default monitor>\"\nDisplaySize            286 179    # In millimeters\nEndSection\nNote\nIf you are using the proprietary NVIDIA driver, you may have to put\nOption \"UseEdidDpi\" \"FALSE\"\nunder\nDevice\nor\nScreen\nsection to make it take effect.\nIf you do not have specifications for physical screen width and height (most specifications these days only list by diagonal size), you can use the monitor's native resolution (or aspect ratio) and diagonal length to calculate the horizontal and vertical physical dimensions. Using the Pythagorean theorem on a 13.3\" diagonal length screen with a 1280x800 native resolution (or 16:10 aspect ratio):\n$ echo 'scale=5;sqrt(1280^2+800^2)' | bc  # 1509.43698\nThis will give the pixel diagonal length, and with this value you can discover the physical horizontal and vertical lengths (and convert them to millimeters):\n$ echo 'scale=5;(13.3/1509)*1280*25.4' | bc  # 286.43072\n$ echo 'scale=5;(13.3/1509)*800*25.4'  | bc  # 179.01920\nNote\nThis calculation works for monitors with square pixels; however, there is the rare monitor that may compress aspect ratio (e.g 16:10 aspect resolution to a 16:9 monitor). If this is the case, you should measure your screen size manually.\nSetting DPI manually\nNote\nWhile you can set any DPI you like and applications using Qt and GTK will scale accordingly, it is recommended to set it to\n96\n(100%, no scaling),\n120\n(25% higher),\n144\n(50% higher),\n168\n(75% higher),\n192\n(100% higher) etc., to reduce scaling artifacts to GUIs that use bitmaps. Reducing it below 96 DPI may not reduce the size of the GUIs graphical elements, as typically the lowest DPI the icons are made for is 96.\nFor RandR compliant drivers (for example the open source ATI driver), you can set it by:\n$ xrandr --dpi 144\nNote\nApplications that comply with the setting will not change immediately. You have to start them anew.\nTo make it permanent, see\nAutostarting#On Xorg startup\n.\nProprietary NVIDIA driver\nYou can manually set the DPI by adding the option under the\nDevice\nor\nScreen\nsection:\nOption              \"DPI\" \"96 x 96\"\nManual DPI Setting Caveat\nGTK very often overrides the server's DPI via the optional\nX resource\nXft.dpi\n. To find out whether this is happening to you, check with:\n$ xrdb -query | grep dpi\nWith GTK library versions since 3.16, when this variable is not otherwise explicitly set, GTK sets it to 96. To have GTK apps obey the server DPI you may need to explicitly set\nXft.dpi\nto the same value as the server. The\nXft.dpi\nresource is the method by which some desktop environments optionally force DPI to a particular value in personal settings. Among these are\nKDE\nand\nTDE\n.\nDisplay Power Management\nDPMS\nis a technology that allows power saving behaviour of monitors when the computer is not in use. This will allow you to have your monitors automatically go into standby after a predefined period of time.\nComposite\nThe Composite extension for X causes an entire sub-tree of the window hierarchy to be rendered to an off-screen buffer. Applications can then take the contents of that buffer and do whatever they like. The off-screen buffer can be automatically merged into the parent window, or merged by external programs called compositing managers. For more information, see\nWikipedia:Compositing window manager\n.\nSome window managers (e.g.\nCompiz\n,\nEnlightenment\n,\nKWin\n,\nmarco\n,\nmetacity\n,\nmuffin\n,\nmutter\n,\nXfwm\n) do compositing on their own. For other window managers, a standalone composite manager can be used.\nList of composite managers\nPicom\n— Lightweight compositor with shadowing, advanced blurring and fading. Forked from Compton.\nhttps://github.com/yshui/picom\n||\npicom\nXcompmgr\n— Composite window-effects manager.\nhttps://gitlab.freedesktop.org/xorg/app/xcompmgr/\n||\nxcompmgr\nGamescope\n— The micro-compositor from Valve, with gaming-oriented features such as FSR upscaling. Forked from steamos-compositor.\nhttps://github.com/ValveSoftware/gamescope\n||\ngamescope\nsteamos-compositor-plus\n— Valve's compositor, with some added tweaks and fixes.\nhttps://github.com/chimeraos/steamos-compositor-plus\n||\nsteamos-compositor-plus\nAUR\nTips and tricks\nAutomation\nThis section lists utilities for automating keyboard / mouse input and window operations (like moving, resizing or raising).\nTool\nPackage\nManual\nKeysym\ninput\nWindow\noperations\nNote\nxautomation\nxautomation\nxte(1)\nYes\nNo\nAlso contains screen scraping tools. Cannot simulate\nF13\nand more.\nxdo\nxdo\nxdo(1)\nNo\nYes\nSmall X utility to perform elementary actions on windows.\nxdotool\nxdotool\nxdotool(1)\nYes\nYes\nVery buggy\nand not in active development, e.g: has broken CLI parsing.\n[3]\n[4]\nxvkbd\nxvkbd\nAUR\nxvkbd(1)\nYes\nNo\nVirtual keyboard for Xorg, also has the\n-text\noption for sending characters.\nAutoKey\nautokey-qt\nAUR\nautokey-gtk\nAUR\ndocumentation\nYes\nYes\nHigher-level, powerful macro and scripting utility, with both Qt and Gtk front-ends.\nSee also\nClipboard#Tools\nand\nan overview of X automation tools\n.\nNested X session\nThis article or section is out of date.\nReason:\nmaybe tell about Xephyr before (Discuss in\nTalk:Xorg\n)\nTo run a nested session of another desktop environment:\n$ /usr/bin/Xnest :1 -geometry 1024x768+0+0 -ac -name Windowmaker & wmaker -display :1\nThis will launch a Window Maker session in a 1024 by 768 window within your current X session.\nThis needs the package\nxorg-server-xnest\nto be installed.\nA more modern way of doing a nested X session is with\nXephyr\n.\nStarting an application without a window manager\nSee\nxinit#Starting applications without a window manager\n.\nStarting GUI programs remotely\nSee main article:\nOpenSSH#X11 forwarding\n.\nOn-demand disabling and enabling of input sources\nWith the help of\nxinput\nyou can temporarily disable or enable input sources. This might be useful, for example, on systems that have more than one mouse, such as the ThinkPads and you would rather use just one to avoid unwanted mouse clicks.\nInstall\nthe\nxorg-xinput\npackage.\nFind the name or ID of the device you want to disable:\n$ xinput\nFor example in a Lenovo ThinkPad T500, the output looks like this:\n$ xinput\n⎡ Virtual core pointer                          id=2    [master pointer  (3)]\n⎜   ↳ Virtual core XTEST pointer                id=4    [slave  pointer  (2)]\n⎜   ↳ TPPS/2 IBM TrackPoint                     id=11   [slave  pointer  (2)]\n⎜   ↳ SynPS/2 Synaptics TouchPad                id=10   [slave  pointer  (2)]\n⎣ Virtual core keyboard                         id=3    [master keyboard (2)]\n↳ Virtual core XTEST keyboard               id=5    [slave  keyboard (3)]\n↳ Power Button                              id=6    [slave  keyboard (3)]\n↳ Video Bus                                 id=7    [slave  keyboard (3)]\n↳ Sleep Button                              id=8    [slave  keyboard (3)]\n↳ AT Translated Set 2 keyboard              id=9    [slave  keyboard (3)]\n↳ ThinkPad Extra Buttons                    id=12   [slave  keyboard (3)]\nDisable the device with\nxinput --disable\ndevice\n, where\ndevice\nis the device ID or name of the device you want to disable. In this example we will disable the Synaptics Touchpad, with the ID 10:\n$ xinput --disable 10\nTo re-enable the device, just issue the opposite command:\n$ xinput --enable 10\nAlternatively using the device name, the command to disable the touchpad would be:\n$ xinput --disable \"SynPS/2 Synaptics TouchPad\"\nPersistently disable input source\nYou can disable a particular input source using a configuration snippet:\n/etc/X11/xorg.conf.d/30-disable-\ndevice\n.conf\nSection \"InputClass\"\nIdentifier   \"disable-\ndevice\n\"\nDriver       \"\ndriver_name\n\"\nMatchProduct \"\ndevice_name\n\"\nOption       \"Ignore\" \"True\"\nEndSection\ndevice\nis an arbitrary name, and\ndriver_name\nis the name of the input driver, e.g.\nlibinput\n.\ndevice_name\nis what is actually used to match the proper device. For alternate methods of targeting the correct device, such as\nlibinput\n's\nMatchIsTouchscreen\n, consult your input driver's documentation. Though this example uses libinput, this is a driver-agnostic method which simply prevents the device from being propagated to the driver.\nKilling application with hotkey\nRun script on hotkey:\n#!/bin/sh\nwindowFocus=$(xdotool getwindowfocus)\npid=$(xprop -id \"$windowFocus\" | grep PID)\nkill -9 \"$pid\"\nDependencies:\nxorg-xprop\n,\nxdotool\nSee also\n#Killing an application visually\n.\nBlock TTY access\nTo block tty access when in an X add the following to\nxorg.conf\n:\nSection \"ServerFlags\"\nOption \"DontVTSwitch\" \"True\"\nEndSection\nThis can be used to help restrict command line access on a system accessible to non-trusted users.\nPrevent a user from killing X\nTo prevent a user from killing X when it is running add the following to\nxorg.conf\n:\nSection \"ServerFlags\"\nOption \"DontZap\"      \"True\"\nEndSection\nNote\nThe\nCtrl+Alt+Backspace\nshortcut is not directly what triggers killing the X server, but the\nTerminate_Server\naction from the keyboard map. This is usually not set by default, see\nXorg/Keyboard configuration#Terminating Xorg with Ctrl+Alt+Backspace\n.\nKilling an application visually\nWhen an application is misbehaving or stuck, instead of using\nkill\nor\nkillall\nfrom a terminal and having to find the process ID or name,\nxorg-xkill\nallows to click on said application to close its connection to the X server. Many existing applications do indeed abort when their connection to the X server is closed, but some can choose to continue.\nRootless Xorg\nXorg may run with standard user privileges instead of root (so-called \"rootless\" Xorg). This is a significant security improvement over running as root. Note that some popular\ndisplay managers\ndo not support rootless Xorg (e.g.\nLightDM\nor\nXDM\n).\nYou can verify which user Xorg is running as with\nps -o user= -C Xorg\n.\nSee also\nXorg.wrap(1)\n,\nsystemd-logind(8)\n,\nSystemd/User#Xorg as a systemd user service\n,\nFedora:Changes/XorgWithoutRootRights\nand\nFS#41257\n.\nUsing xinitrc\nTo configure rootless Xorg using\nxinitrc\n:\nRun startx as a subprocess of the login shell; run\nstartx\ndirectly and do not use\nexec startx\n.\nEnsure that Xorg uses virtual terminal for which permissions were set, i.e. passed by logind in\n$XDG_VTNR\nvia\n.xserverrc\n.\nIf using certain proprietary display drivers,\nkernel mode setting\nauto-detection\nwill fail. In such cases, you must set\nneeds_root_rights = no\nin\n/etc/X11/Xwrapper.config\n.\nNote that executing\nstartx\ndirectly without\nexec\nleaves the shell open in the case of a xorg crash. Since some lock screens are executed inside xorg, this can lead to full access to the executing user.\nUsing GDM\nGDM\nwill run Xorg without root privileges by default when\nkernel mode setting\nis used.\nSession log redirection\nWhen Xorg is run in rootless mode, Xorg logs are saved to\n~/.local/share/xorg/Xorg.log\n. However, the stdout and stderr output from the Xorg session is not redirected to this log. To re-enable redirection, start Xorg with the\n-keeptty\nflag and redirect the stdout and stderr output to a file:\nstartx -- -keeptty >~/.xorg.log 2>&1\nAlternatively, copy\n/etc/X11/xinit/xserverrc\nto\n~/.xserverrc\n, and append\n-keeptty\n. See\n[5]\n.\nXorg as Root\nAs explained above, there are circumstances in which rootless Xorg is defaulted to. If this is the case for your configuration, and you have a need to run Xorg as root, you can configure\nXorg.wrap(1)\nto require root:\nWarning\nRunning Xorg as root poses security issues. See\n#Rootless Xorg\nfor further discussion.\n/etc/X11/Xwrapper.config\nneeds_root_rights = yes\nWayback\nWayback is an X11 compatibility layer which allows for running full X11 desktop environments (and window managers) using Wayland components. It's available from the AUR as\nwayback-x11\nAUR\npackage.\nTroubleshooting\nGeneral\nIf a problem occurs, view the log stored in either\n/var/log/\nor, for the rootless X default since v1.16, in\n~/.local/share/xorg/\n.\nGDM\nusers should check the\nsystemd journal\n.\n[6]\nThe logfiles are of the form\nXorg.n.log\nwith\nn\nbeing the display number. For a single user machine with default configuration the applicable log is frequently\nXorg.0.log\n, but otherwise it may vary. To make sure to pick the right file it may help to look at the timestamp of the X server session start and from which console it was started. For example:\n$ grep -e Log -e tty Xorg.0.log\n[    40.623] (==) Log file: \"/home/archuser/.local/share/xorg/Xorg.0.log\", Time: Thu Aug 28 12:36:44 2014\n[    40.704] (--) controlling tty is VT number 1, auto-enabling KeepTty\nTip\nTo monitor the log with human-readable timestamps,\ntail(1)\n's output can be piped to\nts(1)\n(provided by the\nmoreutils\npackage). This will give correct timestamps only for lines added to the log while the command is running. For example:\n$ tail -f ~/.local/share/xorg/Xorg.0.log | ts\nIn the logfile then be on the lookout for any lines beginning with\n(EE)\n, which represent errors, and also\n(WW)\n, which are warnings that could indicate other issues.\nIf there is an\nempty\n.xinitrc\nfile in your\n$HOME\n, either delete or edit it in order for X to start properly. If you do not do this X will show a blank screen with what appears to be no errors in your\nXorg.0.log\n. Simply deleting it will get it running with a default X environment.\nIf the screen goes black, you may still attempt to switch to a different virtual console (e.g.\nCtrl+Alt+F6\n), and blindly log in as root. You can do this by typing\nroot\n(press\nEnter\nafter typing it) and entering the root password (again, press\nEnter\nafter typing it).\nYou may also attempt to kill the X server with:\n# pkill -x X\nIf this does not work, reboot blindly with:\n# reboot\nCheck specific pages in\nCategory:Input devices\nif you have issues with keyboard, mouse, touchpad etc.\nSearch for common problems in\nAMDGPU\n,\nIntel\nand\nNVIDIA\narticles.\nBlack screen, No protocol specified, Resource temporarily unavailable for all or some users\nX creates configuration and temporary files in current user's home directory. Make sure there is free disk space available on the partition your home directory resides in. Unfortunately, X server does not provide any more obvious information about lack of disk space in this case.\nDRI with Matrox cards stopped working\nIf you use a Matrox card and DRI stopped working after upgrading to Xorg, try adding the line:\nOption \"OldDmaInit\" \"On\"\nto the\nDevice\nsection that references the video card in\nxorg.conf\n.\nFrame-buffer mode problems\nX fails to start with the following log messages:\n(WW) Falling back to old probe method for fbdev\n(II) Loading sub module \"fbdevhw\"\n(II) LoadModule: \"fbdevhw\"\n(II) Loading /usr/lib/xorg/modules/linux//libfbdevhw.so\n(II) Module fbdevhw: vendor=\"X.Org Foundation\"\ncompiled for 1.6.1, module version=0.0.2\nABI class: X.Org Video Driver, version 5.0\n(II) FBDEV(1): using default device\nFatal server error:\nCannot run in framebuffer mode. Please specify busIDs for all framebuffer devices\nTo correct,\nuninstall\nthe\nxf86-video-fbdev\npackage.\nProgram requests \"font '(null)'\"\nError message:\nunable to load font `(null)'\n.\nSome programs only work with bitmap fonts. Two major packages with bitmap fonts are available,\nxorg-fonts-75dpi\nand\nxorg-fonts-100dpi\n. You do not need both; one should be enough. To find out which one would be better in your case, try\nxdpyinfo\nfrom\nxorg-xdpyinfo\n, like this:\n$ xdpyinfo | grep resolution\nand use what is closer to the shown value.\nRecovery: disabling Xorg before GUI login\nIf Xorg is set to boot up automatically and for some reason you need to prevent it from starting up before the login/display manager appears (if the system is wrongly configured and Xorg does not recognize your mouse or keyboard input, for instance), you can accomplish this task with two methods.\nChange default target to\nrescue.target\n. See\nsystemd#Change default target to boot into\n.\nIf you have not only a faulty system that makes Xorg unusable, but you have also set the GRUB menu wait time to zero, or cannot otherwise use GRUB to prevent Xorg from booting, you can use the Arch Linux live CD. Follow the\ninstallation guide\nabout how to mount and chroot into the installed Arch Linux. Alternatively try to switch into another\ntty\nwith\nCtrl+Alt\n+ function key (usually from\nF1\nto\nF7\ndepending on which is not used by X), login as root and follow steps below.\nDepending on setup, you will need to do one or more of these steps:\nDisable\nthe\ndisplay manager\n.\nDisable the\nautomatic start of X\n.\nRename the\n~/.xinitrc\nor comment out the\nexec\nline in it.\nX clients started with \"su\" fail\nIf you are getting\nClient is not authorized to connect to server\n, try adding the line:\nsession        optional        pam_xauth.so\nto\n/etc/pam.d/su\nand\n/etc/pam.d/su-l\n.\npam_xauth\nwill then properly set environment variables and handle\nxauth\nkeys.\nX failed to start: Keyboard initialization failed\nIf the filesystem (specifically\n/tmp\n) is full,\nstartx\nwill fail. The log file will contain:\n(EE) Error compiling keymap (server-0)\n(EE) XKB: Could not compile keymap\n(EE) XKB: Failed to load keymap. Loading default keymap instead.\n(EE) Error compiling keymap (server-0)\n(EE) XKB: Could not compile keymap\nXKB: Failed to compile keymap\nKeyboard initialization failed. This could be a missing or incorrect setup of xkeyboard-config.\nFatal server error:\nFailed to activate core devices.\n...\nMake some free space on the relevant filesystem and X will start.\nA green screen whenever trying to watch a video\nYour color depth is set wrong. It may need to be 24 instead of 16, for example.\nSocketCreateListener error\nIf X terminates with error message\nSocketCreateListener() failed\n, you may need to delete socket files in\n/tmp/.X11-unix\n. This may happen if you have previously run Xorg as root (e.g. to generate an\nxorg.conf\n).\nInvalid MIT-MAGIC-COOKIE-1 key when trying to run a program as root\nThat error means that only the current user has access to the X server. The solution is to give access to root:\n$ xhost +si:localuser:root\nThat line can also be used to give access to X to a different user than root.\nSee also\nXplain\n- In-depth explanation of the X Window System\nXorg(1)\nPrepare for LPIC-1 exam 2 - topic 106.1: X11\n- briefly covers architecture,\n#Configuration\n,\ndesktop environments\n, remote usage,\nWayland\n.\nxorg.conf(5)\nGentoo:Xorg/Guide#Configuration\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Xorg&oldid=853617\n\"\nCategory\n:\nX server\nHidden categories:\nPages or sections flagged with Template:Move\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nXorg\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Xorg"}}
{"text": "Wayland - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nWayland\n7 languages\nDeutsch\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nKMS\nXorg\nScreen capture#Wayland\nWayland\nis a display server protocol. It is aimed to become the successor of the\nX Window System\n. You can find a\ncomparison between Wayland and Xorg on Wikipedia\n.\nDisplay servers using the Wayland protocol are called\ncompositors\nbecause they also act as\ncompositing window managers\n. Below you can find a\nlist of Wayland compositors\n.\nFor compatibility with native X11 applications to run them seamlessly,\nXwayland\ncan be used, which provides an X Server in Wayland.\nRequirements\nMost Wayland compositors only work on systems using\nKernel mode setting\n. Wayland by itself does not provide a graphical environment; for this you also need a compositor (see the following section), or a desktop environment that includes a compositor (e.g.\nGNOME\nor\nPlasma\n).\nFor the GPU driver and Wayland compositor to be compatible they must support the same buffer API. There are two main APIs:\nGBM\nand\nEGLStreams\n.\nBuffer API\nGPU driver support\nWayland compositor support\nGBM\nAll except\nNVIDIA\n< 495*\nAll\nEGLStreams\nNVIDIA\nGNOME\n* NVIDIA ≥ 495 supports both EGLStreams and GBM.\n[1]\nSince NVIDIA introduced GBM support, many compositors (including Mutter and KWin) started using it by default for NVIDIA ≥ 495. GBM is generally considered better with wider support, and EGLStreams only had support because NVIDIA did not provide any alternative way to use their GPUs under Wayland with their proprietary drivers. Furthermore, KWin\ndropped support for EGLStreams\nafter GBM was introduced into NVIDIA.\nIf you use a popular desktop environment/compositor and a GPU still supported by NVIDIA, you are most likely already using GBM backend. To check, run\njournalctl -b 0 --grep \"renderer for\"\n. To force GBM as a backend, set the following\nenvironment variables\n:\nGBM_BACKEND=nvidia-drm\n__GLX_VENDOR_LIBRARY_NAME=nvidia\nCompositors\nSee\nWindow manager#Types\nfor the difference between\nStacking\n,\nTiling\nand\nDynamic\n.\nStacking\nCOSMIC\nCompositor\n— Compositor for the COSMIC desktop environment.\nhttps://github.com/pop-os/cosmic-comp\n||\ncosmic-comp\nEnlightenment\n— See\nEnlightenment#Manually\n. More Info:\n[2]\n[3]\nhttps://www.enlightenment.org/\n||\nenlightenment\nhikari\n— wlroots-based compositor inspired by\ncwm\nwhich is actively developed on FreeBSD but also supports Linux.\nhttps://web.archive.org/web/20241220075628/https://hikari.acmelabs.space/\n||\nhikari\nAUR\nKDE\nKWin\n— See\nKDE#Starting Plasma\n.\nhttps://userbase.kde.org/KWin\n||\nkwin\nlabwc\n— wlroots-based compositor inspired by Openbox.\nhttps://github.com/labwc/labwc\n||\nlabwc\nLiri Shell\n— Part of\nLiri\n, built using QtQuick and QtCompositor as a compositor for Wayland.\nhttps://github.com/lirios/shell\n||\nliri-shell-git\nAUR\nMutter\n— See\nGNOME#Starting\n.\nhttps://gitlab.gnome.org/GNOME/mutter\n||\nmutter\nwaybox\n— a *box-style (minimalist) Wayland compositor modeled largely on Openbox\nhttps://github.com/wizbright/waybox\n||\nwaybox\nAUR\nwayfire\n— 3D compositor inspired by\nCompiz\nand based on wlroots.\nhttps://wayfire.org/\n||\nwayfire\nAUR\nWeston\n— Wayland compositor designed for correctness, reliability, predictability, and performance.\nhttps://gitlab.freedesktop.org/wayland/weston\n||\nweston\nwio\n— wlroots-based compositor that aims to replicate the look and feel of Plan 9's Rio desktop.\nhttps://gitlab.com/Rubo/wio\n||\nwio-wl\nAUR\nwlmaker\n— wlroots-based compositor that's inspired by\nWindow Maker\n.\nhttps://github.com/phkaeser/wlmaker\n||\nwlmaker\nAUR\nwoodland\n— a minimal lightweight wlroots-based window-stacking compositor for Wayland, inspired by Wayfire and TinyWl.\nhttps://github.com/DiogenesN/woodland\n||\nwoodland\nAUR\nTiling\nCagebreak\n— Based on cage, inspired by\nratpoison\n.\nhttps://github.com/project-repo/cagebreak\n||\ncagebreak\nAUR\nMangoWC\n— A\ndwl\n-based compositor with a standard configuration file, an optional scrolling layout and support for eye candy.\nhttps://github.com/DreamMaoMao/mangowc\n||\nmangowc-git\nAUR\nmiracle-wm\n— A Wayland compositor based on Mir in the style of i3 and sway with the intention to be flashier and more feature-rich than either, like swayfx.\nhttps://github.com/miracle-wm-org/miracle-wm\n||\nmiracle-wm\nAUR\nniri\n— A scrollable-tiling Wayland compositor.\nhttps://github.com/YaLTeR/niri/\n||\nniri\nQtile\n— A full-featured, hackable tiling window manager and Wayland compositor written and configured in Python.\nhttps://github.com/qtile/qtile\n||\nqtile\nSway\n—\ni3\n-compatible Wayland compositor based on wlroots.\nhttps://github.com/swaywm/sway\n||\nsway\nSwayFx\n—\nSway\n, but with eye candy!\nhttps://github.com/WillPower3309/swayfx\n||\nswayfx\nAUR\nVelox\n— Simple window manager based on swc, inspired by dwm and\nxmonad\n.\nhttps://github.com/michaelforney/velox\n||\nvelox-git\nAUR\nDynamic\ncwc\n—\nawesome\n-like Wayland compositor based on wlroots.\nhttps://cudiph.github.io/cwc/apidoc/\n||\ncwc\nAUR\ndwl\n—\ndwm\n-like Wayland compositor based on wlroots.\nhttps://codeberg.org/dwl/dwl\n||\ndwl\nAUR\nHyprland\n— A dynamic tiling Wayland compositor that does not sacrifice on its looks.\nhttps://hypr.land\n||\nhyprland\njapokwm\n— Dynamic Wayland tiling compositor based around creating layouts, based on wlroots.\nhttps://github.com/werererer/japokwm\n||\njapokwm-git\nAUR\nriver\n— Dynamic tiling Wayland compositor inspired by dwm and\nbspwm\n.\nhttps://codeberg.org/river/river\n||\nriver\nOther\nCage\n— Displays a single fullscreen application like a kiosk.\nhttps://www.hjdskes.nl/projects/cage/\n||\ncage\nGNOME Kiosk\n— Mutter based compositor that provides an environment suitable for fixed purpose, or single application deployments like wall displays and point-of-sale systems.\nhttps://gitlab.gnome.org/GNOME/gnome-kiosk\n||\ngnome-kiosk\nAUR\nphoc\n— A tiny wlroots-based compositor for mobile devices.\nhttps://gitlab.gnome.org/World/Phosh/phoc\n||\nphoc\nWayback\n— X11 compatibility layer which allows for running full X11 desktop environments using Wayland components. It is experimental, in the early stage of development.\nhttps://wayback.freedesktop.org/\n||\nwayback-x11\nAUR\nSome of the above may support\ndisplay managers\n. Check\n/usr/share/wayland-sessions/\ncompositor\n.desktop\nto see how they are started.\nDisplay managers\nDisplay managers listed below support launching Wayland compositors.\nName\nRuns on\nDescription\nemptty\ntty\nSimple CLI Display Manager on TTY.\nGDM\nWayland\nGNOME\ndisplay manager.\ngreetd\nWayland/Xorg/tty\nSee\nGreetd#Greeters\n.\nMinimal and flexible login daemon.\nlemurs\ntty\nTUI display manager written in Rust.\nlidm\nAUR\ntty\nA fully colorful customizable TUI display manager made in C.\nLightDM\nXorg\n[4]\nCross-desktop display manager.\nly\ntty\nTUI display manager written in Zig\nSDDM\nWayland/Xorg\nQML-based display manager.\ntbsm\nAUR\ntty\nSimple CLI session launcher written in pure bash.\nuwsm\ntty\nSession and XDG autostart manager for standalone compositors.\nProvides a TUI menu, but can also be used with other display managers.\nXwayland\nXwayland(1)\nis an X server that runs under Wayland and provides compatibility for native\nX11\napplications that are yet to provide Wayland support. To use it,\ninstall\nthe\nxorg-xwayland\npackage.\nXwayland is started via a compositor, so you should check the documentation for your chosen compositor for Xwayland compatibility and instructions on how to start Xwayland.\nNote\nSecurity: Xwayland is an X server, so it does not have the security features of Wayland\nPerformance: Xwayland has a\nnearly identical performance\nto that of X11. In some cases you might notice degraded performance, especially on NVIDIA cards.\nCompatibility: Xwayland is not fully backward compatible with X11. Some applications may not work properly under Xwayland.\nNVIDIA driver\nNote\nNVIDIA drivers prior to version 470 (e.g.\nnvidia-390xx-dkms\nAUR\n) do not support hardware accelerated Xwayland, causing non-Wayland-native applications to suffer from poor performance in Wayland sessions.\nEnabling\nDRM KMS\nis required. There may be additional information in the\nofficial documentation\nregarding your display manager (e.g.\nGDM\n).\nKwin Wayland debug console\nIf you use\nkwin\n, execute the following to see which windows use Xwayland or native Wayland, surfaces, input events, clipboard contents, and more.\n$ qdbus6 org.kde.KWin /KWin org.kde.KWin.showDebugConsole\nDetect Xwayland applications\nTo determine whether an application is running via Xwayland, you can run\nextramaus\nAUR\n.\nMove your mouse pointer over the window of an application. If the red mouse moves, the application is running via Xwayland.\nAlternatively, you can use\nxorg-xeyes\nand see if the eyes are moving, when moving the mouse pointer over an application window.\nAnother option is to run\nxwininfo\n(from\nxorg-xwininfo\n) in a terminal window: when hovering over an Xwayland window the mouse pointer will turn into a + sign. If you click the window it will display some information and end, but it will not do anything with native Wayland windows.You can use\nCtrl+C\nto end it.\nYou can also use\nxlsclients\n(from the\nxorg-xlsclients\npackage). To list all applications running via Xwayland, run\nxlsclients -l\n.\nGUI libraries\nGTK\nThe\ngtk3\nand\ngtk4\npackages have the Wayland backend enabled. GTK will default to the Wayland backend, but it is possible to override it to Xwayland by modifying an environment variable:\nGDK_BACKEND=x11\n.\nFor theming issues, see\nGTK#Wayland backend\n.\nQt\nTo enable Wayland support in\nQt\n5, install the\nqt5-wayland\npackage. Qt 5 applications will then run under Wayland on a Wayland session.\nWhile it should not be necessary, to explicitly run a Qt application with the Wayland plugin\n[5]\n, use\n-platform wayland\nor\nQT_QPA_PLATFORM=wayland\nenvironment variable\n.\nTo force the usage of\nX11\non a Wayland session, use\nQT_QPA_PLATFORM=xcb\n.\nThis might be necessary for some proprietary applications that do not use the system's implementation of Qt.\nQT_QPA_PLATFORM=\"wayland;xcb\"\nallows Qt to use the xcb (X11) plugin instead if Wayland is not available.\n[6]\nThe factual accuracy of this article or section is disputed.\nReason:\nThis feels wrong or outdated. I don't know about other potential applications, but KeepassXC doesn't need any of this to minimize to tray properly under Sway (Discuss in\nTalk:Wayland\n)\nOn some compositors, for example\nsway\n, Qt applications running natively might have missing functionality. For example,\nKeepassXC\nwill be unable to minimize to tray. This can be solved by installing\nqt5ct\nand setting\nQT_QPA_PLATFORMTHEME=qt5ct\nbefore running the application.\nDue to the\nIncorrect sizing and bad text rendering with WebEngine using fractional scaling on Wayland\nQt WebEngine bug, applications using Qt WebEngine, for example\nCalibre\n, may display jagged fonts.\nA workaround is launching the application with\nQT_SCALE_FACTOR_ROUNDING_POLICY=RoundPreferFloor\n.\nThis prevents the application window being fractional scaled.\nClutter\nThe Clutter toolkit has a Wayland backend that allows it to run as a Wayland client. The backend is enabled in the\nclutter\npackage.\nTo run a Clutter application on Wayland, set\nCLUTTER_BACKEND=wayland\n.\nSDL\nIn\nSDL3\n, Wayland is used by default to communicate with the desktop compositor.\nTo run an SDL2 application on Wayland, set\nSDL_VIDEODRIVER=wayland\n.\nSDL_VIDEODRIVER=\"wayland,x11\"\nallows SDL2 to use the x11 video driver instead if Wayland is not available.\n[7]\n. You may also want to install\nlibdecor\nto enable window decorations (for example, on GNOME).\nRefer to the\nofficial documentation\nfor more details.\nGLFW\nThe\nglfw\npackage has support for Wayland, and uses the Wayland backend if the\nenvironment variable\nXDG_SESSION_TYPE\nis set to\nwayland\nand the application developer has not set a specific desired backend.\nSee the\nsource code\nfor more information.\nGLEW\nIf the\nglew-wayland-git\nAUR\npackage does not work with the needed GLEW-based applications, the option is to use\nglew\nwith Xwayland. See\nFS#62713\n.\nEFL\nEnlightenment has\ncomplete Wayland support\n.\nTo run an EFL-based application on Wayland, set\nELM_DISPLAY=wl\n.\nwinit\nWinit is a window handling library in Rust. It will default to the Wayland backend, but it is possible to override it to Xwayland by modifying environment variables:\nPrior to version 0.29.2, set\nWINIT_UNIX_BACKEND=x11\nFor version 0.29.2 and higher, unset\nWAYLAND_DISPLAY\n, which forces a fallback to X using the\nDISPLAY\nvariable.\n[8]\nElectron\nNote\nIn\nPlasma\n, some Electron applications can use the wrong icon (default Wayland one) for the window, while using the correct icon for the taskbar. To fix that, you can create a special application/window rule, forcing the desktop file name on such applications.\nWayland support can be activated using command line flags, or an environment variable.\nCommand line flags\nNote\nSome packages do not forward flags to Electron, and thus will need the application developer to implement a solution.\nSee\nChromium#Native Wayland support\nto command-line flags needed to work on Wayland. Note that the command-line flag\n--ozone-platform-hint=auto\ndoes not work since Electron 38.\nYou can pass these flags manually, persist them in an\nElectron configuration file\n, or\noverride the .desktop file at ~/.local/share/applications\nof an application by adding the flags to the end of the\nExec=\nline.\nThe factual accuracy of this article or section is disputed.\nReason:\nOld version of Electron needs\n--enable-features=WebRTCPipeWireCapturer\nBut what version is it enable by default? Also default behavior of Electron vendored by non-free software would be wrong. (Discuss in\nTalk:Wayland\n)\nElectron enable WebRTC screen capture over PipeWire by default. The capture is based on\nxdg-desktop-portal\n.\nA case of missing top bars can be solved by using:\n--enable-features=WaylandWindowDecorations\n. This will typically be necessary under\nGNOME\n(supported since\nelectron17\n).\nEnvironment variable\nApplications using Electron between versions 28 and 37 can use the\nenvironment variable\nELECTRON_OZONE_PLATFORM_HINT\nset to\nauto\nor\nwayland\n.\nThis takes lower priority than the command line flags.\nJava\nThe open source implementation of the\nJava\nplatform OpenJDK, does not yet have native support for Wayland.\nUntil\nWakefield\n, the project that aims to implement Wayland in OpenJDK, is available, Xwayland can be used.\nSee\nDebian:Wayland#Java Programs (supported since OpenJDK 16?)\n:\nStarting with OpenJDK 16, the JRE can dynamically load GTK3 (which has Wayland support), it appears this might be supported according to this\ndiscussion\n.\nThe\n_JAVA_AWT_WM_NONREPARENTING\nenvironment variable\ncan be set to \"1\" to fix misbehavior where the application starts with a blank screen.\nSince XWayland doesn't have full feature parity with Wayland,\nWLToolkit\ncan be used to fill the gaps while Wakefield isn't ready. It can be activated with\n-Dawt.toolkit.name=WLToolkit\n. Some programs such as the\nJetBrains IDEs support it\n.\nTips and tricks\nAutomation\nydotool\n(\nydotool\n) - Generic command-line automation tool (not limited to wayland).\nEnable/start\nthe\nydotool.service\nuser unit\n. See\nydotoold(8)\n,\nydotool(1)\n.\nwtype\n(\nwtype\n) - xdotool type for wayland. See\nwtype(1)\n.\nkeyboard\n- Python library that works on Windows and Linux with experimental OS X support.  Also see the\nmouse\nlibrary.\nwlrctl\n(\nwlrctl\nAUR\n) - A command line utility for miscellaneous wlroots extensions (supports the foreign-toplevel-management, virtual-keyboard, virtual-pointer)\nRemap keyboard or mouse keys\nSee\nInput remap utilities\n.\nScreencast\nSee\nScreen capture#Screencasting\nand\nScreen capture#Screencast Wayland windows with X11 applications\n.\nPersist clipboard after app close\nThis article or section is a candidate for merging with\nClipboard\n.\nNotes:\nThis is a standard behavior even on Xorg. There are many other clipboard managers. (Discuss in\nTalk:Wayland\n)\nDue to Wayland's design philosophy, clipboard data is stored in the memory of the source client. When the client closes, the clipboard data is lost. You can solve this using\nwl-clip-persist\n, which runs in the background to reads the clipboard data and stores it in its own memory, separate from the source client.\nAutostart wayland compositor as systemd service\nNote\nUniversal Wayland Session Manager\nautomatically generates systemd units for your compositors, moreover it helps you to\nintegrate graphical applications with systemd\n.\nIf you do not want to use a display manager or a shell, you can autostart your Wayland compositor with a\nsystemd\nservice. Adjust the\nExecStart\nline with the compositor you want to use. Here is an example for\nKDE Plasma\n:\n/etc/systemd/system/wayland-compositor.service\n[Unit]\nAfter=graphical.target systemd-user-sessions.service modprobe@drm.service\nConflicts=getty@tty1.service\n[Service]\nUser=\nusername\nWorkingDirectory=~\nPAMName=login\nTTYPath=/dev/tty1\nUnsetEnvironment=TERM\nStandardOutput=journal\nExecStart=/usr/lib/plasma-dbus-run-session-if-needed /usr/bin/startplasma-wayland\n[Install]\nWantedBy=graphical.target\nUse another renderer for wlroots based compositor\nYou can use another\nwlroots renderer\nsuch as vulkan by specifying the\nWLR_RENDERER\nenvironment variable for wlroots based compositor. The list of available ones is on the\nwlroots documentation\n.\nTroubleshooting\nColor correction\nSee\nBacklight#Color correction\n.\nSlow motion, graphical glitches, and crashes\nGnome-shell users may experience display issues when they switch to Wayland from X. One of the root cause might be the\nCLUTTER_PAINT=disable-clipped-redraws:disable-culling\nset by yourself for Xorg-based gnome-shell. Just try to remove it from\n/etc/environment\nor other rc files to see if everything goes back to normal.\nRemote display\nwlroots0.18\nand\nwlroots0.19\n(used by\nsway\n) offers a VNC backend via\nwayvnc\nsince version 0.10. RDP backend has been removed\n[9]\n.\nmutter\nhas now remote desktop enabled at compile time, see\n[10]\nand\ngnome-remote-desktop\nfor details.\nkrfb\noffers a VNC server for\nkwin\n.\nkrfb-virtualmonitor\ncan be used to set up another device as an extra monitor.\nThere was a merge of FreeRDP into Weston in 2013, enabled via a compile flag. The\nweston\npackage has it enabled since version 6.0.0.\nwaypipe\n(or\nwaypipe-git\nAUR\n) is a transparent proxy for Wayland applications, with a wrapper command to run over\nSSH\nHere is an example for launching a remote KDE kcalc under Plasma:\n$ waypipe ssh example.local env QT_QPA_PLATFORM=wayland QT_QPA_PLATFORMTHEME=KDE dbus-launch kcalc\nInput grabbing in games, remote desktop and VM windows\nIn contrast to Xorg, Wayland does not allow exclusive input device grabbing, also known as active or explicit grab (e.g.\nkeyboard\n,\nmouse\n), instead, it depends on the Wayland compositor to pass keyboard shortcuts and confine the pointer device to the application window.\nThis change in input grabbing breaks current applications' behavior, meaning:\nHotkey combinations and modifiers will be caught by the compositor and will not be sent to remote desktop and virtual machine windows.\nThe mouse pointer will not be restricted to the application's window which might cause a parallax effect where the location of the mouse pointer inside the window of the virtual machine or remote desktop is displaced from the host's mouse pointer.\nWayland solves this by adding protocol extensions for Wayland and Xwayland. Support for these extensions is needed to be added to the Wayland compositors. In the case of native Wayland clients, the used widget toolkits (e.g GTK, Qt) needs to support these extensions or the applications themselves if no widget toolkit is being used. In the case of Xorg applications, no changes in the applications or widget toolkits are needed as the Xwayland support is enough.\nThese extensions are already included in\nwayland-protocols\n, and supported by\nxorg-xwayland\n.\nThe related extensions are:\nXwayland keyboard grabbing protocol\nCompositor shortcuts inhibit protocol\nRelative pointer protocol\nPointer constraints protocol\nSupporting Wayland compositors:\nMutter,\nGNOME\n's compositor\nsince release 3.28\nwlroots supports relative-pointer and pointer-constraints\nKwin\nKDE#X11 shortcuts conflict on Wayland\nKeyboard shortcuts inhibit\nSupporting widget toolkits:\nGTK since release 3.22.18.\nGTK themes not working\nSee\nhttps://github.com/swaywm/sway/wiki/GTK-3-settings-on-Wayland\n.\nAvoid loading NVIDIA modules\nAdd\n__EGL_VENDOR_LIBRARY_FILENAMES=/usr/share/glvnd/egl_vendor.d/50_mesa.json\nas\nenvironment variable\nbefore launching a Wayland compositor like\nsway\n.\nMagnifying/surface scaling\nScreen magnifying is not solved yet, a pull request was merged mid-2022\nproviding the protocol wp-surface-scale\n.\nWayland lag/stuttering since kernel 6.11.2 (AMD)\nUntil this issue is patched in future kernel releases, a workaround is to add\namdgpu.dcdebugmask=0x400\nto the cmdline.\nSee:\nhttps://community.frame.work/t/wayland-lag-stuttering-since-kernel-6-11-2/59422\nGames / applications suspended when not in focus\nWhen changing workspace or ALT+TAB:ing, games (and possibly other graphical applications) are suspended put in some weird state, and they (partially) stop. Symptoms include things like audio dropping (partially) out, game not progressing, ping times rising high or network dropping out, but only if the game window is not in focus. It is possible some games can work around this issue by changing to a window, but some do not. This is extremely annoying if the player needs to ALT+TAB out of the game occasionally (such as more complex games which require heavy usage of web browsing, documentation and 3rd party tools) - or if the gameplay is interrupted for some reason.\nPossible workaround include setting environment variables\nMESA_VK_WSI_PRESENT_MODE=immediate\nand/or\nvk_xwayland_wait_ready=false\n. (please add more information and reference to upstream documentation here if found! The feature is elusive and seems poorly documented).\nSee also\nWayland documentation online\nOfficial repository\nFedora:How to debug Wayland problems\nWe are Wayland now!\n- An updated version of \"Are we Wayland yet?\"\nAwesome Wayland projects\nCursor themes\nArch Linux forum discussion\ni3 Migration Guide - Common X11 apps used on i3 with Wayland alternatives\nWayland Explorer - A better way to read Wayland documentation\nHow can I tell if an application is using XWayland\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Wayland&oldid=854438\n\"\nCategory\n:\nWayland\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Merge\nSearch\nSearch\nWayland\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Wayland"}}
{"text": "GNOME - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nGNOME\n9 languages\nČeština\nDeutsch\nEspañol\nItaliano\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nDesktop environment\nGTK\nGDM\nGNOME/Tips and tricks\nGNOME/Troubleshooting\nGNOME/Files\nGNOME/Gedit\nGNOME/Web\nGNOME/Evolution\nGNOME/Flashback\nGNOME/Keyring\nGNOME/Document viewer\nOfficial repositories#gnome-unstable\nGNOME\n(/(ɡ)noʊm/) is a\ndesktop environment\nthat aims to be simple and easy to use. It is designed by\nThe GNOME Project\nand is composed entirely of free and open-source software. It uses\nWayland\n, and the available sessions are\nGNOME\n, the default, runs GNOME Shell on\nWayland\n. Traditional X applications are run through Xwayland.\nGNOME Classic\nprovides a \"\ntraditional desktop experience\n\" (with an interface similar to GNOME 2) by using\ncertain extensions and values\n. Thus, it is a customized form of GNOME Shell rather than a truly distinct mode.\nInstallation\nThe following\npackage groups\nare available:\ngnome\ncontains the base GNOME desktop and the well-integrated\ncore applications\n;\ngnome-circle\ncontains various\nextra applications\nextending the GNOME ecosystem.\ngnome-extra\ncontains\ndevelopment tools\nas well as some further applications and games that fits well into GNOME.\nThe base desktop consists of\nGNOME Shell\n, a plugin for the\nMutter\nwindow manager. It can be installed separately with\ngnome-shell\n.\nNote\nmutter\nacts as a composite manager for the desktop, employing hardware graphics acceleration to provide effects aimed at reducing screen clutter. The GNOME session manager automatically detects if your video driver is capable of running GNOME Shell and if not, falls back to software rendering using\nllvmpipe\n.\nUnstable releases can also be used, see\nOfficial repositories#gnome-unstable\n.\nStarting\nGNOME can be started either graphically with a\ndisplay manager\nor manually from the console (some features may be missing). The display manager included in\ngnome\nis\nGDM\n.\nNote\nSupport for screen locking (and more) in GNOME is provided by GDM. If GNOME is not started with GDM, another screen locker may be used. See\nList of applications/Security#Screen lockers\n.\nGraphically\nIf you installed the\ngnome\ngroup and want GNOME to start automatically on next boot,\nenable\ngdm.service\n. You can then select the desired session:\nGNOME\nor\nGNOME Classic\n(only displayed if\ngnome-shell-extensions\nis installed) from the display manager's session menu.\nIf you prefer to start GNOME right away, thereby avoiding a reboot,\nstart\nthe aforementioned\ngdm.service\nfrom a graphically unoccupied tty instead.\nManually\nNote\nAn X server is still necessary to run applications that have not yet been ported to\nWayland\n, see\nWayland#Xwayland\nfor details. Applications using certain graphics libraries, such as Qt, can be forced to use Wayland by setting environment variables. See\nWayland#GUI libraries\nfor more information.\nSession type\nGNOME session inherits session type from systemd. Systemd session type is determined from\nXDG_SESSION_TYPE\nenvironment variable when the session is started, and can only be changed by the controller of that session afterwards. See the systemd issue on\nGithub\n.\nTherefore merely setting\nXDG_SESSION_TYPE\nafter login does not work. Instead, create a systemd drop-in file to set environment for getty :\n/etc/systemd/system/getty@tty1.service.d/wayland.conf\n[Service]\nEnvironment=XDG_SESSION_TYPE=wayland\nTo show session type after reload:\n$ loginctl session-status\nStart session\nAfter\nXDG_SESSION_TYPE\nand login session type is set correctly, manually starting a Wayland session is possible with:\n$ gnome-session\nRunning\ngnome-shell --wayland\ndirectly is not recommended, because it lacks session management.\nNote that manual invocation of Gnome does\nnot\nrequire\ngdm\n(consequently also the accompanying\ngdm.service\n) at all and is thus also accessible for users with a (possibly very) minimal installation of Gnome composing of a selected few packages included in the more inclusive\ngnome\ngroup in accordance to personal preference.\nTo start on login to tty1, add to your\n.bash_profile\n:\ngnome-session --no-reexec\nThe\n--no-reexec\nflag prevents gnome-session from starting a login shell which sources the profile again and loops.\nFirefox and QT applications do not respect\nXDG_SESSION_TYPE\n, so add variables for them as well:\nif [[ -z $DISPLAY && $(tty) == /dev/tty1 && $XDG_SESSION_TYPE == wayland ]]; then\nMOZ_ENABLE_WAYLAND=1 QT_QPA_PLATFORM=wayland exec gnome-session --no-reexec\nfi\nGNOME applications in Wayland\nWhen the\nGNOME\nsession is used, GNOME applications will be run using Wayland. For debugging cases,\nhttps://docs.gtk.org/gtk3/running.html\nand\nhttps://docs.gtk.org/gtk4/running.html\nlist options and environment variables.\nNavigation\nTo learn how to use the GNOME shell effectively, read the\nGNOME Shell Cheat Sheet\n; it highlights GNOME shell features and keyboard shortcuts. Features include task switching, keyboard use, window control, the panel, overview mode, and more. A few of the shortcuts are:\nSuper+m\n: show notification list\nSuper+a\n: show application grid\nAlt+Tab\n: cycle active applications\nAlt+`\n(the key above\nTab\non US keyboard layouts): cycle windows of the application in the foreground\nAlt+F2\n, then enter\nr\nor\nrestart\n: restart the shell in case of graphical shell problems (only in X/legacy mode, not in Wayland mode).\nSee\n/Tips and tricks#Navigation\nfor changes to the default configuration making the window-switching resemble that of Windows.\nSee\nKeyboard navigation\nfor more shortcuts.\nLegacy names\nNote\nSome GNOME programs have undergone name changes where the application's name in documentation and about dialogs has been changed but the executable name has not. A few such applications are listed in the table below.\nTip\nSearching for the legacy name of an application in the Shell search bar will successfully return the application in question. For instance, searching for\nnautilus\nwill return\nFiles\n.\nLegacy\nCurrent\nBaobab\nDisk Usage Analyzer\nDecibels\nAudio Player\nEpiphany\nWeb\nLoupe\nImage Viewer\nNautilus\nFiles\nPapers\nDocument Viewer\nShowtime\nVideo Player\nSimple Scan\nDocument Scanner\nSnapshot\nCamera\nConfiguration\nGNOME Settings (\ngnome-control-center\n) and GNOME applications use the\ndconf\nconfiguration system to store their settings.\nYou can directly access the dconf database using the\ngsettings(1)\ncommand line tool. This also allows you to configure settings not exposed by the user interfaces. Command line tool\ndconf(1)\ncan directly modify the underlying database, bypassing validation. The configuration keys of gsettings and dconf are equivalent, but in a slightly different format:\ngsettings set mygroup.mysubgroup mysetting myvalue\nin gsettings would be\ndconf write /mygroup/mysubgroup/mysetting myvalue\nin dconf.\nUp until GNOME 3.24, settings were applied by the GNOME settings daemon (located at\n/usr/lib/gnome-settings-daemon/gnome-settings-daemon\n), which could be run outside of a GNOME session.\nGNOME 3.24, however, replaced the GNOME settings daemon with several separate settings plugins\n/usr/lib/gnome-settings-daemon/gsd-*\nwhich were later moved to\n/usr/lib/gsd-*\n. These plugins are now controlled via desktop files under\n/etc/xdg/autostart/\n(matching\norg.gnome.SettingsDaemon.*.desktop\n). To run these plugins outside of a GNOME session, you will now need to copy/edit the appropriate\ndesktop entries\nto\n~/.config/autostart\n.\nThe configuration is usually performed user-specific; this section does not cover how to create configuration templates for multiple users.\nSystem settings\nColor\nThe daemon\ncolord\nreads the display's EDID and extracts the appropriate color profile. Most color profiles are accurate and no setup is required; however, for those that are not accurate, or for older displays, color profiles can be put in\n~/.local/share/icc/\nand directed to.\nNight Light\nGNOME comes with a built-in blue light filter similar to\nRedshift\n. You can enable and customise the time you want to enable Night Light from the display settings menu. Furthermore, you can tweak the kelvin temperature with the following\ndconf\nsetting, where 5000 is an example value:\n$ gsettings set org.gnome.settings-daemon.plugins.color night-light-temperature 5000\nTip\nTo change the daytime temperature in a Wayland session, install the\nNight Light Slider extension\n.\nNote\nNight Light works on NVIDIA cards in Wayland sessions since version 545.29.02\nDate & time\nIf the system has a configured\nNetwork Time Protocol daemon\n, it will be effective for GNOME as well. The synchronization can be set to manual control from the menu, if required.\nGNOME supports automatic time zone selection (can be enabled in\nDate & Time\nsection of the system settings, given that location services are enabled (see\nPrivacy\nsection of the settings).\nNote\nAutomatic time zone selection might not work anymore because of the retirement of Mozilla Location Services. See\n[1]\n. For workarounds see\nSystem time#Setting based on geolocation\n.\nTo show the date in the top bar, execute:\n$ gsettings set org.gnome.desktop.interface clock-show-date true\nAdditionally, to show week numbers in the calendar opened on the top bar, execute:\n$ gsettings set org.gnome.desktop.calendar show-weekdate true\nDefault applications\nUpon installing GNOME for the first time, you may find that the wrong applications are handling certain protocols. For example,\ntotem\nopens videos instead of a previously used\nVLC\n. Some of the associations can be set from system settings via\nDefault Applications\n.\nFor other protocols and methods, see\nDefault applications\nfor configuration.\nMouse and touchpad\nMost touchpad settings can be set from system settings via\nMouse & Touchpad\n.\nDepending on your device, other configuration settings may be available, but not exposed via the default GUI. For example, a different touchpad\nclick-method\n$ gsettings range org.gnome.desktop.peripherals.touchpad click-method\nenum\n'default'\n'none'\n'areas'\n'fingers'\nto be set manually:\n$ gsettings set org.gnome.desktop.peripherals.touchpad click-method 'fingers'\nor via\ngnome-tweaks\n.\nNote\nThe\nsynaptics\ndriver is not supported by GNOME. Instead, you should use\nlibinput\n. See\nthis bug report\n.\nResize windows by mouse\nBy default, you can use your mouse to move windows by holding down\nSuper\n, clicking and holding the left mouse button and dragging the mouse around.\nAdditionally, you can enable using your mouse to resize windows by holding down\nSuper\n, clicking and holding the right mouse button and dragging the mouse around:\n$ gsettings set org.gnome.desktop.wm.preferences resize-with-right-button true\nIf you don't like the\nSuper\nkey, you can also change the modifier to something else, like\nAlt\nor\nCtrl\n:\n$ gsettings set org.gnome.desktop.wm.preferences mouse-button-modifier \"'<Alt>'\"\nNetwork\nNetworkManager\nis the native tool of the GNOME project to control network settings from the shell. If you have not already,\ninstall\nthe\nnetworkmanager\npackage and\nenable\nthe\nNetworkManager.service\nsystemd unit.\nWhile any other\nnetwork manager\ncan be used alternatively, NetworkManager provides the full integration via the shell network settings and a status indicator applet\nnetwork-manager-applet\n(not required for GNOME).\nNote\nHidden wireless networks set up with\nnetworkmanager\n's\nnmtui\ndo not connect automatically. You need to create a new profile using GNOME control center in order to restore auto-connect capabilities for that network.\nOnline accounts\nSome online accounts, such as\nownCloud\n, require\ngvfs-goa\nand\ngvfs-dnssd\nto be installed for full functionality in GNOME applications such as\nGNOME Files\nand GNOME Documents\n[2]\n.\nSee\nOnline accounts\nfor more information.\nSearch\nThe GNOME shell has a search that can be quickly accessed by pressing the\nSuper\nkey and starting to type. The\nlocalsearch\npackage is installed by default as a dependency of\nnautilus\nfrom the\ngnome\ngroup and provides an indexing application and metadata database. It can be configured with the\nSearch\nmenu item in\nSettings\n. It is started automatically by\ngnome-session\nwhen the user logs in.\nlocalsearch does not automatically recurse into all directories under the user's home directory, so you may need to add custom paths via the\nSearch > Search locations\nmenu item. To exclude a directory from the indexing, create an empty\n.nomedia\nfile.\nA status is available with\nlocalsearch status\nand the indexed content can be searched (\nlocalsearch search --help\n), edited (\nlocalsearch tag --help\n), or reset from the commandline. See\nlocalsearch help\nand\nlocalsearch\ncommand\n--help\n, or the\nonline help\nfor reference.\nThe database uses\ntinysparql-sql(1)\nand can also be queried directly, if needed.\nAccessibility\nGNOME has accessibility settings available via\nSettings > Accessibility\n. The main settings may be toggled directly after enabling a top bar icon, but note further settings are available via the sub-menus for\nSeeing\n,\nHearing\n,\nTyping\n,\nPointing and clicking\nand\nZoom\n. See\nhttps://help.gnome.org/users/gnome-help/stable/a11y.html.en\nfor information on them.\nAdditionally, a default set of keyboard shortcuts can be set via\nSettings > Keyboard > View and Customize Keyboard Shortcuts > Accessibility\n. For example, pressing\nAlt\n,\nSuper\nand\n8\ntoggles zooming.\nDevice Security Settings\nGNOME 43 comes with a new\nDevice Security\npanel in Settings. This requires\nfwupd\nin order to function. See\n[3]\n.\nAdvanced settings\nAs noted above, many configuration options such as changing the\nGTK\ntheme or the\nwindow manager\ntheme are not exposed in GNOME Settings (\ngnome-control-center\n). Those users that want to configure these settings may wish to use the GNOME Tweaks (\ngnome-tweaks\n), a convenient graphical tool which exposes many of these settings.\nGNOME settings (which are stored in the DConf database) can also be configured using the\ndconf-editor\n(a graphical DConf configuration tool) or the\ngsettings\ncommand line tool. The GNOME Tweaks does not do anything else in the background of the GUI; note though that you will not find all settings described in the following sections in it.\nExtensions\nThe catalogue of extensions is available at\nhttps://extensions.gnome.org\n, they can be installed either through\nofficial repositories\n(only a few),\nthe AUR\nor through\nthe browser\n.\nThe factual accuracy of this article or section is disputed.\nReason:\nThe note below suggests manual user file management as recommended since it is \"easier\" but does not explain why. (Discuss in\nTalk:GNOME\n)\nNote\nInstalling extensions through the browser makes them available for the current user only and requires you to manually update each one. This is the easier method.\nAdditionally, if you decided to install extensions from the browser instead, you need to install\ngnome-browser-connector\n. It is not required to install extensions from the official repositories or the AUR.\nInstalling extensions through the AUR (or through official repositories, if you find them there) makes them available system-wide (and automates the update process if using an\nAUR helper\n).\nInstalled extensions can also be configured, enabled or disabled through a GUI with\ngnome-extensions-app\n, from the command line with\ngnome-extensions(1)\n, or from the browser. In your browser, extensions can be installed then activated in the browser by setting the switch in right top right of the screen to\nON\nand clicking\nInstall\non the popup window (if the extension in question is not installed). Installed extensions may be seen at\nhttps://extensions.gnome.org/local/\n, where available updates can be checked.\nThe\ngnome-shell-extensions\npackage provides a set of very useful extensions maintained as part of the GNOME project.\nextension-manager\nis a graphical tool which can also be used to install and remove extensions, as well as enable and disable them, both system-wide and for a user. Prior to using it, consider its\nlist of known issues\n.\nTo enable usage of extensions (disabled by default):\n$ gsettings set org.gnome.shell disable-user-extensions false\nTo list currently enabled extensions:\n$ gsettings get org.gnome.shell enabled-extensions\nThe above command may list extensions that have been removed. To only list extensions that are enabled\nand\ninstalled, use\ngnome-extensions\ninstead:\n$ gnome-extensions list --enabled\nFor more information about GNOME shell extensions, see\nhttps://extensions.gnome.org/about/\n.\nAppearance\nThemes\nNote\nAs of\nGnome 42\n, many default Gnome applications use GTK 4 with libadwaita. These apps do not currently support changing themes through gsettings or\ngnome-tweaks\n, the only visual configuration available is through Settings > Appearance. See\nGTK#Themes\nfor setting a GTK theme other than Adwaita or Adwaita-dark.\nGNOME uses Adwaita by default. To apply Adwaita-dark only to GTK 2 applications, use the following symlink:\n$ ln -s /usr/share/themes/Adwaita-dark ~/.themes/Adwaita\nNote\nThe Adwaita-dark theme is provided by\ngnome-themes-extra\nwhich may not be installed on a minimal installation of GNOME.\nTo select new themes (move them to the appropriate directory and) use GNOME Tweaks or the GSettings commands below.\nFor the GTK theme:\n$ gsettings set org.gnome.desktop.interface gtk-theme\ntheme-name\nFor the icon theme:\n$ gsettings set org.gnome.desktop.interface icon-theme\ntheme-name\nNote\nThe window manager theme follows the GTK theme. Using\norg.gnome.desktop.wm.preferences theme\nis deprecated and ignored.\nSee\nGTK#Themes\nand\nIcons#Icon themes\n.\nTitlebar button order\nTo set the order for the GNOME window manager (Mutter, Metacity):\n$ gsettings set org.gnome.desktop.wm.preferences button-layout ':minimize,maximize,close'\nTip\nThe colon indicates which side of the titlebar the window buttons will appear.\nGNOME Shell themes\nThe theme of GNOME Shell itself is configurable. To use a Shell theme, firstly ensure that you have the\ngnome-shell-extensions\npackage installed. Then enable the\nUser Themes\nextension, either through the GNOME Extensions application or through the\nGNOME Shell Extensions\nwebpage. Shell themes can then be loaded and selected using GNOME Extensions.\nThere are a number of GNOME Shell themes available\nin the AUR\n, many themes do not have the same name format, so instead try searching for the appropriate theme in the AUR. Shell themes can also be downloaded from\ngnome-look.org\n.\nAppIndicators/Top bar icons\nTo enable AppIndicators, which is useful for controlling/monitoring certain applications running in the background, Install\ngnome-shell-extension-appindicator\nor\ngnome-shell-extension-appindicator-git\nAUR\n,\nrestart the GNOME Shell\n, then enable the AppIndicator extension in the GNOME Extensions application or by running\n$ gnome-extensions enable $(gnome-extensions list | grep -m 1 appindicatorsupport)\nShell animation speed\nThe GNOME shell animation can be sped up, slowed down or disabled. See\nGNOME/Tips and tricks#Change animation speed\n.\nShell blur\nBlur my Shell is an extension that adds blur effects to the overview screen as well as the shell itself and other apps. Install\ngnome-shell-extension-blur-my-shell\nAUR\nor\ngnome-shell-extension-blur-my-shell-git\nAUR\nfor development updates. This extension is highly customizable, and you may choose to blur certain applications.\nBetter Alt-Tab Functionality\nThe default Alt-Tab in GNOME is very simple and does not show overviews of the selected windows. You can change the Alt-Tab shortcut from \"Switch Applications\" to \"Switch Windows\" in Settings to show window overviews.\nYou can also use Coverflow Alt-Tab. It is an extension that expands the Alt-Tab behavior and adds features to make switching between applications easier while also giving it a better look. Install\ngnome-shell-extension-coverflow-alt-tab-git\nAUR\n, then you may change the configuration of this extension to your liking.\nNote: Super-` provides \"Switch windows of an application` by default.\nAutostart\nGNOME implements\nXDG Autostart\n.\nThe\ngnome-tweaks\nallows managing autostart-entries.\nTip\nIf the plus sign button in the Tweaks's Startup Applications section is unresponsive, try starting the Tweaks from the terminal using the following command:\ngnome-tweaks\n. See the following\nforum thread\n.\nNote\nThe deprecated\ngnome-session-properties\ndialog can be added by\ninstalling\nthe\ngnome-session-properties\nAUR\n[\nbroken link\n: package not found]\npackage. This also provides functionality to disable system-wide autostarted applications, something that\ngnome-tweaks\ndoes not allow.\nDesktop\nDash to Dock\nTo move the dash out of the overview and turn it into a dock to easily launch and switch applications,\ninstall\ngnome-shell-extension-dash-to-dock\nAUR\n.\nStartup in Overview Mode\nStarting from GNOME 40, the desktop will start directly into Overview Mode instead of an empty desktop (like in previous versions). To mimic legacy behaviour, one may\ninstall\ngnome-shell-extension-no-overview\nAUR\n.\nAlternatively, you can disable it using gsettings if using\ngnome-shell-extension-dash-to-dock\nAUR\n:\n$ gsettings set org.gnome.shell.extensions.dash-to-dock disable-overview-on-startup true\nSee the discussion at\n[4]\n.\nClipboard history\nUnlike other desktop environments, GNOME does not have a built-in tool to manage the clipboard history. This can be done however with the help of an extension. Install\ngnome-shell-extension-clipboard-indicator\nAUR\n.\nWeather\nTo display the current weather information in the top panel based on a chosen location, install\ngnome-shell-extension-openweather\nAUR\n. The weather information is updated in real-time and displays useful data such as conditions, wind speed, pressure, etc...\nSound input/output device selector\nThis article or section is being considered for removal.\nReason:\nProbably not needed anymore.\nPackages compatible\nup to Gnome 43 only. (Discuss in\nTalk:GNOME\n)\nBy default, if you want to change your sound input or output device or change your microphone's volume, you need to open GNOME Control Center and configure these settings from there. To integrate a device selector and a microphone volume slider, install\ngnome-shell-extension-sound-output-device-chooser\nAUR\nor\ngnome-shell-extension-sound-output-device-chooser-git\nAUR\n. Further configuration can be done after installation.\nFonts\nTip\nIf you set the\nScaling factor\nto a value above 1.00, the Accessibility menu will be automatically enabled.\nFonts can be set for Window titles, Interface (applications), Documents and Monospace. See the Fonts tab in the Tweaks for the relevant options.\nFor hinting, RGBA will likely be desired as this fits most monitors types, and if fonts appear too blocked reduce hinting to\nSlight\nor\nNone\n.\nInput methods\nGNOME has integrated support for\ninput methods\nthrough\nIBus\n. Only\nibus\nand the wanted input method engine (e.g.\nibus-libpinyin\nfor Intelligent Pinyin) needed to be installed. After installation, the input method engine can be added as a keyboard layout under\nKeyboard > Input Sources\nin GNOME Settings (\ngnome-control-center\n).\nKeyboard Layout quirks\nIf you are using an alternative keyboard layout like Neo2 which uses multiple layers/modifiers, you might need to go to\nKeyboard > Type Special Characters\nin GNOME Settings (\ngnome-control-center\n) and change the\nAlternate Characters Key\naway from\nRight Alt\nso that it can be used as a native modifier of the keyboard layout. Setting it to e.g.\nLeft Alt\nprevents\nAlt+Tab\n, so be careful what you change it to.\nWithout this change, your left\nMod3\nkey might work, but the right one (\nAltGr\n) does not. (As of 2021-05-18)\nPower\nWhen you are using a laptop, you might want to alter the following settings controlling behavior when idle, screen lock power button presses and lid close:\n$ gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-ac-timeout\n3600\n$ gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-ac-type\nhibernate\n$ gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-battery-timeout\n1800\n$ gsettings set org.gnome.settings-daemon.plugins.power sleep-inactive-battery-type\nhibernate\n$ gsettings set org.gnome.settings-daemon.plugins.power power-button-action\nsuspend\n$ gsettings set org.gnome.desktop.lockdown disable-lock-screen\ntrue\nTo keep the monitor active when the lid is closed:\n$ gsettings set org.gnome.settings-daemon.plugins.xrandr default-monitors-setup do-nothing\nGNOME 3.24 deprecated the following settings:\norg.gnome.settings-daemon.plugins.power button-hibernate\norg.gnome.settings-daemon.plugins.power button-power\norg.gnome.settings-daemon.plugins.power button-sleep\norg.gnome.settings-daemon.plugins.power button-suspend\norg.gnome.settings-daemon.plugins.power critical-battery-action\nDo not suspend when laptop lid is closed\nThe settings panel of GNOME does not provide an option for the user to change the action triggered when the laptop lid is closed. To change the lid switch action system-wide, edit the systemd settings in\n/etc/systemd/logind.conf\n. To turn off suspend on lid close, set\nHandleLidSwitch=ignore\n, as described in\nPower management#ACPI events\n.\nChange critical battery level action\nThe settings panel does not provide an option for changing the critical battery level action. These settings have been removed from dconf as well. They are now managed by upower. Edit the upower settings in\n/etc/UPower/UPower.conf\n. Find these settings and adjust to your needs.\n/etc/UPower/UPower.conf\nPercentageLow=10\nPercentageCritical=3\nPercentageAction=2\nCriticalPowerAction=HybridSleep\nPower modes\nInstall the\npower-profiles-daemon\noptional dependency (of\ngnome-control-center\n) for power profiles support. Explicitly\nstarting/enabling\nthe\npower-profiles-daemon\nservice is unnecessary since\ngnome-shell\nand GNOME Settings both request its activation upon launching.\nWhen the service is active, power profiles can be managed through the\nPower\nsection of GNOME Settings and in the system menu.\nScreencast\nThe built-in screenshot tool comes without the Screencast option by default. Install the\ngst-plugin-pipewire\noptional dependency (of\ngnome-shell\n) to enable screen recording.\nUse a different window manager\nGNOME Shell does not support using a different\nwindow manager\n, however\nGNOME Flashback\nprovides sessions for Metacity and\nCompiz\n. Furthermore, it is possible to define your own\ncustom GNOME sessions\nwhich use alternative components.\nUnder\nWayland\n, replacing GNOME Shell with a different compositor will cause certain sections of\ngnome-control-center\n(GNOME Settings) to populate incorrectly.\ngnome-control-center\nwill work, but since\nmutter\n(GNOME Shell) will not be available to provide settings for populating these sections, they will not have an effect or may not populate accurately with your settings. Sections affected are bluetooth, display, and mouse/touchpad to name a few.\nSee also\nOfficial Website\nContributing to GNOME, feature requests, bugs, code\nWikipedia article\nGNOME-Shell Extensions\nGNOME Shell Cheat Sheet\nCustomization (themes, icons...):\nPersonalize GNOME\nGNOME Look\nGNOME applications:\nGNOME Apps Index\nWikipedia:GNOME Core Applications\nGNOME Source/Mirrors:\nGNOME GitLab\nGNOME Github Mirror\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=GNOME&oldid=852834\n\"\nCategory\n:\nGNOME\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages with broken package links\nSections flagged with Template:Remove\nSearch\nSearch\nGNOME\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/GNOME"}}
{"text": "KDE - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nKDE\n9 languages\nDeutsch\nEspañol\nItaliano\nMagyar\n日本語\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\nDesktop environment\nDisplay manager\nWindow manager\nQt\nSDDM\nDolphin\nKDE Wallet\nKDevelop\nTrinity\nUniform look for Qt and GTK applications\nOfficial repositories#kde-unstable\nKDE\nis a software project currently comprising a\ndesktop environment\nknown as\nPlasma\n, a collection of libraries and frameworks (KDE Frameworks) and several applications (KDE Applications) as well.\nKDE upstream has a well maintained\nUserBase wiki\n. Detailed information about most KDE applications can be found there.\nInstallation\nPlasma\nInstall\nthe\nplasma-meta\nmeta-package or the\nplasma\ngroup. For differences between\nplasma-meta\nand\nplasma\nreference\nPackage group\n. Alternatively, for a more minimal Plasma installation, install the\nplasma-desktop\npackage. Upstream KDE has\npackage and setup recommendations\nto get a fully-featured Plasma session.\nIf you are an\nNVIDIA\nuser with the proprietary\nnvidia\ndriver and wish to use the Wayland session, enable the\nDRM kernel mode setting\n.\nPlasma Mobile\nInstall\nplasma-mobile\nAUR\n.\nKDE applications\nTo install the full set of KDE Applications, install the\nkde-applications-meta\nmeta-package or the\nkde-applications\ngroup. If you only want KDE applications for a certain category, like gaming or education, install the relevant dependency of\nkde-applications-meta\n. Note that installing applications alone will not install any version of Plasma.\nUnstable releases\nSee\nOfficial repositories#kde-unstable\nfor beta releases.\nStarting Plasma\nStarting from Plasma 6.4, the Wayland session has matured enough to become\nthe default and preferred one\n: the X11 session is only available separately with the\nplasma-x11-session\npackage\n[1]\n. The\nXorg\nsession is still supported, but will be\nremoved in Plasma 6.8\n. See\nWayland Known Significant Issues\nand\nX11 Known Significant Issues\nfor more information.\nPlasma can be started either using a\ndisplay manager\n, or from the console.\nUsing a display manager\nTip\nThe preferred\ndisplay manager\nis\nSDDM\n.\nSelect\nPlasma (Wayland)\nto launch a new session in\nWayland\n.\nSelect\nPlasma (X11)\nto launch a new session in\nXorg\n.\nSelect\nPlasma Mobile (Wayland)\nto launch a new Plasma Mobile session in\nWayland\n.\nFrom the console\nTo start a Plasma on Wayland session from a console, run\n/usr/lib/plasma-dbus-run-session-if-needed /usr/bin/startplasma-wayland\n[2]\n.\nTo start Plasma with\nxinit/startx\n, append\nexport DESKTOP_SESSION=plasma\nand\nexec startplasma-x11\nto your\n.xinitrc\nfile or run directly in the console\nstartx /usr/bin/startplasma-x11\n. If you want to start Xorg at login, please see\nStart X at login\n.\nConfiguration\nMost settings for KDE applications are stored in\n~/.config/\n. However, configuring KDE is primarily done through the\nSystem Settings\napplication. It can be started from a terminal by executing\nsystemsettings\n.\nPersonalization\nPlasma desktop\nThemes\nThere are different types of KDE themes, varying by scope of what they modify:\nGlobal themes\n, comprehensive packages that can include Plasma themes, application styles, colors, fonts, icons, cursors, splash screens, SDDM themes, and Konsole color schemes. Global themes can be applied with the\nlookandfeeltool\ncommand line tool.\nPlasma themes\n, modifying the look of Plasma panels and widgets. These often have a recommended accompanying Kvantum or Aurorae theme to complete the look.\nApplication styles\n, modifying the look of programs.\nApplication styles that use\ntheme engines\nsuch as\nKvantum\n,\nQtCurve\n[3]\n,\nQSvgStyle\n[4]\n, and\nAurorae\n.\n#Icon themes\n, providing icons for applications, files, and actions.\nFor easy system-wide installation and updating, some themes are available in both the\nofficial repositories\nand the\nAUR\n.\nGlobal themes can also be installed through\nSystem Settings > Colors & Themes > Global Theme > Get New...\n.\nWarning\nGlobal themes are commonly provided by end users and not monitored. You should use extreme caution when downloading and applying global themes. They can run arbitrary code and loss of user data has\noccurred\n.\nTip\nInstall\nplasma-sdk\nto be able to easily edit Plasma Themes, explore Icons and test Plasma widgets, check out also\nkde-development-environment-meta\n.\nGTK application appearance\nTip\nFor Qt and GTK theme consistency, see\nUniform look for Qt and GTK applications\n.\nThe recommended theme for a pleasant appearance in GTK applications is\nbreeze-gtk\n, a GTK theme designed to mimic the appearance of Plasma's Breeze theme.\nInstall\nkde-gtk-config\n(part of the\nplasma\ngroup), relogin and select\nBreeze\nas the GTK theme in\nSystem Settings > Colors & Themes > Application Style > Configure GNOME/GTK Application Style...\n.\nThis article or section is out of date.\nReason:\nThe Plasma GTKd background service overwrites GTK settings on Plasma startup. (Discuss in\nTalk:KDE\n)\nIn some themes, tooltips in GTK applications have white text on white backgrounds making it difficult to read. To change the colors in GTK2 applications, find the section for tooltips in the\n.gtkrc-2.0\nfile and change it. For GTK3 application two files need to be changed,\ngtk.css\nand\nsettings.ini\n.\nSome GTK2 programs like\nvuescan-bin\nAUR\nstill look hardly usable due to invisible checkboxes with the Breeze or Adwaita skin in a Plasma session. To workaround this, install and select e.g. the Numix-Frost-Light skin of the\nnumix-frost-themes\nAUR\nunder\nSystem Settings > Colors & Themes > Application Style > Configure GNOME/GTK Application Style... > GTK theme\n. Numix-Frost-Light looks similar to Breeze.\nFaces\nPlasma and\nSDDM\nwill both use images found at\n/var/lib/AccountsService/icons/\nas users' avatars. To configure with a graphical interface, you can use\nSystem Settings > Users\n. The file corresponding to your username can be removed to restore the default avatar.\nWidgets\nPlasmoids\nare widgets for Plasma desktop shell designed to enhance the functionality of desktop, they can be found on the\nAUR\n.\nPlasmoid scripts can also be installed by right-clicking onto a panel or the desktop and choosing\nEnter Edit Mode > Add Widgets... > Get New Widgets... > Download New Plasma Widgets\n. This will present a front-end for\nhttps://store.kde.org/\nthat allows you to install, uninstall, or update third-party Plasmoid scripts with just one click.\nSound applet in the system tray\nInstall\nplasma-pa\nor\nkmix\n(start Kmix from the Application Launcher).\nplasma-pa\nis now installed by default with\nplasma\n, no further configuration needed.\nNote\nTo adjust the\nstep size of volume increments/decrements\n, add e.g.\nVolumePercentageStep=1\nin the\n[Global]\nsection of\n~/.config/kmixrc\n.\nDisable panel shadow\nAs the Plasma panel is on top of other windows, its shadow is drawn over them.\n[5]\nTo disable this behaviour without impacting other shadows,\ninstall\nxorg-xprop\nand run:\n$ xprop -remove _KDE_NET_WM_SHADOW\nthen select the panel with the plus-sized cursor.\n[6]\nFor automation, install\nxorg-xwininfo\nand create the following script:\n/usr/local/bin/kde-no-shadow\n#!/bin/bash\nfor WID in $(xwininfo -root -tree | sed '/\"plasmashell\": (\"plasmashell\" \"plasmashell\")/!d; s/^  *\\([^ ]*\\) .*/\\1/g'); do\nxprop -id $WID -remove _KDE_NET_WM_SHADOW\ndone\nMake the script\nexecutable\n.\nThe factual accuracy of this article or section is disputed.\nReason:\nAutostarting does not work because the script starts too early (something like\nsleep 5\nmay help but is unreliable). (Discuss in\nTalk:KDE\n)\nThe script can be run on login with\nAdd Login Script\nin\nAutostart\n:\n$ kcmshell6 autostart\nDisplay scaling / High DPI displays\nSee\nHiDPI#KDE Plasma\n.\nPlasma Mobile\nThe\nplasma-phone-settings\nrepository contains several recommended settings which can be applied globally (\n/etc/xdg\n) and/or per user (\n~/.config\n).\nLock screen\n/etc/xdg/kscreenlockerrc\n(or\n~/.config/kscreenlockerrc\n) locks the screen immediately after login.\n[7]\nThis is useful in combination with\nSDDM#Autologin\n.\n/etc/xdg/kscreenlockerrc\n[Daemon]\nLockOnStart=true\nVirtual keyboard\nTo use a virtual keyboard in the Wayland session, install\nplasma-keyboard\nand enable it in\nSystem Settings > Keyboard > Virtual Keyboard\n.\nIf your device has a hardware keyboard, but you want to use the virtual keyboard, add the\nKWIN_IM_SHOW_ALWAYS=1\nenvironment variable\nto your Wayland session.\nTo use a virtual keyboard in the X11 session, choose an appropriate one from\nList of applications/Utilities#On-screen keyboards\nand run it manually.\nWindow decorations\nWindow decorations\ncan be found in the\nAUR\n.\nThey can be changed in\nSystem Settings > Colors & Themes > Window Decorations\n, there you can also directly download and install more themes with one click.\nIcon themes\nIcon themes can be installed and changed on\nSystem Settings > Colors & Themes > Icons\n.\nNote\nAlthough all modern Linux desktops share the same icon theme format, desktops like\nGNOME\nuse fewer icons (esp. in menus and toolbars). Themes developed for such desktops usually lack icons required by Plasma and KDE applications. It is recommended to install Plasma compatible icon themes instead.\nTip\nSince some icon themes do not inherit from the default icon theme, some icons may be missing.\nTo inherit from the Breeze, add\nbreeze\nto the\nInherits=\narray in\n/usr/share/icon/\ntheme-name\n/index.theme\n, for example:\nInherits=breeze,hicolor\n. You need to reapply this patch after every update to the icon theme, consider using\nPacman hooks\nto automate the process.\nSpace efficiency\nThe Plasma Netbook shell has been dropped from Plasma 5, see the following\nKDE forum post\n. However, you can achieve something similar by editing the file\n~/.config/kwinrc\nadding\nBorderlessMaximizedWindows=true\nin the\n[Windows]\nsection.\nThumbnail generation\nTo allow thumbnail generation for media or document files on the desktop and in Dolphin, install\nkdegraphics-thumbnailers\nand\nffmpegthumbs\n.\nThen enable the thumbnail categories for the desktop via\nright click\non the\ndesktop background\n>\nConfigure Desktop and Wallpaper...\n>\nIcons\n>\nConfigure Preview Plugins...\n.\nIn\nDolphin\n, navigate to\nConfigure > Configure Dolphin... > Interface > Previews\n.\nNight Light\nPlasma provides a\nRedshift\n-like feature (working on both\nXorg\nand\nWayland\n) called Night Light. It makes the colors on the screen warmer to reduce eye strain at the time of your choosing. It can be enabled in\nSystem Settings > Colors & Themes > Night Light\n.\nPrinting\nTip\nUse the\nCUPS\nweb interface for faster configuration. Printers configured in this way can be used in KDE applications.\nYou can also configure printers in\nSystem Settings > Printers\n. To use this method, you must first install the following packages\nprint-manager\n,\ncups\n,\nsystem-config-printer\n. See\nCUPS#Configuration\n.\nSamba/Windows support\nThe Dolphin share functionality requires the package\nkdenetwork-filesharing\nand usershares, which the stock\nsmb.conf\ndoes not have enabled. Instructions to add them are in\nSamba#Enable Usershares\n, after which sharing in Dolphin should work out of the box after restarting Samba.\nAccessing Windows shares from Dolphin works out of the box. Use the path\nsmb://\nservername\n/\nshare\nto browse the files.\nTip\nUse\n*\n(asterisk) for both username and password when accessing a Windows share without authentication in Dolphin's prompt.\nUnlike GTK file browsers which utilize GVfs also for the launched program, opening files from Samba shares in Dolphin via KIO makes Plasma copy the whole file to the local system first with most programs (VLC is an exception).\nTo workaround this, you can use a GTK based file browser like\nthunar\nwith\ngvfs\nand\ngvfs-smb\n(and\ngnome-keyring\nfor saving login credentials) to access SMB shares in a more able way.\nAnother possibility is to\nmount\na Samba share via\ncifs-utils\nto make it look to Plasma like if the SMB share was just a normal local folder and thus can be accessed normally.\nSee\nSamba#Manual mounting\nand\nSamba#Automatic mounting\n.\nA GUI solution is available with\nsamba-mounter-git\nAUR\n, which offers basically the same functionality via an easy to use option located at\nSystem Settings\n>\nNetwork Drivers\n. However, it might break with new KDE Plasma versions.\nKDE Desktop activities\nKDE Desktop Activities\nare special workspaces where you can select specific settings for each activity that apply only when you are using said activity.\nPower management\nInstall\npowerdevil\nfor an integrated Plasma power managing service. This service offers additional power saving features, monitor brightness control (if supported) and battery reporting including peripheral devices.\nTip\nIntegration with\npower profiles\nrequires the\npower-profiles-daemon\noptional dependency.\nThe factual accuracy of this article or section is disputed.\nReason:\nRegarding the note below, it might be that the problem is the logind setting\nLidSwitchIgnoreInhibited\nwhich defaults to\nyes\n.\n[8]\n(Discuss in\nTalk:KDE\n)\nNote\nPower Devil may not\ninhibit\nall logind settings (such as the lid close action for laptops). In these cases, the logind setting itself will need to be changed - see\nPower management#ACPI events\n.\nAutostart\nPlasma can autostart applications and run scripts on startup and shutdown. To autostart an application, navigate to\nSystem Settings > Autostart\nand add the program or shell script of your choice. For applications, a\n.desktop\nfile will be created, for login scripts, a\n.desktop\nfile launching the script will be created.\nNote\nPrograms can be autostarted on login only, whilst shell scripts can also be run on shutdown or even before Plasma itself starts.\nShell scripts will only be run if they are marked\nexecutable\n.\nShell scripts previously placed in\n~/.config/autostart-scripts/\nwill get\nautomatically migrated to .desktop files\n.\nPlace\nDesktop entries\n(i.e.\n.desktop\nfiles) in the appropriate\nXDG Autostart\ndirectory.\nPlace or symlink shell scripts in one of the following directories:\n~/.config/plasma-workspace/env/\n: for executing scripts at login before launching Plasma.\n~/.config/plasma-workspace/shutdown/\n: for executing scripts when Plasma exits.\nSee\nofficial documentation\n.\nPhonon\nFrom\nWikipedia\n:\nPhonon is the multimedia API provided by KDE and is the standard abstraction for handling multimedia streams within KDE software and also used by several Qt applications.\nPhonon was originally created to allow KDE and Qt software to be independent of any single multimedia framework such as GStreamer or xine and to provide a stable API for a major version's lifetime.\nPhonon is being widely used within KDE, for both audio (e.g., the System notifications or KDE audio applications) and video (e.g., the\nDolphin\nvideo thumbnails). It can use the following backends:\nVLC\n:\nphonon-qt6-vlc\nGStreamer\n:\nphonon-qt6-gstreamer-git\nAUR\n, see\nGStreamer#Installation\nfor additional codec support\nmpv\n:\nphonon-qt6-mpv\nAUR\nKDE\nrecommends only the VLC backend\n, as the GStreamer backend is\nunmaintained\n.\nNote\nMultiple backends can be installed at once and prioritized via the\nphononsettings\napplication.\nAccording to the\nKDE forums\n, the VLC backend lacks support for\nReplayGain\n.\nIf using the VLC backend, you may experience crashes every time Plasma wants to send you an audible warning and in quite a number of other cases as well\n[9]\n. A possible fix is to rebuild the VLC plugins cache:\n# /usr/lib/vlc/vlc-cache-gen /usr/lib/vlc/plugins\nBackup and restore\nPlasma stores personalized desktop settings as configuration files in the\nXDG_CONFIG_HOME\nfolder. Use the\ndetail of configuration files\nto select and choose a\nmethod of backup and restore\n.\nsystemd startup\nPlasma uses a\nsystemd user\ninstance to launch and manage all the Plasma services. This is the default startup method since Plasma 5.25, but can be\ndisabled to use boot scripts instead\nwith the following command (however this may stop working in a future release):\n$ kwriteconfig6 --file startkderc --group General --key systemdBoot false\nMore details about the implementation can be read in\nEdmundson's blog: Plasma and the systemd startup\n.\nSpell checking\nKDE applications use\nsonnet\nfor spell checking. See its optional dependencies for the supported\nspell checkers\n.\nConfigure it in\nSystem Settings > Spell Check\n.\nRunning KWin Wayland on NVIDIA\nSee\nhttps://community.kde.org/Plasma/Wayland/Nvidia\n.\nApplications\nThe KDE project provides a suite of applications that integrate with the Plasma desktop. See the\nkde-applications\ngroup for a full listing of the available applications. Also see\nCategory:KDE\nfor related KDE application pages.\nAside from the programs provided in KDE Applications, there are many other applications available that can complement the Plasma desktop. Some of these are discussed below.\nSystem administration\nTerminate Xorg server through KDE System Settings\nNavigate to the submenu\nSystem Settings > Keyboard > Advanced (tab) > Key sequence to kill the X server\nand ensure that the checkbox is ticked.\nKCM\nKCM stands for\nKC\nonfig\nM\nodule. KCMs can help you configure your system by providing interfaces in System Settings, or through the command line with\nkcmshell6\n.\nsddm-kcm\n— KDE Configuration Module for\nSDDM\n.\nhttps://invent.kde.org/plasma/sddm-kcm\n||\nsddm-kcm\nkde-gtk-config\n— GTK2 and GTK3 Configurator for KDE.\nhttps://invent.kde.org/plasma/kde-gtk-config\n||\nkde-gtk-config\nwacom tablet\n— KDE GUI for the Wacom Linux Drivers.\nhttps://www.linux-apps.com/p/1127862/\n||\nwacomtablet\nMore KCMs can be found at\nlinux-apps.com\n.\nDesktop search\nKDE implements desktop search with a software called\nBaloo\n, a file indexing and searching solution.\nWeb browsers\nThe following web browsers can integrate with Plasma:\nKonqueror\n— Part of the KDE project, supports two rendering engines – KHTML and the\nChromium\n-based Qt WebEngine.\nhttps://konqueror.org/\n||\nkonqueror\nFalkon\n— A Qt web browser with Plasma integration features, previously known as Qupzilla. It uses Qt WebEngine.\nhttps://userbase.kde.org/Falkon/\n||\nfalkon\nChromium\n— Chromium and its proprietary variant Google Chrome have limited Plasma integration.\nThey can use KWallet\nand KDE Open/Save windows.\nhttps://www.chromium.org/\n||\nchromium\nFirefox\n— Firefox can be configured to better integrate with Plasma. See\nFirefox#KDE integration\nfor details.\nhttps://mozilla.org/firefox\n||\nfirefox\nTip\nStarting from Plasma 5.13, one can integrate\nFirefox\nor\nChrome\nwith Plasma: providing media playback control from the Plasma tray, download notifications and find open tabs in KRunner.\nInstall\nplasma-browser-integration\nand the corresponding browser add-on. Chrome/Chromium support should already be included, for Firefox add-on see\nFirefox#KDE integration\n.\nPIM\nKDE offers its own stack for\npersonal information management\n(PIM). This includes emails, contacts, calendar, etc. To install all the PIM packages, you could use the\nkde-pim\npackage group or the\nkde-pim-meta\nmeta package.\nAkonadi\nAkonadi is a system meant to act as a local cache for PIM data, regardless of its origin, which can be then used by other applications. This includes the user's emails, contacts, calendars, events, journals, alarms, notes, and so on. Akonadi does not store any data by itself: the storage format depends on the nature of the data (for example, contacts may be stored in vCard format).\nInstall\nakonadi\n. For additional addons, install\nkdepim-addons\n.\nNote\nIf you wish to use a database engine other than\nMariaDB\n, then when installing the\nakonadi\npackage, use the following command to skip installing the\nmariadb\ndependencies:\n# pacman -S akonadi --assume-installed mariadb\nSee also\nFS#32878\n.\nIf Akonadi cannot find\n/usr/bin/mysqld\nupon first start, it will fall back to using SQLite.\nMySQL\nBy default Akonadi will use\n/usr/bin/mysqld\n(\nMariaDB\nby default, see\nMySQL\nfor alternative providers) to run a managed MySQL instance with the database stored in\n~/.local/share/akonadi/db_data/\n.\nSystem-wide MySQL instance\nAkonadi supports using the system-wide\nMySQL\nfor its database.\n[10]\nThis article or section needs expansion.\nReason:\nAdd instructions. (Discuss in\nTalk:KDE\n)\n~/.config/akonadi/akonadiserverrc\n[%General]\nDriver=QMYSQL\n[QMYSQL]\nHost=\nName=akonadi_\nusername\nOptions=\"UNIX_SOCKET=/run/mysqld/mysqld.sock\"\nStartServer=false\nPostgreSQL\nAkonadi supports either using the existing system-wide\nPostgreSQL\ninstance, i.e.\npostgresql.service\n, or running a PostgreSQL instance with user privileges and the database in\n~/.local/share/akonadi/db_data/\n.\nPer-user PostgreSQL instance\nInstall\npostgresql\nand\npostgresql-old-upgrade\n.\nEdit\nthe Akonadi configuration file so that it has the following contents:\n~/.config/akonadi/akonadiserverrc\n[%General]\nDriver=QPSQL\nNote\nWhen Akonadi starts, it will create the\n[QPSQL]\nsection and set the appropriate variables in it.\nThe database will be stored in\n~/.local/share/akonadi/db_data/\n.\nStart Akonadi with\nakonadictl start\n, and check its status:\nakonadictl status\n.\nNote\nStarting with\nakonadi\n19.08.0-1 the PostgreSQL database cluster in\n~/.local/share/akonadi/db_data/\nwill get automatically upgraded when a major PostgreSQL version upgrade is detected.\nFor previous\nakonadi\nversions major PostgreSQL version upgrades will require a manual database upgrade. Follow the\nupdate instructions on KDE UserBase Wiki\n. Make sure to adjust the paths to PostgreSQL binaries to those used by\npostgresql\nand\npostgresql-old-upgrade\n, see\nPostgreSQL#Upgrading PostgreSQL\n.\nSystem-wide PostgreSQL instance\nThis requires an already configured and running\nPostgreSQL\n.\nCreate a PostgreSQL user account for your user:\n[postgres]$ createuser\nusername\nCreate a database for Akonadi:\n[postgres]$ createdb -O\nusername\n-E UTF8 --locale=C -T template0 akonadi-\nusername\nEdit\nthe Akonadi configuration file to match the configuration below:\n~/.config/akonadi/akonadiserverrc\n[%General]\nDriver=QPSQL\n[QPSQL]\nHost=/run/postgresql\nName=akonadi-\nusername\nStartServer=false\nNote\nCustom port, username and password can be specified with options\nPort=\n,\nUser=\n,\nPassword=\nin the\n[QPSQL]\nsection.\nStart Akonadi with\nakonadictl start\n, and check its status:\nakonadictl status\n.\nSQLite\nTo use\nSQLite\n,\nedit\nthe Akonadi configuration file to match the configuration below:\n~/.config/akonadi/akonadiserverrc\n[%General]\nDriver=QSQLITE\nNote\nWhen Akonadi starts, it will create the\n[QSQLITE]\nsection and set the appropriate variables in it.\nThe database will be stored as\n~/.local/share/akonadi/akonadi.db\n.\nDisabling Akonadi\nUsers who want to disable Akonadi would need to not start any KDE applications that rely on it. See this\nsection in the KDE userbase\nfor more information.\nKDE Connect\nKDE Connect\nprovides several features to connect your\nAndroid\nor\niOS\nphone with your Linux desktop:\nShare files and URLs to/from KDE from/to any app, without wires.\nTouchpad emulation: Use your phone screen as your computer's touchpad.\nNotifications sync (4.3+): Read your Android notifications from the desktop.\nShared clipboard: copy and paste between your phone and your computer.\nMultimedia remote control: Use your phone as a remote for Linux media players.\nWi-Fi connection: no usb wire or bluetooth needed.\nRSA Encryption: your information is safe.\nYou will need to install KDE Connect both on your computer and on your phone. For PC,\ninstall\nkdeconnect\npackage. For Android, install KDE Connect from\nGoogle Play\nor from\nF-Droid\n. If you want to browse your phone's filesystem, you need to\ninstall\nsshfs\nas well and configure filesystem exposes in your Android app. For iOS, install KDE Connect from the\nApp Store\n. Not all features from the Android version are available on the iOS version.\nTo use remote input functionality on a Plasma Wayland session, the\nxdg-desktop-portal\npackage is required.\nIt is possible to use KDE Connect even if you do not use the Plasma desktop. For GNOME users, better integration can be achieved by installing\ngnome-shell-extension-gsconnect\nAUR\ninstead of\nkdeconnect\n. To start the KDE Connect daemon manually, execute\n/usr/bin/kdeconnectd\n.\nIf you use a\nfirewall\n, you need to open UDP and TCP ports\n1714\nthrough\n1764\n.\nSometimes, KDE Connect will not detect a phone. You can restart the services by running\nkillall kdeconnectd\nand then opening kdeconnect in system settings or running\nkdeconnect-cli --refresh\nfollowed by\nkdeconnect-cli -l\n. You can also use\nPair new device > Add devices by IP\non KDE Connect for Android.\nTips and tricks\nUse a different window manager\nIt is possible to use a window manager other than KWin with Plasma. This allows you to combine the functionality of the KDE desktop with the utility of a\ntiling window manager\n, which may be more fleshed out than KWin tiling scripts.\nThe component chooser settings in Plasma\nno longer allows changing the window manager\n, but you are still able to swap KWin via other methods.\nNote\nWhen replacing Kwin with a window manager which does not provide a Compositor (such as Openbox), any desktop compositing effects e.g. transparency will be lost. In this case, install and run a separate Composite manager to provide the effects such as\nXcompmgr\nor\npicom\n.\nReplacing KWin service\nSince KDE 5.25,\nPlasma's systemd based startup\nis enabled by default.\nTo replace KWin in this startup, you must first\nmask\nthe\nplasma-kwin_x11.service\nfor the current user to prevent it from starting.\nThen,\ncreate\na new systemd\nuser unit\nto start your preferred WM\n[11]\n:\n~/.config/systemd/user/plasma-custom-wm.service\n[Install]\nWantedBy=plasma-workspace.target\n[Unit]\nDescription=Plasma Custom Window Manager\nBefore=plasma-workspace.target\n[Service]\nExecStart=\n/path/to/other/wm\nSlice=session.slice\nRestart=on-failure\nTo use it, do (as\nuser units\n) a\ndaemon-reload\n, make sure you have\nmasked\nplasma-kwin_x11.service\nthen\nenable\nthe newly created\nplasma-custom-wm.service\n.\nNote\nWhen using i3 window manager with Plasma, it may be necessary to manually set dialogs to open in floating mode in order for them to correctly appear. For more information, see\ni3#Correct handling of floating dialogs\n.\nUsing script-based boot and KDEWM\nPlasma's script-based boot is used by disabling\n#systemd startup\n. If you have done so, you can change the window manager by setting the\nKDEWM\nenvironment variable\nbefore Plasma is invoked.\nSystem-wide\nThis article or section is a candidate for merging with\nEnvironment variables#Globally\n.\nNotes:\nThis technique should be moved into a new section there (2.1.3: Using Xsession), and then this section merged with the previous one. (Discuss in\nTalk:KDE\n)\nIf you have root access, you can also add an XSession that will be available to all users as an option on the login screen.\nFirst, create a script with execution permissions as follows:\n/usr/local/bin/plasma-i3.sh\n#!/bin/sh\nexport KDEWM=/usr/bin/i3\n/usr/bin/startplasma-x11\nReplace\n/usr/bin/i3\nto the path to your preferred WM. Ensure the path is correctly set. If KDE is unable to start the window manager, the session will fail and the user will be returned to the login screen.\nThen, to add an XSession, add a file in\n/usr/share/xsessions/\nwith the following content:\n/usr/share/xsessions/plasma-i3.desktop\n[Desktop Entry]\nType=XSession\nExec=/usr/local/bin/plasma-i3.sh\nDesktopNames=KDE\nName=Plasma (i3)\nComment=KDE Plasma with i3 as the WM\nKDE/Openbox session\nThe\nopenbox\npackage provides a session for using KDE with\nOpenbox\n. To make use of this session, disable\n#systemd startup\nand select\nKDE/Openbox\nfrom the\ndisplay manager\nmenu.\nFor those starting the session manually, add the following line to your\nxinit\nconfiguration:\n~/.xinitrc\nexec openbox-kde-session\nKWin tiling window scripts\nA list of KWin extensions that can be used to make KDE behave more like a\ntiling window manager\n.\nPolonium\n— An (unofficial) successor to Bismuth\nhttps://github.com/zeroxoneafour/polonium\n||\nkwin-polonium\nAUR\nKröhnkite\n— A dynamic tiling extension inspired by dwm.\nhttps://github.com/anametologin/krohnkite\n||\nkwin-scripts-krohnkite\nAUR\nKZones\n— A script that mimicks the behavior of Microsoft PowerToys and Windows 11 snap layouts.\nhttps://github.com/gerritdevriese/kzones\n||\nkwin-scripts-kzones\nAUR\nConfiguring monitor resolution / multiple monitors\nTo enable display resolution management and multiple monitors in Plasma, install\nkscreen\n. This provides additional options to\nSystem Settings > Display & Monitor\n.\nConfiguring ICC profiles\nOn X11,\nICC profiles\nare handled by\ncolord\n. To configure them in Plasma,\ninstall\ncolord-kde\n. This provides additional options in\nSystem Settings > Color Management\n. ICC profiles can be imported using\nImport Profile\n.\nFor Wayland sessions, color management is handled by the compositor, i.e. KWin for Plasma. In this case, no additional package is required. The color profile can be configured per monitor in\nSystem Settings > Display & Monitor > Color Profile\n.\nHDR\nHDR support is experimental and only works in a Wayland session.\nSystem Settings > Display & Monitor > High Dynamic Range > Enable HDR\n.\nFor more information on displaying HDR content see\nHDR monitor support\n. Development details about HDR in Plasma can be found on\nXaver Hugl's blog post\n.\nWhen enabling HDR mode in KDE Plasma, SDR content can appear extremely dark, sometimes making the screen nearly\nunreadable\n. To address this, KDE provides two key sliders in display settings:\nMaximum SDR Brightness\n, which adjusts the brightness mapping for SDR content in HDR mode, and\nBrightness\nwhich controls the overall display backlight or\nluminance\nDisable opening application launcher with Super key (Windows key)\nTo disable this feature, you currently have to edit the\nkwinrc\nconfig file and set the\nMeta\nkey under\nModifierOnlyShortcuts\nto an empty string:\n$XDG_CONFIG_HOME/kwinrc\n[ModifierOnlyShortcuts]\nMeta=\nAlternatively, you can also run the following command:\n$ kwriteconfig6 --file kwinrc --group ModifierOnlyShortcuts --key Meta \"\"\nDisable bookmarks showing in application menu\nWith the Plasma Browser integration installed, KDE will show bookmarks in the application launcher.\nTo disable this feature, go to\nSystem Settings > Search > Plasma Search\nand uncheck\nBookmarks\n.\nIBus Integration\nIBus\nis an\ninput method framework\nand can be integrated into KDE. See\nIBus#Integration\nfor details.\nUsing\nIBus\nmay be required when using KDE on\nWayland\nto offer accented characters and dead keys support\n[12]\n.\nEnable hotspot in plasma-nm\nSee\nNetworkManager#Sharing internet connection over Wi-Fi\n.\nRestore previous saved session\nIf you have\nSystem Settings > Session > Desktop Session > Session Restore > On login, launch apps that were open: On last logout\n(default) selected, ksmserver (KDE's session manager) will automatically save/load all open applications to/from\n~/.config/ksmserverrc\non logout/login.\nNote\nCurrently, native Wayland windows cannot be restored. See\nWayland Showstoppers\nfor the current state of development.\nReceive local mail in KMail\nIf you have set up local mail delivery with a\nmail server\nthat uses the\nMaildir\nformat, you may want to receive this mail in KMail. To do so, you can re-use KMail's default receiving account \"Local Folders\" that stores mail in\n~/.local/share/local-mail/\n.\nSymlink the\n~/Maildir\ndirectory (where Maildir format mail is commonly delivered) to the Local Folders' inbox:\n$ ln -s .local/share/local-mail/inbox ~/Maildir\nAlternatively, add a new receiving account with the type\nMaildir\nand set\n~/Maildir\nas its directory.\nConfigure Plasma for all users\nEdit\nconfig/main.xml\nfiles in the\n/usr/share/plasma\n. For example, to configure the Application Launcher for all users, edit\n/usr/share/plasma/plasmoids/org.kde.plasma.kickoff/contents/config/main.xml\n. To prevent the files from being overwritten with package updates, add the files to\nPacman's NoUpgrade\nDisable hibernate\nThis article or section is a candidate for merging with\nPower management\n.\nNotes:\nThis is not specific to KDE. Merge and then either leave this section as a stub linking to that one. (Discuss in\nTalk:KDE\n)\nProperly disable the hibernate feature and hide it from the menu with a Polkit policy rule.\n/etc/polkit-1/rules.d/99-disable-hibernate.rules\n// Disable hibernate for all users\npolkit.addRule(function(action, subject) {\nif ((action.id == \"org.freedesktop.login1.hibernate\")) {\nreturn polkit.Result.NO;\n}\n});\npolkit.addRule(function(action, subject) {\nif ((action.id == \"org.freedesktop.login1.hibernate-multiple-sessions\")) {\nreturn polkit.Result.NO;\n}\n});\nAlternatively, add the following lines to a file in\n/etc/systemd/sleep.conf.d/\n:\n/etc/systemd/sleep.conf.d/00-disable-hibernation.conf\n[Sleep]\nAllowHibernation=no\nAllowSuspendThenHibernate=no\nAllowHybridSleep=no\nUsing window rules\nKwin has the ability to specify rules for specific windows/applications. For example, you can force enable the window titlebar even if the application developer decided that there should not be one. You can set such rules as specific starting position, size, minimize state, keeping above/below others and so on.\nTo create a rule you can press\nAlt+F3\nwhen the window of interest is in focus. Then, in\nMore Actions > Configure special application/window settings\n, you can set the desired property. A list of created rules is available from\nSystem Settings > Window Management > Window Rules\n.\nMount network shares in fixed location\nBy default KDE mount manager (\nkio-fuse\n) will mount network shares to\n${XDG_RUNTIME_DIR}/kio-fuse-\n6-char-random-string\n.\nCreate directory, e.g.\nmnt_kio\nin your home directory:\n$ mkdir ~/mnt_kio\nOverride default\nkio-fuse.service\nusing a\ndrop-in file\n:\n~/.config/systemd/user/kio-fuse.service.d/mountpoint.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/kio-fuse -f %h/mnt_kio\nNow if you mount your network shares via dbus or by openning some file from remote share in Dolphin:\n$ dbus-send --session --print-reply --type=method_call \\\n--dest=org.kde.KIOFuse \\\n/org/kde/KIOFuse \\\norg.kde.KIOFuse.VFS.mountUrl \"smb://etcetc\"\nThey will be mounted to\n~/mnt_kio\n.\nLocally Integrated Menu\nTo have the menu bar integrated with the title bar, install\nmaterial-kwin-decoration-git\nAUR\nfrom the AUR, then in System Settings > Window Decorations, select 'Material' and add the Application Menu button to the title bar (preferably as second from the left). Works only on X11 session.\nPre-authorize remote control on Wayland\nXdg-desktop-portal-kde has support for remote input from a remote desktop session, a virtual KVM switch, kde-connect, emulated devices like a controller using steam-input, etc. This authorization is lost after the application or the desktop-portal is restarted, which causes the \"Remote control requested\" window pop up every time and makes unattended access impossible.\nAs of plasma version 6.3, a permission system was\nimplemented\n, which allows to pre-authorize applications. Currently, the permission api is only available through the\nflatpak\ncli, although applications do not need to run as a flatpak to be able to get pre-authorized.\nAs per\nthe upstream docs\nand\nflatpak-permission-set\nman pages, you need to figure out if the application you want to authorize sets an application ID or not. If started through a runner like\nKRunner\n, it gets set by plasma and is usually the filename of the\n.desktop\n-file under\n/usr/share/applications\n.\nFor example, to pre-authorize a virtual KVM switch like\nlan-mouse\n, you would do:\n$ flatpak permission-set kde-authorized remote-desktop de.feschbar.LanMouse yes\nIf you start it as a daemon in a\nsystemd user-unit\n, you should use the name of that unit instead:\n$ flatpak permission-set kde-authorized remote-desktop lan-mouse yes\nIf you application does not set an ID, you can leave that field empty:\n$ flatpak permission-set kde-authorized remote-desktop \"\" yes\nTroubleshooting\nKDE applications fail to start in GNOME after upgrade to KDE 6\nWayland is used by default for KDE 6 applications, and the KDE applications fail to work under GNOME Wayland (and potentially other DEs/WMs) in this scenario. This can be fixed by setting the\nQT_QPA_PLATFORM=xcb\nenvironment variable\n.\nThis is a workaround for KDE bugs and not a problem with Wayland itself.\nKDE icons missing after upgrade to KDE 6\nAfter the last upgrade to KDE 6 you may notice issues with all of the KDE icons not displaying. Newly created accounts showed them just fine.\nThe issue for this is that the theme got lost while upgrading and had to be reassigned manually. For this go to\nSystem Settings > Colors & Themes > Icons\nand select the theme you would like to use for the icons again.\nqt5ct and kvantum bugs after upgrade\nThis article or section is out of date.\nReason:\nThis was added 2021-02-15 : the \"latest update\" is one year old, is this fixed ? (Discuss in\nTalk:KDE\n)\nLatest update might cause incompatible HiDPI scaling that made some interfaces becomes too big for your screen, some icons are missing or can not be displayed, and missing panels or widgets.\nTry to remove\nqt5ct\nand\nkvantum\nrelated package, then apply default global Plasma theme. If the problem persists, try clearing all your KDE configuration and reinstalling\nplasma\nto overwrite the configuration. Be sure to check HiDPI scaling in KDE system settings as well.\nFonts are huge or seem disproportional\nTry to force font DPI to\n96\nin\nSystem Settings > Text & Fonts > Fonts\n.\nIf that does not work, try setting the DPI directly in your Xorg configuration as documented in\nXorg#Setting DPI manually\n.\nConfiguration related\nMany problems in KDE are related to its configuration.\nPlasma desktop behaves strangely\nPlasma problems are usually caused by unstable\nPlasma widgets\n(colloquially called\nplasmoids\n) or\nPlasma themes\n. First, find which was the last widget or theme you had installed and disable or uninstall it.\nSo, if your desktop suddenly exhibits \"locking up\", this is likely caused by a faulty installed widget. If you cannot remember which widget you installed before the problem began (sometimes it can be an irregular problem), try to track it down by removing each widget until the problem ceases. Then you can uninstall the widget, and file a bug report on the\nKDE bug tracker\nonly if it is an official widget\n. If it is not, it is recommended to find the entry on the\nKDE Store\nand inform the developer of that widget about the problem (detailing steps to reproduce, etc.).\nIf you cannot find the problem, but you do not want\nall\nthe settings to be lost, navigate to\n~/.config/\nand run the following command:\n$ for j in plasma*; do mv -- \"$j\" \"${j%}.bak\"; done\nThis command will rename\nall\nPlasma related configuration files to\n*.bak\n(e.g.\nplasmarc.bak\n) of your user and when you will relogin into Plasma, you will have the default settings back. To undo that action, remove the\n.bak\nfile extension. If you already have\n*.bak\nfiles, rename, move, or delete them first. It is highly recommended that you create regular backups anyway. See\nSynchronization and backup programs\nfor a list of possible solutions.\nClean cache to resolve upgrade problems\nThe\nproblem\nmay be caused by old cache. Sometimes, after an upgrade, the old cache might introduce strange, hard to debug behaviour such as unkillable shells, hangs when changing various settings, Ark being unable to extract archives or Amarok not recognizing any of your music. This solution can also resolve problems with KDE and Qt applications looking bad after an update.\nRebuild the cache using the following commands:\n$ rm ~/.config/Trolltech.conf\n$ kbuildsycoca6 --noincremental\nOptionally, empty the\n~/.cache/\nfolder contents, however, this will also clear the cache of other applications:\n$ rm -rf ~/.cache/*\nSometimes, empty the\n~/.cache/\nfolder does not work, for example, if you encountered the following error:\nkf.service.sycoca: The menu spec file ( \"\" ) contains a Layout or DefaultLayout tag without the mandatory Merge tag inside. Please fix it.\nIt might be something related to outdated configuration files. In the above case, moving\n~/.config/menus/\nfolder away may fix the issue. In other cases, try moving each file out of\n~/.config/menus/\nfolder could be a good way to check what triggers the error.\nPlasma desktop does not respect locale/language settings\nPlasma desktop may use different settings than you set at KDE System Settings panel, or in\nlocale.conf\n(per\nLocale#Variables\n). First thing to do is log out and log in after removing\n~/.config/plasma-localerc\n, if this does not fix the issue, try to edit the file manually. For example, to set\nLANG\nvariable to\nes_ES.UTF-8\nand the\nLC_MESSAGES\nvariable to\nen_US.UTF-8\n:\n~/.config/plasma-localerc\n[Formats]\nLANG=es_ES.UTF-8\n[Translations]\nLANGUAGE=en_US\nCannot change theme, icons, fonts, colors in systemsettings; most icons are not displayed\nMake sure that\nQT_QPA_PLATFORMTHEME\nenvironment variable\nis unset, the command\nprintenv QT_QPA_PLATFORMTHEME\nshould show empty output. Otherwise if you had an environment set (most likely qt5ct or qt6ct) the variable will force qt5ct/qt6ct settings upon Qt applications, the command\nexport QT_QPA_PLATFORMTHEME=\nshould unset the environment.\nAn easier (and more reliable) solution can be to uninstall completely qt5ct and qt6ct.\nVolume control, notifications or multimedia keys do not work\nHiding certain items in the System Tray settings (e.g. Audio Volume, Media Player or Notifications) also disables related features. Hiding the\nAudio Volume\ndisables volume control keys,\nMedia Player\ndisables multimedia keys (rewind, stop, pause) and hiding\nNotifications\ndisables showing notifications.\nLogin Screen KCM does not sync cursor settings to SDDM\nThe Login Screen KCM reads your cursor settings from\n~/.config/kcminputrc\n, without this file no settings are synced. The easiest way to generate this file is to change your cursor theme in\nSystem Settings > Colors & Themes > Cursors\n, then change it back to your preferred cursor theme.\nMissing panels/widgets\nA crash or hardware change can modify the screen numbers, even on a single monitor setup. The panels/widgets can be missing after such an event, this can be fixed in the\n~/.config/plasma-org.kde.plasma.desktop-appletsrc\nfile by changing the\nlastScreen\nvalues.\nGraphical problems\nMake sure you have the proper driver for your GPU installed. See\nXorg#Driver installation\nfor more information. If you have an older card, it might help to\n#Disable desktop effects manually or automatically for defined applications\nor\n#Disable compositing\n.\nForcing dGPU usage on hybrid graphics systems\nHybrid graphics\nis a power management strategy commonly used in laptops that keeps the dedicated graphics processor (dGPU) inactive when not needed, defaulting to the integrated graphics processor (iGPU) for basic desktop rendering to conserve battery life.\nWhile this approach saves power, it can result in suboptimal desktop performance, including low frame rates in animations and potential graphical artifacts, even on systems with capable dGPUs.\nForcing KDE Plasma to utilize the discrete GPU can significantly improve desktop responsiveness and visual quality.\nMethod 1: DRI_PRIME (Open-source drivers)\nFor systems using open-source graphics drivers (Intel + AMDGPU, Intel + Nouveau), you can\nglobally set\nthe\nDRI_PRIME\nenvironment variable to specify the dGPU:\nDRI_PRIME=1\nThe index value (0 or 1) depends on your system configuration. Verify which index corresponds to your dGPU by running:\nDRI_PRIME=1 glxinfo\nNote\nThis method does not work with NVIDIA proprietary drivers. For NVIDIA systems, use\nPRIME render offload\nor the KWin method below.\nMethod 2: KWIN_DRM_DEVICES (KWin-specific)\nFor direct control over KWin's GPU selection, create a startup script that sets the DRM device priority:\n~/.config/plasma-workspace/env/gpu.sh\n#!/bin/bash\nexport KWIN_DRM_DEVICES=/dev/dri/card1:/dev/dri/card0\nTo identify your DRM cards and their corresponding GPUs:\nfor i in /sys/class/drm/card*/device; do\necho \"Card: $(basename $(dirname $i))\"\nif [ -f \"$i/vendor\" ] && [ -f \"$i/device\" ]; then\necho \"GPU: $(cat $i/vendor) $(cat $i/device)\"\nfi\necho \"---\"\ndone\nList the dGPU first in the\nKWIN_DRM_DEVICES\nvariable to prioritize it for rendering.\nGetting current state of KWin for support and debug purposes\nThis command prints out a summary of the current state of KWin including used options, used compositing backend and relevant OpenGL driver capabilities. See more on\nMartin's blog\n.\n$ qdbus6 org.kde.KWin /KWin org.kde.KWin.supportInformation\nDisable desktop effects manually or automatically for defined applications\nPlasma has desktop effects enabled by default and e.g. not every game will disable them automatically. You can disable desktop effects in\nSystem Settings > Window Management > Desktop Effects\nand you can toggle desktop effects with\nAlt+Shift+F12\n.\nAdditionally, you can create custom KWin rules to automatically disable/enable compositing when a certain application/window starts under\nSystem Settings > Window Management > Window Rules\n.\nEnable transparency\nIf you use a transparent background without enabling the compositor, you will get the message:\nThis color scheme uses a transparent background which does not appear to be supported on your desktop\nIn\nSystem Settings > Display & Monitor > Compositor\n, check\nCompositing: Enable on startup\nand restart Plasma.\nDisable compositing\nIn\nSystem Settings > Display & Monitor > Compositor\n, uncheck\nCompositing: Enable on startup\nand restart Plasma.\nFlickering in fullscreen when compositing is enabled\nIn\nSystem Settings > Display & Monitor > Compositor\n, uncheck\nCompositing: Allow applications to block compositing\n. This may harm performance.\nEffects such as Expose, Overview and Desktop Grid are jerky\nSetting the environment variable\nQSG_USE_SIMPLE_ANIMATION_DRIVER\nfor KWIN reduces jerking in some Quick Scene Graphics based effects. For this purpose, it is sufficient to create a drop-in for the service running KWIN:\n/etc/systemd/user/plasma-kwin_x11.service.d/10-kwin_QSG_SAD.conf\n[Service]\nEnvironment=\"QSG_USE_SIMPLE_ANIMATION_DRIVER=1\"\n(in the case of Wayland session, use\nplasma-kwin_wayland.service.d\nas directory name)\nThen restart the session.\nAnother try is to set\nQSG_NO_VSYNC\ninstead of\nQSG_USE_SIMPLE_ANIMATION_DRIVER\n.\nPlasma cursor sometimes shown incorrectly\nCreate the directory\n~/.local/share/icons/default/\n(alternatively,\n~/.icons/default\n), then, inside it, create a file named\nindex.theme\n, then add to it the following contents:\n~/.local/share/icons/default/index.theme\n[Icon Theme]\nInherits=breeze_cursors\nIf applicable, replace\nbreeze_cursors\nwith the cursor theme you use (cursor themes can be found in\n/usr/share/icons/\n, e.g.\nBreeze_Light\n).\nNote\nYou must relogin for these changes to take effect.\nOn Wayland, it is necessary for\nxdg-desktop-portal-gtk\nto be installed for GTK/GNOME applications to correctly apply cursor themes.\nFirefox and Thunderbird ignore cursor theme\nFirefox and Thunderbird running under\nWayland\nwill refer to GSettings to determine which cursor to display.\nTo sync KDE settings to GTK applications, install\nkde-gtk-config\n.\nIf you do not want to install an extra package, you can set the cursor theme manually:\n$ gsettings set org.gnome.desktop.interface cursor-theme\ncursor-theme-name\nCursor jerking/flicking when changing roles (e.g., when mousing over hyperlinks)\nTry installing the appropriate 2D acceleration driver for your system and window manager.\nUnusable screen resolution set\nYour local configuration settings for kscreen can override those set in\nxorg.conf\n. Look for kscreen configuration files in\n~/.local/share/kscreen/\nand check if mode is being set to a resolution that is not supported by your monitor.\nBlurry icons in system tray\nIn order to add icons to tray, applications often make use of the library appindicator. If your icons are blurry, check which version of libappindicator you have installed. If you only have\nlibappindicator-gtk2\nAUR\ninstalled, you can install\nlibappindicator\nas an attempt to get clear icons.\nCannot change screen resolution when running in a virtual machine\nWhen running Plasma in a\nVMware\n,\nVirtualBox\nor\nQEMU\nvirtual machine, kscreen may not allow changing the guest's screen resolution to a resolution higher than 800×600.\nThe workaround is to set the\nPreferredMode\noption in\nxorg.conf.d(5)\n. Alternatively try using a different graphics adapter in the VM, e.g. VBoxSVGA instead of VMSVGA for VirtualBox and Virtio instead of QXL for QEMU. See\nKDE Bug 407058\nfor details.\nDolphin, Kate, etc. stuck long time when opening\nCheck whether your user directories (\nDocuments\n,\nDownloads\n, etc.) are read-only.\nSpectacle screenshot uses old screen state\nIn\nSystem Settings > Display & Monitor > Compositor\n, change\nKeep window thumbnails\nfrom\nOnly from Shown windows\nto\nNever\n. If you are using Intel graphics, ensure that\nxf86-video-intel\nis\nnot installed\n.\nPoor font rendering in GTK applications\nSee\nXDG Desktop Portal#Poor font rendering in GTK applications on KDE Plasma\n.\nImproper window resizing\nYou may observe that windows of some applications do not resize properly, but rather, the resized portion is transparent and mouse clicks are sent to the underlying window. To correct this behavior, change KDE's GTK3 theme to something other than oxygen-gtk.\nRandom lockups while using modesetting or nouveau driver for old nvidia cards\nSee\nNouveau#Random lockups with kernel error messages\n.\nSound problems\nNote\nFirst make sure you have\nalsa-utils\ninstalled.\nNo sound after suspend\nIf there is no sound after suspending and KMix does not show audio devices which should be there, restarting plasmashell and pulseaudio may help:\n$ killall plasmashell\n$ systemctl --user restart pulseaudio.service\n$ plasmashell\nSome applications may also need to be restarted in order for sound to play from them again.\nMP3 files cannot be played when using the GStreamer Phonon backend\nThis can be solved by installing the GStreamer libav plugin (package\ngst-libav\n). If you still encounter problems, you can try changing the Phonon backend used by installing another such as\nphonon-qt6-vlc\n.\nThen, make sure the backend is preferred via\nphononsettings\n.\nNo volume control icon in tray and cannot adjust sound by function key\nCheck if you have\nplasma-pa\ninstalled.\nNo sound after a short time\nIf\njournalctl -p4 -t pulseaudio\ncontains entries saying\nFailed to create sink input: sink is suspended\n, try commenting the following line in\n/etc/pulse/default.pa\n:\n#load-module module-suspend-on-idle\nIf the issue persists,\nplasma-meta\nor\nplasma\nmay have installed\npulseaudio\nalongside\nwireplumber\n. To fix the issue, replace\npulseaudio\nwith\npipewire-pulse\n. If\npulseaudio\nis preferred, replace\nwireplumber\nwith\npipewire-media-session\n. See\nPipeWire#PulseAudio clients\nand\nthis forum thread\nfor more details.\nPower management\nNo Suspend/Hibernate options\nIf your system is able to suspend or hibernate using\nsystemd\nbut do not have these options shown in KDE, make sure\npowerdevil\nis installed.\nNo power profile options\nMake sure you\ninstalled\npowerdevil\nand\npower-profiles-daemon\n.\nRun\npowerprofilesctl\nand check the driver. If it is\nintel_pstate\nor\namd_pstate\n, you are done, otherwise see\nCPU frequency scaling#Scaling drivers\nfor more information on enabling them.\nKMail\nClean Akonadi configuration to fix KMail\nSee\n[13]\nfor details.\nIf you want a backup, copy the following configuration directories:\n$ cp -a ~/.local/share/akonadi ~/.local/share/akonadi-old\n$ cp -a ~/.config/akonadi ~/.config/akonadi-old\nEmpty IMAP inbox in KMail\nFor some IMAP accounts KMail will show the inbox as a top-level container (so it will not be possible to read messages there) with all other folders of this account inside.\n[14]\n. To solve this problem simply disable the server-side subscriptions in the KMail account settings.\nAuthorization error for EWS account in KMail\nWhile setting up EWS account in KMail, you may keep getting errors about failed authorization even for valid and fully working credentials. This is likely caused by broken communication between\nKWallet\nand KMail. To workaround the issue set a passsword via qdbus:\n$ qdbus6 org.freedesktop.Akonadi.Resource.akonadi_ews_resource_0 /Settings org.kde.Akonadi.Ews.Wallet.setPassword \"XXX\"\nAggressive QXcbConnection / kscreen.xcb.helper journal logging\nSee\nQt#Disable/Change Qt journal logging behaviour\n.\nKF5/Qt 5 applications do not display icons in i3/FVWM/awesome\nSee\nQt#Configuration of Qt 5/6 applications under environments other than KDE Plasma\n.\nProblems with saving credentials and persistently occurring KWallet dialogs\nIt is not recommended to turn off the\nKWallet\npassword saving system in the user settings as it is required to save encrypted credentials like Wi-Fi passphrases for each user. Persistently occuring KWallet dialogs can be the consequence of turning it off.\nIn case you find the dialogs to unlock the wallet annoying when applications want to access it, you can let the\ndisplay managers\nSDDM\nand\nLightDM\nunlock the wallet at login automatically, see\nKDE Wallet#Unlock KDE Wallet automatically on login\n. The first wallet needs to be generated by KWallet (and not user-generated) in order to be usable for system program credentials.\nIn case you want the wallet credentials not to be opened in memory for every application, you can restrict applications from accessing it with\nkwalletmanager\nin the KWallet settings.\nIf you do not care for credential encryption at all, you can simply leave the password forms blank when KWallet asks for the password while creating a wallet. In this case, applications can access passwords without having to unlock the wallet first.\nDiscover does not show any applications\nThis can be solved by installing\npackagekit-qt6\n.\nWarning\nAs explained in a\nGitHub comment\nby a Package Maintainer, \"Handling system packages via packagekit is just fundamentally incompatible with our high-maintenance rolling release distro, where any update might leave the system in an unbootable or otherwise unusable state if the user does not take care reading pacman's logs or merging pacnew files before rebooting.\"\nDiscover stops showing updates from Arch repositories\nDiscover sometimes will not remove its PackageKit alpm lock. To release it, remove\n/var/lib/PackageKit/alpm/db.lck\n. Use \"Refresh\" in Discover and updates should appear (if there are any updates pending).\nHigh CPU usage of kscreenlocker_greet with NVIDIA drivers\nAs described in\nKDE Bug 347772\nNVIDIA OpenGL drivers and QML may not play well together with Qt 5. This may lead\nkscreenlocker_greet\nto high CPU usage after unlocking the session. To work around this issue, set the\nQSG_RENDERER_LOOP\nenvironment variable\nto\nbasic\n.\nThen kill previous instances of the greeter with\nkillall kscreenlocker_greet\n.\nOS error 22 when running Akonadi on ZFS\nIf your home directory is on a\nZFS\npool, create a\n~/.config/akonadi/mysql-local.conf\nfile with the following contents:\n[mysqld]\ninnodb_use_native_aio = 0\nSee\nMariaDB#OS error 22 when running on ZFS\n.\nSome programs are unable to scroll when their windows are inactive\nThis is caused by the problematic way of GTK3 handling mouse scroll events. A workaround for this is to set\nenvironment variable\nGDK_CORE_DEVICE_EVENTS=1\n. However, this workaround also breaks touchpad smooth scrolling and touchscreen scrolling.\nTeamViewer behaves slowly\nWhen using TeamViewer, it may behave slowly if you use smooth animations (such as windows minimizing). See\n#Disable compositing\nas a workaround.\nKmail, Kontact and Wayland\nKmail may become unresponsive, show a black messageviewer or similar, often after having been minimized and restored. A workaround may be to set\nenvironment variable\nQT_QPA_PLATFORM=\"xcb;wayland\"\n. See\nKDE Bug 397825\n.\nUnlock widgets (Plasma ≥ 5.18)\nIf you previously locked your widgets, you will probably find yourself unable to unlock them again.\nYou just have to run this command to do so:\n$ qdbus6 org.kde.plasmashell /PlasmaShell evaluateScript \"lockCorona(false)\"\nThe new\nCustomize Layout\ndoes not require to lock them back up but if want to do that:\n$ qdbus6 org.kde.plasmashell /PlasmaShell evaluateScript \"lockCorona(true)\"\nKIO opens URLs with the wrong program\nCheck file associations regarding HTML, PHP, etc... and change it to a browser. KIO's cache files are located in\n$HOME/.cache/kioexec\n. See also\nxdg-utils#URL scheme handlers\n.\nLock the screen before suspending and hibernating\nIn the System Settings application, KDE offers a setting to automatically lock the screen after waking up from sleep. Upon resuming,\nsome users\nreport that the screen is briefly showed before locking. To prevent this behavior and have KDE lock the screen before suspending, create a hook in\nsystemd(1)\nby creating the following file as the root user:\n/usr/lib/systemd/system-sleep/lock_before_suspend.sh\n#!/bin/bash\ncase $1/$2 in\npre/*)\ncase $2 in\nsuspend|hibernate)\nloginctl lock-session\nsleep 1\n;;\nesac\n;;\nesac\nThe use of\nsleep\nis necessary in order for the\nloginctl lock-session\ncommand to complete before the device is suspended. Using a lower timeout may not allow for this to complete.\nAfter creating the file, make it\nexecutable\n.\nFinally, make sure that the KDE setting is enabled by going to\nSystem Settings > Screen Locking\nand checking the\nLock screen automatically: After waking from sleep\ncheckbox.\nX11 shortcuts conflict on Wayland\nSome X11 software like\nfreerdp\ncan grab keyboard input since KDE 5.27. Others like\nVMware\ncannot grab correctly.\n[15]\nIt is inappropriate to force grab\nin Xserver\nor in compositors.\n[16]\nYou can solve it in an elegant way as follows:\nRight click the window titlebar (e.g. VMware or Citrix);\nMore Actions > Configure Special Window Settings...\nClick\nAdd Property...\nand select\nIgnore global shortcuts\n.\nSelect\nforce\nand\nyes\n. Apply it.\nSystem settings not applying when changed\nThis can be caused because system settings cannot access/modify the .config folder in your home directory.\nTo fix this, you need to change the owner of the folder:\n# chown\nuser\n:\nuser\n/home/\nuser\n/.config\nuser\nrefers to the name of the user that you are logged into in KDE Plasma. If the name of your home directory is not the same as the user you are logged in as, you can change it accordingly.\nIf this does not work, you might need to change the permissions of the folder:\n# chmod 755 /home/\nuser\n/.config\nPlasma 6 Global Menu not working with some applications\nThere are issues with the Widget \"Global Menu\" not working with some applications even after installing\nappmenu-gtk-module\nand\nlibdbusmenu-glib\n. The fix is to install the\nplasma5-integration\nand to restart your Session.\nAutomatic mounting of internal drives not working\nThe factual accuracy of this article or section is disputed.\nReason:\nDoubtful advice from security standpoint. Why not use\nfstab user options\ninstead? (Discuss in\nTalk:KDE\n)\nIt is necessary to add a\nPolkit\nrule allowing mounting of internal drives without elevated privileges:\n/etc/polkit-1/rules.d/10-udisks2.rules\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.freedesktop.udisks2.filesystem-mount-system\") {\nreturn polkit.Result.YES;\n}\n});\nSee also\nKDE homepage\nKDE news\nKDE Blogs\nKDE Forums\nKDE Wikis\nKDE bug tracker and reporter\nMartin Graesslin's blog\nKDE Matrix Rooms\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=KDE&oldid=854198\n\"\nCategory\n:\nKDE\nHidden categories:\nPages or sections flagged with Template:Out of date\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Merge\nSearch\nSearch\nKDE\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/KDE"}}
{"text": "PipeWire - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPipeWire\n6 languages\nSuomi\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\n/Examples\nSound system\nWirePlumber\nPipeWire\nis a new low-level multimedia framework. It aims to offer capture and playback for both audio and video with minimal latency and support for\nPulseAudio\n,\nJACK\n,\nALSA\nand\nGStreamer\n-based applications.\nThe daemon based on the framework can be configured to be both an audio server (with PulseAudio and JACK features) and a video capture server.\nPipeWire also supports containers like\nFlatpak\nand does not rely on the\naudio\nand\nvideo\nuser groups\n. Instead, it uses a\nPolkit\n-like security model, asking Flatpak or Wayland for permission to record screen or audio.\nInstallation\nInstall\nthe\npipewire\npackage from the official repositories. There is also\nlib32-pipewire\nfor\nmultilib\nsupport.\nPipewire uses\nsystemd/User\nfor management of the server and automatic socket activation.\nOptionally, install\npipewire-docs\nto review the documentation.\nPipewire can work as drop-in replacement for other audio servers. See\n#Audio\nfor details.\nSession manager\nLike\nJACK\n, PipeWire implements no connection logic internally. The burden of watching for new streams and connecting them to the appropriate output device or application is left to an external component known as a session manager.\nWirePlumber\nWirePlumber\nis the recommended session manager. It is based on a modular design, with Lua plugins that implement the actual management functionality.\nThe stock configuration files are stored in\n/usr/share/wireplumber\n. The recommended way to customize Wireplumber is adding snippets overriding specific settings in\n/etc/wireplumber\nor\n~/.config/wireplumber\n.\n[1]\n.\nWirePlumber changed its configuration format in version 0.5 from\n.lua\nto\n.conf\n. See\nhttps://pipewire.pages.freedesktop.org/wireplumber/daemon/configuration/migration.html#config-migration\nfor migration instructions.\nPipeWire Media Session\npipewire-media-session\nis deprecated and no longer recommended. It was mostly implemented for testing and as an example for building new session managers.\nGUI\nCable\n— A PyQt application to dynamically modify PipeWire and WirePlumber settings at runtime.\nhttps://github.com/magillos/Cable\n||\ncable\nAUR\ncoppwr\n— Low level control and diagnostic GUI for PipeWire.\nhttps://github.com/dimtpap/coppwr\n||\ncoppwr\nAUR\nHelvum\n— GTK-based patchbay for PipeWire, inspired by the JACK tool\ncatia\n. Does not save wire sets.\nhttps://gitlab.freedesktop.org/pipewire/helvum\n||\nhelvum\npwvucontrol\n— Pipewire Volume Control. Alternative to pavucontrol.\nhttps://github.com/saivert/pwvucontrol\n||\npwvucontrol\nAUR\nqpwgraph\n— Qt-based Graph/Patchbay for PipeWire, inspired by the JACK tool QjackCtl. Saves wire sets.\nhttps://gitlab.freedesktop.org/rncbc/qpwgraph\n||\nqpwgraph\nsonusmix\n— Pipewire audio routing tool\nhttps://codeberg.org/sonusmix/sonusmix\n||\nsonusmix\nAUR\nConfiguration\nThe PipeWire package provides an initial set of\nconfiguration files\nin\n/usr/share/pipewire\n. You should not edit these files directly, as package updates will overwrite your changes. To configure PipeWire, you can copy files from\n/usr/share/pipewire\nto the alternate system-wide location\n/etc/pipewire\n, or to the user location\n~/.config/pipewire\n. An equally named file in a directory with a higher precedence makes the analogous files ignored.\nPipeWire brings a custom\nPro Audio\n(do not confuse with\npro audio\n) profile in addition to the PulseAudio profiles, selectable through\npavucontrol\n.\nUsage\nAudio\nPipeWire can be used as an audio server, similar to PulseAudio and JACK. It aims to replace both PulseAudio and JACK, by providing a PulseAudio-compatible server implementation and ABI-compatible libraries for JACK clients. See the blog post\nPipeWire Late Summer Update 2020\nfor more information.\nFirst, install\npipewire-audio\n. Depending on the type of audio clients, you may also need to take some extra steps. You may need to install additional firmware for your audio device, see\nAdvanced Linux Sound Architecture#Firmware\n.\nALSA clients\nInstall\npipewire-alsa\n(and remove\npulseaudio-alsa\nif it was installed) to route all applications using the ALSA API through PipeWire.\nPulseAudio clients\nInstall\npipewire-pulse\n. It will replace\npulseaudio\nand\npulseaudio-bluetooth\n. Reboot, re-login or\nstop\npulseaudio.service\nand\nstart\nthe\npipewire-pulse.service\nuser unit\nto see the effect.\nNormally, no further action is needed as the user service\npipewire-pulse.socket\nshould be enabled automatically by the package. To check if the replacement is working, run the following command for the\nServer Name\nand default input/output:\n$ pactl info\n...\nServer Name: PulseAudio (on PipeWire\nx.y.z\n)\n...\nDefault Sink: alsa_output.{bus}-{device}.{profile}\nDefault Source: alsa_input.{bus}-{device}.{profile}\n...\npactl(1)\nis provided by PulseAudio client library package (\nlibpulse\n), which is installed with\npipewire-pulse\nas a dependency.\nSetting overall or individual channel volume\nTo adjust output channel volume, the\nsink\nneeds to be specified using\npactl get-sink-volume {sink\n} using the value of\nDefault Sink:\n(above) or\nName:\n(below), default sink device (\n@DEFAULT_SINK@\n), or\nSink #\n(e.g.\n1\nbelow):\n$ pactl list sinks | grep -B1 -A9 State:\nSink #1\nState: RUNNING\nName: alsa_output.pci-0000_2d_00.4.analog-surround-51\n...\nDriver: PipeWire\n...\nMute: no\nVolume: front-left: 65536 / 100% / 0.00 dB,   front-right: 65536 / 100% / 0.00 dB,   rear-left: 65536 / 100% / 0.00 dB,   rear-right: 65536 / 100% / 0.00 dB,   front-center: 65536 / 100% / 0.00 dB,   lfe: 65536 / 100% / 0.00 dB\nbalance 0.00\nHint: if audio is playing,\ngrep(1)\nfor\nRUNNING\nas other devices will be\nSUSPENDED\n.\nThe\nbalance\nratio is calculated automatically. To set the overall volume of the default device use:\npactl set-sink-volume @DEFAULT_SINK@ 75%\nTo set individual channels, provide each channel volume separately:\npactl set-sink-volume @DEFAULT_SINK@ 100% 75% 100% 75% 100% 100%\nSource\ninputs are handled similarly.  For further configuration (e.g. regarding modules) see the official upstream Wiki about\nMigration from PulseAudio\nand\nPipewire-Pulse Configuration\n.\nJACK clients\nInstall\npipewire-jack\nfor\nJACK\nsupport. There is also\nlib32-pipewire-jack\nfor\nmultilib\nsupport.\npw-jack(1)\nmay be used to start JACK clients, but it is technically not required, as it only serves as a wrapper around the\nPIPEWIRE_REMOTE\n,\nPIPEWIRE_DEBUG\nand\nPIPEWIRE_LATENCY\nenvironment variables.\nIt is possible to request a custom buffer size by setting a quotient of buffersize/samplerate (which equals the block latency in seconds):\nPIPEWIRE_LATENCY=\"128/48000\"\napplication\nBluetooth devices\nPipeWire handles\nBluetooth audio devices\nif the\npipewire-audio\npackage is installed.\nAutomatic profile selection\nWirePlumber\nhas profile auto-switching enabled by default. It can automatically switch between HSP/HFP and A2DP profiles whenever an input stream is detected. You can disable it with the following command:\n$ wpctl settings --save bluetooth.autoswitch-to-headset-profile false\npipewire-media-session\nhas it disabled by default. You can set\nbluez5.autoswitch-profile\nproperty to\ntrue\nto enable it:\n/etc/pipewire/media-session.d/bluez-monitor.conf (or ~/.config/pipewire/media-session.d/bluez-monitor.conf)\n...\nrules = [\n{\n...\nactions = {\nupdate-props = {\n...\nbluez5.autoswitch-profile = true\n...\nPipeWire patch sets for command line\nqpwgraph\ncan be used to visualize and create connections, and also save and load patch sets.\nFor non-GUI needs, the following are bash scripts to save wiresets, load wiresets, and dewire all connections. For saving and loading, use a command-line parameter for the filename.\npw-savewires\n#!/bin/bash\nif [[ \"$#\" -ne 1 ]]; then\necho\necho 'usage: pw-savewires filename'\necho\nexit 1\nfi\nrm -- \"$1\" &> /dev/null\nlink_nodeOutput=''\nwhile IFS= read -r line; do\nif [[ \"$line\" =~ [|] ]];\nthen\nlink_nodeInput=`echo $line | cut -d \">\" -f 2`\necho \"Saving $link_nodeOutput, ${link_nodeInput//' '}\"\necho \"$link_nodeOutput ${link_nodeInput//' '}\" >> \"$1\"\nelse\nlink_nodeOutput=\"$line\"\nfi\ndone < <(pw-link -lo)\npw-loadwires\n#!/bin/bash\nif [[ \"$#\" -ne 1 ]]; then\necho\necho 'usage: pw-loadwires filename'\necho\nexit 1\nfi\nwhile IFS= read -r line; do\necho \"Connecting $line\"\npw-link $line\ndone < <(cat -- \"$1\")\npw-dewire\n#!/bin/bash\nlink_nodeOutput=''\nwhile IFS= read -r line; do\nif [[ \"$line\" =~ [|] ]];\nthen\nlink_nodeInput=`echo $line | cut -d \">\" -f 2`\necho \"Removing $link_nodeOutput, ${link_nodeInput//' '}\"\npw-link -d $link_nodeOutput ${link_nodeInput//' '}\nelse\nlink_nodeOutput=\"$line\"\nfi\ndone < <(pw-link -lo)\nSharing audio devices with computers on the network\nPipeWire supports sharing audio over the network using several mechanisms, including:\nAES67\nRTP\nApple Airplay\n(without DRM features)\nJACK (\nnetjack2\n)\nRoc\nPipeWire Native RTP\nPulseAudio's network protocol\nSnapcast\nThe PipeWire wiki includes an\noverview and comparison page\nfor the different network protocols.\nThe Pulse Tunnel method is described below. The PipeWire PulseAudio implementation supports\nnetwork streaming\n. An easy way to share audio between computers on the network is to use the\nAvahi\ndaemon for discovery. To enable this functionality,\ninstall\nthe\npipewire-zeroconf\npackage.\nMake sure that the\navahi-daemon.service\nis running (and UDP port\n5353\nis open if using a\nfirewall\n) on all computers that will be sharing audio.\nNote\nSome GUI volume managers hide network cards by default. (ex: in Plasma one has to \"Configure Audio Volume...\" and check \"Show virtual devices\".\nTo share the local audio devices load the appropriate modules on the host (make sure to use the local IP address):\n$ pactl load-module module-native-protocol-tcp listen=\n192.168.1.10\n$ pactl load-module module-zeroconf-publish\nThen load the discovery module on the clients:\n$ pactl load-module module-zeroconf-discover\nIt is also possible to load the modules automatically by creating a dedicated configuration file:\n/etc/pipewire/pipewire-pulse.conf.d/50-network-party.conf (or ~/.config/pipewire/pipewire-pulse.conf.d/50-network-party.conf)\npulse.cmd = [\n{ cmd = \"load-module\" args = \"module-native-protocol-tcp listen=\n192.168.1.10\n\" }\n{ cmd = \"load-module\" args = \"module-zeroconf-discover\" }\n{ cmd = \"load-module\" args = \"module-zeroconf-publish\" }\n]\nStreaming audio to an AirPlay receiver\nIt is possible to stream audio to a device that is posing as an\nAirPlay Receiver\n. To enable this functionality, load the\nRAOP Discover module\n:\n$ pactl load-module module-raop-discover\nIt is also possible to load this module automatically by creating a dedicated configuration file:\n/etc/pipewire/pipewire.conf.d/raop-discover.conf (or ~/.config/pipewire/pipewire.conf.d/raop-discover.conf)\ncontext.modules = [\n{\nname = libpipewire-module-raop-discover\nargs = { }\n}\n]\nSome speakers' AirPlay implementations (like Sonos AirPlay 2 speakers) may require opening up ports 6001 and 6002 for incoming UDP traffic on your source device.\nRun PipeWire on top of native JACK\nPipeWire can also run as a\nJACK\nclient on top of the native JACK daemon if desired.\nSee\nJACK and PipeWire (PipeWire wiki)\nand\nJACK Bridge (PipeWire wiki)\nfor more information and additional configuration (like available channels for example).\nTo use it install the\npipewire-jack-client\nand start JACK. Pipewire should be bridged automatically.\nNote\nSince pipewire\n0.3.81\nloading the jackdbus module is done automatically and is no longer necessary.\nIt can manually be loaded (as explained by\npactl(1)\n) like a PulseAudio module:\npactl load-module module-jackdbus-detect\nbefore starting jack.\nUse ALSA dmix devices as PipeWire sinks\nIt is possible to have a PipeWire server (or multiple, for each user) output to ALSA via\nALSA dmix devices\n. This allows you to use ALSA as the primary audio output system while being able to use non-ALSA devices such as Bluetooth headphones.\nALSA dmix setup\nSuppose you have two cards,\nPCH\nand\nHDMI\n:\n/proc/asound/cards\n0 [PCH            ]: HDA-Intel - HDA Intel PCH\nHDA Intel PCH at 0xdff40000 irq 146\n1 [HDMI           ]: HDA-Intel - HDA ATI HDMI\nHDA ATI HDMI at 0xdfe60000 irq 147\nand your PCMs look like:\n/proc/asound/pcm\n00-00: ALC1220 Analog : ALC1220 Analog : playback 1 : capture 1\n00-02: ALC1220 Alt Analog : ALC1220 Alt Analog : capture 1\n01-03: HDMI 0 : HDMI 0 : playback 1\n01-07: HDMI 1 : HDMI 1 : playback 1\n01-08: HDMI 2 : HDMI 2 : playback 1\n01-09: HDMI 3 : HDMI 3 : playback 1\n01-10: HDMI 4 : HDMI 4 : playback 1\n01-11: HDMI 5 : HDMI 5 : playback 1\nand suppose your ALSA configuration looks something like this:\n/etc/asound.conf\nctl.!default {\ntype hw\ncard PCH\n}\npcm.!default {\ntype plug\nslave.pcm \"\ndmix:PCH,0\n\"\n}\npcm.dhdmi {\ntype plug\nslave.pcm \"\ndmix:HDMI,9\n\"\n}\nIn this particular example, the dmix devices would be\ndmix:PCH,0\nand\ndmix:HDMI,9\n.\nPipeWire dmix setup\nFirst of all, stop WirePlumber from monitoring and adding hardware ALSA devices by disabling the\nmonitor.alsa\nfeature:\n/etc/wireplumber/wireplumber.conf.d/disable-alsa-monitor.conf (or ~/.config/wireplumber/wireplumber.conf.d/disable-alsa-monitor.conf)\nwireplumber.profiles = {\nmain = {\nmonitor.alsa = disabled\n}\n}\nNow, configure PipeWire to use dmix devices. The default configuration file (\n/usr/share/pipewire/pipewire.conf\n) contains a\ncommented out example\nwhich you can use as a basis.\nAdd your own element to the\ncontext.objects\narray:\n/etc/pipewire/pipewire.conf.d/alsa-dmix.conf (or ~/.config/pipewire/pipewire.conf.d/alsa-dmix.conf)\ncontext.objects = [\n# We do not start with dmix, but with an input device.\n# Do not forget to add an input device.\n# On a friend's Laptop, I saw Zoom having a nervous\n# breakdown and endlessly crying because no input device\n# was configured! You have been warned.\n{ factory = adapter\nargs = {\nfactory.name           = api.alsa.pcm.source\nnode.name              = \"alsa-mic-internal\" # name of pulse device (mpv)\nnode.description       = \"Mic Internal\" # name of pulse device (pavucontrol)\nmedia.class            = \"Audio/Source\"\napi.alsa.path          = \"\nhw:PCH,0\n\"\n}\n}\n# Okay, now we add our dmix PCMs\n{ factory = adapter\nargs = {\nfactory.name           = api.alsa.pcm.sink # sink for dmix\nnode.name              = \"alsa-dmix-internal\" # name of pulse device (mpv)\nnode.description       = \"PCM Internal\" # name of pulse device (pavucontrol)\nmedia.class            = \"Audio/Sink\" # Sink for dmix\napi.alsa.path          = \"\ndmix:PCH,0\n\"\n}\n}\n{ factory = adapter\nargs = {\nfactory.name           = api.alsa.pcm.sink # sink for dmix\nnode.name              = \"alsa-dmix-hdmi\" # name of pulse device (mpv)\nnode.description       = \"PCM HDMI\" # name of pulse device (pavucontrol)\nmedia.class            = \"Audio/Sink\" # Sink for dmix\n# remember this is a non-default dmix from /etc/asound.conf\napi.alsa.path          = \"\ndmix:HDMI,9\n\"\n}\n}\n]\nAs a user (non-root), check out the output of\nwpctl status\n, and set the default input(source) and output(sink) devices to your liking with\nwpctl set-default\nID\n.\nID\nis the number before sink/source names.\nNow, you can fully test your configuration.\nSwitching between device profiles\nSome hardware audio devices, like\nsnd_hda_intel\n, function differently depending on which profile the device is running in. In the case of\nsnd_hda_intel\n, there are separate profiles for HDMI and analog output.\nSwitching to HDMI with WirePlumber:\n$ wpctl set-profile <device-ID> 3\n$ wpctl status\n...\n├─ Sinks:\n│  *   53. Built-in Audio Digital Stereo (HDMI) [vol: 1.00]\n...\nSwitching to analog with WirePlumber:\n$ wpctl set-profile <device-ID> 1\n$ wpctl status\n...\n├─ Sinks:\n│  *   51. Built-in Audio Analog Stereo        [vol: 0.60]\n...\nMulti-user audio sharing\nSometimes it is useful to let other users connect to your PipeWire instance. For example, if you login into a different user's account using\nXephyr\nand want the audio you play in the Xephyr session to come out the speakers which are managed by the outer user.\nOne method to do this is to configure the outer user's pipewire-pulse config to listen for localhost tcp connections.\nCreate a file like under the outer user's home directory:\n~/.config/pipewire/pipewire-pulse.conf.d/pulse-server.conf\npulse.properties = {\nserver.address = [\n\"unix:native\"\n\"tcp:127.0.0.1:4713\"   # Now the outer user's pipewire server listens on the IP4 loopback\n]\n}\nThen set the environment variable\nPULSE_SERVER=tcp:127.0.0.1:4713\nin the inner user's session. For example,\nexport\ning it before you start\nXephyr\nas the inner user. More information and alternative setups can be found on\nthis forum thread\n.\nWebRTC screen sharing\nMost applications used to rely on X11 for capturing the desktop (or individual applications), for example when using WebRTC in web browsers (e.g. on Google Meet). On Wayland, the screen sharing mechanism is handled through the\nXDG Desktop Portal\nand PipeWire, which enables sharing content under Wayland with fine-grained access controls.\nTip\nTest whether WebRTC screen sharing is working by using\nMozilla's GetUserMedia WebRTC test page\n.\nNote\nxdg-desktop-portal\n1.10.0 fixed a mismatch between specification and implementation of its D-Bus interface.\n[2]\nHence, some clients may not work with xdg-desktop-portal 1.10.0 or newer.\nFirefox (84+) and Chromium (110+) support this method by default, while on older versions of Chromium (73+), one needs to enable\nWebRTC PipeWire support\nby setting the corresponding (experimental) flag at the URL\nchrome://flags/#enable-webrtc-pipewire-capturer\nor via CLI argument\n--enable-features=WebRTCPipeWireCapturer\n.\nobs-studio\n(27+) supports this method by using the new PipeWire capture source.\nVideo\nThis article or section needs expansion.\nReason:\npipewire-v4l2\n(Discuss in\nTalk:PipeWire\n)\nAlthough the software is not yet production-ready, it is safe to play around with. Most applications that rely on\nGStreamer\nto handle e.g. video streams should work out-of-the-box using the PipeWire GStreamer plugin, see\nGStreamer#PipeWire\n. Applications like e.g.\ncheese\nare therefore already able to share video input using it.\nUsing\npipewire-v4l2\n, it should also be possible to use the\npw-v4l2\nscript to preload a library (\n/lib/pipewire-0.3/v4l2/libpw-v4l2.so\n) that intercepts v4l2 calls and routes video through pipewire.\nAudio post-processing\nPipewire module-filter-chain\nPipewire has an internal module called\nfilter-chain\nthat can create nodes to process audio input and output. See\n/usr/share/pipewire/filter-chain/\nfor examples including equalization, virtual surround sound, LADSPA plugins and channel mixing.\nLADSPA\nYou can install many LADSPA plugins from the official repositories and use them in Pipewire filter chains.\nTo list plugin labels and available controls provided by a specific file use\nanalyseplugin\nfrom the\nladspa\npackage:\n$ analyseplugin /usr/lib/ladspa/lsp-plugins-ladspa.so\nSystemwide parametric equalization\nPipeWire filter-chain supports Parametric EQ\n[3]\n. Create a config file inside\n/etc/pipewire/pipewire.conf.d/\n(or\n~/.config/pipewire/pipewire.conf.d/\n), then edit it to incorporate desired parameters using the following example:\ncontext.modules = [\n{\nname = libpipewire-module-filter-chain\nargs = {\nnode.description = \"Equalizer Sink\"\nmedia.name       = \"Equalizer Sink\"\nfilter.graph = {\nnodes = [\n{\ntype  = builtin\nname  = eq\nlabel = param_eq\nconfig = {\nfilters = [\n{ type = bq_peaking, freq = 100, gain = 0.0, q = 1.0 },\n{ type = bq_peaking, freq = 500, gain = 0.0, q = 1.0 },\n{ type = bq_peaking, freq = 2000, gain = 0.0, q = 1.0 },\n]\n}\n}\n]\nlinks = []\n}\naudio.channels = 2\naudio.position = [ FL FR ]\ncapture.props = {\nnode.name   = \"effect_input.eq\"\nmedia.class = Audio/Sink\n}\nplayback.props = {\nnode.name   = \"effect_output.eq\"\nnode.passive = true\n}\n}\n}\n]\nYou can use arbitrary amount of filters.\nIf you require a pre-amp, apply a\nbq_highshelf\nfilter at frequency 0, for example:\n{ type = bq_highshelf, freq = 0, gain = -5.0, q = 1.0 },\nRestart Pipewire, select \"Equalizer Sink\" as your default sound output device; this should then apply to all applications.\nAlternatively, instead of specifying the\nfilters\narray, you can provide a\nfilename\nproperty, pointing to a parametric equalizer configuration generated from the\nAutoEQ\nproject or\nSquiglink\n, like:\nconfig = {\nfilename = \"/path/to/parametric.txt\"\n}\nEasyEffects\nEasyEffects (former PulseEffects, with GTK) is a Qt utility which provides a large array of audio effects and filters to individual application output streams and microphone input streams. Notable effects include an input/output equalizer, output loudness equalization and bass enhancement, input de-esser and noise reduction plug-in. See\nthe GitHub page\nfor a full list of effects.\nNote\nFirefox has an issue with microphone stream, see\nGithub issue\n.\nIn order to use EasyEffects, install\neasyeffects\n. See\nCommunity Presets\nfor a collection of preset configurations. See\nAutoEq\nfor collection of algorithmically generated EQ presets for headphones.\nNote\nEasyEffects may crash after starting, throwing gtk errors, see\nGithub issue\nfor work around.\nNote\nFor PulseEffects legacy version, see\nPulseAudio#PulseEffects\n.\nNoiseTorch\nNoiseTorch is an alternative way for noise suppression, packaged with\nnoisetorch\nAUR\n. There also exists\nnoisetorch-git\nAUR\n.\nAfter starting it the module can be loaded for the selected microphone. It is possible to adjust the voice activation threshold, which should be set to the highest level, not filtering out any actual voice.\nYou can start audio processing with systemd automatically, see\n[4]\n. Note that the noisetorch binary path is different if installed from AUR.\nNoise suppression for voice\nInstall\nthe\nnoise-suppression-for-voice\npackage.\nThen simply follow the instructions given on\nGitHub\n.\nJamesDSP\nJamesDSP for Linux\n(available as\njamesdsp\nAUR\n) provides open-source sound effects for PipeWire and PulseAudio. It uses its own effects engine and without depending on LADSPA, Calf, etc. JamesDSP was initially published as an audio effects processor for Android devices.\nUsing LADSPA, LV2 and VST plugins\nIf you want to choose between the full list of available LADSPA, LV2 and VST plugins, you can apply them using\ncarla\nwith\npipewire-jack\n.\nStart Carla and go to\nSettings > Configure Carla > Engine\n. Make sure\nAudio driver\nis set to\nJACK\nand choose a\nprocess mode\ndepending on your needs. You can also choose the process mode by running Carla with a specific command, for example\ncarla-rack\nfor the\nContinuous Rack\nmode.\nYou can connect application outputs to Carla manually, but if you want to pass multiple applications through Carla, it might be more convenient to create a single virtual device between applications and Carla and optionally use it as a default device. At the begin, create a new null sink named\ndefault_null_sink\n.\n/etc/pipewire/pipewire.conf.d/10-default-null-sink.conf (or ~/.config/pipewire/pipewire.conf.d/10-default-null-sink.conf)\ncontext.objects = [\n{\nfactory = adapter\nargs = {\nfactory.name = support.null-audio-sink\nnode.name = \"default_null_sink\"\nmedia.class = Audio/Sink\naudio.position = [ FL FR ]\nmonitor.channel-volumes = true\nmonitor.passthrough = true\n}\n}\n]\nRestart PipeWire to apply changes.\nAlternatively, you can create a temporary virtual device with\npw-cli(1)\nor, if\npipewire-pulse\nis installed, with\npactl(1)\n. See\nthe PipeWire wiki\nfor details.\nIn the\nRack\ntab, add whichever plugin you want. Make sure they are\nstereo\ntype. You can change their order. In the\nContinuous Rack\nprocess mode, the one on top of the list will be the first to receive the audio stream, just like in EasyEffects. Afterwards go to the\nPatchbay\ntab and connect the\ndefault_null_sink\nL/R monitors to Carla inputs, then Carla outputs to the playbacks of your desired device (speakers, earphones, HDMI, etc). Save the configuration to a local file, for example\n~/Documents/carla_sink_effects.carxp\n. Carla will automatically restore the connections after opening this file.\nYou can test the effects while a multimedia application is reproducing audio, i.e. watching a video on a website through Firefox. There are two methods to do it. The first one, inside Carla\nPatchbay\ntab, disconnecting all Firefox connections and linking its L/R outputs to\ndefault_null_sink\nplaybacks. The second through\npavucontrol\n, locating Firefox audio stream and redirecting it to\ndefault_null_sink\n(this should remember the connection to automatically redirect the application to the same sink on the next instance).\nTo run Carla with the\nContinuous Rack\nprocess mode and load the saved file at startup, create a\nsystemd user service\n:\n~/.config/systemd/user/jack-carla-rack.service\n[Unit]\nDescription=Load Carla Rack JACK host\n[Service]\nEnvironment=PIPEWIRE_LINK_PASSIVE=true\nType=exec\nExecStart=/usr/bin/carla-rack --no-gui %h/Documents/carla_sink_effects.carxp\n[Install]\nWantedBy=default.target\nThen\nenable\nthe\njack-carla-rack.service\nuser unit\n.\nNote that if you set the\ndefault_null_sink\nas the default device in system settings, all applications will be redirected to it and the volume keys will change its level, not the one on the speakers. If you want to control volume speakers, leave them as the default in system settings and redirect your desired application to\ndefault_null_sink\ninside pavucontrol (Pipewire compatibility layer will remember the connection on the next instance of the same application).\nTroubleshooting\nThis article or section is a candidate for merging with\nPipeWire/Troubleshooting\n.\nNotes:\nThis section is long enough to be split into a dedicated subpage. (Discuss in\nTalk:PipeWire#Move Troubleshooting into a new separate page\n)\nAudio\nMicrophone is not detected by PipeWire\nPipeWire's\nalsa-monitor\nmodule uses\nalsa-card-profiles\nto detect devices by default. If this is not working for you, try to turn off\napi.alsa.use-acp\n, or optionally turn on\napi.alsa.use-ucm\nin\nwireplumber\n:\n/etc/wireplumber/wireplumber.conf.d/alsa-config.conf (or ~/.config/wireplumber/wireplumber.conf.d/alsa-config.conf)\nmonitor.alsa.properties = {\n# Use ALSA-Card-Profile devices. They use UCM or the profile\n# configuration to configure the device and mixer settings.\n# alsa.use-acp = true\n# Use UCM instead of profile when available. Can be disabled\n# to skip trying to use the UCM profile.\nalsa.use-ucm = true\n}\nWith\npipewire-media-session\n:\n/etc/pipewire/media-session.d/alsa-monitor.conf (or ~/.config/pipewire/media-session.d/alsa-monitor.conf)\n...\nrules = [\n{\n...\nactions = {\nupdate-props = {\n...\napi.alsa.use-acp = false\n...\nThen, restart WirePlumber and check available devices:\nThis article or section is out of date.\nReason:\nOption\n--list-targets\nis no longer available in the recent versions of\npw-record\n; in order to list objects use either\nwpctl status\nor\npw-cli ls\nor\npw-dump\ninstead. (Discuss in\nTalk:PipeWire\n)\n$ pw-record --list-targets\nAvailable targets (\"*\" denotes default): 62\n58: description=\"Built-in Audio\" prio=1872\n60: description=\"Built-in Audio\" prio=2000\n*\t62: description=\"Built-in Audio (Loopback PCM)\" prio=1984\nAn alternative solution suggested in\nthis PipeWire issue\nis to add the microphone manually. First of all, make sure the microphone is detected by ALSA.\n$ arecord -l\n**** List of CAPTURE Hardware Devices ****\ncard\ncard_number\n:\ncard_name\n, device\ndevice_number\n:\ndevice_name\n...\nChoose your microphone from the list, and to further test the microphone, run the following commands.\n$ arecord --duration=5 --format=dat --device=hw:\ncard_number\n,\ndevice_number\ntest-mic.wav # record from the mic\n$ aplay test-mic.wav # play it\nIf the microphone is working with\narecord\n, but not detected by PipeWire, try to add a config file to manually add this device.\n/etc/pipewire/pipewire.conf.d/microphone.conf (or ~/.config/pipewire/pipewire.conf.d/microphone.conf)\ncontext.objects = [\n{ factory = adapter\nargs = {\nfactory.name           = api.alsa.pcm.source\nnode.name              = \"microphone\"\nnode.description       = \"Undetected Microphone\"\nmedia.class            = \"Audio/Source\"\napi.alsa.path          = \"hw:\ncard_number\n,\ndevice_number\n\"\n}\n}\n]\nAnd then restart PipeWire to reload the config.\nSound does not automatically switch when connecting a new device\nTo automatically switch to newly connected devices, create this file:\n/etc/pipewire/pipewire-pulse.conf.d/switch-on-connect.conf (or ~/.config/pipewire/pipewire-pulse.conf.d/switch-on-connect.conf)\npulse.cmd = [\n{ cmd = \"load-module\" args = \"module-switch-on-connect\" }\n]\nThen\nrestart\nthe\npipewire-pulse.service\nwith\nsystemctl --user\nand check that\nmodule-switch-on-connect\nis loaded.\nNo sound after connecting to Bluetooth device\nAs of 2020-12-07, if there is no sound after connecting a Bluetooth device, you might need to switch the default sink and/or move a sink input to the correct sink. Use\npactl list sinks\nto list the available sinks and\npactl set-default-sink\nto switch the default sink to the Bluetooth device. This can be automated via\nudev\nusing a script similar to\nthis one\n.\nSee this\nReddit thread\nfor a discussion of the issue. According to author of the script, the headset profile (HSP) might still have problems.\nNo sound in mpv, vlc, totem, but sound works in web browser and GNOME speaker test\nThe factual accuracy of this article or section is disputed.\nReason:\nThe writing style is not wiki, but more like a blog. It needs a rephrase + shortening. Sub chapters are overkill as well. Issue root cause is guessed not verified.  (Discuss in\nTalk:PipeWire\n)\nCondition description\nThe best tool to verify the condition of this issue is to use\nmpv\non a file that is expected to work with installed codecs:\n$ mpv --ao=alsa\ntest_file.mpv\n$ mpv --ao=pcm\ntest_file.mpv\n$ mpv --ao=jack\ntest_file.mpv\n$ mpv --ao=pulse\ntest_file.mpv\n$ mpv --ao=openal\ntest_file.mpv\nThis recipie applies if some or all of the above tests produce sound and the same test with\npipewire\noption does not produce sound:\n$ mpv --ao=pipewire\ntest_file.mpv\nGnome desktop speaker test and web browser 'youtube' produce valid sound outcomes.\nSwitching inputs, muting, unmuting, changing volume in Gnome does not resolve the issue.\nSink status reported by\npactl list sinks\nas 'SUSPENDED' is of no concern, because status properly changes when running video through a web browser.\nUse of\npactl info\ndoes not point to any obvious issues.\nInspection of relevant\nsystemd\nunit logs does not point to any obvious issues.\nReason for the issue\nIt seems that a path from\npipewire\nto hardware got muted or changed somehow.  The original author does not know how to identify and point out at the issue using command line tooling.\nSolution\nInstall\nthe\npavucontrol\npackage.  Run\npavucontrol\n, select the appropriate source in the Configuration tab,  select it again in the Output device tab and then use Mute button to mute and unmute the source while\nmpv --ao=pipewire test.mp4\nvideo is running.\nIn another case, removing\n~/.local/state/wireplumber/\nand rebooting solved the same problem.\nLow volume\nAfter replacing PulseAudio with Pipewire, sound may work fine, but after a reboot, the volume becomes intolerably low.\nOpen\nalsamixer\n, use\nF6\nto select the proper soundcard, and make sure the ALSA volumes are at 100%.\nalsactl\nshould maintain this setting after reboot.\nIncreasing RLIMIT_MEMLOCK\nDec 13 11:11:11 HOST pipewire-pulse[99999]: Failed to mlock memory 0x7f4f659d8000 32832: This is not a problem but for best performance, consider increasing RLIMIT_MEMLOCK\nInstall\nrealtime-privileges\nand add your own user to the\nrealtime\ngroup.\nAlternatively, increasing memlock from 64kB to 128kB seems enough to fix this. If you are running\npipewire-pulse\nunder\nsystemd/User\n, add:\nusername\tsoft\tmemlock\t64\nusername\thard\tmemlock\t128\nto\n/etc/security/limits.d/username.conf\nChanging the default sample rate\nBy default PipeWire sets a fixed global sample rate of 48kHz. If you need to change it, you can set a new default (although it isn't recommended):\n/etc/pipewire/pipewire.conf (or ~/.config/pipewire/pipewire.conf)\n...\ncontext.properties = {\n...\ndefault.clock.rate          =\nsample_rate\n...\nThis, however, isn't recommended as this will affect latencies as the quantum values aren't re-calculated automatically. You will have to change these yourself if you want to preserve the same ratio. To quote the documentation:\nThe default clock rate determines the real time duration of the min/max/default quantums. You might want to change the quantums when you change the default clock rate to maintain the same duration for the quantums.\nKeep in mind that the rates of the streams will remain the same. All that PipeWire will be doing here is resampling to meet your new rate. So the 48kHz streams that would've been left unaltered will now be resampled.\nIf you have gear that can handle different sample rates, it is instead recommended to leave the defaults and follow as indicated here:\n#Changing the allowed sample rate(s)\nChanging the allowed sample rate(s)\nPipeWire can also change dynamically the output sample rates supported by your DAC. The sample rate follows the sample rate of the audio stream being played.\n/etc/pipewire/pipewire.conf (or ~/.config/pipewire/pipewire.conf)\n...\ncontext.properties = {\n...\ndefault.clock.allowed-rates = [\nsample_rate_1\nsample_rate_2\nsample_rate_3\n... ]\n...\nfor example,\n[ 44100 88200 176400 48000 96000 192000 ]\n.\nSay the default sample rate is\n48000\n, which is the default. Normally if a stream outputs audio at 44100Hz (i.e. a music player playing a song at CD quality), Pipewire will resample the stream to 48kHz. However, if you have\n44100\nin this list, Pipewire will instead do the following. Pipewire will see that the stream is at 44100Hz, then check if\n44100\nis in the allowed rates and that the receiving output device (i.e. DAC) supports the rate.\nIn such case, the DAC will play the song losslessly.\nIf the rate isn't in the list or if the DAC doesn't support the rate, PipeWire will simply fall back to resampling the stream to the default sample rate.\nAccording to\nthe developer\n: \"PipeWire allows up to 16 different sample rates and will switch when possible\". That means, with configuration above,\nno resampling is done\nwhen supported. Since PipeWire\n0.3.61\nup to 32 different sample rates can be configured.\nGetting allowed sample rate(s)\nConsult your hardware manual for supported values of your DAC. Supported rates by the kernel driver codec are listed with the following command.\n$ grep -E 'Codec|Audio Output|rates' /proc/asound/card*/codec#*\nIf your DAC does not report codec information, you can try to obtain supported rates like this:\n$ grep -m1 -Hn \"\" /proc/asound/card?/stream? | tee /dev/tty | awk -F':' '{print $1}' | xargs grep 'Rates'\nNote\nAlthough your DAC chip may report rates higher than advertised in specification, some of them were designed for exotic modes like USB to I2S\nChecking currently used sample rate\nTo check which output sample rate is being used for a card run:\n$ grep rate: /proc/asound/card?/pcm??/sub?/hw_params\n/proc/asound/card1/pcm0p/sub0/hw_params:rate: 96000 (96000/1)\nIn\npcm0p\nor\npcm0c\nc\nis short for \"capture\" and\np\nis for \"playback\".\nCommand:\n$ pw-top\nalso shows currently used sample rate for each card and audio stream.\nTip\nIf your DAC will not switch to a higher rate, after setting default.clock.allowed-rates, it may mean that system cannot read rates supported by DAC. In such case you can still try setting default.clock.rate\nSound quality\nLossless\nLossless output (no resampling) is easy to configure with PipeWire. All you should have to do is set the following, which is described here:\n#Changing the allowed sample rate(s)\n. Read that section for further context. These are the industry standard rates that you'll encounter, being the CD quality family (44100Hz, 88200Hz, 176400Hz) and DVD quality family (48kHz, 96kHz, 192kHz). Most audio streams will be in one of these rates. As long as your player of choice is the main stream, and your DAC supports the rate, PipeWire will use it.\nEnsure that your player is the only stream playing or resampling may occur as everything else is resampled to match the sample rate of the main graph.\n/etc/pipewire/pipewire.conf (or ~/.config/pipewire/pipewire.conf)\n...\ncontext.properties = {\n...\ndefault.clock.allowed-rates = [\n44100\n88200\n176400\n48000\n96000\n192000\n]\n...\nResampling\nIf you used PulseAudio with\nresample-method = speex-float-10\nor\nsoxr-vhq\n, then you might consider setting\nresample.quality\nto\n10\nor the maximum\n14\n:\n/etc/pipewire/client.conf.d/resample.conf (or ~/.config/pipewire/client.conf.d/resample.conf)\nstream.properties = {\nresample.quality = 10\n}\nDo not forget to\nrestart\nthe\npipewire.service\nand\npipewire-pulse.socket\nuser units\n(never forget\npipewire-pulse.socket\nif you want your configuration changes to be applied).\nThere is a very little quality difference between\n10\nand\n14\n, but the CPU load difference is 2-3x. And the latency difference between\n4\n,\n10\n,\n14\nis yet to be investigated by anybody.\nresample.quality = 14\non 44100→48000 Hz on Ryzen 2600 causes\npipewire\nor\npipewire-pulse\nprocesses to cause 4.0% one CPU core load.\nYou can compare resamplers here:\nhttps://src.infinitewave.ca/\n(do not pay attention to anything above 18 KHz and over 120 dB). speex is listed as \"Xiph.org Speex\".\nPipeWire uses its own resampling algorithm called Spa. Like with SoX's\nsox\n, Speex's\nspeexenc\n, PipeWire includes its standalone version:\nspa-resample\n. Usage:\n$ spa-resample -q 14 -f s24 -r 48000 input16bit44100orAnythingElse.wav output24bit48000hz.wav\nIt is probably somehow possible to use other resamplers by creating your own sink. Or just use a plugin in your music player (e.g., Qmmp has SoX plugin).\nExternal sound card not activated after reconnect\nCheck\n~/.config/pipewire/media-session.d/default-profile\nif there is any entry with default profile \"off\" and remove it. If that does not help, remove all files from\n~/.config/pipewire/media-session.d/\nand\nrestart\nthe\npipewire.service\nuser unit\n.\nNo Sound or pactl info shows Failure: Connection refused\nIt means applications are unable to connect to the PipeWire-Pulse service check if the\npipewire-pulse.service\nuser unit\nis running.\nIf that does not fix it, run\nstrace -f -o /tmp/pipe.txt pactl info\nand pastebin\n/tmp/pipe.txt\nwhile seeking help on IRC (\n#pipewire\non OFTC) or the mailing-lists.\nLow audio quality on Bluetooth\nIn case Bluetooth playback stutters, check the\nunit status\nof the\npipewire.service\nuser unit for errors similar as below:\nFeb 17 18:23:01 HOST pipewire[249297]: (bluez_input.18:54:CF:04:00:56.a2dp-sink-60) client too slow! rate:512/48000 pos:370688 status:triggered\nIf they appear, check the currently selected codec using\npactl list sinks\nand try changing it by setting\nbluez5.codec\nto one of\nsbc aac ldac aptx aptx_hd\n. You can also try mSBC support (fixes mic on Sony 1000XM3, i.e. Headphones WH-1000XM3 and Earbuds WF-1000XM3), and the SBC-XQ codec.\nNote\nHeadphones like the WH-1000XM3 refuse to advertise any codecs other than SBC/SBC-XQ if \"Sound Quality Mode\" is set to \"Priority On Stable Connection\" instead of \"Prioritize Sound Quality\" in the companion app.\nWith\nwireplumber\n:\n/etc/wireplumber/wireplumber.conf.d/bluez-config.conf (or ~/.config/wireplumber/wireplumber.conf.d/bluez-config.conf)\nmonitor.bluez.properties = {\nbluez5.enable-sbc-xq = true\nbluez5.enable-msbc = true\nbluez5.codecs = [ sbc sbc_xq ]\n}\nWith\npipewire-media-session\n:\n/etc/pipewire/media-session.d/bluez-monitor.conf (or ~/.config/pipewire/media-session.d/bluez-monitor.conf)\n...\nproperties = {\n...\nbluez5.enable-msbc = true\nbluez5.enable-sbc-xq = true\nbluez5.codecs = [sbc sbc_xq]\n...\nRestart PipeWire by\nrestarting\nthe\npipewire.service\nuser unit for the changes to take effect.\nNoticeable audio delay or audible pop/crack when starting playback\nThis is caused by node suspension when inactive.\nWith\nwireplumber\n, create a new file to overwrite the default configuration:\n/etc/wireplumber/wireplumber.conf.d/disable-suspension.conf (or ~/.config/wireplumber/wireplumber.conf.d/disable-suspension.conf)\nmonitor.alsa.rules = [\n{\nmatches = [\n{\n# Matches all sources\nnode.name = \"~alsa_input.*\"\n},\n{\n# Matches all sinks\nnode.name = \"~alsa_output.*\"\n}\n]\nactions = {\nupdate-props = {\nsession.suspend-timeout-seconds = 0\n}\n}\n}\n]\n# bluetooth devices\nmonitor.bluez.rules = [\n{\nmatches = [\n{\n# Matches all sources\nnode.name = \"~bluez_input.*\"\n},\n{\n# Matches all sinks\nnode.name = \"~bluez_output.*\"\n}\n]\nactions = {\nupdate-props = {\nsession.suspend-timeout-seconds = 0\n}\n}\n}\n]\nRestart\npipewire.service\nand\nwireplumber.service\nto apply changes.\nInstead of disabling suspension entirely, you can also change the timeout value to the desired number of seconds of delay before source suspension.\nSome devices implement their own detection of silence and suspension. For them disabling node suspention alone won't work. It's possible to work around them by adding a small amount of noise, making it so the output never goes fully silent:\n.../disable-suspension.conf\n...\nsession.suspend-timeout-seconds = 0,  # 0 disables suspend\ndither.method = \"wannamaker3\", # add dither of desired shape\ndither.noise = 2, # add additional bits of noise\n...\nIt may be necessary to play with\ndither.noise\nand\ndither.method\nparameters to make it so the noise is sufficiently silent and simultaneously loud enough to prevent detection of silence. See\nPipeWire documentation\n.\nWith\npipewire-media-session\n:\nDisable this by editing\n/etc/pipewire/media-session.d/*-monitor.conf\ndepending on where the delay occurs and changing property\nsession.suspend-timeout-seconds\nto 0 to disable or experiment with other values and see what works.\nAlternatively you can comment out the line\nsuspend-node\nin\n/etc/pipewire/media-session.d/media-session.conf\n.\nRestart\nboth\npipewire.service\nand\npipewire-pulse.service\nto apply these changes, or alternatively reboot.\nAudio cutting out when multiple streams start playing\nThis problem can typically be diagnosed by reading the\njournal\nof the\npipewire-pulse.service\nuser unit\nand finding lines similar to:\npipewire-pulse[21740]: pulse-server 0x56009b9d5de0: [Nightly] UNDERFLOW channel:0 offset:370676 underrun:940\nAccording to the\nofficial PipeWire troubleshooting guide\n, to solve this problem for\nwireplumber\n:\n/etc/wireplumber/wireplumber.conf.d/alsa-config.conf (or ~/.config/wireplumber/wireplumber.conf.d/alsa-config.conf)\nmonitor.alsa.rules = [\n{\nmatches = [\n{\nnode.name = \"~alsa_output.*\"\n}\n]\nactions = {\nupdate-props = {\napi.alsa.period-size   = 1024\napi.alsa.headroom      = 8192\n}\n}\n}\n]\nWith\npipewire-media-session\n:\n/etc/pipewire/media-session.d/alsa-monitor.conf (or ~/.config/pipewire/media-session.d/alsa-monitor.conf\napi.alsa.headroom = 1024\nIf you experience audio stuttering because of kernel page locking or late scheduling see\nGaming#Tweaking kernel parameters for response time consistency\n.\nAudio is distorted\nFor microphones, try navigating to the card that is having issues after running\nalsamixer\nand use the arrow keys to reduce any \"Mic Boost\" or \"Internal Mic Boost\" options.\nFollow\n#Changing the default sample rate\n, reducing the sample rate to\n44100\n(44.1 kHz).\nAudio problems after standby\nIf the sound is missing or otherwise garbled after waking the machine up from sleep, it might help to reinitialize ALSA:\n# alsactl init\nHigh latency with USB DACs (e.g. Schiit DACs)\nChanging sample rates or formats might help reduce latency with some DACs such as Schiit Hel 2.\n[5]\nFor\npipewire-media-session\n:\nCopy the default configuration file\n/usr/share/pipewire/media-session.d/alsa-monitor.conf\ninto\n/etc/pipewire/media-session.d/\n(or\n~/.config/pipewire/media-session.d/\n).\nThen append a new rule-block similar to the following one:\n/etc/pipewire/media-session.d/alsa-monitor.conf (or ~/.config/pipewire/media-session.d/alsa-monitor.conf)\n...\nrules = {\n...\n{\nmatches = [\n{\nnode.name = \"alsa_output.\nname-of-node\n\"\n}\n]\nactions = {\nupdate-props = {\naudio.format = \"S24_3LE\"\naudio.rate = 96000\n# Following value should be doubled until audio does not cut out or other issues stop occurring\napi.alsa.period-size = 128\n...\nFor\nwireplumber\n:\n/etc/wireplumber/wireplumber.conf.d/update-rate-and-format.conf (or ~/.config/wireplumber/wireplumber.conf.d/update-rate-and-format.conf)\nmonitor.alsa.rules = [\n{\nmatches = [\n{\nnode.name = \"alsa_output.\nname-of-node\n\"\n}\n]\nactions = {\nupdate-props = {\naudio.format = \"S24_3LE\"\naudio.rate = 96000\n# Following value should be doubled until audio does not cut out or other issues stop occurring\napi.alsa.period-size = 128\n}\n}\n}\n]\nalsa_output.\nname-of-node\nnode can be obtained using\npw-top\n.\nYour DAC might support a different format or sample rate. You can check what your DAC supports by querying\nALSA\n:\nFirst get the card number of your DAC:\n$ aplay -l\n...\ncard 3: S2 [Schiit Hel 2], device 0: USB Audio [USB Audio]\nSubdevices: 0/1\nSubdevice #0: subdevice #0\n...\nSo in this example it would be card 3.\nGet all supported sample rates and formats:\n$ cat /proc/asound/card\nX\n/stream\nX\n...\nPlayback:\n...\nInterface 1\nAltset 1\nFormat: S16_LE\nChannels: 2\nEndpoint: 0x05 (5 OUT) (ASYNC)\nRates: 44100, 48000, 88200, 96000, 176400, 192000, 352800, 384000\nData packet interval: 125 us\nBits: 16\n...\nInterface 1\nAltset 2\nFormat: S24_3LE\nChannels: 2\nEndpoint: 0x05 (5 OUT) (ASYNC)\nRates: 44100, 48000, 88200, 96000, 176400, 192000, 352800, 384000\nData packet interval: 125 us\nBits: 24\n...\nInterface 1\nAltset 3\nFormat: S32_LE\nChannels: 2\nEndpoint: 0x05 (5 OUT) (ASYNC)\nRates: 44100, 48000, 88200, 96000, 176400, 192000, 352800, 384000\nData packet interval: 125 us\nBits: 32\n...\n...\nIn this case\nS16_LE, S24_3LE, S32_LE\nare the supported formats and\n44100, 48000, 88200, 96000, 176400, 192000, 352800, 384000\nare the supported sample rates across all formats.\nNo sound from USB DAC until 30% volume\nSome USB DACs will have no sound output until a certain level of volume is reached\n[6]\n. Typically, this is around 15% to 30%, which may result in an uncomfortably loud initial volume and the inability to maintain a low volume. The solution is to ignore hardware mixer volume control by setting\napi.alsa.soft-mixer\nfor the device to\ntrue\n.\nTo achieve this with\nwireplumber\n, use:\n/etc/wireplumber/wireplumber.conf.d/alsa-soft-mixer.conf (or ~/.config/wireplumber/wireplumber.conf.d/alsa-soft-mixer.conf)\nmonitor.alsa.rules = [\n{\nmatches = [\n{\ndevice.name = \"alsa_card.\nname-of-device\n\"\n}\n]\nactions = {\nupdate-props = {\n# Do not use the hardware mixer for volume control. It\n# will only use software volume. The mixer is still used\n# to mute unused paths based on the selected port.\napi.alsa.soft-mixer = true\n}\n}\n}\n]\nRefer to\nWirePlumber#Obtain_interface_name_for_rules_matching\nto find the correct value to replace\n\"alsa_card.\nname-of-device\n\"\n.\nAlternatively, you may specify\n\"~alsa_card.*\"\nto apply the rules to all your audio devices.\nThen, restart pipewire, e.g. by running\nsystemctl --user restart pipewire\n. Set your master volume in\nalsamixer\n, then save the settings by running\nalsactl store\nas root. You should now be able to use your volume mixer as normal.\nRealtime audio does not work\nIf\nRTKit error: org.freedesktop.DBus.Error.AccessDenied\nshows up in the\nstatus\nof the\npipewire.service\nuser unit\n, then the priority of the pipewire daemon was not changed to realtime. See\n[7]\nfor this issue.\nSimultaneous output to multiple sinks on the same sound card\nCreate a copy of\n/usr/share/alsa-card-profile/mixer/profile-sets/default.conf\nso that changes persist across updates. Here we define a profile joining the two default mappings for Analog and HDMI.\n/usr/share/alsa-card-profile/mixer/profile-sets/multiple.conf\n[General]\nauto-profiles = no\n[Mapping analog-stereo]\ndevice-strings = front:%f\nchannel-map = left,right\npaths-output = analog-output analog-output-lineout analog-output-speaker analog-output-headphones analog-output-headphones-2\npaths-input = analog-input-front-mic analog-input-rear-mic analog-input-internal-mic analog-input-dock-mic analog-input analog-input-mic analog-input-linein analog-input-aux analog-input-video analog-input-tvtuner analog-input-fm analog-input-mic-line analog-input-headphone-mic analog-input-headset-mic\npriority = 15\n[Mapping hdmi-stereo]\ndescription = Digital Stereo (HDMI)\ndevice-strings = hdmi:%f\npaths-output = hdmi-output-0\nchannel-map = left,right\npriority = 9\ndirection = output\n[Profile multiple]\ndescription = Analog Stereo Duplex + Digital Stereo (HDMI) Output\noutput-mappings = analog-stereo hdmi-stereo\ninput-mappings = analog-stereo\nThen configure your session manager to use the new card-profile for matching devices. Identifying information can be found using\npw-dump\nor\nwpctl\n.\nFor\nwireplumber\n:\n/etc/wireplumber/wireplumber.conf.d/alsa-custom.conf (or ~/.config/wireplumber/wireplumber.conf.d/alsa-custom.conf)\nmonitor.alsa.rules = [\n{\nmatches = [\n{\ndevice.nick = \"HDA Intel PCH\"\n}\n]\nactions = {\nupdate-props = {\napi.alsa.use-acp = true\napi.acp.auto-profile = false\napi.acp.auto-port = false\ndevice.profile-set = \"multiple.conf\"\ndevice.profile = \"multiple\"\n}\n}\n}\n]\nFor\npipewire-media-session\n:\n/etc/pipewire/media-session.d/alsa-monitor.conf (or ~/.config/pipewire/media-session.d/alsa-monitor.conf)\nrules = [\n{\nmatches = [ { alsa.card_name = \"HDA Intel PCH\" } ]\nactions = {\nupdate-props = {\napi.alsa.use-acp = true\ndevice.profile-set = \"multiple.conf\"\ndevice.profile = \"multiple\"\napi.acp.auto-profile = false\napi.acp.auto-port = false\n}\n}\n}\n]\nNo notification sounds from Discord\nThis might cause by having the min.quantum too low, try setting it to more than 700. You can make an override for Discord specifically by appending the following rule to the pulse.rules section of pipewire-pulse.conf.\n/etc/pipewire/pipewire-pulse.conf (or ~/.config/pipewire/pipewire-pulse.conf)\n...\npulse.rules = [\n...\n{\n# Discord notification sounds fix\nmatches = [ { application.process.binary = \"Discord\" } ]\nactions = {\nupdate-props = {\npulse.min.quantum      = 1024/48000     # 21ms\n}\n}\n}\n...\nFMOD games crashing under PipeWire\nSome games that use an old version of the\nFMOD audio engine\n, like\nPillars of Eternity\n, invoke\npulseaudio --check\nand crash if the PulseAudio binary is not present. A workaround is to symlink\n/bin/pulseaudio\nto\n/bin/true\n.\n[8]\n# ln -s /bin/true /bin/pulseaudio\nNote that if you wish to reinstall PulseAudio, you need to remove the symlink.\nAuto-switching is not working\nIf auto-switching is not working it may be an issue with\nWirePlumber\nstate. As suggested by\nthis comment\nyou can delete\nWirePlumber\n's local state and restart the daemon to see if that helps:\n$ rm -r ~/.local/state/wireplumber/\nThen\nrestart\nthe\nwireplumber.service\nuser unit\n.\nMissing realtime priority/crackling under load after suspend\nDue to a\nbug from 2011\nin rtkit, suspend events cause PipeWire's realtime priority to be revoked and not restored. To disable the protection which causes this,\nedit\nrtkit-daemon.service\n:\n/etc/systemd/system/rtkit-daemon.service.d/override.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/rtkit-daemon --no-canary\nThen restart the\nrtkit-daemon.service\nunit and\npipewire.service\nuser unit, along with the media session service.\nNo sound during streaming to RAOP devices (Sonos etc.)\nSet up mDNS hostname resolution using either\nAvahi\nor\nsystemd-resolved\n.\nNo sound devices show up in KDE Plasma\nPipeWire clients (including the desktop environment) may rely on the\nXDG_RUNTIME_DIR\nenvironment variable\nto connect to the PipeWire daemon.\n[9]\nIf you experience no sound devices immediately after login, it may be because this variable has manually been set to the wrong path.\nAlthough this be resolved by manually restarting PipeWire, other issues can still occur such as being unable to screen share in Chromium (with\npipewire context failed\n).\nXDG_RUNTIME_DIR\nis automatically set by\npam_systemd(8)\n, so you should remove any instances of it being set in your initialization files.\nDevice volume for SDDM and LightDM users is not restored on login\nIf you use\nSDDM\nor\nLightDM\nand notice that your audio volume level is not properly restored after logging in, mask PipeWire for the display manager's user, since WirePlumber running under the display manager can interfere with your user's WirePlumber session.\n# systemctl --user -M\nuser\n@ mask pipewire.socket\nReplace\nuser\nwith\nsddm\nfor SDDM or\nlightdm\nfor LightDM.\nFor more details, see this\nDebian Wiki article\n.\nTerminal bell not working\nFrom PipeWire's perspective, one must have the module x11.bell loaded. This shall be the configuration default (see also in config files mentioned above). Check if you have package\npipewire-x11-bell\ninstalled. Also, your window manager might influence the terminal bell, e.g., for xfwm, check in the xfwm-terminal settings that \"Audible bell\" is activated. Now, restart pipewire service:\n$ systemctl --user restart pipewire\nYou can try if the terminal bell works with:\n$ echo $'\\a'\nNo sound until after first playback attempt\nWhen PipeWire is started using socket activation, some PipeWire-native applications may attempt to play audio before\nWirePlumber\nconfigures the nodes, resulting in an error, for example:\n$ mpv -v\n/path/to/file\n[ao/pipewire] PipeWire does not have any audio sinks, skipping\n[ao] Failed to initialize audio driver 'pipewire'\n$ journalctl --user -u mpd.service\noutput: Failed to play on \"PipeWire\" (pipewire): no target node available\nexception: Failed to open audio output\nAs a workaround, you can\nenable\nthe\npipewire.service\nuser unit\n.\nVideo\nOBS (etc.) display nothing, even if they ask for a window/screen\nIf you are sure that you have\nxdg-desktop-portal\ninstalled as well as either\nxdg-desktop-portal-gtk\nor\nxdg-desktop-portal-kde\n, check the running state of the daemons.\nIn OBS, if everything is working, you should see this in\nstdout\n:\n...\ninfo: [pipewire] desktop selected, setting up screencast\ninfo: [pipewire] created stream 0x5632d7456850\ninfo: [pipewire] playing stream…\nFor multi-monitor setups the\nslurp\npackage will allow to capture of all the screens.\nSee also\nWiki\n— PipeWire Wiki on Freedesktop GitLab\nPipewire Update Blog Post\n— Blog post from January 2018 outlining the state of PipeWire at the time\nPipeWire Late Summer Update 2020\n— Blog post from September 2020\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=PipeWire&oldid=852856\n\"\nCategory\n:\nMultimedia\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Out of date\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nPipeWire\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/PipeWire"}}
{"text": "PulseAudio - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPulseAudio\n5 languages\nDeutsch\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\n/Examples\n/Troubleshooting\nPipeWire\nPulseAudio\nis a general purpose sound server intended to run as a middleware between your applications and your hardware devices, either using\nAdvanced Linux Sound Architecture\n(ALSA) or\nOpen Sound System\n(OSS). It also offers easy network streaming across local devices using\nAvahi\nif enabled. While its main purpose is to ease audio configuration, its modular design allows more advanced users to configure the daemon precisely to best suit their needs.\nNote\nSome confusion may occur between ALSA and PulseAudio. ALSA includes a Linux kernel component with sound card drivers, as well as a userspace component,\nlibasound\n.\n[1]\nPulseAudio builds only on the kernel component, but offers compatibility with\nlibasound\nthrough\npulseaudio-alsa\n.\n[2]\nInstallation\nInstall\nthe\npulseaudio\npackage.\nSome PulseAudio modules are not included in the main package and must be installed separately if needed:\npulseaudio-alsa\nfor PulseAudio to manage ALSA as well, see\n#ALSA\npulseaudio-bluetooth\nfor\nBluetooth\nsupport (BlueZ), see the\nBluetooth headset\npage\npulseaudio-equalizer\nfor equalizer sink (\nqpaeq\n)\npulseaudio-jack\nfor\nJACK\nsink, source and jackdbus detection\npulseaudio-lirc\nfor infrared volume control with\nLIRC\npulseaudio-zeroconf\nfor Zeroconf (\nAvahi\n/DNS-SD) support\nFront-ends\nThere are a number of front-ends available for controlling the PulseAudio daemon:\nConsole\nncpamixer\n— Ncurses mixer for PulseAudio inspired by\npavucontrol\n.\nhttps://github.com/fulhax/ncpamixer\n||\nncpamixer\nAUR\npacmixer\n—\nalsamixer(1)\nalike for PulseAudio.\nhttps://github.com/KenjiTakahashi/pacmixer\n||\npacmixer\nAUR\nPAmix\n— Ncurses PulseAudio mixer similar to\npavucontrol\n.\nhttps://github.com/patroclos/PAmix\n||\npamix\nAUR\npamixer\n— PulseAudio command line mixer.\nhttps://github.com/cdemoulins/pamixer\n||\npamixer\npavolume\n— Simple command-line volume control for PulseAudio with libnotify messages.\nhttps://github.com/sseemayer/pavolume\n||\npavolume-git\nAUR\nPonymix\n— Command line mixer for PulseAudio.\nhttps://github.com/falconindy/ponymix\n||\nponymix\nAUR\npulseaudio-ctl\n— Control PulseAudio volume from the shell or mapped to keyboard shortcuts.\nhttps://github.com/graysky2/pulseaudio-ctl\n||\npulseaudio-ctl\nAUR\npulsemixer\n— CLI and curses mixer for PulseAudio. Discontinued development.\nhttps://github.com/GeorgeFilipkin/pulsemixer\n||\npulsemixer\nGraphical\nKMix\n—\nKDE\nvolume control application supporting several platforms including PulseAudio, system tray applet configurable.\nhttps://apps.kde.org/kmix/\n||\nkmix\nMicTray\n— Lightweight system tray application which lets you control the microphone state and volume using PulseAudio.\nhttps://github.com/Junker/MicTray\n||\nmictray\nAUR\npa-applet\n— System tray applet for PulseAudio with volume bar.\nhttps://github.com/fernandotcl/pa-applet\n||\npa-applet-git\nAUR\npa-notify\n— PulseAudio or PipeWire volume notification daemon.\nhttps://github.com/ikrivosheev/pa-notify\n||\npa-notify\nAUR\npasystray\n— System tray applet for PulseAudio.\nhttps://github.com/christophgysin/pasystray\n||\npasystray\nplasma-pa\n—\nKDE\nPlasma applet for audio volume management using PulseAudio.\nhttps://invent.kde.org/plasma/plasma-pa\n||\nplasma-pa\nPulseAudio Equalizer\n— LADSPA based multiband equalizer for PulseAudio.\nhttps://github.com/pulseaudio-equalizer-ladspa/equalizer\n||\npulseaudio-equalizer-ladspa\nPulseAudio Graph Control\n— Electron-based volume and graph control for PulseAudio.\nhttps://github.com/futpib/pagraphcontrol#readme\n||\npagraphcontrol-git\nAUR\nPulseAudio Preferences\n— Simple GTK configuration dialog for PulseAudio.\nhttps://freedesktop.org/software/pulseaudio/paprefs/\n||\npaprefs\nPulseAudio Volume Control\n— Simple GTK volume control tool (\"mixer\") for PulseAudio.\nhttps://freedesktop.org/software/pulseaudio/pavucontrol/\n||\npavucontrol\nPulseAudio Volume Control (Qt)\n— Mixer for PulseAudio (Qt port of\npavucontrol\n).\nhttps://github.com/lxqt/pavucontrol-qt\n||\npavucontrol-qt\nPulseAudio Volume Meter\n— Simple GTK volume meter for PulseAudio. Discontinued development.\nhttp://0pointer.de/lennart/projects/pavumeter/\n||\npavumeter\nAUR\nPulseEffects\n— Audio effects for PulseAudio applications.\nhttps://github.com/wwmm/easyeffects/tree/pulseaudio-legacy\n||\npulseeffects-legacy\nAUR\nVolctl\n— Per-application system tray applet volume control and OSD for PulseAudio.\nhttps://buzz.github.io/volctl/\n||\nvolctl\nAUR\nXfce PulseAudio Panel Plugin\n— PulseAudio plugin for\nXfce\n4 panel.\nhttps://goodies.xfce.org/projects/panel-plugins/xfce4-pulseaudio-plugin\n||\nxfce4-pulseaudio-plugin\nConfiguration\nBy default, PulseAudio is configured to automatically detect all sound cards and manage them. It takes control of all detected ALSA devices and redirects all audio streams to itself, making the PulseAudio daemon the central configuration point. The daemon should work mostly out of the box, only requiring a few minor tweaks.\nWhile PulseAudio usually runs fine out of the box and requires only minimal configuration, advanced users can change almost every aspect of the daemon by either altering the default configuration file to disable modules or writing your own from scratch.\nPulseAudio runs as a server daemon that can run either system-wide or on per-user basis using a client/server architecture. The daemon by itself does nothing without its\nmodules\nexcept to provide an API and host dynamically loaded modules. The audio routing and processing tasks are all handled by various modules, including PulseAudio's native protocol itself (provided by\nmodule-native-protocol-unix\n). Clients reach the server through one of many protocol modules that will accept audio from external sources, route it through PulseAudio and eventually have it go out through a final other module. The output module does not have to be an actual sound output: it can dump the stream into a file, stream it to a broadcasting server such as\nIcecast\n, or even just discard it.\nYou can find a detailed list of all available modules at\nPulseAudio Loadable Modules\n. To enable them you can just add a line\nload-module\nmodule-name-from-list\nto\n~/.config/pulse/default.pa\n.\nConfiguration files\nPulseAudio will first look for configuration files in the home directory\n~/.config/pulse/\n, and if they are not found, the system-wide configuration from\n/etc/pulse/\nwill be applied.\nTip\nIt is strongly suggested not to edit system-wide configuration files, but rather edit user ones. Create the\n~/.config/pulse\ndirectory, then copy the system configuration files into it and edit according to your need.\nMake sure you keep user configuration in sync with changes to the packaged files in\n/etc/pulse/\n. Otherwise, PulseAudio may refuse to start due to configuration errors.\nThere is usually no need to add your user to the\naudio\ngroup, as PulseAudio uses\nudev\nand\nlogind\nto give access dynamically to the currently \"active\" user. Exceptions would include running the machine headless so that there is no currently \"active\" user.\ndaemon.conf\nThis is the main configuration file to configure the daemon itself. It defines base settings like the default sample rates used by modules, resampling methods, realtime scheduling and various other settings related to the server process. These can not be changed at runtime without restarting the PulseAudio daemon. The defaults are sensible for most users, see the\npulse-daemon.conf(5)\nman page\nfor additional information. Boolean options accepts any of these:\ntrue\n,\nyes\n,\non\nand\n1\nas well as\nfalse\n,\nno\n,\noff\nand\n0\n.\nNote\nPulseAudio does not perform tilde expansion on paths in this file. Use absolute paths for any files.\nOption\nDescription\ndaemonize\nControls whether the server will daemonize itself and return. Set to\nno\nwhen debugging so you can see the debugging information on the terminal.\nresample-method\nWhich resampler to use when audio with incompatible sample rates needs to be passed between modules (e.g. playback of 96kHz audio on hardware which only supports 48kHz). The available resamplers can be listed with\npulseaudio --dump-resample-methods\n. Choose the best tradeoff between CPU usage and audio quality for the present use-case.\nTip\nIn some cases PulseAudio will generate a high CPU load. This can happen when multiple streams are resampled (individually). If this is a common use-case in a workflow, it should be considered to create an additional sink at a matching sample rate which can then be fed into the main sink, resampling only once.\navoid-resampling\nWith\navoid-resampling = yes\n, PulseAudio automatically configures the hardware to the sample rate which the application uses, if the hardware supports this sample rate (needs\nPA 11\nor higher)\nWarning\nEnabling this feature might cause audio distortion, therefore it is disabled by default, see the\nrelease notes\nfor more information.\nenable-remixing\nWhen the input and output have a different channel count (for example, outputting a 6 channel movie into a stereo sink), PulseAudio can either remix all the channels (default,\nyes\n) or just trivially map the channels by their name (left goes to left, right to right, all others ignored) when\nno\n.\nsystem-instance\nIf set to\nyes\n, run the daemon as a\nsystem-wide\ninstance.\nHighly discouraged\nas it can introduce security issues. Useful on\nMultiseat\nsystems, or headless systems that have no real local users. Defaults to\nno\n.\nflat-volumes\nIf set to\nyes\n, scales the device-volume with the volume of the \"loudest\" application. For example, raising the VoIP call volume will raise the hardware volume and adjust the music-player volume so it stays where it was, without having to lower the volume of the music-player manually. Defaults to\nno\n.\nNote\nWhen enabled, this can sometimes be confusing and some applications, unaware of this feature, can set their volume to 100% at startup, potentially blowing your speakers or your ears.\nrealtime-scheduling\nIf your\nkernel\nsupports realtime scheduling (i.e.\nrealtime kernel\n), set this to\nyes\nto ensure PulseAudio can deliver low-latency glitch-free playback. You can adjust\nrealtime-priority\nas well to have it use the correct priority, especially when\nJACK\nis also running on the system.\nnice-level\nSince PulseAudio runs in userspace and involves inter-process communication, audio can be subject to dropouts if the daemon does not have enough CPU time to process the audio. The default usually is enough, but can be tweaked to give PulseAudio the wanted priority over (or below) other applications.\nexit-idle-time\nIf you want to run PulseAudio only when needed and use ALSA otherwise, you can set a delay in seconds after which the daemon will automatically shutdown after all clients are disconnected. Set it to -1 to disable this feature.\nlog-level\nWhen debugging, you may want to increase the logging level of the daemon to see exactly why a specific module fails to load. High logging levels will sometimes print useful information such as detected minimum latency for the system, which can then be used to tweak\ndefault-fragments\nand\ndefault-fragment-size-msec\n.\ndefault-sample-format\nThis usually does not need to be changed, but if your sound card's native format is different, performance and quality can be improved by setting the right format here.\ndefault-sample-rate\nThe default sample rate used by PulseAudio unless overriden at module level. Change this if your sound card does not support 44100Hz or if you wish to upsample all audio. See previous note about CPU usage.\nalternate-sample-rate\nTo fix a common limitation where movies at 48000Hz were needlessly downsampled to 44100Hz, some modules support changing their sample rate dynamically to avoid resampling when possible. See manual for more in-depth information. This usually does not need to be changed.\ndefault-sample-channels\nThe default number of channels when not specified. Usually do not need any change as you can configure more channels on per-module basis.\ndefault-fragments\nAudio samples are split into multiple fragments of\ndefault-fragment-size-msec\neach. The larger the buffer is, the less likely audio will skip when the system is overloaded. On the downside this will increase the overall latency. Increase this value if you have issues.\ndefault-fragment-size-msec\nThe size in milliseconds of each fragment. This is the amount of data that will be processed at once by the daemon.\ndefault.pa\nThis file is a startup script and is used to configure modules. It is actually parsed and read after the daemon has finished initializing and additional commands can be sent at runtime using\npactl(1)\nor\npacmd(1)\n. The startup script can also be provided on the command line by starting PulseAudio in a terminal using\npulseaudio -nC\n. This will make the daemon load the CLI module and will accept the configuration directly from the command line, and output resulting information or error messages on the same terminal. This can be useful when debugging the daemon or just to test various modules before setting them permanently on disk. The manual page is quite self-explanatory, consult\npulse-cli-syntax(5)\nfor the details of the syntax.\nThe default configuration also loads\nmodule-gsettings\nto apply settings specified by\npaprefs\n.\nTip\nRather than being a complete copy,\n~/.config/pulse/default.pa\ncan start with the line\n.include /etc/pulse/default.pa\nand then just override the defaults.\nRun\npacmd list-sinks | grep -Ei 'index:|name:'\nto list available sinks. The present default sink is marked with an asterisk.\nEdit\n~/.config/pulse/default.pa\nto insert/alter the set-default-sink command using the sink's name as the numbering cannot be guaranteed repeatable.\nsystem.pa\nThis file is a startup script used in place of\ndefault.pa\nwhen PulseAudio is running in system-wide mode.\nclient.conf\nThis is the configuration file read by every PulseAudio client application. It is used to configure runtime options for individual clients. It can be used to set and configure the default sink and source statically as well as allowing (or disallowing) clients to automatically start the server if not currently running. If autospawn is enabled, clients will automatically start PulseAudio if it is not already running when a client attempts to connect to it. This can be useful if you do not want PulseAudio to always be running to conserve system resources. Otherwise, you really should have it start with your X11 session.\nConfiguration command\nThe main command to configure a server during runtime is\npacmd\n. Run\npacmd --help\nfor a list options, or just run\npacmd\nto enter the shell interactive mode and\nCtrl+d\nto exit. All modifications will immediately be applied.\nOnce your new settings have been tested and meet your needs, edit the\ndefault.pa\naccordingly to make the change persistent. See\nPulseAudio/Examples\nfor some basic settings.\nTip\nLeave the\nload-module module-default-device-restore\nline in the\ndefault.pa\nfile untouched. It will allow you to restart the server in its default state, thus dismissing any wrong setting.\nIt is important to understand that the \"sources\" (processes, capture devices) and \"sinks\" (sound cards, servers, other processes) accessible and selectable through PulseAudio depend upon the current hardware \"Profile\" selected. These \"Profiles\" are those ALSA \"pcms\" listed by the command\naplay -L\n, and more specifically by the command\npacmd list-cards\n, which will include a line \"index:\", a list beginning \"profiles:\", and a line \"active profile: <...>\" in the output, among other things. \"Profiles\" correspond to different card input/output configurations, notably the number of available input/output channels.\nThe \"active profile\" can be set with the command\npacmd set-card-profile INDEX PROFILE\n, with\nno\ncomma separating INDEX and PROFILE, where INDEX is just the number on the line \"index:\" and a PROFILE name is everything shown from the beginning of any line under \"profiles:\" to just\nbefore\nthe colon and first space, as shown by the command\npacmd list-cards\n. For instance,\npacmd set-card-profile 0 output:analog-stereo+input:analog-stereo\n.\nIt may be easier to select a \"profile\" with a graphical tool like\npavucontrol\n, under the\nConfiguration\ntab, or KDE System Settings, under the\nSound\ntab. Each audio \"card\", which are those devices listed by the command\naplay -l\n, or again by the command\npacmd list-cards\n, will have its own selectable \"profile\". When a \"profile\" has been selected, the then available \"sources\" and \"sinks\" can be seen by using the commands\npacmd list-sources\nand\npacmd list-sinks\n. Note that the \"index\" of the available sources and sinks will change each time a card profile is changed.\nThe selected \"Profile\" can be an issue for some applications, especially the Adobe Flash players, typically\n/usr/lib/mozilla/plugins/libflashplayer.so\nand\n/usr/lib/PepperFlash/libpepflashplayer.so\n. Often, these Flash players will only work when one of the Stereo profiles is selected, and otherwise, will play video with no sound, or will simply \"crash\". When all else fails, you might try selecting a different profile.\nOf course, when configuring some variation of Surround Sound in PulseAudio, the appropriate Surround profile will have to be selected, before Surround Sound will work, or in order to do things like remap the speaker channels.\nIf the only profile you seem to have is \"HiFi\", this means that you are using\nALSA Use Case Manager\nprofiles instead of PulseAudio profiles. See\nPulseAudio/Examples#Disabling UCM/\"HiFi\"\nfor information on how to get back to using PulseAudio profiles.\nConnection and authentication\nSince PulseAudio runs as a daemon as the current user, clients needs to know where to find the daemon socket to connect to it as well as a shared random cookie file clients use to authenticate with it. By default, clients should be able to locate the daemon without problem using environment variables, X11 root window properties, the\ndefault-server\noption in\nclient.conf\nand finally by trying the default location\n$XDG_RUNTIME_DIR/pulse/native\n(typically\nunix:/run/user/\nuser-id\n/pulse/native\n). However, if you have clients that needs to access PulseAudio outside of your X11 session like\nmpd\nrunning as a different user, you will need to tell it how to connect to your PulseAudio instance. See\nPulseAudio/Examples#Allowing multiple users to share a PulseAudio daemon\nfor a complete example. An authentication cookie containing random bytes is enabled by default to ensure audio does not leak from one user to another on a multi-user system. If you already control who can access the server using user/group permissions, you can disable the cookie by passing\nauth-cookie-enabled=0\nto\nmodule-native-protocol-unix\n.\nEnvironment variables\nThese two variables are the important ones in order for libpulse clients to locate PulseAudio if you moved its socket to somewhere else. See\npulseaudio(1)\nfor more details and other useful environment variables clients will read.\nVariable\nDefinition\nPULSE_SERVER\nDefines where the server is. It takes a protocol prefix like\nunix:\nor\ntcp\nfollowed by the path or IP of the server. Example:\nunix:/home/pulse/native-sock\n.\nPULSE_COOKIE\nPoint this to the location of a file that contains the random cookie generated by PulseAudio. This file will be read by clients and its content sent to the server, thus the file has to be readable by all audio clients. It does not need to be the same file, as long as its content matches the one the daemon uses.\nX11 properties\nWhen using SSH X11 forwarding (i.e. when the\nDISPLAY\nand\nSSH_CONNECTION\nenvironment variables\nare present), libpulse clients also use window properties on the root window of the X11 server to help find the daemon.\nX11 properties can be queried using\nxprop -root\n, or with\npax11publish -d\nto read pulse-specific properties.\npax11publish\ncan also be used to update the properties from environment variables (\npax11publish -e\n, or\npax11publish -r\nto remove them entirely). If possible, it is recommended to let PulseAudio do it by itself using the\nmodule-x11-publish\nmodule or the\nstart-pulseaudio-x11\ncommand.\nVariable\nDefinition\nPULSE_SERVER\nString value (\nxprop -root -f PULSE_SERVER 8s -set PULSE_SERVER 127.0.0.1:4713\nor\npax11publish -e -S 127.0.0.1:4713\n), works the same as the environment variable of the same name.\nPULSE_COOKIE\nString value that contains the hexadecimal representation of the authentication cookie.\nRunning\nPulseAudio on Arch has\npulseaudio.socket\nenabled by default for the\nsystemd/User\ninstance. This means that PulseAudio will automatically start when needed.\nNote\nTo disable\npulseaudio.socket\n,\nmask\nthe\npulseaudio.socket\nuser unit\n. This will allow you to have\npulseaudio\ninstalled without applications using it, e.g. you do not need sound or you are using an alternate sound server.\nThis systemd-based approach takes precedence over the\nautospawn\noption described in\npulse-client.conf(5)\n.\npulseaudio\ncomes with option disabled by default, so you need not worry about setting it yourself.\n[3]\nMany\ndesktop environments\nsupport\nXDG Autostart\n. In those desktop environments, PulseAudio will be launched automatically regardless of the socket activation status.\nFor more information, see\nPulseAudio: Running\n.\nStopping\nStop\nthe\npulseaudio.socket\nand\npulseaudio.service\nuser units\n.\nBack-end configuration\nALSA\nWarning\nDo\nnot\nattempt to change the ALSA configuration files while using the default PulseAudio configuration. The default configuration grabs the hardware devices directly in order to allow all the on-the-fly configurations using the GUIs. Changes to the ALSA configurations will very likely be ignored by PulseAudio and ALSA applications will break randomly while trying to access an ALSA device already used by PulseAudio. If you intend to change the ALSA configurations, also configure PulseAudio manually to output to your own ALSA device and play nice with your configuration.\nIf you have applications that do not support PulseAudio explicitly but rely on ALSA, these applications will try to access the sound card directly via ALSA and will therefore bypass PulseAudio. PulseAudio will thus not have access to the sound card any more. As a result, all applications relying on PulseAudio will not be working any more, leading to\nthis issue\n. To prevent this, you will need to install the\npulseaudio-alsa\npackage. It contains the necessary\n/etc/alsa/conf.d/99-pulseaudio-default.conf\nfor configuring ALSA to use PulseAudio. Also make sure that\n~/.asoundrc\ndoes not exist, as it would override the\n/etc/asound.conf\nfile.\nAlso install\nlib32-libpulse\nand\nlib32-alsa-plugins\nif you run a x86_64 system and want to have sound for 32-bit\nmultilib\nprograms like\nWine\nand\nSteam\n.\nTo prevent applications from using\nOSS emulation\nand bypassing PulseAudio (thereby preventing other applications from playing sound), make sure the module\nsnd_pcm_oss\nis not being loaded at boot. If it is currently loaded (\nlsmod | grep oss\n), disable it by executing:\n# rmmod snd_pcm_oss\nEnable DTS via ALSA\nTo enable PulseAudio DTS (Digital Theater System) via ALSA install\ndcaenc\nAUR\npackage and enable it:\n/etc/asound.conf\n<confdir:pcm/dca.conf>\nFinally restart PulseAudio. If experience volume issues with your DTS device and/or PulseAudio, you may fix it by looking for more setting option at\ndcaenc's GitLab\n.\nExpose PulseAudio sources, sinks and mixers to ALSA\nAlthough\npulseaudio-alsa\ncontains the necessary configuration file to allow ALSA applications to use PulseAudio's default device, ALSA's\npulse\nplugin is more versatile than that:\n~/.asoundrc (or /etc/asound.conf)\n# Create an alsa input/output using specific PulseAudio sources/sinks\npcm.pulse-example1 {\ntype pulse\ndevice \"my-combined-sink\" # name of a source or sink\nfallback \"pulse-example2\" # if combined not available\n}\npcm.pulse-example2 {\ntype pulse\ndevice \"other-sound-card\" # name of a source or sink\n# example: device \"alsa_output.pci-0000_00_1b.0.analog-stereo\"\n}\n# Create an ALSA mixer using specific PulseAudio sources/sinks\n# these can be tested with \"alsamixer -D pulse-example3\"\nctl.pulse-example3 {\ntype pulse\ndevice \"my-output\" # name of source or sink to control\n# example: always control the laptop speakers:\n# device \"alsa_output.pci-0000_00_1b.0.analog-stereo\"\nfallback \"pulse-example4\" # supports fallback too\n}\n# Mixers also can control a specific source and sink, separately:\nctl.pulse-example4 {\ntype pulse\nsink \"my-usb-headphones\"\nsource \"my-internal-mic\"\n# example: output to HDMI, record using internal\nsink \"alsa_output.pci-0000_01_00.1.hdmi-stereo-extra1\"\nsource \"alsa_input.pci-0000_00_1b.0.analog-stereo\"\n}\n# These can override the default mixer (example: for pnmixer integration)\nctl.!default {\ntype pulse\nsink \"alsa_output.pci-0000_01_00.1.hdmi-stereo-extra1\"\nsource \"alsa_input.pci-0000_00_1b.0.analog-stereo\"\n}\nThe\nsource code\ncan be read to know all available options.\nALSA/dmix without grabbing hardware device\nNote\nThis section describes alternative configuration, which is generally\nnot\nrecommended.\nYou may want to use ALSA directly in most of your applications while still being able to use applications which require PulseAudio at the same time. The following steps allow you to make PulseAudio use dmix instead of grabbing ALSA hardware device.\nRemove the\npulseaudio-alsa\npackage, which provides compatibility layer between ALSA applications and PulseAudio. After this your ALSA applications will use ALSA directly without being hooked by PulseAudio.\nIn\n/etc/pulse/default.pa\n, comment or delete the\nload-module module-udev-detect\nline and add the following lines:\n/etc/pulse/default.pa\nload-module module-alsa-sink device=dmix\nload-module module-alsa-source device=dsnoop\nOptional:\nIf you use\nkmix\nyou may want to control ALSA volume instead of PulseAudio volume: set\nKMIX_PULSEAUDIO_DISABLE=1\nas an\nenvironment variable\n.\nNow, reboot your computer and try running ALSA and PulseAudio applications at the same time. They both should produce sound simultaneously.\nUse\npavucontrol\nto control PulseAudio volume if needed.\nOSS\nThere are multiple ways of making OSS-only programs output to PulseAudio:\nossp\nInstall the\nossp\npackage and\nstart\nosspd.service\n.\npadsp wrapper\nPrograms using OSS can work with PulseAudio by starting it with\npadsp(1)\n(included with\nlibpulse\n):\n$ padsp\nOSSprogram\nA few examples:\n$ padsp aumix\n$ padsp sox foo.wav -t ossdsp /dev/dsp\nYou can also add a custom wrapper script like this:\n/usr/local/bin/\nOSSprogram\n#!/bin/sh\nexec padsp /usr/bin/\nOSSprogram\n\"$@\"\nMake sure\n/usr/local/bin\ncomes before\n/usr/bin\nin your\nPATH\n.\nNote\nSome applications (e.g.\nFactorio\nwith the OSS audio driver) do not work when the\nmodule-udev-detect\nhas the option\ntsched=0\n.\nGStreamer\ngst-plugins-good\nprovides the\npulseaudio\nplugin for applications using\nGStreamer\n.\nOpenAL\nOpenAL Soft should use PulseAudio by default, but can be explicitly configured to do so:\n/etc/openal/alsoft.conf\ndrivers=pulse,alsa\nlibao\nEdit the libao configuration file:\n/etc/libao.conf\ndefault_driver=pulse\nBe sure to remove the\ndev=default\noption of the\nalsa\ndriver or adjust it to specify a specific PulseAudio sink name or number.\nNote\nYou could possibly also keep the libao standard of outputting to the\nalsa\ndriver and its default device if you install\npulseaudio-alsa\nsince the ALSA default device then\nis\nPulseAudio.\nAudio post-processing\nPulseEffects\nPulseEffects\nis a GTK advanced utility for applying several audio effects (e.g. Noise reduction, Equalizer etc.) to audio input and output.\nNote\nPulseEffects new version (\nEasyEffects\n) only supports\nPipeWire\n. You need to install the legacy version (\npulseeffects-legacy\nAUR\nor\npulseeffects-legacy-git\nAUR\n) to use it with PulseAudio.\nYou may need to also install its optional dependency\nlsp-plugins\nin order to get plugins to work. If PulseEffects plugins are greyed out after installing plugins, trying to start the daemon produces an error, or no devices are shown in the\nSettings > PulseAudio\ntab, consider clearing the cache as shown in\n[4]\n.\nA collection of PulseEffects presets can be found in\ncommunity presets\n.\nEqualization\nIf you want to use a different equalizer rather that the one integrated in\n#PulseEffects\n, there are the following options.\nLADSPA module\nInstall\npulseaudio-equalizer-ladspa\n, an equalizer based on LADSPA\nswh-plugins\n. Launch\npulseaudio-equalizer-gtk\nGUI and tweak the parameters to match your expectations.\nIntegrated module\nPulseAudio has an integrated 10-band equalizer system. In order to use it, install\npulseaudio-equalizer\nand load\nmodule-equalizer-sink\n:\nWarning\nPulseAudio equalizer module is considered\nunstable and might be removed from PulseAudio\n.\n$ pactl load-module module-equalizer-sink\nAlso load\nmodule-dbus-protocol\nif your configuration does not load it by default.\nTo start the GUI, run\nqpaeq\n.\nNote\nIf\nqpaeq\nhas no effect, install\npavucontrol\nand change \"ALSA Playback on\" to \"FFT based equalizer on ...\" while the media player is running.\nTo load the equalizer module on every boot, create a\n.pa\nfile in\n/etc/pulse/default.pa.d/\nor edit\n~/.config/pulse/default.pa\nand add the following lines:\n### Load the integrated PulseAudio equalizer\nload-module module-equalizer-sink\nNote\nThe equalizer sink needs to be loaded after the master sink is already available.\nDynamic Range Compression\nDynamic range compression\ncan be done with\n#PulseEffects\n, however PulseEffects might introduce much overhead and latency to audio stream, so if you only need a compression effect and a minor load on the system, other options are available using a\nmodule-ladspa-sink\n.\nSteve Harris plugin\nSteve Harris LADSPA is a set of plugins containing various compression modules. Install\nswh-plugins\nand edit the configuration as the following:\n~/.config/pulse/default.pa\n.include /etc/pulse/default.pa\nset-default-sink\nyour_card_sink_name\nload-module module-ladspa-sink sink_name=shw_sc4 sink_master=\nyour_card_sink_name\nplugin=sc4_1882 label=sc4 control=,,,,,,\nset-default-sink shw_sc4\nYou have to specify your card sink name, get it from\npacmd list-sinks\n. In order to apply the changes, stop and restart PulseAudio. The above configuration has empty control options using the default values.\nTo tweak the module with custom control parameters, fill them respecting the right order.\nControl option\nDescription\nRMS/peak (0/1)\nThe blanace between the RMS and peak envelope followers. RMS is generally better for subtle, musical compression and peak is better for heavier, fast compression and percussion.\nAttack time (ms)\nThe attack time in milliseconds.\nRelease time (ms)\nThe release time in milliseconds.\nThreshold level (dB)\nThe point at which the compressor will start to kick in.\nRatio (1:n)\nThe gain reduction ratio used when the signal level exceeds the threshold. 1 means no compression; higher values stronger compression.\nKnee radius (dB)\nThe distance from the threshold where the knee curve starts.\nMakeup gain (dB)\nControls the gain of the makeup input signal in decibels.\nOther plugins can be found in\nSteve Harris' LADSPA Plugin Documentation\n.\nCalf plugin\nFor a more professional compressor, you can use the one developed by\nCalf Studio Gear\n[\ndead link\n2025-08-16—SSL error]\n. Install\ncalf-ladspa\nAUR\nand edit the configuration as the following\n~/.config/pulse/default.pa\n.include /etc/pulse/default.pa\nset-default-sink\nyour_card_sink_name\nload-module module-ladspa-sink sink_name=calf_comp_x2 sink_master=\nyour_card_sink_name\nplugin=veal label=Compressor control=,,,,,,,,,,\nset-default-sink calf_comp_x2\nThe plugin has 11 control options. If you want to insert custom values, read the following table and do not forget to specify them in the right order.\nControl option\nDefault\nMin\nMax\nType\nInfo\nBypass\n0\n0\n1\nBool\nLevel in\n1\n0.015625\n64\nFloat db\nThreshold\n0.125\n0.000976563\n1\nFloat dbFs\nFor example, to set -18 db, the right value is 10^(-18/20) = 0.158\nRatio\n2\n1\n20\nFloat\nAttack\n20\n0.01\n2000\nFloat ms\nRelease\n250\n0.01\n2000\nFloat ms\nMakeup\n1\n1\n64\nFloat db\nKnee\n2.828427125\n1\n8\nFloat db\nRMS/Peak\n0\n0\n1\nBool\n0 = RMS; 1 = Peak\nStereo Link\n0\n0\n1\nBool\n0 = Average; 1 = Max\nMix\n1\n0\n1\nFloat\nPercentage\nTo understand the meaning of every single option, read the\nCalf Compressor Documentation\n[\ndead link\n2025-08-16—SSL error]\n.\nMicrophone echo/noise cancellation\nArch does not load the PulseAudio echo-cancellation module by default, therefore, we have to add it in\n/etc/pulse/default.pa.d/\n. First you can test if the module is present with\npacmd\nand entering\nlist-modules\n. If you cannot find a line showing\nname: <module-echo-cancel>\nyou have to create:\n/etc/pulse/default.pa.d/noise-cancellation.pa\n### Enable Echo/Noise-Cancellation\nload-module module-echo-cancel use_master_format=1 aec_method=webrtc aec_args=\"analog_gain_control=0 digital_gain_control=1\" source_name=echoCancel_source sink_name=echoCancel_sink\nset-default-source echoCancel_source\nset-default-sink echoCancel_sink\nthen restart PulseAudio:\n$ pulseaudio -k\n$ pulseaudio --start\nand check if the module is activated by starting\npavucontrol\n. Under\nRecording\n, the input device should show\nEcho-Cancel Source Stream from\n.\nTurning on\nbeamforming=1\nin the\naec_args\ncan also significantly reduce background noise if you have more than one microphone (which is common on many new laptops). However, beamforming requires specifying your\nmic_geometry\n(see below).\nIf you want existing streams to be automatically moved to the new sink and source, you have to load the\nmodule-switch-on-connect\nwith\nignore_virtual=no\nbefore.\nNote\nIf you plug in a USB sound card or headset, or you have for example a 5.1 Speaker configuration and plug in a headset on your front audio connectors after you have loaded the\nmodule-echo-cancel\n, you have to manually unload and load the\nmodule-echo-cancel\nagain, because unfortunately there is no way to tell the module that it should automatically switch to the new default 'source_master' and 'source_sink'. See\n[5]\n.\nPossible 'aec_args' for 'aec_method=webrtc'\nThis article or section is out of date.\nReason:\nSome args were\nremoved\nin PulseAudio 17.0. (Discuss in\nTalk:PulseAudio\n)\nHere is a list of possible 'aec_args' for 'aec_method=webrtc' with their default values\n[6]\n[7]\n:\nanalog_gain_control=1\n- Analog AGC - 'Automatic Gain Control' done over changing the volume directly - Will most likely lead to\ndistortions\n.\ndigital_gain_control=0\n- Digital AGC - 'Automatic Gain Control' done in post processing (higher CPU load).\nexperimental_agc=0\n- Allow enabling of the webrtc experimental AGC mechanism.\nagc_start_volume=85\n- Initial volume when using AGC - Possible values 0-255 - A too low initial volume may prevent the AGC algorithm from ever raising the volume high enough\n[8]\n.\nhigh_pass_filter=1\n- ?\nnoise_suppression=1\n- Noise suppression.\nvoice_detection=1\n- VAD - Voice activity detection.\nextended_filter=0\n- The extended filter is more complex and less sensitive to incorrect delay reporting from the hardware than the regular filter. The extended filter mode is disabled by default, because it seemed produce worse results during double-talk\n[9]\n. Enable this option if your microphone or speaker has a larger latency, for example, if you use a wireless microphone or some HDMI TVs as speaker.\nintelligibility_enhancer=0\n- Some bits for webrtc intelligibility enhancer.\ndrift_compensation=0\n- Drift compensation to allow echo cancellation between different devices (such as speakers on your laptop and the microphone on your USB webcam). - only possible with \"mobile=0\".\nbeamforming=0\n- This can significantly reduce background noise. See\n[10]\n[11]\nmic_geometry=x1,y1,z1,x2,y2,z2\n- Only with \"beamforming=1\".\ntarget_direction=a,e,r\n- Only with \"beamforming=1\". Note: If the module does not want to load with this argument, set azimuth (a) to the desired value, but set elevation (e) and radius (r) to 0.\nmobile=0\n- ?\nrouting_mode=speakerphone\n- Possible Values \"quiet-earpiece-or-headset,earpiece,loud-earpiece,speakerphone,loud-speakerphone\" - only valid with \"mobile=1\".\ncomfort_noise=1\n- ? - only valid with \"mobile=1\".\nDisable audio post processing in certain applications\nIf you are using the\nmodule-echo-cancel\n, you probably do not want other applications to do additional audio post processing. Here is a list for disabling audio post processing in following applications:\nMumble:\nConfigure > Settings > Audio Input\nEcho Cancellation\n: select\nDisabled\nNoise suppression\n: select\nDisabled\nMax. Amplification\n: set slider to\n1.00\nTeamSpeak:\nTools -> Options -> Capture\nUncheck: 'Typing attenuation', 'Remove background noise', 'Echo cancellation' and 'Echo reduction (Ducking)'\nFirefox: see\nFirefox tweaks#Disable WebRTC audio post processing\nSteam:\nSettings > Voice > Advanced Options > Show\nDisable the following sliders:\nEcho cancellation\n,\nNoise cancellation\n,\nAutomatic volume/gain control\nScript for reloading module-echo-cancel\nSince the module-echo-cancel is not always needed, or must be reloaded if the source_master or sink_master has changed, it is nice to have a easy way to load or reload the module-echo-cancel.\nCreate\nthe following script and make it\nexecutable\n:\nechoCancelEnable.sh\n#!/bin/sh\naecArgs=\"$*\"\n# If no \"aec_args\" are passed on to the script, use this \"aec_args\" as default:\n[ -z \"$aecArgs\" ] && aecArgs=\"analog_gain_control=0 digital_gain_control=1\"\nnewSourceName=\"echoCancelSource\"\nnewSinkName=\"echoCancelSink\"\n# \"module-switch-on-connect\" with \"ignore_virtual=no\" (needs PulseAudio 12 or higher) is needed to automatically move existing streams to a new (virtual) default source and sink.\nif ! pactl list modules short | grep \"module-switch-on-connect.*ignore_virtual=no\" >/dev/null 2>&1; then\necho Load module \\\"module-switch-on-connect\\\" with \\\"ignore_virtual=no\\\"\npactl unload-module module-switch-on-connect 2>/dev/null\npactl load-module module-switch-on-connect ignore_virtual=no\nfi\n# Reload \"module-echo-cancel\"\necho Reload \\\"module-echo-cancel\\\" with \\\"aec_args=$aecArgs\\\"\npactl unload-module module-echo-cancel 2>/dev/null\nif pactl load-module module-echo-cancel use_master_format=1 aec_method=webrtc aec_args=\\\"$aecArgs\\\" source_name=$newSourceName sink_name=$newSinkName; then\n# Set a new default source and sink, if module-echo-cancel has loaded successfully.\npacmd set-default-source $newSourceName\npacmd set-default-sink $newSinkName\nfi\nTo run the script easily from the graphical environment, you can create a\ndesktop launcher\nfor it.\nRecurrent neural network noise suppression (RNNoise)\nInstalling the package\nnoise-suppression-for-voice\nwill allow real-time noise suppression based on RNNoise: Learning Noise Suppression\n[12]\n. Configuration details can be found on the projects Github site\n[13]\n. One can install Cadmus (\ncadmus-deb\nAUR\nor\ncadmus-appimage\nAUR\n) which is a GUI frontend for @werman's PulseAudio real-time noise suppression plugin.\nAnother alternative is\nnoisetorch\nAUR\nwhich is also built on top of RNNoise. There is not only input noise cancellation but also an output.\nApplications\nQEMU\nRefer to\nQEMU#Creating an audio backend\nfor a detailed guide on how to configure PulseAudio within\nQEMU\n.\nAlsaMixer.app\nInstall\npulseaudio-alsa\nand make\nalsamixer.app\nAUR\ndockapp for the\nwindowmaker\nAUR\nuse PulseAudio, e.g.:\n$ AlsaMixer.app --device pulse\nHere is a two examples where the first one is for ALSA and the other one is for PulseAudio. You can run multiple instances of it. Use the\n-w\noption to choose which of the control buttons to bind to the mouse wheel.\n$ AlsaMixer.app -3 Mic -1 Master -2 PCM --card 0 -w 1\n$ AlsaMixer.app --device pulse -1 Capture -2 Master -w 2\nSee\n#ALSA\nfor details.\nXMMS2\nMake it switch to PulseAudio output:\n$ xmms2 server config output.plugin pulse\nand to ALSA:\n$ xmms2 server config output.plugin alsa\nTo make XMMS2 use a different output sink, e.g.:\n$ xmms2 server config pulse.sink alsa_output.pci-0000_04_01.0.analog-stereo.monitor\nSee also\nthe official guide\n.\nKDE Plasma Workspaces and Qt\nPulseAudio will automatically be used by KDE / Qt applications. It is supported by default in the KDE sound mixer. For more information see the\nKDE page in the PulseAudio wiki\n.\nIf the phonon-gstreamer backend is used for\nPhonon\n, GStreamer should also be configured as described in\n#GStreamer\n.\nAudacious\nAudacious\nnatively supports PulseAudio. In order to use it, set\nFile > Settings > Audio > Output plugin > PulseAudio Output\n.\nMusic Player Daemon (MPD)\nConfigure\nMPD\nto use PulseAudio. See also\nMusic Player Daemon/Tips and tricks#PulseAudio\n.\nMPlayer\nMPlayer\nnatively supports PulseAudio output with the\n-ao pulse\noption. It can also be configured to default to PulseAudio output, in\n~/.mplayer/config\nfor per-user, or\n/etc/mplayer/mplayer.conf\nfor system-wide:\n/etc/mplayer/mplayer.conf\nao=pulse\nmpv\nmpv\nsupports PulseAudio same as written for\n#MPlayer\n. Configuration in\n~/.config/mpv/mpv.conf\nper-user, or\n/etc/mpv/mpv.conf\nsystem-wide.\nguvcview\nguvcview\nwhen using the PulseAudio input from a\nWebcam\nmay have the audio input suspended resulting in no audio being recorded.  You can check this by executing:\n$ pactl list sources\nIf the audio source is \"suspended\" then create the folowing\n.pa\nfile:\n/etc/pulse/default.pa.d/no-module-suspend-on-idle.pa\nunload-module module-suspend-on-idle\nAnd then either restarting PulseAudio or your computer will only idle the input source instead of suspending it.  guvcview will then correctly record audio from the device.\nNetworked audio\nThis article or section is a candidate for merging with\nPulseAudio/Examples#PulseAudio over network\n.\nNotes:\nNo need for two separate sections. (Discuss in\nTalk:PulseAudio\n)\nOne of PulseAudio's unique features is its ability to stream audio from clients over TCP to a server running the PulseAudio daemon reliably within a LAN. Ensure that client and server systems agree on the time (i.e., use NTP), or audio streams may be choppy or may not work at all. For a more detailed guide visit the\nofficial PulseAudio documentation\n.\nTo enable the TCP module on the server (the computer that actually outputs sound), create the following\n.pa\nfile:\n/etc/pulse/default.pa.d/tcp.pa\nload-module module-native-protocol-tcp\nOr you can use the\npaprefs\nGUI application (root is not required). Go to\nNetwork Server > Enable network access to local sound devices\n.\nTo make sure\nmodule-native-protocol-tcp\nis loaded on the server, you can use:\n$ pacmd list-modules | grep module-native-protocol-tcp\nIt is a requirement that both the client and server share the same cookie. Ensure that the clients and server share the same cookie file found under\n~/.config/pulse/cookie\n. It does not matter whose cookie file you use (the server or a client's), just that the server and client(s) share the same one.\nIf it is undesirable to copy the cookie file from clients, anonymous clients can access the server by passing\nauth-anonymous\nto\nmodule-native-protocol-tcp\non the server (again in\n/etc/pulse/default.pa.d/\n):\nload-module module-native-protocol-tcp auth-anonymous=1\nIt is also possible to authenticate based on client IP address:\nload-module module-native-protocol-tcp auth-ip-acl=127.0.0.1;192.168.0.0/24\nChange the LAN IP subnet to match that of those clients you wish to have access to the server.\nStarting system-wide on boot\nThe PulseAudio daemon normally starts as a user service when a user logs in and attempts to play some sort of audio. For running a dedicated PulseAudio server accepting client connections over TCP, the daemon must be started on boot as a system service.  Note\nthat in most desktop use cases, system mode likely is not the right choice\n.\nTo run PulseAudio in a system mode, first we need to set up users and groups needed by system-wide PulseAudio server instance\n[14]\n:\nAdd user\npulse\n. PulseAudio daemon switches to this user after starting.\n# useradd -d /var/run/pulse -s /usr/bin/nologin -G audio pulse\nOptionally add user\npulse\nto the\nbluetooth\ngroup, if you have it (BlueZ) and want PulseAudio to use Bluetooth.\n# usermod -aG bluetooth pulse\nAdd group\npulse-access\n. This group is used by PulseAudio server for access control.\n# groupadd pulse-access\nAdd users to\npulse-access\ngroup, if you want them to have access to the system-wide PulseAudio instance.\n# usermod -aG pulse-access root\nCreate the service\npulseaudio.service\nin\n/etc/systemd/system\ncontaining the following:\n/etc/systemd/system/pulseaudio.service\n[Unit]\nDescription=Sound Service\n[Service]\n# Note that notify will only work if --daemonize=no\nType=notify\nExecStart=/usr/bin/pulseaudio --daemonize=no --exit-idle-time=-1 --disallow-exit=true --system --disallow-module-loading\nRestart=always\n[Install]\nWantedBy=default.target\nTip\nWhen PulseAudio starts in the system mode, it will change its user and group from\nroot\nto\npulse\n.\n[15]\nThe user and group name is\nhard-coded\n: starting the service as pulse user does not work and PulseAudio complains that it is not root.\nThen\nenable\npulseaudio.service\nat the system level. You will also need to disable the user-level PulseAudio service across the whole system by\nmasking\nthe\npulseaudio.socket\nwith the\n--global\nflag.\nThis is necessary even if you are accessing the system over SSH, to make sure the user-level PulseAudio service will never start.\nWhen PulseAudio starts in the system mode,\n/etc/pulse/system.pa\nis used instead of\ndefault.pa\n, so be sure to put any necessary settings in\nsystem.pa\n.\nSelecting the server\nFor a single shell or command you can set the\nPULSE_SERVER\nenvironment variable\nto the host name or IP address of the desired PulseAudio server:\n$ env PULSE_SERVER=\nserver-hostname-or-ip\nmplayer test.mp3\nAlternatively, you can create or modify\n~/.config/pulse/client.conf\nor\n/etc/pulse/client.conf\nto set a default-server persistently:\ndefault-server =\nserver-hostname-or-ip\nIt is also possible to specify multiple servers separated by spaces which are subsequently tried by PulseAudio\n[16]\n:\ndefault-server =\nserver1\nbackup\nTips and tricks\nThis article or section is a candidate for merging with\nPulseAudio/Examples\n.\nNotes:\nSame topic. (Discuss in\nTalk:PulseAudio\n)\nKeyboard volume control\nMap\nthe following commands to your volume keys:\nXF86AudioRaiseVolume\n,\nXF86AudioLowerVolume\nand\nXF86AudioMute\n.\nFirst find out which sink corresponds to the audio output you would like to control.\nTo list available sinks:\n$ pactl list sinks short\nSuppose sink 0 is to be used, to raise the volume:\n$ sh -c \"pactl set-sink-mute 0 false ; pactl set-sink-volume 0 +5%\"\nTo lower the volume:\n$ sh -c \"pactl set-sink-mute 0 false ; pactl set-sink-volume 0 -5%\"\nTo mute/unmute the volume:\n$ pactl set-sink-mute 0 toggle\nTo mute/unmute the microphone:\n$ pactl set-source-mute 1 toggle\nTip\nTo have keyboard shortcuts operate always on the default sink, specify\n@DEFAULT_SINK@\nas the sink number, for example\npactl set-sink-mute @DEFAULT_SINK@ toggle\n.\nFor more advanced control, such as limiting the maximum volume, consider using one of the\nconsole front-ends\n.\nPlay sound from a non-interactive shell (systemd service, cron)\nReplace\nuser\nwith the user running PulseAudio:\n# machinectl shell --uid=\nuser\n.host /usr/bin/paplay /usr/share/sounds/freedesktop/stereo/complete.oga\nX11 Bell Events\nTo get PulseAudio to handle X11 bell events, run the following commands after the X11 session has been started:\n$ pactl upload-sample /usr/share/sounds/freedesktop/stereo/bell.oga bell-window-system\n$ pactl load-module module-x11-bell display=$DISPLAY\nOr use configuration files\n/etc/pulse/default.pa.d/\nor\n~/.config/pulse/default.pa\n:\n~/.config/pulse/default.pa\n.include /etc/pulse/default.pa\n# audible bell\nload-sample-lazy bell-window-system /usr/share/sounds/freedesktop/stereo/bell.oga\nload-module module-x11-bell\nTo adjust the volume of the X11 bell, run the following command:\n$ xset b 100\n100 is a percentage. This requires the\nxorg-xset\npackage. See\nAutostarting\nfor a way to run these commands automatically when the X11 session is started.\nSwitch on connect\nThe\nswitch-on-connect\nmodule switches the output sound to new devices when connected. For example, if you plug in a USB headset, the output will be switched to that. If you unplug it, the output will be set back to the last device.\nThis module is disabled by default for being too aggressive, but can be enabled by adding the line\nload-module module-switch-on-connect\nto your\n~/.config/pulse/default.pa\n.\nNote\nThis does not work with some devices, see\nPulseAudio/Troubleshooting#ALSA channels mute when headphones are plugged/unplugged improperly\n.\nScript for switching output ports\nSome sound cards present the option of multiple analog outputs, being switchable through using PulseAudio ports. But switching manually can become a chore, so you can automate this with the\npactl\ncommand.\nList available ports:\n$ LC_ALL=C.UTF-8 pactl list sinks\nSink #0\n...\nPorts:\nanalog-output-speaker: Speakers (type: Speaker, priority: 10000, availability unknown)\nanalog-output-headphones: Headphones (type: Headphones, priority: 9900, not available)\nActive Port: analog-output-speaker\nCurrent port can be obtained through:\n$ LC_ALL=C.UTF-8 pactl list sinks | grep \"Active Port\" | cut -d ' ' -f 3-\nSwitch the active port:\n$ pactl set-sink-port\nsink-index\nport\nThis process can be automated through a simple script. This script then can be given a shortcut by the user:\n~/pa.sh (or anything the user wants)\n#!/bin/sh\n# This script uses notify-send from the libnotify package to warn the user of the currently swapped to port.\n# User could adapt it to their needs or change it.\nCURRENT_PORT=$(LC_ALL=C.UTF-8 pactl list sinks | grep \"Active Port\" | cut -d ' ' -f 3-)\nif [ \"$CURRENT_PORT\" = \"analog-output-speaker\" ] ; then\npactl set-sink-port 0 \"analog-output-headphones\"\nnotify-send --expire-time=2000 \"PulseAudio\" \"Headphones\"\nelse\npactl set-sink-port 0 \"analog-output-speaker\"\nnotify-send --expire-time=2000 \"PulseAudio\" \"Speakers\"\nfi\nThis script is intended to swap between two ports. First checking the current port then swapping it. Users might need to change the sink index number and the port names to fit their machine.\nDisable muting media on entering voice call (module-role-cork)\nWhen entering a voice call (e.g. in Microsoft Teams, maybe others too) any media applications might be muted. To disable this behaviour you can simply disable this module in PulseAudio configuration:\n/etc/pulse/default.pa.d/no-cork.pa\nunload-module module-role-cork\nAdvanced configuration and use cases\nSee\nPulseAudio/Examples\n.\nTroubleshooting\nSee\nPulseAudio/Troubleshooting\n.\nSee also\nPulseAudio official website\n, including documentation\nPulseAudio under the hood\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=PulseAudio&oldid=845971\n\"\nCategory\n:\nSound\nHidden categories:\nPages with dead links\nPages or sections flagged with Template:Out of date\nPages or sections flagged with Template:Merge\nSearch\nSearch\nPulseAudio\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/PulseAudio"}}
{"text": "Power management - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPower management\n6 languages\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\n/Suspend and hibernate\n/Wakeup triggers\nCPU frequency scaling\nDisplay Power Management Signaling\nHybrid graphics\nsysctl\nPower management\nis a feature that turns off the power or switches system components to a low-power state when inactive.\nIn Arch Linux, power management consists of two main parts:\nConfiguration of the Linux\nkernel\n, which interacts with the hardware:\nKernel parameters\nKernel modules\nudev\nrules\nConfiguration of userspace tools, which interact with the kernel and react to its events. Many userspace tools also allow modification of kernel configuration in a \"user-friendly\" way. See\n#Userspace tools\nfor the options.\nUserspace tools\nThese tools allow you to change a lot of settings without the need to edit config files by hand. Only run\none\nof these tools to avoid possible conflicts as they all work more or less similarly. Have a look at the\npower management category\nto get an overview on what power management options exist in Arch Linux.\nThese are the more popular scripts and tools designed to help power saving:\nConsole\nacpid\n—  A daemon for delivering ACPI power management events with netlink support.\nhttps://sourceforge.net/projects/acpid2/\n||\nacpid\nLaptop Mode Tools\n— Utility to configure laptop power saving settings, considered by many to be the de facto utility for power saving though may take a bit of configuration.\nhttps://github.com/rickysarraf/laptop-mode-tools\n||\nlaptop-mode-tools\nAUR\nlibsmbios\n— Library and tools for interacting with Dell SMBIOS tables.\nhttps://github.com/dell/libsmbios\n||\nlibsmbios\npower-profiles-daemon\n— Makes power profiles handling available over D-Bus.\nhttps://gitlab.freedesktop.org/upower/power-profiles-daemon\n||\npower-profiles-daemon\npowerstat\n— A tool that measures power consumption using the ACPI or Intel RAPL interface.\nhttps://github.com/ColinIanKing/powerstat\n||\npowerstat\nAUR\npowertop\n— A tool to diagnose issues with power consumption and power management to help set power saving settings.\nhttps://github.com/fenrus75/powertop\n||\npowertop\nsystemd\n— A system and service manager.\nhttps://systemd.io/\n||\nsystemd\nTLP\n— Advanced power management for Linux.\nhttps://linrunner.de/tlp\n||\ntlp\nTuneD\n— Daemon that performs monitoring and adaptive configuration of devices in the system.\nhttps://tuned-project.org\n||\ntuned\nUPower\n— Abstraction for enumerating power devices, listening to device events and querying history and statistics.\nhttps://upower.freedesktop.org\n||\nupower\nGraphical\nbatsignal\n— Lightweight battery monitor that uses libnotify to warn of low battery levels.\nhttps://github.com/electrickite/batsignal\n||\nbatsignal\ncbatticon\n— Lightweight and fast battery icon that sits in your system tray.\nhttps://github.com/valr/cbatticon\n||\ncbatticon\nGNOME Power Statistics\n— System power information and statistics for GNOME.\nhttps://gitlab.gnome.org/GNOME/gnome-power-manager\n||\ngnome-power-manager\nKDE Power Devil\n— Power management module for Plasma.\nhttps://invent.kde.org/plasma/powerdevil\n||\npowerdevil\nLXQt Power Management\n— Power management module for LXQt.\nhttps://github.com/lxqt/lxqt-powermanagement\n||\nlxqt-powermanagement\nMATE Power Management\n— Power management tool for MATE.\nhttps://github.com/mate-desktop/mate-power-manager\n||\nmate-power-manager\nMATE Power Statistics\n— System power information and statistics for MATE.\nhttps://github.com/mate-desktop/mate-power-manager\n||\nmate-power-manager\npoweralertd\n— Daemon for delivering UPower notifications.\nhttps://git.sr.ht/~kennylevinsen/poweralertd\n||\npoweralertd\nAUR\npowerkit\n— Desktop independent power manager.\nhttps://github.com/rodlie/powerkit\n||\npowerkit\nAUR\nvattery\n— Battery monitoring application written in Vala that will display the status of a laptop battery in a system tray.\nhttps://www.jezra.net/projects/vattery.html\n||\nvattery\nAUR\nXfce Power Manager\n— Power manager for Xfce.\nhttps://docs.xfce.org/xfce/xfce4-power-manager/start\n||\nxfce4-power-manager\nACPI events\nsystemd\nhandles some power-related\nACPI\nevents, whose actions can be configured in\n/etc/systemd/logind.conf\nor\n/etc/systemd/logind.conf.d/*.conf\n— see\nlogind.conf(5)\n. On systems with no dedicated power manager, this may replace the\nacpid\ndaemon which is usually used to react to these ACPI events.\nThe specified action for each event can be one of\nignore\n,\npoweroff\n,\nreboot\n,\nhalt\n,\nsuspend\n,\nhibernate\n,\nhybrid-sleep\n,\nsuspend-then-hibernate\n,\nlock\nor\nkexec\n. In case of hibernation and suspension, they must be properly\nset up\n. If an event is not configured,\nsystemd\nwill use a default action.\nEvent handler\nDescription\nDefault action\nHandlePowerKey\nTriggered when the power key/button is pressed.\npoweroff\nHandleSuspendKey\nTriggered when the suspend key/button is pressed.\nsuspend\nHandleHibernateKey\nTriggered when the hibernate key/button is pressed.\nhibernate\nHandleLidSwitch\nTriggered when the lid is closed, except in the cases below.\nsuspend\nHandleLidSwitchDocked\nTriggered when the lid is closed if the system is inserted in a docking station, or more than one display is connected.\nignore\nHandleLidSwitchExternalPower\nTriggered when the lid is closed if the system is connected to external power.\naction set for\nHandleLidSwitch\nTo apply changes,\nreload\nsystemd-logind.service\n.\nNote\nsystemd\ncannot handle AC and Battery ACPI events, so if you use\nLaptop Mode Tools\nor other similar tools\nacpid\nis still required.\nWhen performing lid switches in short succession,\nlogind\nwill delay the suspend action for up to 90s to detect possible docks.\n[1]\nThis delay was made configurable with systemd v220.\n[2]\nYou can use e.g.\nHoldoffTimeoutSec=30s\nin\nlogind.conf\nor its drop-in file.\nPower managers\nSome\ndesktop environments\ninclude power managers which\ninhibit\n(temporarily turn off) some or all of the\nsystemd\nACPI settings. If such a power manager is running, then the actions for ACPI events can be configured in the power manager alone. Changes to\n/etc/systemd/logind.conf\nor\n/etc/systemd/logind.conf.d/*.conf\nneed be made only if you wish to configure behaviour for a particular event that is not inhibited by the power manager.\nNote that if the power manager does not inhibit\nsystemd\nfor the appropriate events you can end up with a situation where\nsystemd\nsuspends your system and then when the system is woken up the other power manager suspends it again. The power managers of\nGNOME\n,\nMATE\n,\nPlasma\nand\nXfce\nissue the necessary\ninhibited\ncommands. If the\ninhibited\ncommands are not being issued, such as when using\nacpid\nor others to handle ACPI events, set the\nHandle\noptions to\nignore\n. See also\nsystemd-inhibit(1)\n.\nxss-lock\nxss-lock\nsubscribes to the systemd-events\nsuspend\n,\nhibernate\n,\nlock-session\n, and\nunlock-session\nwith appropriate actions (run locker and wait for user to unlock or kill locker).\nxss-lock\nalso reacts to\nDPMS\nevents and runs or kills the locker in response.\nAutostarting\nthe following for example:\n$ xss-lock -- i3lock -n -i\nbackground_image.png\n&\nPower saving\nNote\nSee\nLaptop#Power management\nfor power management specific to laptops, such as battery monitoring. See also pages specific to your CPU and GPU (e.g.,\nRyzen\n,\nAMDGPU\n).\nThis section is a reference for creating custom scripts and power saving settings such as by udev rules. Make sure that the settings are not managed by some\nother utility\nto avoid conflicts.\nAlmost all of the features listed here are worth using whether or not the computer is on AC or battery power. Most have negligible performance impact and are just not enabled by default because of commonly broken hardware/drivers. Reducing power usage means reducing heat, which can even lead to higher performance on a modern Intel or AMD CPU, thanks to\ndynamic overclocking\n.\nPrint power settings\nThis script prints power settings and a variety of other properties for USB and PCI devices.  Note that root permissions are needed to see all settings.\n#!/bin/bash\nfor i in $(find /sys/devices/ -name \"bMaxPower\")\ndo\nbusdir=${i%/*}\nbusnum=$(<$busdir/busnum)\ndevnum=$(<$busdir/devnum)\ntitle=$(lsusb -s $busnum:$devnum)\nprintf \"\\n\\n+++ %s\\n  -%s\\n\" \"$title\" \"$busdir\"\nfor ff in $(find $busdir/power/ -type f ! -empty 2>/dev/null)\ndo\nv=$(cat $ff 2>/dev/null|tr -d \"\\n\")\n[[ ${#v} -gt 0 ]] && echo -e \" ${ff##*/}=$v\";\nv=;\ndone | sort -g;\ndone;\nprintf \"\\n\\n\\n+++ %s\\n\" \"Kernel Modules\"\nfor mod in $(lspci -k | sed -n '/in use:/s,^.*: ,,p' | sort -u)\ndo\necho \"+ $mod\";\nsystool -v -m $mod 2> /dev/null | sed -n \"/Parameters:/,/^$/p\";\ndone\nProcessors with Intel Hardware P-state support\nThis article or section is a candidate for merging with\nCPU frequency scaling\n.\nNotes:\nMore context in the main article. (Discuss in\nTalk:Power management\n)\nThe available energy preferences of an Intel Hardware P-state (HWP) supported processor are\ndefault\n,\nperformance\n,\nbalance_performance\n,\nbalance_power\n,\npower\n.\nThis can be validated by running\n$ cat /sys/devices/system/cpu/cpufreq/policy*/energy_performance_available_preferences\nTo conserve more energy, you can edit the configuration by creating the following file:\n/etc/tmpfiles.d/energy_performance_preference.conf\nw /sys/devices/system/cpu/cpufreq/policy*/energy_performance_preference - - - - balance_power\nSee the\nx86_energy_perf_policy(8)\nman page for more details on energy-performance policy in Intel processors. Also see\nsystemd-tmpfiles(8)\nand\ntmpfiles.d(5)\nman pages for temporary files/directories details.\nAudio\nWhether power saving is turned on by default depends on a given driver, e.g. it is on for HD Audio.\nIdentify\nthe module in use, then run\n$ modinfo --field=parm\nmodule_name\n| column --separator=':' --table --table-columns-limit=2\nand look for a\nkernel module parameter\n(like\npower_save\n) that adjusts or disables power-saving feature.\nNote\nPower-saving feature might cause audible click noises (pops) and other issues. See the dedicated pages for the relevant solution:\nAdvanced Linux Sound Architecture/Troubleshooting#Power saving\nPipeWire#Noticeable audio delay or audible pop/crack when starting playback\nPulseAudio/Troubleshooting#Pops when starting and stopping playback\nBacklight\nSee\nBacklight\n.\nBluetooth\nTo disable Bluetooth completely,\nblacklist\nthe\nbtusb\nand\nbluetooth\nmodules.\nAlternatively, create the following udev rules:\n/etc/udev/rules.d/50-bluetooth.rules\n# disable bluetooth\nSUBSYSTEM==\"rfkill\", ATTR{type}==\"bluetooth\", ATTR{state}=\"0\"\nTo turn off Bluetooth only temporarily, use\nrfkill(8)\n:\n# rfkill block bluetooth\nWeb camera\nIf you will not use integrated web camera then\nblacklist\nthe\nuvcvideo\nmodule.\nKernel parameters\nThis section uses configurations in\n/etc/sysctl.d/\n, which is\n\"a drop-in directory for kernel sysctl parameters.\"\nSee\nThe New Configuration Files\nand more specifically\nsysctl.d(5)\nfor more information.\nDisabling NMI watchdog\nThis article or section needs expansion.\nReason:\nGive guidance on how many interrupts is a lot of interrupts.. (Discuss in\nTalk:Power management\n)\nThe\nNMI\nwatchdog is a debugging feature to catch hardware hangs that cause a kernel panic. On some systems it can generate a lot of interrupts, causing a noticeable increase in power usage. To list these interrupts per CPU core since last boot, you can use:\n$ grep NMI /proc/interrupts\nNMI:     22     58     24     23     24     39     22     30   Non-maskable interrupts\nTo turn the hardlockup detector off, use:\n/etc/sysctl.d/disable_watchdog.conf\nkernel.nmi_watchdog = 0\nor add\nnmi_watchdog=0\nto the\nkernel line\n.\nAlternatively add\nnowatchdog\nto the\nkernel line\nto disable both hard and soft lockup detectors. See\n[3]\nWriteback Time\nIncreasing the virtual memory dirty writeback time helps to aggregate disk I/O together, thus reducing spanned disk writes, and increasing power saving. To set the value to 60 seconds (default is 5 seconds):\n/etc/sysctl.d/dirty.conf\nvm.dirty_writeback_centisecs = 6000\nTo do the same for journal commits on supported filesystems (e.g. ext4, btrfs...), use\ncommit=60\nas an option in\nfstab\n.\nNote that this value is modified as a side effect of the Laptop Mode setting below. See also\nsysctl#Virtual memory\nfor other parameters affecting I/O performance and power saving.\nLaptop Mode\nSee the\nkernel documentation\non the laptop mode \"knob\" - \"A sensible value for the knob is 5 seconds\".\n/etc/sysctl.d/laptop.conf\nvm.laptop_mode = 5\nNote\nThis setting is mainly relevant to spinning-disk drives.\nNetwork interfaces\nWake-on-LAN\ncan be a useful feature, but if you are not making use of it then it is simply draining extra power waiting for a magic packet while in suspend. You can adapt the\nWake-on-LAN#udev\nrule to disable the feature for all ethernet interfaces. To enable powersaving with\niw\non all wireless interfaces:\n/etc/udev/rules.d/\n81\n-wifi-powersave.rules\nACTION==\"add\", SUBSYSTEM==\"net\", KERNEL==\"wl*\", RUN+=\"/usr/bin/iw dev $name set power_save on\"\nThe name of the configuration file is important. With the use of\npersistent device names\nin systemd, the above network rule, named lexicographically\nafter\n80-net-setup-link.rules\n, is applied after the device is renamed with a persistent name e.g.\nwlan0\nrenamed\nwlp3s0\n. Be aware that the\nRUN\ncommand is executed after all rules have been processed and must anyway use the persistent name, available in\n$name\nfor the matched device.\nIntel wireless cards (iwlwifi)\nAdditional power saving functions of Intel wireless cards with\niwlwifi\ndriver can be enabled by passing the correct parameters to the kernel module. Making them persistent can be achieved by adding the lines below to the\n/etc/modprobe.d/iwlwifi.conf\nfile:\noptions iwlwifi power_save=1\nThis option will probably increase your median latency:\noptions iwlwifi uapsd_disable=0\nOn kernels < 5.4 you can use this option, but it will probably decrease your maximum throughput:\noptions iwlwifi d0i3_disable=0\nDepending on your wireless card one of these two options will apply.\noptions iwlmvm power_scheme=3\noptions iwldvm force_cam=0\nYou can check which one is relevant by checking which of these modules is running using\n# lsmod | grep '^iwl.vm'\nKeep in mind that these power saving options are experimental and can cause an unstable system.\niwd\nIf using\niwd\n, power-saving can be disabled for all Wi-Fi devices with the following config file:\n/etc/iwd/main.conf\n[DriverQuirks]\nPowerSaveDisable=*\nYou can also replace\n*\nwith a specific driver name, see\niwd.config(5) § SETTINGS\n.\nNetworkManager\nIf using\nNetworkManager\n, power-saving can be disabled globally for every connection with a config file, for example:\n/etc/NetworkManager/conf.d/powersave.conf\n[connection]\nwifi.powersave=2\nTip\nSpecifically, this value can be set to any of the following:\n0\n— to use the globally configured value\n1\n— to do not touch the current configuration\n2\n— to globally disable power-saving\n3\n— to globally enable power-saving\nBus power management\nActive State Power Management\nFrom\nWikipedia\n:\nActive-state power management\n(\nASPM\n) is a power management mechanism for PCI Express devices to garner power savings while otherwise in a fully active state. Predominantly, this is achieved through active-state link power management; i.e., the PCI Express serial link is powered down when there is no traffic across it. It is normally used on laptops and other mobile Internet devices to extend battery life.\nAt boot, the BIOS enables or disables ASPM based on hardware support. To check for support:\n# lspci -vv | grep 'ASPM.*abled;'\nFetch available ASPM policies and the current system default using the following:\n$ cat /sys/module/pcie_aspm/parameters/policy\n[default] performance powersave powersupersave\nASPM might be disabled for the following reasons\n[4]\n:\nThe BIOS determined that needed to happen.\nPCIE requires ASPM but L0s is optional so you might have L0s disabled and only L1 enabled.\nYou have a buggy BIOS.\nYou have no BIOS and your systems programmers did not address ASPM yet.\nIf you believe that your hardware has support for ASPM despite the above, it can be force-enabled for the kernel to handle with the\npcie_aspm=force\nkernel parameter\n.\nWarning\nForce-enabling ASPM on an unsupported system may lead to increased power consumption. Furthermore, it may cause system freezes or kernel panics, so make sure you have a way to undo the option if it is unsuitable.\nForcing ASPM takes place in the kernel, and therefore it may still remain disabled in hardware and not work. To check whether this is the case, run\ndmesg | grep ASPM\nas root. Consult the Wiki article specific to your hardware for more information if possible.\nAs long as ASPM is supported and enabled, it is possible to select a desired policy for the current session. For example, switch to\npowersupersave\nfor the current session by doing the following:\n# echo powersupersave > /sys/module/pcie_aspm/parameters/policy\nTo configure a specific ASPM state to enable upon system boot (using\npowersupersave\nas an example), add\npcie_aspm.policy=powersupersave\nas a\nkernel parameter\n.\nPCI Runtime Power Management\n/etc/udev/rules.d/pci_pm.rules\nSUBSYSTEM==\"pci\", ATTR{power/control}=\"auto\"\nSUBSYSTEM==\"ata_port\", KERNEL==\"ata*\", ATTR{device/power/control}=\"auto\"\nThe rule above powers down unused devices.\nSome devices will not wake up again. To allow runtime power management only for devices that are known to work, use simple matching against vendor and device IDs (use\nlspci -nn\nto get these values):\n/etc/udev/rules.d/pci_pm.rules\n# whitelist for pci autosuspend\nSUBSYSTEM==\"pci\", ATTR{vendor}==\"0x1234\", ATTR{device}==\"0x1234\", ATTR{power/control}=\"auto\"\nAlternatively, to blacklist devices that are not working with PCI runtime power management and enable it for all other devices:\n/etc/udev/rules.d/pci_pm.rules\n# blacklist for pci runtime power management\nSUBSYSTEM==\"pci\", ATTR{vendor}==\"0x1234\", ATTR{device}==\"0x1234\", ATTR{power/control}=\"on\", GOTO=\"pci_pm_end\"\nSUBSYSTEM==\"pci\", ATTR{power/control}=\"auto\"\nLABEL=\"pci_pm_end\"\nUSB autosuspend\nThe Linux kernel can automatically suspend USB devices when they are not in use. This can sometimes save quite a bit of power, however some USB devices are not compatible with USB power saving and start to misbehave (common for USB mice/keyboards).\nudev\nrules based on whitelist or blacklist filtering can help to mitigate the problem.\nThe example is enabling autosuspend for all USB devices except for keyboards and mice:\n/etc/udev/rules.d/50-usb_power_save.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", ATTR{product}!=\"*Mouse\", ATTR{product}!=\"*Keyboard\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\nTo allow autosuspend only for devices that are known to work, use simple matching against vendor and product IDs (use\nlsusb\nto get these values):\n/etc/udev/rules.d/50-usb_power_save.rules\n# whitelist for usb autosuspend\nACTION==\"add\", SUBSYSTEM==\"usb\", TEST==\"power/control\", ATTR{idVendor}==\"05c6\", ATTR{idProduct}==\"9205\", ATTR{power/control}=\"auto\"\nAlternatively, to blacklist devices that are not working with USB autosuspend and enable it for all other devices:\n/etc/udev/rules.d/50-usb_power_save.rules\n# blacklist for usb autosuspend\nACTION==\"add\", SUBSYSTEM==\"usb\", ATTR{idVendor}==\"05c6\", ATTR{idProduct}==\"9205\", GOTO=\"power_usb_rules_end\"\nACTION==\"add\", SUBSYSTEM==\"usb\", TEST==\"power/control\", ATTR{power/control}=\"auto\"\nLABEL=\"power_usb_rules_end\"\nThe default autosuspend idle delay time is controlled by the\nautosuspend\nparameter of the\nusbcore\nbuilt-in\nkernel module\n. To set the delay to 5 seconds instead of the default 2 seconds, add the following\nkernel parameter\nfor your boot loader.\nusbcore.autosuspend=5\nSimilarly to\npower/control\n, the delay time can be fine-tuned per device by setting the\npower/autosuspend\nattribute. This means, alternatively, autosuspend can be disabled by setting\npower/autosuspend\nto -1 (i.e., never autosuspend):\n/etc/udev/rules.d/50-usb_power_save.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", ATTR{idVendor}==\"05c6\", ATTR{idProduct}==\"9205\", ATTR{power/autosuspend}=\"-1\"\nSee the\nLinux kernel documentation\nfor more information on USB power management.\nSATA Active Link Power Management\nThe current setting can be read from or written to\n/sys/class/scsi_host/host*/link_power_management_policy\nas follows:\n$ grep . /sys/class/scsi_host/host*/link_power_management_policy\n$ echo \"med_power_with_dipm\" >/sys/class/scsi_host/host\nN\n/link_power_management_policy\nAvailable ALPM settings\nSetting\nDescription\nPower saving\nmax_performance\ncurrent default\nNone\nmedium_power\n-\n~1.0 Watts\nmed_power_with_dipm\nrecommended setting\n1\n~1.5 Watts\nmin_power\nWARNING: possible data loss\n2\n~1.5 Watts\nSince Linux 4.15 there is a\nsetting\ncalled\nmed_power_with_dipm\nthat matches the behaviour of Windows IRST driver settings and should not cause data loss with recent SSDs or HDDs. The power saving can be significant, ranging\nfrom 1.0 to 1.5 Watts (when idle)\n. It has become the default setting for Intel based laptops in Linux 4.16\n[5]\n. In Linux 6.11 it became the default setting\n[6]\n.\nWarning\nThe\nmin_power\nSATA Active Link Power Management setting can lead to data loss on some devices. Do not enable this setting unless you have frequent backups.\nYou can configure\nlink_power_management_policy\nsettings persistently by adding a\nudev\nrules file, for example:\n/etc/udev/rules.d/hd_power_save.rules\nACTION==\"add\", SUBSYSTEM==\"scsi_host\", KERNEL==\"host*\", ATTR{link_power_management_policy}=\"med_power_with_dipm\"\nNote\nThis adds latency when accessing a drive that has been idle, so it is one of the few settings that may be worth toggling based on whether you are on AC power.\nNot all combinations of SATA host controllers and storage devices work well with the default\nmed_power_with_dipm\nsetting. For example:\nas of linux-6.8.1, Intel 7 Series Chipset controllers will experience timeouts and link degradation when accessing Crucial M550 SSDs (with firmware MU02).\nas of linux-6.9.6, AMD 600 Series Chipset SATA Controllers used with HL-DT-ST BDDVDRW GGC-H20L optical disk drives have the annoying effect that the ROM drive will noisily be re-initialized every few minutes.\nIn such cases, using the\nmedium_power\nsetting can fix the problem.\nHard disk drive\nSee\nhdparm#Power management configuration\nfor drive parameters that can be set.\nPower saving is not effective when too many programs are frequently writing to the disk. Tracking all programs, and how and when they write to disk is the way to limit disk usage. Use\niotop\nto see which programs use the disk frequently. See\nImproving performance#Storage devices\nfor other tips.\nSmall adjustments such as setting the\nnoatime\noption can also help. If enough RAM is available, consider disabling or limiting\nswappiness\nas it has the possibility to limit a good number of disk writes.\nFor Seagate drives with\nPowerChoice\ntechnology, tricks setting APM via\nhdparm\nwill not work due to the\nEPC\n(Extended Power Conditions) feature. Rather than setting APM, you can\ninstall\nopenseachest\nAUR\nand fully disable EPC like so (replace\nX\nwith actual drive letter):\n# openSeaChest_PowerControl --scan\n# openSeaChest_PowerControl -d /dev/sd\nX\n-i\n# openSeaChest_PowerControl -d /dev/sd\nX\n--showEPCSettings\n# openSeaChest_PowerControl -d /dev/sd\nX\n--EPCfeature disable\n# openSeaChest_PowerControl -d /dev/sd\nX\n--showEPCSettings\nLast invocation will give the following summary:\n==========================================================================================\nopenSeaChest_PowerControl - openSeaChest drive utilities - NVMe Enabled\nCopyright (c) 2014-2023 Seagate Technology LLC and/or its Affiliates, All Rights Reserved\nopenSeaChest_PowerControl Version: 3.3.1-4_1_1 X86_64\nBuild Date: Jul  4 2023\nToday: Tue Jul  4 17:49:36 2023        User: root\n==========================================================================================\n/dev/sd\nX\n- ST1000NM0008-2F2100 - ZFA19JG2 - SN02 - ATA\n===EPC Settings===\n* = timer is enabled\nC column = Changeable\nS column = Savable\nAll times are in 100 milliseconds\nName       Current Timer Default Timer Saved Timer   Recovery Time C S\nIdle A      0            *10           *10           1             Y Y\nIdle B      0            *1200         *1200         3             Y Y\nIdle C      0             6000          6000         16            Y Y\nStandby Z   0             9000          9000         46            Y Y\nZeroes in the first column confirm that parking and spindown were disabled successfully\nTools and scripts\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nMerged from\nPower saving\n, needs reorganization to fit into this page. (Discuss in\nTalk:Power management\n)\nUsing a script and a udev rule\nThis article or section is a candidate for merging with\nLaptop#Power management\n.\nNotes:\nMight be a better fit for the laptop-specific page. (Discuss in\nTalk:Power management\n)\nSince systemd users can suspend and hibernate through\nsystemctl suspend\nor\nsystemctl hibernate\nand handle acpi events with\n/etc/systemd/logind.conf\n, it might be interesting to remove\npm-utils\nand\nacpid\n. There is just one thing systemd cannot do (as of systemd-204): power management depending on whether the system is running on AC or battery. To fill this gap, you can create a single\nudev\nrule that runs a script when the AC adapter is plugged and unplugged:\n/etc/udev/rules.d/powersave.rules\nSUBSYSTEM==\"power_supply\", ATTR{online}==\"0\", RUN+=\"/path/to/your/script true\"\nSUBSYSTEM==\"power_supply\", ATTR{online}==\"1\", RUN+=\"/path/to/your/script false\"\nNote\nYou can use the same script that\npm-powersave\nuses. You just have to make it executable and place it somewhere else (for example\n/usr/local/bin/\n).\nExamples of powersave scripts:\nftw\n, package:\nftw-git\nAUR\npowersave\nthrottlectl\n, from\nthrottlectl\nAUR\nThe above udev rule should work as expected, but if your power settings are not updated after a suspend or hibernate cycle, you should add a script in\n/usr/lib/systemd/system-sleep/\nwith the following contents:\n/usr/lib/systemd/system-sleep/00powersave\n#!/bin/sh\ncase $1 in\npre) /path/to/your/script false ;;\npost)\nif cat /sys/class/power_supply/AC0/online | grep 0 > /dev/null 2>&1\nthen\n/path/to/your/script true\nelse\n/path/to/your/script false\nfi\n;;\nesac\nexit 0\nDo not forget to make it executable!\nNote\nBe aware that AC0 may be different for your laptop, change it if that is the case.\nAllow users to shutdown\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nMerged from\nAllow users to shutdown\n, needs reorganization to fit into this page. (Discuss in\nTalk:Power management\n)\nButton and lid events\nThe suspend, poweroff and hibernate button presses and lid close events are handled by\nlogind\nas described in\n#ACPI events\n.\nUsing systemd-logind\nIf you are using\npolkit\n, users with non-remote session can issue power-related commands as long as\nthe session is not broken\n.\nTo check if your session is active:\n$ loginctl show-session $XDG_SESSION_ID --property=Active\nThe user can then use\nsystemctl\ncommands in the command line, or add them to menus:\n$ systemctl poweroff\n$ systemctl reboot\nOther commands can be used as well, including\nsystemctl suspend\nand\nsystemctl hibernate\n. See the\nSystem Commands\nsection in\nsystemctl(1)\n.\nUsing sudo\nInstall\nsudo\n, and\nconfigure it\nto give the user root privileges. The user will then be able to use the\nsudo systemctl\ncommands (e.g.\nsudo systemctl poweroff\n,\nsudo systemctl reboot\n,\nsudo systemctl suspend\nand\nsudo systemctl hibernate\n). See the\nSystem Commands\nsection in\nsystemctl(1)\nUsers without root privileges\nIf users should only be allowed to use shutdown commands, but not have other privileges, add the following to the end of\n/etc/sudoers\nusing the\nvisudo\ncommand as root. Substitute\nuser\nfor your username and\nhostname\nfor the machine's hostname.\nuser\nhostname\n=NOPASSWD: /usr/bin/systemctl poweroff,/usr/bin/systemctl halt,/usr/bin/systemctl reboot\nNow your user can shutdown with\nsudo systemctl poweroff\n, and reboot with\nsudo systemctl reboot\n. Users wishing to power down a system can also use\nsudo systemctl halt\n. Use the\nNOPASSWD:\ntag only if you do not want to be prompted for your password.\nSee also\nThinkWiki:How to reduce power consumption\nHow to get longer battery life on Linux\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Power_management&oldid=850952\n\"\nCategory\n:\nPower management\nHidden categories:\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Style\nSearch\nSearch\nPower management\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Power_management"}}
{"text": "CPU frequency scaling - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nCPU frequency scaling\n6 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\n中文（简体）\nFrom ArchWiki\nRelated articles\nPower saving\nLaptop Mode Tools\nUndervolting CPU\nCPU performance scaling\nenables the operating system to scale the CPU frequency up or down in order to save power or improve performance. Scaling can be done automatically in response to system load, adjust itself in response to ACPI events, or be manually changed by user space programs.\nThe Linux kernel offers CPU performance scaling via the\nCPUFreq\nsubsystem, which defines two layers of abstraction:\nScaling governors\nimplement the algorithms to compute the desired CPU frequency, potentially based off of the system's needs.\nScaling drivers\ninteract with the CPU directly, enacting the desired frequencies that the current governor is requesting.\nA default scaling driver and governor are selected automatically, but userspace tools like\ncpupower\n,\nacpid\n,\nLaptop Mode Tools\n, or GUI tools provided for your desktop environment, may still be used for advanced configuration.\nUserspace tools\ni7z\ni7z\nAUR\nis an i7 (and now i3, i5, i7, i9) CPU reporting tool for Linux. It can be launched from a Terminal with the command\ni7z\nor as GUI with\ni7z-gui\n.\nturbostat\nturbostat\ncan display the frequency, power consumption, idle status and other statistics of the modern Intel and AMD CPUs.\ncpupower\ncpupower\nis a set of userspace utilities designed to assist with CPU frequency scaling. The package is not required to use scaling, but is highly recommended because it provides useful command-line utilities and a\nsystemd\nservice to change the governor at boot.\nThe configuration file for\ncpupower\nis located in\n/etc/default/cpupower\n. This configuration file is read by a bash script in\n/usr/lib/systemd/scripts/cpupower\nwhich is activated by\nsystemd\nwith\ncpupower.service\n. You may want to\nenable\ncpupower.service\nto start at boot.\nthermald\nthermald\nis a\nLinux daemon\nused to prevent the overheating of Intel CPUs. This daemon proactively controls thermal parameters using P-states, T-states, and the Intel power clamp driver. thermald can also be used for older Intel CPUs. If the latest drivers are not available, then the daemon will revert to x86 model specific registers and the Linux \"cpufreq subsystem\" to control system cooling.\nBy default, it monitors CPU temperature using available CPU digital temperature sensors and maintains CPU temperature under control, before hardware takes aggressive correction action. If there is a skin temperature sensor in thermal sysfs, then it tries to keep skin temperature under 45C.\nOn Tiger Lake laptops (e.g.\nDell Latitude 3420\n), this daemon has been reported as\nunlocking more performance\nthan what would be otherwise available.\nThe associated systemd unit is\nthermald.service\n, which should be\nstarted\nand\nenabled\n. See\nthermald(8)\nfor more information.\npower-profiles-daemon\nThe\npowerprofilesctl\ncommand-line tool from\npower-profiles-daemon\nhandles power profiles (e.g. balanced, power-saver, performance) through the\npower-profiles-daemon\nservice. GNOME and KDE also provide\ngraphical interfaces\nfor profile switching; see the following:\nGNOME#Power modes\nKDE#Power management\nSee the\nproject's README\nfor more information on usage, use cases, and comparisons with similar projects.\nStart/enable\nthe\npower-profiles-daemon\nservice. Note that when\npowerprofilesctl\nis launched, it also attempts to start the service (see the\nunit status\nof\ndbus.service\n).\nNote\npower-profiles-daemon\nconflicts\nwith other power management services such as\nTLP\n,\ntuned\nand\nsystem76-power\nAUR\n. To use one of the aforementioned services instead without\nuninstalling\npower-profiles-daemon\n(due to its potential status as a dependency), disable the\npower-profiles-daemon\nservice by\nmasking\nit (see also\n[1]\n,\n[2]\n).\ntuned\nnow offers a\ntuned-ppd\nservice compatibility layer for\npower-profiles-daemon\nsince version 2.23.0.\ntuned\ntuned\nis a daemon for monitoring and adaptive tuning of system devices. It can configure GPU power modes, PCIe power management, set sysctl settings, adjust kernel scheduling and more; a daemon that also configures out aspects of power management in the system.\nAs of\nrelease 2.23.0\n, the project ships with\ntuned-ppd\n, a compatibility layer for programs written for\npower-profiles-daemon\n, such as the following:\nGNOME#Power modes\nKDE#Power management\nFor reasons why tuned should be used instead of power-profiles-daemon, see Fedora's\nproposal\nto replace it with tuned. For opposite arguments, see\n[3]\n.\nStart/enable\nthe\ntuned\ndaemon service. For power-profiles-daemon compatibility, also\nstart/enable\nthe\ntuned-ppd\nservice. To control tuned from the command line, use\ntuned-adm\nto view, set, and recommend profiles.\nNote\ntuned-ppd\nis configured at\n/etc/tuned/ppd.conf\n. To set which\ntuned\nprofile is used whenever a program selects a\npower-profiles-daemon\nprofile, edit the file, which includes all the power-profiles-daemon modes and battery detection.\ncpupower-gui\ncpupower-gui-git\nAUR\nis a graphical utility designed to assist with CPU frequency scaling. The GUI is based on\nGTK\nand is meant to provide the same options as\ncpupower\n.\ncpupower-gui\ncan enable or disable cores and change the maximum/minimum CPU frequency and governor for each core. The application handles privilege granting through\npolkit\nand allows any logged-in user in the\nwheel\nuser group\nto change the frequency and governor. See\ncpupower-gui systemd units\nfor more information on\ncpupower-gui.service\nand\ncpupower-gui-user.service\n.\ngnome-shell-extension-cpupower\ngnome-shell-extension-cpupower-git\nAUR\nis a\nGNOME\nshell extension that can alter minimum/maximum CPU frequencies and enable/disable frequency boosting.\nauto-cpufreq\nauto-cpufreq\nAUR\nis an automatic CPU speed and power optimizer for Linux based on active monitoring of laptop's battery state, CPU usage, CPU temperature and system load.\nnvidia-powerd\nThe\nnvidia-powerd\ndaemon provides support for\nNVIDIA\n's Dynamic Boost technology on supported laptop platforms. It acts as a system-wide power controller that dynamically redistributes power between the GPU and CPU based on workload demands, while maintaining the system's total thermal budget.\n[4]\nStart/enable\nthe\nnvidia-powerd\nservice, which is provided by the\nnvidia-utils\npackage.\nNote\nThe prerequisites for\nnvidia-powerd\nare: NVIDIA Ampere (or newer) GPU, Intel Comet Lake (or newer) or AMD Renoir (or newer) chipset, and firmware-level Dynamic Boost support (verify with\nnvidia-settings -q DynamicBoostSupport\n).\nScaling drivers\nThe factual accuracy of this article or section is disputed.\nReason:\nSome of this information is platform/vendor-specific, lacks clarity/distinction between old and more recent features (such as Hardware P-States), or is an otherwise misinterpretation/conflation of the Kernel\nWorking-State Power Management\nand\nCPU performance scaling\nsubsystems. (Discuss in\nTalk:CPU frequency scaling\n)\nScaling drivers implement controls over frequency scaling by interfacing with the CPU hardware. They can communicate with scaling governor for generic frequency control (the ACPI 2.0 standard introduced\npower-performance states (\"P-states\")\n), but can also have additional features (such as Hardware-based P-States, which allow the CPU to govern frequency autonomously).\n[5]\nNote\nThe native\nCPUFreq\nscaling driver is loaded automatically.\nscaling_driver\nDescription\nacpi_cpufreq\nUtilizes\nACPI power-performance states (P-States)\n. This driver also supports the Intel Enhanced SpeedStep (previously supported by the deprecated\nspeedstep_centrino\nmodule). For AMD Ryzen, it only provides 3 frequency states.\namd_pstate\nThis driver has three modes corresponding to different degrees of autonomy from the CPU hardware: active, passive, and guided. The\namd_pstate\nCPU power scaling driver is used automatically in \"active mode\" on supported CPUs (Zen 2 and newer) since kernel version 6.5. See\n#amd_pstate\nfor details.\namd_pstate_epp\nThis driver implements a scaling driver selected by\namd_pstate=active\nwith an internal governor for AMD Ryzen (some Zen 2 and newer) processors.\ncppc_cpufreq\nBased on ACPI's newer CPPC system (see\n#Collaborative processor performance control\n). Common default on AArch64 systems. Works on modern x86 too, but the\nintel_pstate\nand\namd_pstate\ndrivers implement additional hardware-specific features.\nintel_cpufreq\nReported\nscaling_driver\nwhen\nintel_pstate\nis in \"passive mode\"\n[6]\n.\nintel_pstate\nModern frequency scaling driver for Intel processors (Sandy Bridge and newer). It is used automatically for these processors instead of the other drivers below. This driver takes priority over other drivers and is built-in as opposed to being a module. By default,\nintel_pstate\nwill select \"Active Mode\" if the processor supports hardware-managed P-States (HWP), called Speed Shift Technology (SST) by Intel (Skylake processors and newer). If the processor doesn't support HWP (or if using the\nintel_pstate=no_hwp\nparameter\n) then\nintel_pstate\nwill select \"Passive Mode\" and the reported\nscaling_driver\nstring will be \"\nintel_cpufreq\n\". If you encounter a problem while using this driver, you can revert to\nacpi_cpufreq\nscaling driver by adding\nintel_pstate=disable\nto your\nKernel parameters\n. See the\nintel_pstate\ndocumentation\nfor more details.\np4_clockmod\nCPUFreq driver for Intel Pentium 4/Xeon/Celeron processors which lowers the CPU temperature by skipping clocks. (You probably want to use\nspeedstep_lib\ninstead.)\npcc_cpufreq\nThis driver supports Processor Clocking Control interface by Hewlett-Packard and Microsoft Corporation which is useful on some ProLiant servers.\npowernow_k8\nCPUFreq driver for K8/K10 Athlon 64/Opteron/Phenom processors. Since Linux 3.7, 'acpi_cpufreq' will automatically be used for more modern AMD CPUs.\nspeedstep_lib\nCPUFreq driver for Intel SpeedStep-enabled processors (mostly Atoms and older Pentiums)\nThe factual accuracy of this article or section is disputed.\nReason:\nThe following command will only return the drivers that are built as modules, but not the built-ins: for example\nintel_pstate and amd_pstate\n]. (Discuss in\nTalk:CPU frequency scaling\n)\nTo see a full list of available modules, run:\n$ ls /usr/lib/modules/$(uname -r)/kernel/drivers/cpufreq/\nLoad the appropriate module (see\nKernel modules\nfor details). Once the appropriate cpufreq driver is loaded, detailed information about the CPU(s) can be displayed by running\n$ cpupower frequency-info\nSetting maximum and minimum frequencies\nIn some cases, it may be necessary to manually set maximum and minimum frequencies.\nTo set the maximum clock frequency (\nclock_freq\nis a clock frequency with units: GHz, MHz):\n# cpupower frequency-set -u\nclock_freq\nTo set the minimum clock frequency:\n# cpupower frequency-set -d\nclock_freq\nTo set the CPU to run at a specified frequency:\n# cpupower frequency-set -f\nclock_freq\nNote\nTo adjust for only a single CPU core, append\n-c\ncore_number\n.\nThe governor, maximum and minimum frequencies can be set in\n/etc/default/cpupower\n.\nAlternatively, you can set the frequency manually:\n# echo\nvalue\n| tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_max_freq\nThe available values can be found in\n/sys/devices/system/cpu/cpu*/cpufreq/scaling_available_frequencies\nor similar.\n[7]\nConfiguring frequency boosting\nSome processors support raising their frequency above the normal maximum for a short burst of time, under appropriate thermal conditions. On Intel processors, this is called\nTurbo Boost\n, and on AMD processors this is called\nTurbo-Core\n.\nSetting via sysfs (intel_pstate)\nintel_pstate has a driver-specific interface for prohibiting the processor from entering turbo P-States:\n# echo 1 > /sys/devices/system/cpu/intel_pstate/no_turbo\nSetting via sysfs (other scaling drivers)\nFor scaling drivers other than\nintel_pstate\n, if the driver supports boosting, the\n/sys/devices/system/cpu/cpufreq/boost\nattribute will be present, and can be used to disable/enable boosting.\nTo disable boosting, run:\n# echo 0 > /sys/devices/system/cpu/cpufreq/boost\nTo enable boosting, run:\n# echo 1 > /sys/devices/system/cpu/cpufreq/boost\nSetting via x86_energy_perf_policy\nOn Intel processors,\nx86_energy_perf_policy\ncan also be used to configure Turbo Boost:\n# x86_energy_perf_policy --turbo-enable 0\namd_pstate\namd_pstate\nhas three operation modes: CPPC autonomous (active) mode, CPPC non-autonomous (passive) mode and CPPC guided autonomous (guided) mode.\nOfficially supported kernels\nare built with\nCONFIG_X86_AMD_PSTATE_DEFAULT_MODE=3\nwhich means the default for them is the active mode. This can be changed with the\nkernel parameter\namd_pstate=active\n,\namd_pstate=passive\nor\namd_pstate=guided\n. To revert to the\nacpi_cpufreq\ndriver, set\namd_pstate=disable\ninstead.\nActive mode\nThe\nactive\nmode is implemented by\namd_pstate_epp\n(Energy Performance Preference) driver. In this mode, the\namd_pstate_epp\ndriver provides a hint to the hardware when software wants to bias the CPPC firmware towards performance (0x0) or power efficiency (0xff).\nPassive mode\nThe\npassive\nmode is implemented by the\namd_pstate\ndriver. In this mode, the driver defines a desired performance based on the current workload, and specifically how much performance degradation can be tolerated without affecting quality of life.\nGuided mode\nThe\nguided\nmode is implemented by the\namd_pstate\ndriver. In this mode, the\namd_pstate\ndriver requests minimum and maximum performance level and the platform autonomously selects a performance level in this range and appropriate to the current workload.\nNote\nSome motherboards might not enable the required setting in their firmware, leading to a\nthe _CPC object is not present in SBIOS or ACPI disabled\nerror. Change\nEnable CPPC\n, usually found in the\nAMD CBS > NBIO > SMU > CPPC\n, from\nAuto\nto\nEnabled\n, or any similar settings in your UEFI. If they are not present, consult the vendor website for an update, or check if the motherboard has a hidden way to show advanced UEFI options.\nScaling governors\nScaling governors are power schemes determining the desired frequency for the CPU. Some request a constant frequency, others implement algorithms to dynamically adjust according to the system load. The governors included in the kernel are:\nNote\nEach governor is compatible with any scaling driver, with the exceptions of\nintel_pstate\nand\namd_pstate\nin active mode, which provide pseudo-governors in the form of\npowersave\nand\nperformance\n. See\n#Autonomous frequency scaling\nbelow.\nGovernor\nDescription\nperformance\nRun the CPU at the maximum frequency, obtained from\n/sys/devices/system/cpu/cpu\nX\n/cpufreq/scaling_max_freq\n.\npowersave\nRun the CPU at the minimum frequency, obtained from\n/sys/devices/system/cpu/cpu\nX\n/cpufreq/scaling_min_freq\n.\nuserspace\nRun the CPU at user specified frequencies, configurable via\n/sys/devices/system/cpu/cpu\nX\n/cpufreq/scaling_setspeed\n.\nondemand\nScales the frequency dynamically according to current load. Jumps to the highest frequency and then possibly back off as the idle time increases.\nconservative\nScales the frequency dynamically according to current load. Scales the frequency more gradually than ondemand.\nschedutil\nScheduler-driven CPU frequency selection\n[8]\n,\n[9]\n.\nDepending on the scaling driver, one of these governors will be loaded by default:\nschedutil\nsince\nLinux 4.9.5\nthe internal\npowersave\ngovernor for Intel and AMD CPUs using the\nintel_pstate\nand\namd_pstate\ndriver respectively (see the note above, it is equivalent to\nschedutil\n).\nWarning\nUse CPU monitoring tools (for temperatures, voltage, etc.) when changing the default governor.\nTo activate a particular governor, run:\n# cpupower frequency-set -g\ngovernor\nNote\nTo adjust for only a single CPU core, append\n-c\ncore_number\nto the command above.\nActivating a governor requires that specific\nkernel module\n(named\ncpufreq_\ngovernor\n) is loaded. As of kernel 3.4, these modules are loaded automatically.\nAlternatively, you can activate a governor on every available CPU manually:\n# echo\ngovernor\n| tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\nTip\nTo monitor cpu speed in real time, run:\n$ watch cat /sys/devices/system/cpu/cpu[0-9]*/cpufreq/scaling_cur_freq\nTuning the ondemand governor\nSee the\nkernel documentation\nfor details.\nSwitching threshold\nTo set the threshold for stepping up to another frequency:\n# echo -n\npercent\n> /sys/devices/system/cpu/cpufreq/\ngovernor\n/up_threshold\nTo set the threshold for stepping down to another frequency:\n# echo -n\npercent\n> /sys/devices/system/cpu/cpufreq/\ngovernor\n/down_threshold\nSampling rate\nThe sampling rate determines how frequently the governor checks to tune the CPU.\nsampling_down_factor\nis a tunable that multiplies the sampling rate when the CPU is at its highest clock frequency, thereby delaying load evaluation and improving performance. Allowed values for\nsampling_down_factor\nare 1 to 100000.  This tunable has no effect on behavior at lower CPU frequencies/loads.\nTo read the value (default = 1), run:\n$ cat /sys/devices/system/cpu/cpufreq/ondemand/sampling_down_factor\nTo set the value, run:\n# echo -n\nvalue\n> /sys/devices/system/cpu/cpufreq/ondemand/sampling_down_factor\nMake changes permanent\nSince Linux 5.9, it is possible to set the\ncpufreq.default_governor\nkernel option.\n[10]\nTo set the desired scaling parameters at boot, configure the\ncpupower\nutility and enable its systemd service. Alternatively,\nsystemd-tmpfiles\nor\nudev\nrules can be used.\nAutonomous frequency scaling\nBoth Intel and AMD define a way to have the CPU decide its own speed based on (1) a performance range from the system and (2) a performance/power hint specifying the preference. The fully-autonomous mode is activated when:\namd_pstate\nis set to \"active\"—requires CPPC support in both the CPU\nand\nBIOS,\nintel_pstate\nis set to \"active\"\nand\nhardware P-state (HWP) is available (i.e. Sandy Bridge and newer)—works out-of-the-box.\nThe most important feature of active governing is that only two governors appear available,\npowersave\nand\nperformance\n. They do not work\nat all\nlike their normal counterpart, however: these levels are translated into an\nEnergy Performance Preference\nhint for the CPU's internal governor. As a result, they both provide dynamic scaling, similar to the\nschedutil\nor\nondemand\ngeneric governors respectively, differing mostly in latency. The\nperformance\nalgorithm\nshould give better power saving functionality than the old ondemand governor\nfor Intel HWP.\nIntel active, non-HWP\nThe intel-pstate driver has, confusingly, an \"active\" mode that works without the CPU's active decision. This mode turns on when kernel cmdline forces an \"active\" mode but HWP is unavailable or disabled. It will still only provide\npowersave\nand\nperformance\n, but the driver itself does the governing in a way similar to\nschedutil\nand\nperformance\n(i.e. it stays at the maximum P-state). There is no real benefit to this mode compared to passive intel-pstate.\nSetting the EPP\nIt is possible to select in-between hints with the sysfs interfaces available. The interface is identical between AMD and Intel, where the files\n/sys/devices/system/cpu/cpu*/cpufreq/energy_performance_preference\ndescribe the current preference and\n/sys/devices/system/cpu/cpu*/cpufreq/energy_performance_available_preferences\nproviding a list of available preferences. One can also pass a number between 0 (favor performance) and 255 (favor power). A fallback implementation is provided for Intel CPUs without EPP, translating strings to EPB levels (described in next section) but failing on numbers.\nx86_energy_perf_policy\nsupports configuration of EPP hints via the\n--hwp-epp\nswitch on Intel CPUs\nonly\n. It works via direct access of machine-specific registers (MSRs) which differ between Intel and AMD. The program can also restrict the range of HWP frequencies using a range of frequency multipliers.\nTo enable hardware P-States with\nx86_energy_perf_policy(8)\n:\n# x86_energy_perf_policy -H 1\n# x86_energy_perf_policy -U 1\nCollaborative processor performance control\nThe power consumption of modern CPUs is no longer simply dependent on the frequency or voltage setting, as there are modules that can be switched on as needed. Collaborative processor performance control (CPPC) is the P-state replacement provided by ACPI 5.0. Instead of defining a table of static frequency levels, the processor provides many abstract\nperformance levels\nand the operating system selects from these levels. There are two advantages:\nThere is no longer a limit of 16 P-state entries; a typical CPU provides hundreds of levels to choose from.\nThe CPU can provide a higher frequency (e.g. boost) for a performance level when certain parts (e.g. vector FPU) is not used.\nOn the other hand, the flexible frequency breaks frequency-invariant utilization tracking, which is important for fast frequency changes by\nschedutil\n. A number of vendor-specific methods have been used to make the frequency static under CPPC, with most successes coming from arm64.\ncppc_cpufreq\nis the generic CPPC scaling driver.\namd_pstate\nalso uses ACPI CPPC to manage the CPU frequency when the Zen 3 MSR is unavailable – this method, also called \"shared memory\", has higher latency than MSR.\nIntel performance and energy bias hint\nThe\nIntel performance and energy bias hint (EPB)\nis an interface provided by Intel CPUs to allow for user space to specify the desired power-performance tradeoff, on a scale of 0 (highest performance) to 15 (highest energy savings). The EPB register is another layer of performance management functioning independently from frequency scaling. It influences how aggressive P-state and C-state selection will be, and informs internal model-specific decision making that affects energy consumption.\nCommon values and their aliases, as recognized by sysfs and\nx86_energy_perf_policy(8)\nare:\nEPB value\nString\n0\nperformance\n4\nbalance-performance\n6\nnormal, default\n8\nbalance-power\n15\npower\nSetting via sysfs\nThe EPB can be set using a sysfs attribute:\n# echo\nepb\n| tee /sys/devices/system/cpu/cpu*/power/energy_perf_bias\nSetting via x86_energy_perf_policy\nWith\nx86_energy_perf_policy\n:\n# x86_energy_perf_policy --epb\nepb\nSetting via cpupower\nWith\ncpupower\n:\n# cpupower set -b\nepb_value\nWarning\ncpupower does not support the string aliases. If given a string, it will silently set the EPB to 0, corresponding to max performance.\nInteraction with ACPI events\nUsers may configure scaling governors to switch automatically based on different ACPI events such as connecting the AC adapter or closing a laptop lid. A quick example is given below; however, it may be worth reading full article on\nacpid\n.\nEvents are defined in\n/etc/acpi/handler.sh\n. If the\nacpid\npackage is installed, the file should already exist and be executable. For example, to change the scaling governor from\nperformance\nto\nconservative\nwhen the AC adapter is disconnected and change it back if reconnected:\n/etc/acpi/handler.sh\n[...]\nac_adapter)\ncase \"$2\" in\nAC*)\ncase \"$4\" in\n00000000)\necho \"conservative\" >/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\necho -n $minspeed >$setspeed\n#/etc/laptop-mode/laptop-mode start\n;;\n00000001)\necho \"performance\" >/sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\necho -n $maxspeed >$setspeed\n#/etc/laptop-mode/laptop-mode stop\n;;\nesac\n;;\n*) logger \"ACPI action undefined: $2\" ;;\nesac\n;;\n[...]\nTroubleshooting\nBIOS frequency limitation\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nHelp:Style#Language register\n(Discuss in\nTalk:CPU frequency scaling\n)\nSome CPU/BIOS configurations may have difficulties to scale to the maximum frequency or scale to higher frequencies at all. This is most likely caused by BIOS events telling the OS to limit the frequency resulting in\n/sys/devices/system/cpu/cpu0/cpufreq/bios_limit\nset to a lower value.\nEither you just made a specific Setting in the BIOS Setup Utility, (Frequency, Thermal Management, etc.) you can blame a buggy/outdated BIOS or the BIOS might have a serious reason for throttling the CPU on its own.\nReasons like that can be (assuming your machine's a notebook) that the battery is removed (or near death) so you are on AC-power only. In this case, a weak AC-source might not supply enough electricity to fulfill extreme peak demands by the overall system and as there is no battery to assist this could lead to data loss, data corruption or in worst case even hardware damage!\nNot all BIOS'es limit the CPU-Frequency in this case, but, for example, most IBM/Lenovo Thinkpads do. Refer to thinkwiki for more\nthinkpad related info on this topic\n.\nIf you checked there is not just an odd BIOS setting and you know what you are doing, you can make the Kernel ignore these BIOS-limitations.\nWarning\nMake sure you read and understood the section above. CPU frequency limitation is a safety feature of your BIOS and you should not need to work around it.\nThis is\nnot\nrecommended and can seriously damage your hardware: use at your own risk.\n[11]\nSet the\nprocessor.ignore_ppc=1\nkernel parameter\n. For trying this temporarily, change the value in\n/sys/module/processor/parameters/ignore_ppc\nfrom\n0\nto\n1\n.\nSome systems use another mechanism to limit the CPU frequency, e.g., when running without battery or an unofficial power adapter. See\nLenovo ThinkPad T480#CPU stuck at minimum frequency\nfor a way to manipulate the BD PROCHOT bit in Intel CPUs and\nDell XPS 15 (9560)#General slowness & stuttering\nfor alternative fixes. It does not only apply to the Lenovo ThinkPad T480, but is a common problem in Dell XPS models like the XPS15 9550 and XPS15 9560, too. The bit also is what makes at least some Intel-based MacBooks run with minimum CPU frequency when no battery is connected.\nSee also\nLinux CPUFreq - kernel documentation\nReddit post talking about pstate\nProcessor boosting control\nintel_pstate kernel documentation\namd_pstate kernel documentation\nintel_pstate/intel_cpufreq documentation kernel 5.7+\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=CPU_frequency_scaling&oldid=853690\n\"\nCategories\n:\nPower management\nCPU\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Style\nSearch\nSearch\nCPU frequency scaling\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/CPU_frequency_scaling"}}
{"text": "Fan speed control - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nFan speed control\n3 languages\nFrançais\n日本語\n中文（简体）\nFrom ArchWiki\nRelated articles\nlm_sensors\nUndervolting CPU\nCPU frequency scaling\nFan control can bring various benefits to your system, such as quieter working system and power saving by completely stopping fans on low CPU load.\nNote\nLaptop users should be aware about how cooling system works in their hardware. Some laptops have single fan for both CPU and GPU and cools both at the same time. Some laptops have two fans for CPU and GPU, but the first fan cools down CPU and GPU at the same time, while the other one cools CPU only. In some cases, you will not be able to use the\nFancontrol\nscript due to incompatible cooling architecture (e.g. one fan for both GPU and CPU). See\n[1]\nfor some more information about this topic.\nWarning\nConfiguring or completely stopping fans on high system load might result in permanently damaged hardware, or thermal throttling at best.\nFancontrol (lm-sensors)\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThis partially duplicates\nlm_sensors#Configuration\n, it should link there instead. (Discuss in\nTalk:Fan speed control\n)\nfancontrol\nis a part of\nlm_sensors\n, which can be used to control the speed of CPU/case fans. It is most suitable for desktops and laptops, where fan controls are available via\nsysfs(5)\n.\nSupport for newer motherboards may not yet be in the Linux kernel.\nlm-sensors\nWarning\nThe following command is safe by default (pressing\nEnter\nat each prompt). Some advanced options may damage hardware: only modify the defaults if you understand the implications.\nThe first thing to do is to run\n# sensors-detect\nThis will detect all of the sensors present and they will be used for\nfancontrol\n. After that, run the following to check if it detected the sensors correctly:\n$ sensors\ncoretemp-isa-0000\nAdapter: ISA adapter\nCore 0:      +29.0°C  (high = +76.0°C, crit = +100.0°C)\n...\nit8718-isa-0290\nAdapter: ISA adapter\nVcc:         +1.14 V  (min =  +0.00 V, max =  +4.08 V)\nVTT:         +2.08 V  (min =  +0.00 V, max =  +4.08 V)\n+3.3V:       +3.33 V  (min =  +0.00 V, max =  +4.08 V)\nNB Vcore:    +0.03 V  (min =  +0.00 V, max =  +4.08 V)\nVDRAM:       +2.13 V  (min =  +0.00 V, max =  +4.08 V)\nfan1:        690 RPM  (min =   10 RPM)\ntemp1:       +37.5°C  (low  = +129.5°C, high = +129.5°C)  sensor = thermistor\ntemp2:       +25.0°C  (low  = +127.0°C, high = +127.0°C)  sensor = thermal diode\nNote\nIf the output does not display an RPM value for the CPU fan, one may need to\n#Increase the fan divisor for sensors\n. If the fan speed is shown and higher than 0, this is fine.\nConfiguration\nOnce the sensors are properly configured, use\npwmconfig(8)\nto test and configure fan speed control. Following the guide should create\n/etc/fancontrol\n, a customized configuration file. In the guide, the default answers are in parenthesis if you press enter without typing anything. Enter\ny\nfor yes,\nn\nfor no.\n# pwmconfig\nNote\nSome users may experience issues when using\n/sys/class/hwmon/\npaths for their configuration file.\nhwmon\nclass device symlinks point to the absolute paths, and are used to group all of the\nhwmon\nsensors together into one directory for easier access. Sometimes, the order of the\nhwmon\ndevices change from a reboot, causing\nfancontrol\nto stop working. See\n#Device paths have changed in /etc/fancontrol\nfor more information on how to fix this.\nTweaking\nSome users may want to manually tweak the configuration file after running\npwmconfig\nwith root privileges, usually to fix something. For manually tweaking the\n/etc/fancontrol\nconfiguration file, see\nfancontrol(8)\nfor the variable definitions.\nUsers will probably encounter the\nhwmon\npath issues as noted above in\n#Fancontrol (lm-sensors)\n. See\n#Device paths have changed in /etc/fancontrol\nfor more information.\nTip\nUse\nMAXPWM\nand\nMINPWM\noptions that limit fan speed range. See\nfancontrol(8)\nfor details.\nNote\nTemperature and fan sensor paths could change as well (usually on a kernel update) (e.g.\nhwmon0/device/temp1_input\nbecomes\nhwmon0/temp1_input\n). Check the\nfancontrol.service\nunit status\nto find out which path is the troublemaker and correct your configuration file accordingly.\nRunning Fancontrol\nTry to run\nfancontrol\n:\n# fancontrol\nA properly configured setup will not output errors and will take control of the system fans. Users should hear system fans starting shortly after executing this command.\nfancontrol\ncan also be run by\nstarting/enabling\nfancontrol.service\n.\nFor an unofficial GUI,\ninstall\nfancontrol-gui\nAUR\n.\nFancontrol stops working after suspend–wake cycles\nUnfortunately,\nfancontrol\ndoes not work after suspending. As per the\nfiled bug\n, you will have to restart\nfancontrol\nafter suspending. This can be achieved automatically by a\nsystemd hook\n.\nNBFC\nNote\nNBFC has been unmaintained since Mar 29, 2020. New user configs can still be created manually, however predefined configurations have not been added since that time. There are forks that exist to add new configs, such as\nnbfc-revive\n.\nNBFC (NoteBook Fan Control) is a cross-platform fan control solution for notebooks, written in C# and works under\nMono\nruntime. It comes with a powerful configuration system, which allows to adjust it to many different notebook models, including some of the latest ones.\nThere is another lightweight implementation of NBFC, written in C, named\nNBFC-Linux\n. It does not depend on the Mono framework. It can be installed as\nnbfc-linux\nAUR\n.\nInstallation\nNBFC can be installed as\nnbfc\nAUR\n. Also\nstart/enable\nnbfc.service\n.\nConfiguration\nNBFC comes with pre-made profiles. You can find them in\n/opt/nbfc/Configs/\ndirectory. When applying them, use the exact profile name without a file extension (e.g.\nsome profile.xml\nbecomes\n\"some profile\"\n).\nCheck if there is anything NBFC can recommend:\n$ nbfc config -r\nIf there is at least one model, try to apply this profile and see how fan speeds are being handled. For example:\n$ nbfc config -a \"Asus Zenbook UX430UA\"\nNote\nIf you are getting\nFile Descriptor does not support writing\n, delete\nStagWare.Plugins.ECSysLinux.dll\n[2]\nand\nrestart\nnbfc.service\n:\n# mv /opt/nbfc/Plugins/StagWare.Plugins.ECSysLinux.dll /opt/nbfc/Plugins/StagWare.Plugins.ECSysLinux.dll.old\nIf above solution did not help, try appending\nec_sys.write_support=1\nto\nkernel parameters\n.\nIf there are no recommended models, go to\nNBFC git repository\nor\n/opt/nbfc/Configs/\nand check if there are any similar models available from the same manufacturer. For example, on\nAsus Zenbook UX430UQ\n, the configuration\nAsus Zenbook UX430UA\ndid not work well (fans completelly stopped all the time), but\nAsus Zenbook UX410UQ\nworked fantastically.\nRun\nnbfc\nto see all options. More information about configuration is available at\nupstream wiki\n.\nDell laptops\ni8kutils\nis a daemon to configure fan speed according to CPU temperatures on some Dell Inspiron and Latitude laptops. It uses the\n/proc/i8k\ninterface provided by the\ni8k\ndriver (an alias for\ndell_smm_hwmon\n). Results will vary depending on the exact model of laptop.\nIf fancontrol will not work on your system, use the\nignore_dmi=1\nkernel module parameter\nto load\ndell_smm_hwmon\n.\nWarning\ni8kutils\nBIOS system calls stop the kernel for a moment on some systems (confirmed on Dell 9560), this can lead to side effects like audio dropouts, see\nhttps://bugzilla.kernel.org/show_bug.cgi?id=201097\nInstallation\ni8kutils\nAUR\nis the main package to control fan speed. Additionally, you might want to install these:\nacpi\n— must be installed to use\ni8kmon\n.\ntcl\n— must be installed in order to run\ni8kmon\nas a background service (using the\n--daemon\noption).\ntk\n— must be installed together with\ntcl\nto run as X11 desktop applet.\ndell-bios-fan-control-git\nAUR\n— recommended if your BIOS overrides fan control.\nConfiguration\nThe temperature points at which the fan changes speed can be adjusted in the configuration file\n/etc/i8kutils/i8kmon.conf\n. Only three fans speeds are supported (high, low, and off). Look for a section similar to the following:\nset config(0)  {{0 0}  -1  55  -1  55}\nset config(1)  {{1 1}  45  75  45  75}\nset config(2)  {{2 2}  65 128  65 128}\nThis example starts the fan at low speed when the CPU temperature reaches 55 °C, switching to high speed at 75 °C. The fan will switch back to low speed once the temperature drops to 65 °C, and turns off completely at 45 °C.\nTip\nIf when running\ni8kmon\nwith the verbose option you notice that the state changes (example of an output:\n# (57>=55), state=1, low=45, high=75\n) but right and left fans report state 0, you might consider changing the speed value of the first state in the configuration file from default 1000 to 2000 or higher.\nInstallation as a service\ni8kmon\ncan be started automatically by\nstarting/enabling\ni8kmon.service\n.\nBIOS overriding fan control\nSome newer laptops have BIOS fan control in place which will override the OS level fan control. To test if this the case, run\ni8kmon\nwith verbose mode in a command line, make sure the CPU is idle, then see if the fan is turned off or turned down accordingly.\nIf the BIOS fan control is in place, you can try using\ndell-bios-fan-control-git\nAUR\n:\nWarning\nTurning off BIOS fan control could result in damage to your hardware. Make sure you have\ni8kmon\nproperly set up beforehand, or leave the CPU idle while you test this program.\nTo enable BIOS fan control:\n# dell-bios-fan-control 1\nTo disable BIOS fan control:\n# dell-bios-fan-control 0\nBIOS fan control can be automatically disabled by\nstarting/enabling\ndell-bios-fan-control.service\n.\nThinkPad laptops\nSome fan control daemons include\nsimpfand-git\nAUR\nand\nthinkfan\nAUR\n(recommended).\nInstallation\nInstall\nthinkfan\nAUR\n. Optionally, but recommended, install\nlm_sensors\n. If needed, a GUI is available with\nthinkfan-ui\nAUR\n. Then have a look at the files:\n# pacman -Ql thinkfan\nNote that the\nthinkfan\npackage installs\n/usr/lib/modprobe.d/thinkpad_acpi.conf\n, which contains the following\nkernel module parameter\n:\noptions thinkpad_acpi fan_control=1\nNote\nNew Thinkpad models may require an additional\nexperimental=1\nkernel module parameter. So, it is important to check fan functionality.\nSo fan control is enabled by default, but you may need you to manually\nregenerate the initramfs\n.\nNow, reload the module with fan control enabled:\n# modprobe -r thinkpad_acpi\n# modprobe thinkpad_acpi fan_control=1\n# cat /proc/acpi/ibm/fan\nYou should see that the fan level is \"auto\" by default, but you can echo a level command to the same file to control the fan speed manually:\n# echo level 1 > /proc/acpi/ibm/fan\nFan Levels\nLevel\nEffect\n0\noff\n2\nlow speed\n4\nmedium speed\n7\nmaximum speed\nauto\ndefault - automatic, the fan RPM is controlled by the BIOS\nfull-speed / disengaged\nthe maximum fan speed; here the controller does not monitor the fan speed\nThe\nthinkfan\ndaemon will do this automatically.\n\"7\" is not the same as \"disengaged\". \"7\" is the maximum regulated speed (corresponds to \"full-speed\"). disengaged is the maximum unregulated speed.\nSee\nThinkWiki\nfor more details.\nFinally,\nenable\nthe\nthinkfan.service\n.\nTo configure the temperature thresholds, you will need to copy the example configuration file (\n/usr/share/doc/thinkfan/examples/thinkfan.yaml\n) to\n/etc/thinkfan.conf\n, and modify to taste. This file specifies which sensors to read, and which interface to use to control the fan. Some systems have\n/proc/acpi/ibm/fan\nand\n/proc/acpi/ibm/thermal\navailable; on others, you will need to specify something like:\nhwmon: /sys/devices/virtual/thermal/thermal_zone0/temp\nto use generic\nhwmon\nsensors instead of thinkpad-specific ones.\nA configuration example can be found in\nGentoo:Fan speed control/thinkfan#Configuration\n.\nRunning\nYou can test your configuration first by running thinkfan manually (as root):\n# thinkfan -n\nand see how it reacts to the load level of whatever other programs you have running.\nWhen you have it configured correctly,\nstart/enable\nthinkfan.service\n.\nLenovo Legions laptops\nThe tool\nLenovo Legion Linux\nallows to change the fan curves that are stored in the embedded controller. It consists of a kernel module that must be compiled and loaded. Currently, there is no package, but it must be compiled and installed from source.\nThen the fan curve can be set via the hwmon interface. This can be done with the provided script or the Python GUI.\nASUS laptops\nThis topic will cover drivers configuration on ASUS laptops for\nFancontrol (lm-sensors)\n.\nKernel modules\nIn configuration files, we are going to use full paths to\nsysfs\nfiles (e.g.\n/sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1\n). This is because\nhwmon\n1\nmight change to any other number after reboot.\nFancontrol (lm-sensors)\nis written in\nBash\n, so using these paths in configuration file is completely acceptable. You can find complete\n/etc/fancontrol\nconfiguration file examples at\nASUS N550JV#Fan control\n.\nasus-nb-wmi\nasus-nb-wmi\nis a kernel module, which is included in the Linux kernel and is loaded automatically on ASUS laptops. It will only allow to control a single fan and if there is a second fan you will not have any controls over it. Note that blacklisting this module will prevent keyboard backlight to work.\nBelow are the commands to control it. Check if you have any controls over your fan:\n# echo 255 > /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1           # Full fan speed (Value: 255)\n# echo 0 > /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1             # Fan is stopped (Value: 0)\n# echo 2 > /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1_enable      # Change fan mode to automatic\n# echo 1 > /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1_enable      # Change fan mode to manual\n# echo 0 > /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/pwm1_enable      # Change fan mode to full speed\nIf you were able to modify fan speed with above commands, then continue with\n#Generate configuration file with pwmconfig\n.\nasus_fan\nasus_fan\nis a kernel module, which allows to control both fans on some older ASUS laptops. It does not work with the most recent models.\nInstall the\nDKMS\nasus-fan-dkms-git\nAUR\nkernel module\n, providing\nasus_fan\n:\n# modprobe asus_fan\nCheck if you have any control over both fans:\n# echo 255 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm1          # Full CPU fan speed (Value: 255)\n# echo 0 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm1            # CPU fan is stopped (Value: 0)\n# echo 255 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm2          # Full GFX fan speed (Value: 255)\n# echo 0 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm2            # GFX fan is stopped (Value: 0)\n# echo 2 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm1_enable     # Change CPU fan mode to automatic\n# echo 1 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm1_enable     # Change CPU fan mode to manual\n# echo 2 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm2_enable     # Change GFX fan mode to automatic\n# echo 1 > /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/pwm2_enable     # Change GFX fan mode to manual\n# cat /sys/devices/platform/asus_fan/hwmon/hwmon[[:print:]]*/temp1_input          # Display GFX temperature (will always be 0 when GFX is disabled/unused)\nIf everything works, you can\nload the module at boot\nto automate this step.\nGenerate configuration file with pwmconfig\nIf you get an error\nThere are no working fan sensors, all readings are 0\nwhile generating configuration file with\npwmconfig\n, open first console and execute:\n# watch -n 1 \"echo 2 > /sys/devices/platform/\nkernel_module\n/hwmon/hwmon[[:print:]]*/pwm\n1\n_enable\"\nIf you use\nasus_fan\nkernel module and have 2nd fan, in second console:\n# watch -n 1 \"echo 2 > /sys/devices/platform/\nkernel_module\n/hwmon/hwmon[[:print:]]*/pwm\n2\n_enable\"\nAnd finally, in the third console:\n# pwmconfig\nOnce you are done and the configuration file is generated, you should stop the first and second consoles. Continue with\n#Fancontrol (lm-sensors)\n. After the configuration file is generated, you might need to manually replace PWM values with full\nsysfs\npaths as they are used in these steps, because\nhwmon\nnumber values might change after reboot.\nAlternative method using EC registers\nIf the above methods do not work for you, an alternative method is to directly write to certain registers in the embedded controller (EC). Using the\nEC-Probe tool\n, you can set the fan mode to one of the three fan speed modes, provided your model offers such feature in Windows.\nIn ASUS FX504GD model setting the fan speed to one of the three modes uses these register values:\n# ec_probe write 0x5e 0x80 # silent mode\n# ec_probe write 0x5e 0x40 # balance mode\n# ec_probe write 0x5e 0xC0 # performance mode\nHere we write to register\n0x5e\nthat is responsible in setting the fan speed mode.\nIf these values do not work for you, run the\nec-probe\ntool in monitor mode in Windows and try to identify which register in the EC changes value when switching through fan speed modes.\nSetting thermal throttle policy\nInstead of manually controlling fan speed using\nasus-nb-wmi\n, it is also possible to set the\nthermal throttling policy\nto have a more or less aggressive fan control policy. Possible values are\n0\n(default),\n1\n(overboost), and\n2\n(silent).\n# echo\nnumber\n> /sys/devices/platform/asus-nb-wmi/hwmon/hwmon[[:print:]]*/throttle_thermal_policy\nFan control modes on certain TUF series laptops\nOn certain ASUS TUF series laptops, performance and fan control modes can be changed using\nFn+F5\n. The current mode can be viewed by running the following command:\n$ cat /sys/devices/platform/asus-nb-wmi/fan_boost_mode\nNote\nOn some laptops, this setting may instead be at\n/sys/devices/platform/asus-nb-wmi/throttle_thermal_policy\n.\nYou can view the value changing as you use press\nFn+F5\n. 0 is \"Normal Mode\", 1 is \"Performance Mode\", 2 is most likely \"Silent Mode\".\n[3]\nIt is also possible to write these values into the\nfan_boost_mode\nfile as root and have the desired effect.\nThis was tested on the ASUS TUF FX504GE and ASUS TUF FX504GD models and found to be working.\nYou can use\ntuf-fan-boost-notification-git\nAUR\nto get notifications every time the FanSpeed mode gets changed.\nAMDGPU sysfs fan control\nAMDGPU\nkernel driver offers fan control for graphics cards via\nhwmon\nin\nsysfs\n.\nManual fan control\nTo switch to manual fan control from automatic, run\n# echo \"1\" > /sys/class/drm/card0/device/hwmon/hwmon0/pwm1_enable\nSet up fan speed to e.g. 50% (100% are 255 PWM cycles, thus calculate desired fan speed percentage by multiplying its value by 2.55):\n# echo \"128\" > /sys/class/drm/card0/device/hwmon/hwmon0/pwm1\nTo reset to automatic fan control, run\n# echo \"2\" > /sys/class/drm/card0/device/hwmon/hwmon0/pwm1_enable\nWarning\nResetting fan speed to auto may not work due to a driver bug and instead a restart of the driver may be required as a workaround.\nFan curves control\nNewer AMD graphical cards such as RDNA3 graphical cards do not support manual fan control due to firmware limitations\n[4]\n. For these cases AMD provides a\nfan_curve\nsysfs api for controlling the fan curves, for more information on it see\n[5]\n.\namdgpu-fan\nThe\namdgpu-fan\nAUR\npackage is an automated fan controller for AMDGPU-enabled video cards written in Python. It uses a \"speed-matrix\" to match the frequency of the fans with the temperature of the GPU, for example:\nspeed_matrix:  # -[temp(*C), speed(0-100%)]\n- [0, 0]\n- [40, 30]\n- [60, 50]\n- [80, 100]\nLaunch the fan control service by\nstarting/enabling\namdgpu-fan.service\n.\namdfand-bin\nThen\namdfand-bin\nAUR\npackage is a native alternative to\namdgpu-fan\nAUR\n. Launch the fan control service by\nstarting/enabling\namdfand.service\n.\nFor this tool there are also GUI clients available:\namdguid-glow-bin\nAUR\n(Xorg) and\namdguid-wayland-bin\nAUR\n(Wayland). Before starting the client you need to\nenable/start\namdgui-helper.service\n.\nfancurve script\nNot just fan controls are offered via\nhwmon\nin\nsysfs\n, but also GPU temperature reading:\n# cat /sys/class/drm/card0/device/hwmon/hwmon0/temp1_input\nThis outputs GPU temperature in °C + three zeroes, e.g.\n33000\nfor 33°C.\nThe bash script\namdgpu-fancontrol\nby grmat offers a fully automatic fan control by using the described\nsysfs hwmon\nfunctionality. It also allows to comfortably adjust the fancurve's temperature/PWM cycles assignments and a hysteresis by offering abstracted configuration fields at the top of the script.\nTip\nIn order to function correctly, the script needs at least three defined temperature/PWM cycles assignments.\nFor safety reasons, the script sets fan control again to auto when shutting down. This may cause spinning up of fans, which can be worked around at cost of security by setting\nset_fanmode 1\nin the section\nfunction reset_on_fail\n.\nSetting up fancurve script\nTo start the script, it is recommend to do so via\nsystemd\ninit system. This way the script's verbose output can be read via\njournalctl\n/systemctl status. For this purpose, a\n.service\nunit file is already included in the GitHub repository.\nIt may also be required to restart the script via a\nroot-resume.service\nafter hibernation in order to make it automatically function properly again:\n/etc/systemd/system/root-resume.service\n[Unit]\nDescription=Local system resume actions\nAfter=suspend.target\n[Service]\nType=simple\nExecStart=/usr/bin/systemctl restart amdgpu-fancontrol.service\n[Install]\nWantedBy=suspend.target\nOthers\nfan2go-git\nAUR\n— An alternative to Fancontrol independent of device-paths.\nmcontrolcenter-bin\nAUR\n— Fan control application for MSI laptops.\nfw-ectool-git\nAUR\n— Fan configuration for\nFramework Laptops\n.\nCoolerControl\nAUR\n— A fan control daemon with GUI for\nsysfs\nand\nliquidctl\ndevices.\ncontrolfans-git\nAUR\n— Simple GUI written in Qt to configure FAN PWM via HWMON interface. You could use it to setup the kernel auto point for every FAN who support it.\nTroubleshooting\nIncrease the fan divisor for sensors\nIf\nsensors\ndoes not output the CPU fan RPM, it may be necessary to change the fan divisor.\nThe first line of the\nsensors\noutput is the chipset used by the motherboard for readings of temperatures and voltages.\nCreate a file in\n/etc/sensors.d/\n:\n/etc/sensors.d/fan-speed-control.conf\nchip \"\ncoretemp-isa-\n*\"\nset fan\nX\n_div 4\nReplacing\ncoretemp-isa-\nwith name of the chipset and\nX\nwith the number of the CPU fan to change.\nSave the file, and run as root:\n# sensors -s\nwhich will reload the configuration files.\nRun\nsensors\nagain, and check if there is an RPM readout. If not, increase the divisor to 8, 16, or 32. Your mileage may vary.\nDevice paths have changed in /etc/fancontrol\nThe enumerated\nhwmon\nsymlinks located in\n/sys/class/hwmon/\nmight vary in order because the kernel modules do not load in a consistent order per boot. Because of this, it may cause fancontrol to not function correctly. The error is \"Configuration appears to be outdated, please run pwmconfig again\".\nUpstream bug\n.\nSolution\nIn\n/etc/conf.d/lm_sensors\n, there are 2 arrays that list all of the modules detected when you execute\nsensors-detect\n. These get loaded in by fancontrol. If the file does not exist, run\nsensors-detect\nas root, accepting the defaults. Open (or create)\n/etc/modules-load.d/modules.conf\n. Get all of the modules listed from the 2 variables in\n/etc/conf.d/lm_sensors\nand place them into the\n/etc/modules-load.d/modules.conf\nfile, one module per line. Specifying them like this should make a defined order for the modules to load in, which should make the\nhwmon\npaths stay where they are and not change orders for every boot. If this does not work, I highly recommend finding another program to control your fans. If you cannot find any, then you could try using the alternative solution below.\nAlternative solution: absolute paths\nUsing absolute file paths in fancontrol does not work by default, as its helper script\npwmconfig\nis programmed to only use the\nhwmon\npaths to get the files. The way it does this is that it detects whether the\nhwmon\npath that is provided in its configuration file\n/etc/fancontrol\ndid not change, and uses the variables\nDEVNAME\nand\nDEVPATH\nto determine such change. If your\nhwmon\npaths keep changing, this will prevent fancontrol from running no matter what you do. However, one can circumvent this problem. Open\n/usr/bin/fancontrol\n, and comment out this part of the script:\nif ! ValidateDevices \"$DEVPATH\" \"$DEVNAME\"\nthen\necho \"Configuration appears to be outdated, please run pwmconfig again\" >&2\nexit 1\nfi\nNote\nDoing this may make\nfancontrol\nwrite into files you gave it in the configuration file, no matter what the file is. This can corrupt files if you provide the wrong path. Be sure that you are using the correct path for your files.\nAnother thing to note is that while doing this workaround, using\npwmconfig\nto create your script again will overwrite all of your absolute paths that you have configured. Therefore, it is better to manually change the old paths to the new paths if it is needed instead of using\npwmconfig\n.\nCommenting this out should effectively ignore the\nhwmon\nvalidation checks. You can also ignore the variables\nDEVNAME\nand\nDEVPATH\nin the configuration file as well. After this, replace all of the\nhwmon\npaths in the other variables with its absolute path. To make it easier, rerun\npwmconfig\nwith root privileges to refresh the\nhwmon\ndevices. The\nhwmon\npaths in the configuration file should now point to the correct absolute paths. For each\nhwmon\npath, run the following command (where\nN\nis the enumeration of the\nhwmon\npath):\n$ readlink -f /sys/class/hwmon/hwmon\nN\n/device\nThis will give you the absolute path of the device.\nFor example, an\n/etc/fancontrol\nfile lists\nFCTEMPS\nas this:\nFCTEMPS=hwmon2/pwm1=hwmon3/temp1_input\nExecuting\nreadlink -f /sys/class/hwmon/hwmon3/device\ncan, for example, output\n/sys/devices/platform/coretemp.0/\n.\ncd\ninto this directory. If you see a\n/hwmon/hwmon\nN\n/\ndirectory, you have to do this in your\nfancontrol\nconfiguration file to replace the\nhwmon\nN\npath. From the previous example:\n# BEFORE\nFCTEMPS=hwmon2/pwm1=hwmon3/temp1_input\n# AFTER\nFCTEMPS=hwmon2/pwm1=/sys/devices/platform/coretemp.0/hwmon/[[:print:]]*/temp1_input\nEssentially, you must replace the\nhwmon\npath with the absolute path, concatenated with\n/hwmon/[[:print:]]*/\nso that bash can catch the random enumerated\nhwmon\nname.\nIf you do not see the\n/hwmon/hwmon\nN\n/\ndirectory, then you do not have to worry about this. This means that the temperature files are in the root of the device directory. Just replace\nhwmon\nN\n/\nwith the absolute file path. For example:\n# BEFORE\nFCTEMPS=hwmon2/pwm1=hwmon3/temp1_input\n# AFTER\nFCTEMPS=hwmon2/pwm1=/sys/devices/platform/coretemp.0/temp1_input\nAfter replacing all of paths,\nfancontrol\nshould work fine.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Fan_speed_control&oldid=847938\n\"\nCategories\n:\nCPU\nGraphics\nHidden category:\nPages or sections flagged with Template:Style\nSearch\nSearch\nFan speed control\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Fan_speed_control"}}
{"text": "Laptop - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nLaptop\n5 languages\nEspañol\nMagyar\n日本語\nPortuguês\n中文（简体）\nFrom ArchWiki\nAcer\n–\nApple\n–\nASUS\n–\nDell\n–\nFramework\n–\nHP\n–\nIBM/Lenovo\n–\nMSI\n–\nSamsung\n–\nSony\n–\nToshiba\n–\nOther\nThis\nLaptop main page\ncontains links to articles (sections) needed for configuring a laptop for the best experience. Setting up a\nlaptop\nis in many ways the same as setting up a\ndesktop\n. However, there are a few key differences.\nArch Linux\nprovides all the tools and programs necessary to take complete control of your laptop. These programs and utilities are highlighted below, with appropriate tips tutorials.\nTip\nTo gain an overview of the reported/achieved Arch Linux hardware compatibility of a particular laptop model, see the results per vendor of the above subpages.\nIf there are laptop model specific instructions, the respective article is crosslinked in the first column of the vendor subpages. In case the model is not listed in the vendor table, existing instructions of similar models via the\nCategory:Laptops\nvendor subcategory may help.\nPower management\nNote\nYou should read the articles\nPower management\nand\nCPU frequency scaling\nfirst. Additional laptop-specific features are described below.\nPower management is very important for anyone who wishes to make good use of their battery capacity. The following tools and programs help to increase battery life and keep your laptop cool and quiet.\nBattery state\nReading battery state can be done in multiple ways. Classical method is some daemon periodically polling battery level using ACPI interface. On some systems, the battery sends events to\nudev\nwhenever it (dis)charges by 1%, this event can be connected to some action using a udev rule.\nBattery can be checked directly from the kernel using:\n$ cat /sys/class/power_supply/\nBAT0\n/capacity\nBAT0\ncould also have vendor name. For example,\nwacom_battery_0\nfor Wacom stylus pen.\nAlternatively, you can use the\nupower\nabstraction utility:\n$ for BAT_PATH in $(upower -e | grep BAT); do upower -i \"$BAT_PATH\"; done\nACPI\nBattery state can be read using ACPI utilities from the terminal. ACPI command line utilities are provided via the\nacpi\npackage. See\nACPI modules\nfor more information.\ncbatticon\nis a battery icon that sits in the system tray.\nbatify\nAUR\nis an udevrule file triggering plug and battery level notifications (multi-x sessions support).\nbatsignal\nis a lightweight battery monitor daemon that uses libnotify to warn of low battery levels.\nHibernate on low battery level\nIf your battery sends events to\nudev\nwhenever it (dis)charges by 1%, you can use this udev rule to automatically hibernate the system when battery level is critical, and thus prevent all unsaved work from being lost. Alternatively,\nupower\ncan also take action when battery level is at a configurable critical level if\nupower.service\nis\nenabled\n.\nudev\nNote\nNot all batteries report discharge events. Test by running\nudevadm monitor --property\nwhile on battery and see if any events are reported. You should wait at least 1% drop. If no events are reported and\n/sys/class/power_supply/BAT0/alarm\nis non-zero then the battery will likely trigger an event when\nBAT0/energy_now\ndrops below the alarm value, and the udev rule will work as long as the percentage math works out. Some laptops have an option for this disabled in BIOS by default.\n/etc/udev/rules.d/99-lowbat.rules\n# Suspend the system when battery level drops to 5% or lower\nSUBSYSTEM==\"power_supply\", ATTR{status}==\"Discharging\", ATTR{capacity}==\"[0-5]\", RUN+=\"/usr/bin/systemctl hibernate\"\nNote\nIn the example,\n[0-5]\nis a shell-like pattern matching expression that matches one character in the range 0 to 5. It does not mean \"when capacity is in the range from 0 to 5\", and using something like\n[20-25]\nwill not match a capacity in the range 20 to 25. See\nhere\nfor available pattern matching with udev rules.\nTest the command to be run beforehand to make sure it would work. For instance,\n/usr/bin/systemctl hibernate\nmay return the error: \"Call to Hibernate failed: Not enough swap space for hibernation\"\nThis rule will be repeated whenever the condition is set. As such, when resuming from hibernate when the battery is critical, the computer will hibernate directly. Some laptops do not boot beyond a certain battery level, so the rule could be adjusted accordingly.\nIf you have more than one battery or if you are using a battery powered peripheral device, the rule could be triggered unexpectedly by another battery discharging; this can be fixed by obtaining another attribute/value pair to add to your udev rule that specifically match the main battery, for example\nmodel_name\n. Such new attribute/value pair can be obtained for example by checking\n/sys/class/power_supply/\nnameOfMainBattery\n/\nattributesAndOtherDirectories\n, or by running\nudevadm monitor --property\nand waiting for battery events.\nBatteries can jump to a lower value instead of discharging continuously, therefore a udev string matching pattern for all capacities 0 through 5 is used.\nTo shutdown the system instead of hibernating, use\n/usr/bin/systemctl poweroff\n. The\n-i\nflag can be used to ignore shutdown inhibitors, see\nsystemctl(1) § OPTIONS\n. Other rules can be added to perform different actions depending on power supply status and/or capacity.\nIf your system has no or missing ACPI events,\nfrequently run\nthe following script which uses\nacpi\n:\n#!/bin/sh\nacpi -b | awk -F'[,:%]' '{print $2, $3}' | {\nread -r status capacity\nif [ \"$status\" = Discharging -a \"$capacity\" -lt 5 ]; then\nlogger \"Critical battery threshold\"\nsystemctl hibernate\nfi\n}\nIf you have more than one battery or if you are using a battery powered peripheral device, you should modify the second line of the script by adding\ngrep\nto monitor the correct battery like so:\nacpi -b | grep \"Battery 0\" | awk -F'[,:%]' '{print $2, $3}' | {\n. Replace\nBattery 0\nwith your required battery as reported by\nacpi -b\n.\nNote\nUnplugging a battery or peripheral device may break your script since it can cause remaining batteries to be renamed, i.e. when\nBattery 0\nis unplugged,\nBattery 1\nbecomes\nBattery 0\nautomatically, and so on.\nTesting events\nOne way to test udev rules is to have them create a file when they are run. For example:\n/etc/udev/rules.d/98-discharging.rules\nSUBSYSTEM==\"power_supply\", ATTR{status}==\"Discharging\", RUN+=\"/usr/bin/touch /home/\nusername\n/discharging\"\nThis creates a file at\n/home/\nusername\n/discharging\nwhen the laptop charger is unplugged. You can test whether the rule worked by unplugging your laptop and looking for this file. For more advanced udev rule testing, see\nUdev#Testing rules before loading\n.\nUPower\nConfigure UPower, for example:\n/etc/UPower/UPower.conf\nUsePercentageForPolicy=true\nPercentageLow=20.0\nPercentageCritical=10.0\nPercentageAction=5.0\nCriticalPowerAction=HybridSleep\nEnable\nand\nstart\nupower.service\nafterwards.\nSuspend and hibernate\nManually suspending the operating system, either to memory (standby) or to disk (hibernate) sometimes provides the most efficient way to optimize battery life, depending on the usage pattern of the laptop.\nSee the main article\nSuspend and hibernate\n.\nHard drive spin down problem\nDocumented\nhere\n.\nTo prevent your laptop hard drive from spinning down too often, set less aggressive power management as described in\nhdparm#Power management configuration\n. Even the default values may be too aggressive.\nWakeup triggers\nWakeup sources/events/triggers wake the system from any of the hardware\npower-saving\nstates\n. To find and configure these see\nwakeup triggers\n.\nHardware support\nScreen brightness\nSee\nBacklight\n.\nTouchpad\nTo get your touchpad working properly, see the\nlibinput\npage.\nTouchpad Synaptics\nis the older input driver, which is currently in maintenance mode and is no longer updated.\nTouchpad not detected at all\nIf a touchpad device is not detected and shown as a device at all, a possible solution might be using one or more of these kernel parameters:\ni8042.noloop i8042.nomux i8042.nopnp i8042.reset\nElantech\nIf an Elantech Touchpad is not being detected and the following line appears in your\njournal\n:\nelan_i2c 5-0015: 5-0015 supply vcc not found, using dummy regulator\nit is related to an issue with the\npsmouse\nmodule trying to use a secondary bus for the touchpad device, and\nelan_i2c\nfailing to do so. The fix is to force it to use the primary one. Create the file below and reload the\npsmouse\nmodule or reboot:\n/etc/modprobe.d/psmouse.conf\noptions psmouse elantech_smbus=0\nFingerprint reader\nSee\nFingerprint-gui\n,\nfprint\nand\nThinkFinger\n(for ThinkPads).\nWebcam\nSee\nWebcam setup\n.\nHard disk shock protection\nThere are several laptops from different vendors featuring shock protection capabilities. As manufacturers have refused to support open source development of the required software components so far, Linux support for shock protection varies considerably between different hardware implementations.\nCurrently, two projects, named\nHDAPS\nand\nHpfall\n, support this kind of protection. HDAPS is for IBM/Lenovo Thinkpads and hpfall for HP/Compaq laptops.\nHybrid graphics\nThe laptop manufacturers developed new technologies involving two graphic cards in a single computer, enabling both high performance and power saving usages. These laptops usually use an Intel chip for display by default, so an\nIntel graphics\ndriver is needed first. Then you can\nchoose methods\nto utilize the second graphics chip.\nHardware video acceleration\nUse of hardware decoding and encoding can lead to a higher battery life. See\nVideo acceleration\n.\nAudio mute LED\nOn laptops using Intel HD Audio, the user may need to manually specify the codec model in order to get the audio mute LED to work. First, check if your laptop uses Intel HD Audio; the following command will produce output if so:\n$ lsmod | grep snd_hda_intel\nNext, you will need to find your audio codec model:\n$ grep Codec /proc/asound/card*/codec*\nNow you need to find their codec in the\nlist of available model names\n. If you cannot find a codec for your specific model, you may be able to find one that works through trial and error.\nIn order to tell the kernel module which model-specific options to load, specify the\nmodel=\nkernel module parameter\n. For example:\n/etc/modprobe.d/mute-led.conf\noptions snd_hda_intel model=\nmodel_name\nTo test whether or not this worked, the kernel module must be reloaded. You can do this by rebooting.\nIf you need to test a large number of codecs, it may be more efficient to avoid rebooting by first bringing the system to a state where no processes are using the kernel module, and then reloading the module with the new parameters. This can be done by logging out of all graphical and console sessions, and stopping the display manager if using one. Upon logging back in at a console, run the following commands:\n# modprobe -r snd_hda_intel\n# modprobe snd_hda_intel model=\nmodel_name\nThe module will now be using the new codec specified in\nmodel_name\n.\nNetwork time syncing\nFor a laptop, it may be a good idea to use\nChrony\nas an alternative to\nNTPd\n,\nOpenNTPD\nor\nsystemd-timesyncd\nto sync your clock over the network. Chrony is designed to work well even on systems with no permanent network connection (such as laptops), and is capable of much faster time synchronisation than standard ntp. Chrony has several advantages when used in systems running on virtual machines, such as a larger range for frequency correction to help correct quickly drifting clocks, and better response to rapid changes in the clock frequency. It also has a smaller memory footprint and no unnecessary process wakeups, improving power efficiency.\nWriting laptop pages\nSee\nHelp:Laptop page guidelines\nif you want to create or modify any laptop page.\nSee also\nGeneral\nCPU frequency scaling\nis a technology used primarily by notebooks which enables the OS to scale the CPU frequency up or down, depending on the current system load and/or power scheme.\nDisplay Power Management Signaling\ndescribes how to automatically turn off the laptop screen after a specified interval of inactivity (not just blanked with a screensaver but completely shut off).\nWireless network configuration\nprovides information about setting up wireless connection.\nKeyboard input\ndescribes configuration of Media keys.\nacpid\nis a flexible and extensible daemon for delivering ACPI events.\nPages specific to certain laptop types\nSee\nCategory:Laptops\nand its subcategories for pages dedicated to specific models/vendors.\nBattery tweaks for ThinkPads can be found in\nTLP\nand the\ntp_smapi\narticle.\nSee\nASUS Linux\nfor a set of tools designed for recent ROG and TUF laptops.\nExternal resources\nhttps://linux-on-laptops.com/\nhttps://www.linlap.com/\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Laptop&oldid=854425\n\"\nCategory\n:\nLaptops\nSearch\nSearch\nLaptop\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Laptop"}}
{"text": "Bluetooth - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nBluetooth\n6 languages\nDeutsch\nEspañol\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nBluetooth mouse\nBluetooth keyboard\nBluetooth headset\nBlueman\nObexFTP\nBluetooth\nis a standard for the short-range wireless interconnection of cellular phones, computers, and other electronic devices. In Linux, the canonical implementation of the Bluetooth protocol stack is\nBlueZ\n.\nInstallation\nInstall\nthe\nbluez\npackage, providing the Bluetooth protocol stack.\nInstall\nthe\nbluez-utils\npackage, providing the\nbluetoothctl\nutility. Additionally install\nbluez-deprecated-tools\nto have the\ndeprecated BlueZ tools\nas well.\nThe generic Bluetooth driver is the\nbtusb\nkernel module.\nCheck\nwhether that module is loaded. If it is not, then\nload the module\n.\nStart/enable\nbluetooth.service\n.\nNote\nSome Bluetooth adapters are bundled with a Wi-Fi card (e.g. older Intel Centrino cards). These require that the Wi-Fi card is firstly enabled (typically a keyboard shortcut on a laptop) in order to make the Bluetooth adapter visible to the kernel.\nSome Bluetooth cards (e.g. Broadcom) conflict with the network adapter. Thus, you need to make sure that your Bluetooth device gets connected before the network service boot.\nSome tools such as hcitool and hciconfig have been deprecated upstream, and are no longer included in\nbluez-utils\n. Since these tools will no longer be updated, it is recommended that scripts be updated to avoid using them. If you still desire to use them, install additionally\nbluez-deprecated-tools\n. See\nFS#53110\nand\nthe Bluez mailing list\nfor more information.\nSince\n2024\n,\nbluez-obex\nand\nbluez-mesh\nhave been separated from\nbluez\n. Therefore, if you plan to transfer files over Bluetooth,\nbluez-obex\nneeds to be installed and the user service\nobex.service\nneeds to be\nenabled\n.\nFront-ends\nConsole\nbluetoothctl\n— Pairing a device from the shell is one of the simplest and most reliable options.\nhttps://www.bluez.org/\n||\nbluez-utils\nbluetui\n— A TUI for managing Bluetooth devices.\nhttps://github.com/pythops/bluetui\n||\nbluetui\nbluetuith\n— Provides a Bluetooth manager via a Terminal User Interface for easier pairing and device/adapter management, with OBEX File Transfer and mouse support.\nhttps://www.github.com/darkhz/bluetuith\n||\nbluetuith\nAUR\nTip\nTo automate bluetoothctl commands, use\necho -e \"\ncommand1\n\\n\ncommand2\n\\n\" | bluetoothctl\nor\nbluetoothctl --\ncommand\n.\nGraphical\nThe following packages allow for a graphical interface to customize Bluetooth.\nGNOME Bluetooth\n—\nGNOME\n's Bluetooth tool.\ngnome-bluetooth-3.0\nprovides the back-end (\ngnome-bluetooth\nis now legacy)\ngnome-shell\nprovides the status monitor applet\ngnome-control-center\nprovides the configuration front-end GUI that can be accessed by typing Bluetooth on the Activities overview, or with the\ngnome-control-center bluetooth\ncommand.\nYou can also launch the\nbluetooth-sendto\ncommand directly to send files to a remote device.\nnautilus-bluetooth\nAUR\nadds a \"Send via Bluetooth\" entry to Nautilus' right-click menu\nTo receive files, open the Bluetooth settings panel; you can only receive whilst the Bluetooth panel is open.\nTo add a Bluetooth entry to the\nSend To\nmenu in Thunar's file properties menu, see instructions\nhere\n. (The command that needs to be configured is\nbluetooth-sendto %F\n).\nBluedevil\n—\nKDE\n's Bluetooth tool. If there is no Bluetooth icon visible in Dolphin and in the system tray, enable it in the system tray options or add a widget. You can configure Bluedevil and detect Bluetooth devices by clicking the icon. An interface is also available from the KDE System Settings.\nhttps://invent.kde.org/plasma/bluedevil\n||\nbluedevil\nBlueberry\n— Linux Mint's spin-off of GNOME Bluetooth, which works in all desktop environments.\nBlueberry\ndoes not support receiving files through Obex Object Push.\nhttps://github.com/linuxmint/blueberry\n||\nblueberry\nBlueman\n— A full featured Bluetooth manager.\nhttps://github.com/blueman-project/blueman\n||\nblueman\nObexFTP\n— A tool for transferring files to/from any OBEX enabled device.\nhttp://dev.zuckschwerdt.org/openobex/wiki/ObexFtp\n||\nobexftp\nAUR\nOverskride\n— A simple yet powerful Bluetooth client.\nhttps://github.com/kaii-lb/overskride#overskride\n||\noverskride\nAUR\nbtctl\n— A simple Bluetooth connection manager for\nfuzzel\nand other launchers.\nhttps://codeberg.org/kupospelov/btctl\n||\nbtctl\nAUR\nPairing\nNote\nBefore using the Bluetooth device, make sure that it is not blocked by\nrfkill\n.\nThis section describes directly configuring\nbluez\nvia the\nbluetoothctl(1)\ncommand line tool, which might not be necessary if you are using  an alternative front-end tool (such as GNOME Bluetooth).\nThe exact procedure depends on the devices involved and their input functionality.  What follows is a general outline of pairing a device using\nbluetoothctl\n.\nStart the\nbluetoothctl\ninteractive command. Input\nhelp\nto get a list of available commands.\n(optional) Select a default controller with\nselect\nMAC_address\n.\n(optional) Enter\npower on\nto turn the power to the controller on if the device is set to off. It is on by default; see\n#Default adapter power state\n.\nEnter\ndevices\nto get the MAC address of the device with which to pair.\nEnter device discovery mode with\nscan on\ncommand if device is not yet on the list.\nTurn the agent on with\nagent on\nor choose a specific agent: if you press tab twice after\nagent\nyou should see a list of available agents. A Bluetooth agent is what manages the Bluetooth 'pairing code'. It can either respond to a 'pairing code' coming in, or can send one out. The\ndefault-agent\nshould be appropriate in most cases.\n[1]\nEnter\npair\nMAC_address\nto do the pairing (tab completion works).\nIf using a device without a PIN, one may need to manually trust the device before it can reconnect successfully. Enter\ntrust\nMAC_address\nto do so.\nEnter\nconnect\nMAC_address\nto establish a connection.\nAn example session may look this way:\n$ bluetoothctl\n[NEW] Controller 00:10:20:30:40:50\nhostname\n[default]\n[bluetooth]# agent KeyboardOnly\nAgent registered\n[bluetooth]# default-agent\nDefault agent request successful\n[bluetooth]# power on\nChanging power on succeeded\n[CHG] Controller 00:10:20:30:40:50 Powered: yes\n[bluetooth]# scan on\nDiscovery started\n[CHG] Controller 00:10:20:30:40:50 Discovering: yes\n[NEW] Device 00:12:34:56:78:90\ndevice name\n[CHG] Device 00:12:34:56:78:90 LegacyPairing: yes\n[bluetooth]# pair 00:12:34:56:78:90\nAttempting to pair with 00:12:34:56:78:90\n[CHG] Device 00:12:34:56:78:90 Connected: yes\n[CHG] Device 00:12:34:56:78:90 Connected: no\n[CHG] Device 00:12:34:56:78:90 Connected: yes\nRequest PIN code\n[agent] Enter PIN code: 1234\n[CHG] Device 00:12:34:56:78:90 Paired: yes\nPairing successful\n[CHG] Device 00:12:34:56:78:90 Connected: no\n[bluetooth]# connect 00:12:34:56:78:90\nAttempting to connect to 00:12:34:56:78:90\n[CHG] Device 00:12:34:56:78:90 Connected: yes\nConnection successful\nDual boot pairing\nFor dual booting Linux systems, as shown in\n#Saving the configuration\nsimply ensure all files from\n/var/lib/bluetooth/\nBT-Adapter-MAC-address\nare identical on each installation, either by copying or symlinking them.\nWith Windows or macOS, to pair devices on dual boot setups you need to change the pairing keys on your Linux install to match.\nThis page only describes the manual method of doing so. To automate the process, see the\nbt-dualboot project\n(does not support\nBluetooth Low Energy\n) and\nthe related repositories\n.  For a semi-automated process, use the\nbluetooth-dualboot script\nwhich does not edit any files, but it helps you run the right commands and cut-and-paste the correct values.\nSetup\nTo do this, first pair your device on your Arch Linux install. Then reboot into the other OS and pair the device. Now you need to extract the pairing keys, but first switch off the Bluetooth devices to prevent any connection attempts.\nNote\nSome Logitech devices, such as the\nLogitech MX Master\nand Logitech 604 Lightspeed, increment the MAC address by one every time that the device is paired with a new system. You should determine whether this is the case, so that it can be accounted for at the end of the process.\nFor Windows\nYou can extract your Bluetooth keys on either Linux or Windows:\nExtracting on Windows\nFirst, boot into Windows.\nThe registry key containing the link keys may only be accessed by the\nSYSTEM account\n, which cannot be logged into. Therefore, you will need Microsoft's\nPsExec\ntool from the official Windows Sysinternals site in order to run\nregedit.exe\nas\nSYSTEM\n.\nDownload\nPsTools\n, and extract\nPsExec64.exe\n.\nIn an administrator instance of a\ncommand shell\n, from the location of the extracted EXE, launch the registry editor:\n.\\PsExec64.exe -s -i regedit.exe\nIn the registry editor, navigate to the following registry key:\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\BTHPORT\\Parameters\\Keys\nWithin this registry key is one subkey per Bluetooth adapter, named by MAC address. If there are multiple subkeys, and you are unsure of which to use, follow\nthis guide\nto find the MAC address for the desired Bluetooth adapter.\nIn the desired adapter's registry key, there is a name-value pair for each paired device, with the name being its MAC address. Additionally, you might see some subkeys named by MAC addresses, each containing name-value pairs with names like\nLTK\nor\nIRK\n. These subkeys (if any) are for Bluetooth 5.1 devices. If the device you're trying to share has a subkey, it is a Bluetooth 5.1 device. If it does not have a subkey, only a name-value pair, it is not a Bluetooth 5.1 device.\nRight click on the adapter's registry key and export it as a\n.reg\nfile. This is a text file that you can copy keys from. As mentioned, it contains pairing keys in name-value pairs for non-Bluetooth 5.1 devices, and pairing keys (and some other information) in per-device subkeys for Bluetooth 5.1 devices. Make this file available to your Linux installation and reboot into it.\nIf the device you want to share is\nnot\na Bluetooth 5.1 device, jump to\n#Saving the configuration\n. If it is a Bluetooth 5.1 device, you need to make some modifications to the pairing keys and the associated information before finishing up. Refer to\n#Preparing Bluetooth 5.1 Keys\nto see how.\nExtracting on Linux\nNote\nIf your Windows partition is encrypted with Bitlocker, you will not be able to access it from Linux using chntpw.\nBoot into Arch. Install\nchntpw\n. Mount your windows system drive. Change to the registry hive directory and start\nchntpw\non the SYSTEM hive:\nTip\nIf\nrlwrap\nis installed,\nchntpw\ncan be run as\nrlwrap chntpw\nto provide readline-style command-line editing and history.\n$ cd\n/path/to/windows/system\n/Windows/System32/config\n$ chntpw -e SYSTEM\nInside the\nchntpw\nenvironment, run:\n> cd CurrentControlSet\\Services\\BTHPORT\\Parameters\\Keys\nInstead of\nCurrentControlSet\n, you may see\nControlSet00\nX\n(check using\nls\n); use this instead:\n> cd ControlSet00\nX\n\\Services\\BTHPORT\\Parameters\\Keys\nThere will probably be just one subkey, whose name is your Bluetooth adapter's MAC address.\nShow it with\nls\nand\ncd\ninto it:\n> ls\n> cd\nyour-adapter's-mac-address\nThe subkey names under that adapter are the MAC addresses of the\ndevices\nthe adapter is paired to.\nShow them with\nls\n, then\ncd\ninto each of those you want to dual-pair:\n> ls\n> cd\nyour-device's-mac-address\nIf this is\nnot\na Bluetooth 5.1 device, you will only see the pairing key:\n> ls\nNode has 0 subkeys and 1 values\nsize  type        value name    [value if type DWORD]\n16    REG_BINARY <ab12cd34ef56>\nIf so, show a hexdump of your device's key using\nhex\n:\n> hex ab12cd34ef56\n:00000 XX XX XX XX XX XX XX XX XX XX XX XX XX XX XX XX (some other chars)\nThe \"XX\"s are the pairing key. Make note of which keys map to which MAC addresses.\nIf this\nis\na Bluetooth 5.1 device, then you will see several keys corresponding to the one device:\nNode has 0 subkeys and 8 values\nsize     type              value name             [value if type DWORD]\n16  3 REG_BINARY         <LTK>\n4  4 REG_DWORD          <KeyLength>               16 [0x10]\n8  b REG_QWORD          <ERand>\n4  4 REG_DWORD          <EDIV>                 37520 [0x9290]\n16  3 REG_BINARY         <IRK>\n8  b REG_QWORD          <Address>\n4  4 REG_DWORD          <AddressType>              1 [0x1]\n4  4 REG_DWORD          <AuthReq>                 45 [0x2d]\nRefer to\n#Preparing Bluetooth 5.1 Keys\nto see how to use these, using\nhex\nvalue_name\nto obtain the requested values.\nFinally, to import the key(s) into your Linux installation, proceed to\n#Saving the configuration\n.\nFor macOS\nBoot into macOS:\nFor macOS Monterey or newer:\nOpen Keychain Access and search for Bluetooth.\nSort by date.\nIf you've recently removed and reconnected the device then you can simply sort the keys by date modified and pick the latest. It is probably called MobileBluetooth (for older Bluetooth devices) or is just an UUID (for Bluetooth 5.1+).\nDouble click on the entry. Check that the MAC address in the Account field matches the MAC address of your device.\nClick the \"Show password\" checkbox. You will now need to enter your password, twice.\nCopy the text in the password field, it's actually an XML file (\n⌘+a\n⌘+c\n)\nPaste the text in\nbt_keys.txt\nin your home directory.\nFor High Sierra or newer, run the following in a terminal:\n# defaults read /private/var/root/Library/Preferences/com.apple.bluetoothd.plist LinkKeys > ~/bt_keys.txt\nFor Sierra or older, run the following in a terminal:\n# defaults read /private/var/root/Library/Preferences/blued.plist LinkKeys > ~/bt_keys.txt\nThe\n~/.bt_keys.txt\nfile now contains the established Bluetooth keys. For older versions of macOS (High Sierra and older) you will have to reverse the keys before proceeding. For example,\n98 54 2f aa bb cc dd ee ff gg hh ii jj kk ll mm\nbecomes\nMM LL KK JJ GG FF EE DD CC BB AA 2F 54 98\n.\nNote\nThe reversal can be done with the following\nPython\ncode:\n>>> key = \"98 54 2f aa bb cc dd ee ff gg hh ii jj kk ll mm\"\n>>> \" \".join(reversed(key.split()))\nIf this is a Bluetooth 5.1 device, then there will be more than one key corresponding to one device. Refer to\n#Preparing Bluetooth 5.1 Keys\nto see how to use these.\nFinally, to import the key(s) into your Linux installation, reboot into Linux and proceed to\n#Saving the configuration\n.\nPreparing Bluetooth 5.1 Keys\nThis article or section needs expansion.\nReason:\nWe are still working on getting a comprehensive idea of how these work across vendors. For now, documenting specific devices' compatibility with these methods is helpful - especially non-Logitech data points. (Discuss in\nTalk:Bluetooth#Bluetooth 5.1 Devices\n)\nIf you observed the presence of Bluetooth 5.1 keys while following\n#For Windows\nor\n#For macOS\n, you must apply certain transformations to their values before importing them into Linux. Create the requested files with their appropriate contents, for installation in\n#Saving the configuration\n. This process will depend on the device, and some of the values have to be manipulated; code utilities for doing so are provided below.\nDevice\nSource Key and Transformations (Windows)\nSource Key and Transformations (macOS)\nDestination Key File\nLogitech MX Anywhere 3S\nLogitech MX Master 3\nLogitech MX Master 3S\nLogitech MX Keys\nLogitech MX Keys Mini\nLogitech MX Mechanical\nXbox One S Wireless Controller\nCopy\nIRK\n.\nRemove the spaces between the hex octets.\n?\nIdentityResolvingKey.Key\nCopy\nLTK\n.\nRemove the spaces between the hex octets.\n?\nSlaveLongTermKey.Key\nand\nPeripheralLongTermKey.Key\nERand\nand\nEDIV\nshould be\n0\nRandom Number\nand\nEncrypted Diversifier\nshould be\n0\n.\n–\nLogitech MX Anywhere 2S\nELECOM Bitra\nCopy\nIRK\n.\nRemove the spaces between the hex octets.\n?\nIdentityResolvingKey.Key\nCopy\nCSRK\n.\nRemove the spaces between the hex octets.\n?\nLocalSignatureKey.Key\nCopy\nLTK\n.\nRemove the spaces between the hex octets.\n?\nLongTermKey.Key\nCopy\nKeyLength\n.\nConvert the whole number to decimal.\n?\nLongTermKey.EncSize\nCopy\nEDIV\n.\nConvert the whole number to decimal.\n?\nLongTermKey.EDiv\nCopy\nERand\n.\nReverse the order of the octets.\nConvert the whole number to decimal.\n?\nLongTermKey.Rand\nDygma Defy\nCopy\nIRK\n.\nRemove the spaces (or commas) between the hex octets.\n?\nIdentityResolvingKey.Key\nCopy\nLTK\n.\nRemove the spaces (or commas) between the hex octets.\n?\nLongTermKey.Key\nCopy\nKeyLength\n.\nConvert the whole number from hex to decimal.\n?\nLongTermKey.EncSize\nCopy\nEDIV\n.\nConvert the whole number from hex to decimal.\n?\nLongTermKey.EDiv\nCopy\nERand\n.\nReverse the order of the octets and remove the spaces (or commas).\nConvert the whole number from hex to decimal.\n?\nLongTermKey.Rand\nRoyal Kludge F68 keyboard is like the Logitech MX Anywhere 2S\nAlso copy\nCSRKInbound\ntoo.\nRemove the spaces between the hex octets.\n?\nRemoteSignatureKey.Key\nThinkPad TrackPoint Keyboard II\nPebble M350 mouse\nLogitech G604 Lightspeed mouse\nCopy\nIRK\n.\nReverse the order of the octets.\nCopy\nRemote IRK\n.\nConvert from base64 to hex.\nIdentityResolvingKey.Key\nCopy\nLTK\n.\nRemove the spaces between the hexadecimal octets.\nCopy\nRemote Encryption\n>\nLong-term Key\n.\nConvert from base64 to hex.\nLongTermKey.Key\nCopy\nERand\n.\nReverse the order of the octets.\nConvert the whole number to decimal.\nCopy\nRemote Encryption\n>\nRandom Number\n.\nConvert from base64 to a little-endian decimal number (see Python code below).\nLongTermKey.Rand\nCopy\nEDIV\n.\nReverse the order of the octets.\nConvert the whole number to decimal.\nCopy\nRemote Encryption\n>\nEncrypted Diversifier\n.\nConvert from base64 to a little-endian decimal number (see Python code below).\nLongTermKey.EDiv\nOther devices\nCopy\nLTK\n.\nRemove the spaces between the hex octets.\nCopy\nRemote IRK\n.\nConvert from base64 to hex.\nLongTermKey.Key\nCopy\nERand\n.\nReverse the order of the octets.\nConvert the whole number to decimal.\nCopy\nRemote Encryption\n>\nLong-term Key\n.\nConvert from base64 to hex.\nLongTermKey.Rand\nCopy\nEDIV\n.\nRemove the spaces between the hex octets.\nCopy\nRemote Encryption\n>\nEncrypted Diversifier\n.\nConvert from base64 to hex.\nReverse the order of the octets.\nLongTermKey.EDiv\nXbox wireless controller\nCopy\nLTK\n.\nRemove the spaces between the hex octets.\n?\nSlaveLongTermKey.Key\nNote\nTo just remove the spaces from a value, you can use\nthis online tool\nor this\nPython\ncode:\n>>> \"\nkey_value\n\".replace(\" \", \"\")\nThis Python code does only the octet reversal:\n>>> ERand=\" 63 02 84 B8 5D 40 44 DF   \"\n>>> ERand=list(reversed(ERand.strip().split()))\nThis Python code does the additional decimal conversion required for some:\n>>> int(\"\".join(ERand), 16)\n16088054540146049635\nThis Python code does the base64 to hex conversion:\nbinascii.hexlify(base64.decodebytes(b'...')).upper()\nThis Python code does the full macOS Encrypted Diversifier conversion:\nstruct.unpack('<H', base64.decodebytes(b'...'))\nThis Python code does the full macOS Random Number conversion:\nstruct.unpack('<Q', base64.decodebytes(b'...'))\nFor an example of the general case:\nAn\nLTK\nof\n48 4D AF CD 0F 92 22 88 0A 52 9A F4 76 DA 8B 94\nmakes for a\nLongTermKey.Key\nof\n484DAFCD0F9222880A529AF476DA8B94\n.\nAn\nERand\nof\n63 02 84 B8 5D 40 44 DF\nmakes for a\nRand\nof\n16088054540146049635\n.\nAn\nEDIV\nof\n37520\nmakes for an\nEDiv\nof\n37520\n.\nSaving the configuration\nNow that you have the keys change user to root, then continue with:\n# cd /var/lib/bluetooth/\nBT-Adapter-MAC-address\nHere you will find folders for each paired Bluetooth device. For each device you want to pair with Arch and your dual boot, do the following:\n# cd\ndevice-MAC-address\nNote\nAt this point, if you are using a device which increments its MAC address on pairing, you must move the MAC address directory to the incremented path. Either copy the MAC address from Windows, or increment it yourself while minding the fact that each octet is a two-digit\nhexadecimal\nnumber.\nIf you have a pairing key (i.e. this is not a Bluetooth 5.1 device), then edit the\ninfo\nfile and change the key under\n[LinkKey]\n. E.g.:\ninfo\n[LinkKey]\nKey=XXXXXXXXXXXXXXX\nNote\nYou will have to make sure that all the letters are in capital case. Remove any spaces.\nIf you have several keys, as in Bluetooth 5.1, edit the\ninfo\nfile and substitute all applicable keys with their recorded values. E.g. for an Xbox One S Wireless Controller:\ninfo\n[IdentityResolvingKey]\nKey=<IdentityResolvingKey.Key>\n[PeripheralLongTermKey]\nKey=<PeripheralLongTermKey.Key>\n[SlaveLongTermKey]\nKey=<SlaveLongTermKey.Key>\nThen\nrestart\nbluetooth.service\nand\npulseaudio\n(with\npulseaudio -k && pulseaudio --start\n).\nYou should be able to connect to your device now.\nNote\nDepending on your Bluetooth manager, you may need to perform a full reboot in order to reconnect to the device.\nConfiguration\nDefault transport 3.0 vs 5.x (low energy)\nTo force Bluetooth controller to use older Bluetooth transport protocol (e.g. because its simpler to setup dual boot pairing for 3.0 device, than for 5.x BLE device), set\nControllerMode=bredr\nin\n/etc/bluetooth/main.conf\nin the\n[General]\nsection:\n/etc/bluetooth/main.conf\n[General]\nControllerMode=bredr\nDefault value is\nControllerMode=dual\ni.e. both BR/EDR and LE enabled.\nDefault adapter power state\nAs of\nbluez\n5.65, BlueZ' default behavior is to power on all Bluetooth adapters when starting the service or resuming from suspend.\n[2]\nIf you would like the adapter to not be automatically enabled (e.g. on a portable device where you wish to save battery), set\nAutoEnable=false\nin\n/etc/bluetooth/main.conf\nin the\n[Policy]\nsection:\n/etc/bluetooth/main.conf\n[Policy]\nAutoEnable=false\nThe adapter can still be turned on manually by running\npower on\nas described in\n#Pairing\n.\nDiscoverable on startup\nIf the device should always be visible and directly connectable:\n/etc/bluetooth/main.conf\n[General]\nDiscoverableTimeout = 0\nWake from suspend\nTo allow Bluetooth keyboards, mice, etc. to wake the system from suspend. First, check the bios settings and make sure that wake from USB is not disabled. In many cases, Bluetooth from the motherboard is a USB device.\nAdd a new udev rule for Bluetooth adapter(s) (\nUSB Wireless Controller Base Class\n, Bluetooth Programming Interface Protocol) to enable wake from suspend:\n/etc/udev/rules.d/91-bluetooth-wakeup.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", DRIVERS==\"usb\", \\\nATTR{bDeviceClass}==\"e0\", \\\nATTR{bDeviceProtocol}==\"01\", \\\nATTR{bDeviceSubClass}==\"01\", \\\nATTR{power/wakeup}=\"enabled\"\nTo automatically re-configure your Bluetooth keyboard after wakeups to e.g. have a different keymap or key press repeat rate (for details, see\nXorg/Keyboard configuration#Adjusting typematic delay and rate\nand\nxmodmap\n), create an\nexecutable\nscript:\nconfigure_keyboard.sh\n#!/bin/sh\nexport DISPLAY=:0\nxset r rate 220 30\nxmodmap /\nyour\n/\npath\n/\nto\n/.Xmodmap\nThen create an additional udev rule like above:\n/etc/udev/rules.d/92-keyboard-reconfiguration-wakeup.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", DRIVERS==\"usb\", \\\nATTR{bDeviceClass}==\"e0\", \\\nATTR{bDeviceProtocol}==\"01\", \\\nATTR{bDeviceSubClass}==\"01\" \\\nRUN+=\"/\nyour\n/\npath\n/\nto\n/configure_keyboard.sh\"\nEnabling experimental features\nThe Bluez stack keeps new, potentially buggy features behind the D-Bus experimental and kernel experimental options. The functionality included under these varies over time, as experimental features are determined to be stable and no longer require the option (as an example: enabling D-Bus experimental interfaces currently allows to report battery level for old headsets). To enable these, uncomment the corresponding line in the configuration:\n/etc/bluetooth/main.conf\n...\n# Enables D-Bus experimental interfaces\n# Possible values: true or false\nExperimental = true\n# Enables kernel experimental features, alternatively a list of UUIDs\n# can be given.\n# Possible values: true,false,<UUID List>\n# Possible UUIDS:\n...\n# Defaults to false.\nKernelExperimental = true\nAlternatively, you can\nedit\nthe\nbluetooth.service\nto add the\n--experimental\nor\n--kernel\nflag, like this\ndrop-in file\n:\n/etc/systemd/system/bluetooth.service.d/override.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/bluetooth/bluetoothd --experimental\nEither way, you must then\nrestart\nthe\nbluetooth.service\n.\nAudio\nYou will typically need to take an additional step to integrate the audio server with Bluetooth. This is detailed in the below sections.\nSee the\nBluetooth headset\npage for more information about Bluetooth audio and Bluetooth headsets.\nPulseAudio\nIn order to be able to use audio equipment like Bluetooth headphones or speakers, you need to install the additional\npulseaudio-bluetooth\npackage. Make sure to restart\nPulseAudio\nto make the installation take effect:\npulseaudio -k\n. With a default PulseAudio installation (specifically, using a user instance with the packaged\ndefault.pa\n) you should immediately be able to stream audio from a Bluetooth device to your speakers.\n[3]\nIf you have a system-wide PulseAudio setup make sure the user running the daemon (usually\npulse\n) is in the\nlp\ngroup and you load the Bluetooth modules in your PulseAudio config:\n/etc/pulse/system.pa\n...\nload-module module-bluetooth-policy\nload-module module-bluetooth-discover\n...\nOptionally, add\nload-module module-switch-on-connect\nif you want to auto-switch all audio to the Bluetooth device.\nPipeWire\nPipeWire as of v0.3.19 enables its Bluetooth support by default.\nALSA\nNote\nBluez5 has dropped direct integration for\nALSA\nand supports\nPulseAudio\nonly. Follow the instructions below if you cannot or do not want to use PulseAudio.\nFirst, ensure that your Bluetooth audio device is correctly paired and connected to the system.\nThen, install\nbluez-alsa-git\nAUR\n, start (and enable) the\nbluealsa\nservice, and add your user to the\naudio\ngroup.\nRun the following command to check if everything is working as intended (replace\nXX:XX:XX:XX:XX:XX\nand\nFILE.wav\nbelow):\n$ aplay -D bluealsa:SRV=org.bluealsa,DEV=\nXX:XX:XX:XX:XX:XX\n,PROFILE=a2dp\nFILE.wav\nFinally, add the following lines to your\n~/.asoundrc\n:\n~/.asoundrc\ndefaults.bluealsa {\nservice \"org.bluealsa\"\ndevice \"XX:XX:XX:XX:XX:XX\"\nprofile \"a2dp\"\n}\nYou can now use the\nbluealsa\ndevice to reach your Bluetooth audio device. Volume management is conducted normally via\nalsamixer\nwith the option\n-D bluealsa\n.\nBluetooth serial\nTo get Bluetooth serial communication working on Bluetooth-to-Serial modules (HC-05, HC-06) do the following steps:\nPair\nyour Bluetooth device using\nbluetoothctl\nas described\nabove\n.\nInstall\nbluez-deprecated-tools\n, as it provides certain functionality which is missing from newer tools.\nBind paired device MAC address to tty terminal:\n# rfcomm bind rfcomm0\nMAC_address_of_Bluetooth_device\nNow you can open\n/dev/rfcomm0\nfor serial communication:\n$ picocom /dev/rfcomm0 -b 115200\nTroubleshooting\nThis article or section is out of date.\nReason:\nReplace hciconfig with newer commands. (Discuss in\nTalk:Bluetooth\n)\nGeneral Troubleshooting\nDebugging\nIn order to debug, first\nstop\nbluetooth.service\n.\nAnd then start it with the\n-d\nparameter:\n# /usr/lib/bluetooth/bluetoothd -n -d\nAnother option is via the\nbtmon\ntool.\nDeprecated BlueZ tools\nEight BlueZ tools\nwere deprecated\nand removed from\nbluez-utils\n, although not all of them were superseded by newer tools. The\nbluez-deprecated-tools\npackage now provides these deprecated tools.\nDeprecated tool\nMost likely replacement\ngatttool\nbtgatt-client,\nD-Bus Gatt API\n[\ndead link\n2023-10-29—HTTP 404]\nhciattach\nbtattach\nhciconfig\nbtmgmt (and bluetoothctl?)\nhcidump\nbtmon (and btsnoop)\nhcitool\nmissing,\nD-Bus Device API\n[\ndead link\n2023-10-29—HTTP 404]\navailable\nrfcomm\nmissing, implement with\nD-Bus Profile1 API\n[\ndead link\n2023-10-29—HTTP 404]\n?\nciptool\nsdptool\nmissing, functionality seems to be scattered over different D-Bus objects:\nProfile\n[\ndead link\n2023-10-29—HTTP 404]\n,\nAdvertising\n[\ndead link\n2023-10-29—HTTP 404]\n, and the UUIDs arrays in\ndevice\n[\ndead link\n2023-10-29—HTTP 404]\nand\nadapter\n[\ndead link\n2023-10-29—HTTP 404]\n.\nService issues\nsystemd: Condition check resulted in Bluetooth service being skipped\nbluetooth.service\nonly requires the directory\n/sys/class/bluetooth\nto exist, which should be created by kernel module\nbluetooth\n, which is only autoloaded by\nsystemd-udev\nif it actually finds a working Bluetooth hardware device.\nIf your\n/sys/class/bluetooth\ndoes not exist, check if your kernel Bluetooth module is loaded by\nlsmod\n. If not, and you believe you have a Bluetooth device, you can try manually starting them by\nloading the Bluetooth module\nand\nrestarting\nbluetooth.service\n.\nYou should also load your corresponding kernel Bluetooth driver when loading the\nbluetooth\nmodule, most likely\nbtusb\n, but can also be\nbtrtl,btintel,btbcm,bnep,btusb\netc.\nCheck\nbluetooth.service\n's\nunit status\nto see whether it started.\nSee also\nDebian Bug report logs - #853207\n.\nIf\nbluetooth.service\nstarted successfully, there is a chance that you still cannot use Bluetooth normally (e.g.\nbluetoothctl\nsays something like\norg.Bluez.Error.NotReady\nwhen you\nscan on\n). If this happens, try rebooting your computer, and double-check: whether directory\n/sys/class/bluetooth\nexists; whether\nlsmod\nincludes correct Bluetooth modules; log messages in the\njournal\n; etc.\nsystemd-udev\nshould pickup your Bluetooth hardware automatically without manual changes again.\nBluetooth immediately waking up suspend-to-idle devices\nOn systems capable of\nsuspend-to-idle/S2idle/S0ix/Modern Standby\n, Bluetooth controllers will stay enabled during sleep. This will usually cause the system to\nwake up immediately after going to sleep\nif any Bluetooth device is connected.\nTo prevent this, you can disable Bluetooth completely before going to sleep - install\nbluez-utils\nand create this file:\n/etc/systemd/system/bluetooth-disable-before-sleep.service\n[Unit]\nDescription=Disable Bluetooth before going to sleep\nBefore=sleep.target\nBefore=suspend.target\nBefore=hybrid-sleep.target\nBefore=suspend-then-hibernate.target\nStopWhenUnneeded=yes\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/usr/bin/bluetoothctl power off\nExecStop=/usr/bin/bluetoothctl power on\n[Install]\nWantedBy=sleep.target\nWantedBy=suspend.target\nWantedBy=hybrid-sleep.target\nWantedBy=suspend-then-hibernate.target\nEnable\nthis service and check if Bluetooth devices disconnect when going to sleep, and whenever Bluetooth goes back up after waking up the system.\nIf this workaround is in use,\nwaking up the system with a Bluetooth mouse/keyboard\nwill not work.\nBluetooth turns off after logout on a headless/server system\nThis can have various causes:\nBoth\nPulseAudio\nand\nPipeWire\nrun as user services by default, which are terminated once the last session ends. Enable\nlingering\nfor the user to fix this.\nAdditionally, when running\nWirePlumber\nwith\nPipeWire\n(which is usually the case), WirePlumber runs a \"logind-monitor\" which enables Bluetooth on login and disables it on logout. See\nWirePlumber#Keep Bluetooth running after logout / Headless Bluetooth\nfor a fix.\nAdapter issues\nhcitool scan: Device not found\nOn some laptops (e.g. Dell Studio 15, Lenovo Thinkpad X1) you have to switch the Bluetooth mode from HID to HCI. Install the\nbluez-hid2hci\npackage, then\nudev\nshould do this automatically. Alternatively, you can run this command to switch to HCI manually:\n# /usr/lib/udev/hid2hci\nIf the device will not show up and you have a Windows operating system on your machine, try booting it and enable the Bluetooth adapter from windows.\nSometimes also this simple command helps:\n# bluetoothctl power on\nbluetoothctl: No default controller available\nFirst, make sure the device is not being blocked by\nrfkill\n. If using\nUSBGuard\n, make sure it is not blocking the device (see\nUSBGuard#Allow Bluetooth controllers\n).\nOtherwise, consider the following possible causes:\nSome motherboard Bluetooth controllers have a bug which causes this. To see whether this is the issue, run\njournalctl | grep hci\nand check whether it contains\ncommand tx timeout\nor\nReading Intel version command failed\n. If it does, power off your computer and physically unplug the power cable for a few seconds. This forces the controller to reload the firmware, unlike a standard reboot (see\nbug report\n).\nSome Intel cards (such as the 8260) are not picked up correctly by the Bluetooth service. In this case, using the deprecated\nbluez-deprecated-tools\ninstead of\nbluez-utils\nmight fix the issue.\nSome dongles, such as the\nCSR clones\n, have compatibility issues at the kernel level.\nPower saving measures can cause issues, in which case adding the\nkernel parameter\nbtusb.enable_autosuspend=n\nis a potential solution (see\nbug report\n).\nFinally, unloading and loading\nbtusb\nwithout options sometimes helps to get the controller back:\n# modprobe -r btusb\n# modprobe btusb\nrfkill unblock: Do not unblock\nIf your device still soft blocked and you run\nConnMan\n, try this:\n$ connmanctl enable bluetooth\nBluetooth USB dongle\nIf you are using a USB dongle, you should check that your Bluetooth dongle is recognized. You can do that by running\njournalctl -f\nas root when you have plugged in the USB dongle (or inspecting\n/var/log/messages.log\n). It should look something like the following (look out for hci):\nFeb 20 15:00:24 hostname kernel: [ 2661.349823] usb 4-1: new full-speed USB device number 3 using uhci_hcd\nFeb 20 15:00:24 hostname bluetoothd[4568]: HCI dev 0 registered\nFeb 20 15:00:24 hostname bluetoothd[4568]: Listening for HCI events on hci0\nFeb 20 15:00:25 hostname bluetoothd[4568]: HCI dev 0 up\nFeb 20 15:00:25 hostname bluetoothd[4568]: Adapter /org/bluez/4568/hci0 has been enabled\nIf you only get the first two lines, you may see that it found the device but you need to bring it up.\nExample:\n# btmgmt\n[mgmt]# info\nIndex list with 1 item\nhci0:\tPrimary controller\naddr 00:1A:7D:DA:71:10 version 6 manufacturer 10 class 0x000000\nsupported settings: powered connectable fast-connectable discoverable bondable link-security ssp br/edr hs le advertising secure-conn debug-keys privacy static-addr\ncurrent settings:\nconnectable discoverable bondable ssp br/edr le secure-conn\nname Mozart\nshort name\n[mgmt]# select hci0\nSelected index 0\n[hci0]# power up\nhci0 Set Powered complete, settings:\npowered\nconnectable discoverable bondable ssp br/edr le secure-conn\n[hci0]# info\nhci0:\tPrimary controller\naddr 00:1A:7D:DA:71:10 version 6 manufacturer 10 class 0x1c0104\nsupported settings: powered connectable fast-connectable discoverable bondable link-security ssp br/edr hs le advertising secure-conn debug-keys privacy static-addr\ncurrent settings: powered\nconnectable discoverable bondable ssp br/edr le secure-conn\nOr\n# bluetoothctl\n[bluetooth]# show\nController 00:1A:7D:DA:71:10 (public)\nName: Mozart\nAlias: Mozart\nClass: 0x0000095c\nPowered: no\nDiscoverable: yes\nPairable: yes\n[bluetooth]# power on\n[CHG] Controller 00:1A:7D:DA:71:10 Class: 0x001c0104\nChanging power on succeeded\n[CHG] Controller 00:1A:7D:DA:71:10\nPowered: yes\n[bluetooth]# show\nController 00:1A:7D:DA:71:10 (public)\nName: Mozart\nAlias: Mozart\nClass: 0x001c0104\nPowered: yes\nDiscoverable: yes\nPairable: yes\nTo verify that the device was detected you can use\nbtmgmt\nwhich is part of the\nbluez-utils\n. You can get a list of available devices and their identifiers and their MAC address by issuing:\n$ btmgmt info\nIndex list with 1 item\nhci0:\tPrimary controller\naddr 00:1A:7D:DA:71:10\nversion 6\nmanufacturer 10 class 0x1c0104\nsupported settings: powered connectable fast-connectable discoverable bondable link-security ssp br/edr hs le advertising secure-conn debug-keys privacy static-addr\ncurrent settings: powered connectable discoverable bondable ssp br/edr le secure-conn\nIt is possible to check the Bluetooth version as mapped to the HCI version according to the table in the\nofficial specification\n. For example, in the previous output, HCI\nversion 6\nis Bluetooth version 4.0.\nMore detailed information about the device can be retrieved by using the deprecated\nhciconfig\n. (\nbluez-deprecated-tools\n)\n$ hciconfig -a hci0\nhci0:   Type: USB\nBD Address: 00:1B:DC:0F:DB:40 ACL MTU: 310:10 SCO MTU: 64:8\nUP RUNNING PSCAN ISCAN\nRX bytes:1226 acl:0 sco:0 events:27 errors:0\nTX bytes:351 acl:0 sco:0 commands:26 errors:0\nFeatures: 0xff 0xff 0x8f 0xfe 0x9b 0xf9 0x00 0x80\nPacket type: DM1 DM3 DM5 DH1 DH3 DH5 HV1 HV2 HV3\nLink policy: RSWITCH HOLD SNIFF PARK\nLink mode: SLAVE ACCEPT\nName: 'BlueZ (0)'\nClass: 0x000100\nService Classes: Unspecified\nDevice Class: Computer, Uncategorized\nHCI Ver: 2.0 (0x3) HCI Rev: 0xc5c LMP Ver: 2.0 (0x3) LMP Subver: 0xc5c\nManufacturer: Cambridge Silicon Radio (10)\nAudio devices start to skip at short distance from dongle\nIf other devices share the same USB host, they can\ninterrupt communication with audio devices\n. Make sure it is the only device attached to its bus. For example:\n$ lsusb\nBus 002 Device 002: ID 0a12:0001 Cambridge Silicon Radio, Ltd Bluetooth Dongle (HCI mode)\nBus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 001 Device 004: ID 048d:1345 Integrated Technology Express, Inc. Multi Cardreader\nBus 001 Device 003: ID 0424:a700 Standard Microsystems Corp. 2 Port Hub\nBus 001 Device 002: ID 8087:0024 Intel Corp. Integrated Rate Matching Hub\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nCSR dongle 0a12:0001\nThe device\nID 0a12:0001 Cambridge Silicon Radio, Ltd Bluetooth Dongle (HCI mode)\nhas a regression bug, and currently only works in the kernel version 5.17 and < 6.0. For more information, see\nKernel Bug 60824\n.\nLogitech Bluetooth USB dongle\nThere are Logitech dongles (ex. Logitech MX5000) that can work in two modes: Embedded and HCI. In embedded mode dongle emulates a USB device so it seems to your PC that you are using a normal USB mouse/keyoard.\nIf you hold the little red Button on the USB BT mini-receiver it will enable the other mode. Hold the red button on the BT dongle and plug it into the computer, and after 3-5 seconds of holding the button, the Bluetooth icon will appear in the system tray.\nDiscussion\nAlternatively, you can install the\nbluez-hid2hci\npackage. When you connect your Logitech dongle it will automatically switch.\nFoxconn / Hon Hai / Lite-On Broadcom device\nSome of these devices require the firmware to be flashed into the device at boot.\nSome firmware is available when searching for\nbroadcom\non the\nAUR\n, a notable package being\nbroadcom-bt-firmware\nAUR\n, which provides the files for\nmultiple cards\n.\nAlternatively, the firmware can be converted from a Microsoft Windows\n.hex\nfile into a\n.hcd\nusing\nhex2hcd\n(which is installed with\nbluez-utils\n).\nIn order to get the right\n.hex\nfile, try searching the device vendor:product code obtained with\nlsusb\n, for example:\nBus 002 Device 004: ID\n04ca:2006\nLite-On Technology Corp. Broadcom BCM43142A0 Bluetooth Device\nor\nBus 004 Device 004: Id\n0489:e031\nFoxconn / Hon Hai\nAlternatively, boot into Windows (a virtual machine installation will suffice) and get the firmware name from the Device Manager utility. If you want to know the model of your device but cannot see it in\nlsusb\n, you might see it in\nlsusb -v\nas\niProduct\n.\nThe\n.hex\nfile can be extracted from the downloaded Windows driver without having to run Windows for it. Download the right driver, for example\nBluetooth Widcomm\n[\ndead link\n2023-09-16—domain name not resolved]\n. Depending on the format, extracting the files might need\nunrar\nor\ncabextract\n. To find out which of the many\n.hex\nfiles is the right one for you, look in the file\nWin32/bcbtums-win7x86-brcm.inf\nand search for\n[RAMUSB\nE031\n.CopyList]\n, where\nE031\nshould be replaced with the product code (the second hex number in\nlsusb\n) of your device in upper-case. Underneath you should see the file name of the right\n.hex\nfile.\nOnce you have the\n.hcd\nfile, copy it into\n/lib/firmware/brcm/BCM.hcd\n- this filename is suggested by\ndmesg\nand it may change in your case so check your\ndmesg\noutput in order to verify. Then reload the\nbtusb\nmodule:\n# rmmod btusb\n# modprobe btusb\nThe device should now be available. See\nBBS#162688\nfor information on making these changes persistent.\nIntel combined Wi-Fi and Bluetooth cards\nSee\nWireless network configuration#Bluetooth coexistence\n.\nMediatek MT7921 or MT7961 on dual boot with windows\nOn dual boot systems, if Bluetooth firmware versions are different for Windows and Linux, the Bluetooth adapter is not working after rebooting to Windows.\nThe best way to prevent this is updating the Bluetooth drivers (especially firmware) with latest version for each OS.\nIf you cannot find the latest version driver (or firmware) for Windows, you can copy the latest firmware file\n/usr/lib/firmware/mediatek/BT_RAM_CODE_MT7961_1_2_hdr.bin.xz\nfrom Arch Linux and extract to Windows (e.g.\nC:\\WINDOWS\\system32\\DRIVERS\\\n, you can find the firmware file path in the device manager on Windows).\nAdapter disappears after suspend/resume\nFirst, find vendor and product ID of the adapter. For example:\n$ lsusb -tv\n/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=xhci_hcd/12p, 480M\nID 1d6b:0002 Linux Foundation 2.0 root hub\n...\n|__ Port 3: Dev 3, If 0, Class=Wireless, Driver=btusb, 12M\nID 8087:0025 Intel Corp.\n|__ Port 3: Dev 3, If 1, Class=Wireless, Driver=btusb, 12M\nID 8087:0025 Intel Corp.\n...\nIn this case, the vendor ID is 8087 and the product ID is 0025.\nThen, use\nusb_modeswitch\nto reset the adapter:\n# usb_modeswitch -R -v\nvendor_ID\n-p\nproduct_ID\nPairing and connectivity issues\nComputer is not visible\nEnable discoverable mode if your computer cannot be discovered from your phone:\n# bluetoothctl discoverable on\nVerify that discoverable mode is on:\n# bluetoothctl show\nPowered: yes\nDiscoverable: yes\nPairable: yes\nNote\nCheck\nDiscoverableTimeout\nand\nPairableTimeout\nin\n/etc/bluetooth/main.conf\n.\nIf the computer still does not show up, try changing the device class in\n/etc/bluetooth/main.conf\nas follows:\n# Default device class. Only the major and minor device class bits are\n# considered.\n#Class = 0x000100 # Computer Type (from default config)\nClass = 0x100100 # (Object-Transfer Service & Computer Type)\nNote\nIn some cases,\nClass\nin\nmain.conf\ngets overridden after device initialization, so set the class directly with\nhciconfig hci0 class 100100\n.\nA user reported that this was the only solution to make their computer visible for their phone. LG TVs (and some others) are discoverable from their audio devices, so using\n000414\n(the soundbar class) will make such devices appear.\nSee\nhttps://bluetooth-pentest.narod.ru/software/bluetooth_class_of_device-service_generator.html\nto generate Bluetooth device/service classes.\nDevice connects, then disconnects after a few moments\nIf you see messages like the following in the journal, and your device fails to connect or disconnects shortly after connecting:\nbluetoothd: Unable to get connect data for Headset Voice gateway: getpeername: Transport endpoint is not connected (107)\nbluetoothd: connect error: Connection refused (111)\nThis may be because you have already paired the device with another operating system using the same Bluetooth adapter (e.g., dual-booting).  Some devices cannot handle multiple pairings associated with the same MAC address (i.e., Bluetooth adapters). Follow instructions on\n#Dual boot pairing\nfor solving this issue.\nDevice does not show up in scan\nSome devices using Bluetooth low energy do not appear when scanning with bluetoothctl, for example the\nLogitech MX Master\n. You can use\ntransport le\nto scan it.\n# bluetoothctl\n[bluetooth]# menu scan\n[bluetooth]# transport le\n[bluetooth]# back\n[bluetooth]# scan on\n[bluetooth]# devices\n...\nDevice XX:XX:XX:XX:XX:XX DA V2 X <---- low energy device here\nAnother way to connect them is by installing\nbluez-deprecated-tools\n, then\nstart\nbluetooth.service\nand do:\n# bluetoothctl\n[NEW] Controller (MAC) myhostname [default]\n[bluetooth]# power on\n[CHG] Controller (MAC) Class: 0x0c010c\nChanging power on succeeded\n[CHG] Controller (MAC) Powered: yes\n[bluetooth]# scan on\nDiscovery started\n[CHG] Controller (MAC) Discovering: yes\nIn another terminal:\n# hcitool lescan\nWait until your device shows up, then\nCtrl+c\nhcitool. bluetoothctl should now see your device and pair normally.\nNo BLE device can be discovered with Intel Corp. AX200 Bluetooth\nIt seems that BLE passive scan is broken on this device. See\nupstream bug report\nfor more details.\nCannot reconnect after sleep\nYou may notice that you cannot automatically reconnect to a device after it goes to sleep, or after the computer wakes from suspend.\nYou would for example notice the following errors in your logs:\nbluetoothd[487]: Authentication attempt without agent\nbluetoothd[487]: Access denied: org.bluez.Error.Rejected\nThis could be because the device is not marked as\ntrusted\n. See\n#Pairing\n.\nDevice-specific issues\nBluetooth mouse lags / disconnect / does not respond\nSee\nBluetooth mouse#Troubleshooting\n.\nAudio device fails to connect with br-connection-profile-unavailable\nA Bluetooth audio device will fail to connect if pipewire (rather than pulseaudio-bluetooth) is being used, but an instance of pipewire is not running.\nStart\nthe\npipewire.service\nuser unit\nor play some audio to start the pipewire daemon, then try to connect the audio device again.\nInterference between headphones and mouse\nIf you experience audio stuttering while using a Bluetooth mouse and keyboard simultaneously, you can try the following as referenced in #23\nhttps://bugs.launchpad.net/ubuntu/+source/bluez/+bug/424215\n# hciconfig hci0 lm ACCEPT,MASTER\n# hciconfig hci0 lp HOLD,SNIFF,PARK\nContinually connect/disconnect with TP-LINK UB400 and Xbox controller\nUse the settings below:\n/etc/bluetooth/main.conf\n...\n[General]\nJustWorksRepairing = always\nFastConnectable = true\nClass = 0x000100\n...\n[GATT]\nReconnectIntervals=1,1,2,3,5,8,13,21,34,55\nAutoEnable=true\n...\nThen\nrestart\nthe\nbluetooth.service\n.\nYou can see relevant\ndiscussion on xpadneo\nbut the xpadneo driver is not needed.\nFile transfer issues\ngnome-bluetooth\nIf you see this when trying to enable receiving files in bluetooth-properties:\nBluetooth OBEX start failed: Invalid path\nBluetooth FTP start failed: Invalid path\nThen make sure that the\nXDG user directories\nexist.\nCannot receive transferred files due to symlink\nIf incoming file transfers fail on an an otherwise functional Bluetooth connection, the problem may be due to symlinks in your file transfer path.  Logs like this would appear in the journal:\nJun 18 11:18:13 ember obexd[3338969]: open(/home/me/.cache/obexd/MOC740): Operation not permitted (1)\nIf the path shown in the error message contains a symlink, then obexd by default\nwill not accept it\n. The behavior can be overridden on initialization using a\ndrop-in file\nfor the\nobex.service\nuser service\n:\n~/.config/systemd/user/obex.service.d/10-symlink.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/bluetooth/obexd --symlinks\nThen\nreload\nthe\nsystemd\nmanager configuration of the calling user and\nrestart\nthe\nobex.service\nuser unit.\nSee also\nKeeping Bluetooth devices paired between Linux and Windows\nBluetooth link keys on dual-boot systems\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Bluetooth&oldid=854318\n\"\nCategory\n:\nBluetooth\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Out of date\nPages with dead links\nSearch\nSearch\nBluetooth\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Bluetooth"}}
{"text": "QEMU - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nQEMU\n5 languages\nDeutsch\nEspañol\nFrançais\n日本語\n中文（简体）\nFrom ArchWiki\nRelated articles\nCategory:Hypervisors\nLibvirt\nQEMU/Advanced networking\nQEMU/Guest graphics acceleration\nQEMU/Troubleshooting\nPCI passthrough via OVMF\nAccording to the\nQEMU about page\n:\nQEMU is a generic and open source machine emulator and virtualizer.\nWhen used as a machine emulator, QEMU can run OSes and programs made for one machine (e.g. an ARM board) on a different machine (e.g. your x86 PC). By using dynamic translation, it achieves very good performance.\nQEMU can use other hypervisors like\nXen\nor\nKVM\nto use CPU extensions (\nHVM\n) for virtualization. When used as a virtualizer, QEMU achieves near native performance by executing the guest code directly on the host CPU.\nInstallation\nInstall\nthe\nqemu-full\npackage (or\nqemu-base\nfor the version without GUI and\nqemu-desktop\nfor the version with only x86_64 emulation by default) and below optional packages for your needs:\nqemu-block-gluster\n-\nGlusterfs\nblock support\nqemu-block-iscsi\n-\niSCSI\nblock support\nsamba\n-\nSMB/CIFS\nserver support\nAlternatively,\nqemu-user-static\nexists as a usermode and static variant.\nQEMU variants\nQEMU is offered in several variants suited for different use cases.\nAs a first classification, QEMU is offered in full-system and usermode emulation modes:\nFull-system emulation\nIn this mode, QEMU emulates a full system, including one or several processors and various peripherals. It is more accurate but slower, and does not require the emulated OS to be Linux.\nQEMU commands for full-system emulation are named\nqemu-system-\ntarget_architecture\n, e.g.\nqemu-system-x86_64\nfor emulating\nx86_64\nCPUs,\nqemu-system-i386\nfor Intel\n32-bit x86\nCPUs,\nqemu-system-arm\nfor\nARM (32 bits)\n,\nqemu-system-aarch64\nfor\nARM64\n, etc.\nIf the target architecture matches the host CPU, this mode may still benefit from a significant speedup by using a hypervisor like\nKVM\nor Xen.\nUsermode emulation\nIn this mode, QEMU is able to invoke a Linux executable compiled for a (potentially) different architecture by leveraging the host system resources. There may be compatibility issues, e.g. some features may not be implemented, dynamically linked executables will not work out of the box (see\n#Chrooting into arm/arm64 environment from x86_64\nto address this) and only Linux is supported (although\nWine may be used\nfor running Windows executables).\nQEMU commands for usermode emulation are named\nqemu-\ntarget_architecture\n, e.g.\nqemu-x86_64\nfor emulating 64-bit CPUs.\nQEMU is offered in dynamically-linked and statically-linked variants:\nDynamically-linked (default)\nqemu-*\ncommands depend on the host OS libraries, so executables are smaller.\nStatically-linked\nqemu-*\ncommands can be copied to any Linux system with the same architecture.\nIn the case of Arch Linux, full-system emulation is offered as:\nNon-headless (default)\nThis variant enables GUI features that require additional dependencies (like SDL or GTK).\nHeadless\nThis is a slimmer variant that does not require GUI (this is suitable e.g. for servers).\nNote that headless and non-headless versions install commands with the same name (e.g.\nqemu-system-x86_64\n) and thus cannot be both installed at the same time.\nDetails on packages available in Arch Linux\nThe\nqemu-desktop\npackage provides the\nx86_64\narchitecture emulators for full-system emulation (\nqemu-system-x86_64\n). The\nqemu-emulators-full\npackage provides the\nx86_64\nusermode variant (\nqemu-x86_64\n) and also for the rest of supported architectures it includes both full-system and usermode variants (e.g.\nqemu-system-arm\nand\nqemu-arm\n).\nThe headless versions of these packages (only applicable to full-system emulation) are\nqemu-base\n(\nx86_64\n-only) and\nqemu-emulators-full\n(rest of architectures).\nFull-system emulation can be expanded with some QEMU modules present in separate packages:\nqemu-block-gluster\n,\nqemu-block-iscsi\nand\nqemu-guest-agent\n.\nqemu-user-static\nprovides a usermode and static variant for all target architectures supported by QEMU. The installed QEMU commands are named\nqemu-\ntarget_architecture\n-static\n, for example,\nqemu-x86_64-static\nfor intel 64-bit CPUs.\nNote\nAt present, Arch does not offer a full-system mode and statically linked variant (neither officially nor via AUR), as this is usually not needed.\nGraphical front-ends for QEMU\nUnlike other virtualization programs such as\nVirtualBox\nand\nVMware\n, QEMU does not provide a GUI to manage virtual machines (other than the window that appears when running a virtual machine), nor does it provide a way to create persistent virtual machines with saved settings. All parameters to run a virtual machine must be specified on the command line at every launch, unless you have created a custom script to start your virtual machine(s).\nLibvirt\nprovides a convenient way to manage QEMU virtual machines. See\nlist of libvirt clients\nfor available front-ends.\nCreating a new virtualized system\nCreating a hard disk image\nThe factual accuracy of this article or section is disputed.\nReason:\nIf I get the man page right the raw format only allocates the full size if the filesystem does not support \"holes\" or it is explicitly told to preallocate. See\nqemu-img(1) § NOTES\n. (Discuss in\nTalk:QEMU\n)\nTip\nSee\nWikibooks:QEMU/Images\nfor more information on QEMU images.\nTo run QEMU you will need a hard disk image, unless you are booting a live system from CD-ROM or the network (and not doing so to install an operating system to a hard disk image). A hard disk image is a file which stores the contents of the emulated hard disk.\nA hard disk image can be\nraw\n, so that it is literally byte-by-byte the same as what the guest sees, and will always use the full capacity of the guest hard drive on the host. This method provides the least I/O overhead, but can waste a lot of space, as not-used space on the guest cannot be used on the host.\nAlternatively, the hard disk image can be in a format such as\nqcow2\nwhich only allocates space to the image file when the guest operating system actually writes to those sectors on its virtual hard disk. The image appears as the full size to the guest operating system, even though it may take up only a very small amount of space on the host system. This image format also supports QEMU snapshotting functionality (see\n#Creating and managing snapshots via the monitor console\nfor details). However, using this format instead of\nraw\nwill likely affect performance.\nQEMU provides the\nqemu-img\ncommand to create hard disk images. For example to create a 4 GiB image in the\nraw\nformat:\n$ qemu-img create -f raw\nimage_file\n4G\nYou may use\n-f qcow2\nto create a\nqcow2\ndisk instead.\nNote\nYou can also simply create a\nraw\nimage by creating a file of the needed size using\ndd\nor\nfallocate(1)\n.\nWarning\nIf you store the hard disk images on a\nBtrfs\nfile system, you should consider disabling\nCopy-on-Write\nfor the directory before creating any images. Can be specified in option nocow for qcow2 format when creating image:\n$ qemu-img create -f qcow2\nimage_file\n-o nocow=on 4G\nOverlay storage images\nYou can create a storage image once (the 'backing' image) and have QEMU keep mutations to this image in an overlay image. This allows you to revert to a previous state of this storage image. You could revert by creating a new overlay image at the time you wish to revert, based on the original backing image.\nTo create an overlay image, issue a command like:\n$ qemu-img create -o backing_file=\nimg1.raw\n,backing_fmt=\nraw\n-f\nqcow2\nimg1.cow\nAfter that you can run your QEMU virtual machine as usual (see\n#Running a virtualized system\n):\n$ qemu-system-x86_64\nimg1.cow\nThe backing image will then be left intact and mutations to this storage will be recorded in the overlay image file.\nWhen the path to the backing image changes, repair is required.\nWarning\nThe backing image's absolute filesystem path is stored in the (binary) overlay image file. Changing the backing image's path requires some effort.\nMake sure that the original backing image's path still leads to this image. If necessary, make a symbolic link at the original path to the new path. Then issue a command like:\n$ qemu-img rebase -b\n/new/img1.raw\n/new/img1.cow\nAt your discretion, you may alternatively perform an 'unsafe' rebase where the old path to the backing image is not checked:\n$ qemu-img rebase -u -b\n/new/img1.raw\n/new/img1.cow\nResizing an image\nWarning\nResizing an image containing an NTFS boot file system could make the operating system installed on it unbootable. It is recommended to create a backup first.\nThe\nqemu-img\nexecutable has the\nresize\noption, which enables easy resizing of a hard drive image. It works for both\nraw\nand\nqcow2\n. For example, to increase image space by 10 GiB, run:\n$ qemu-img resize\ndisk_image\n+10G\nAfter enlarging the disk image, you must use file system and partitioning tools inside the virtual machine to actually begin using the new space.\nShrinking an image\nWhen shrinking a disk image, you must first reduce the allocated file systems and partition sizes using the file system and partitioning tools inside the virtual machine and then shrink the disk image accordingly. For a Windows guest, this can be performed from the \"create and format hard disk partitions\" control panel.\nWarning\nProceeding to shrink the disk image without reducing the guest partition sizes will result in data loss.\nThen, to decrease image space by 10 GiB, run:\n$ qemu-img resize --shrink\ndisk_image\n-10G\nConverting an image\nYou can convert an image to other formats using\nqemu-img convert\n. This example shows how to convert a\nraw\nimage to\nqcow2\n:\n$ qemu-img convert -f raw -O qcow2\ninput\n.img\noutput\n.qcow2\nThis will not remove the original input file.\nPreparing the installation media\nTo install an operating system into your disk image, you need the installation medium (e.g. optical disc, USB-drive, or ISO image) for the operating system. The installation medium should not be mounted because QEMU accesses the media directly.\nTip\nIf using an optical disc, it is a good idea to first dump the media to a file because this both improves performance and does not require you to have direct access to the devices (that is, you can run QEMU as a regular user without having to change access permissions on the media's device file). For example, if the CD-ROM device node is named\n/dev/cdrom\n, you can dump it to a file with the command:\n$ dd if=/dev/cdrom of=\ncd_image.iso\nbs=4k\nInstalling the operating system\nThis is the first time you will need to start the emulator. To install the operating system on the disk image, you must attach both the disk image and the installation media to the virtual machine, and have it boot from the installation media.\nFor example on i386 guests, to install from a bootable ISO file as CD-ROM and a raw disk image:\n$ qemu-system-x86_64 -cdrom\niso_image\n-boot order=d -drive file=\ndisk_image\n,format=raw\nSee\nqemu(1)\nfor more information about loading other media types (such as floppy, disk images or physical drives) and\n#Running a virtualized system\nfor other useful options.\nAfter the operating system has finished installing, the QEMU image can be booted directly (see\n#Running a virtualized system\n).\nNote\nBy default only 128 MiB of memory is assigned to the machine. The amount of memory can be adjusted with the\n-m\nswitch, for example\n-m 512M\nor\n-m 2G\n.\nTip\nInstead of specifying\n-boot order=x\n, some users may feel more comfortable using a boot menu:\n-boot menu=on\n, at least during configuration and experimentation.\nWhen running QEMU in headless mode, it starts a local VNC server on port 5900 per default. You can use\nTigerVNC\nto connect to the guest OS:\nvncviewer :5900\nIf you need to replace floppies or CDs as part of the installation process, you can use the QEMU machine monitor (press\nCtrl+Alt+2\nin the virtual machine's window) to remove and attach storage devices to a virtual machine. Type\ninfo block\nto see the block devices, and use the\nchange\ncommand to swap out a device. Press\nCtrl+Alt+1\nto go back to the virtual machine.\nPre-made virtual machine images\nIn many cases, it is not necessary or desired to manually install your own operating system, for instance in a cloud environment. Luckily, many pre-made images are available for download from different providers.\nFor\nArch Linux\n, we have the\narch-boxes\nproject with\nweekly image releases\n.\nThere are similar images available for\nFedora\nand\nDebian\n.\nRunning a virtualized system\nqemu-system-*\nbinaries (for example\nqemu-system-i386\nor\nqemu-system-x86_64\n, depending on guest's architecture) are used to run the virtualized guest. The usage is:\n$ qemu-system-x86_64\noptions\ndisk_image\nOptions are the same for all\nqemu-system-*\nbinaries, see\nqemu(1)\nfor documentation of all options.\nUsually, if an option has many possible values, you can use\n$ qemu-system-x86_64\noption\nhelp\nto list all possible values. If it supports properties, you can use\n$ qemu-system-x86_64\noption\nvalue,help\nto list all available properties.\nFor example:\n$ qemu-system-x86_64 -machine help\n$ qemu-system-x86_64 -machine q35,help\n$ qemu-system-x86_64 -device help\n$ qemu-system-x86_64 -device qxl,help\nYou can use these methods and the\nqemu(1)\ndocumentation to understand the options used in the following sections.\nBy default, QEMU will show the virtual machine's video output in a window. One thing to keep in mind: when you click inside the QEMU window, the mouse pointer is grabbed. To release it, press\nCtrl+Alt+g\n.\nWarning\nQEMU should never be run as root. If you must launch it in a script as root, you should use the\n-runas\noption to make QEMU drop root privileges.\nEnabling KVM\nKVM (\nKernel-based Virtual Machine\n) full virtualization must be supported by your Linux kernel and your hardware, and necessary\nkernel modules\nmust be loaded. See\nKVM\nfor more information.\nTo start QEMU in KVM mode, append\n-accel kvm\nto the additional start options. To check if KVM is enabled for a running virtual machine, enter the\n#QEMU monitor\nand type\ninfo kvm\n.\nNote\nThe argument\naccel=kvm\nof the\n-machine\noption is equivalent to the\n-enable-kvm\nor the\n-accel kvm\noption.\nCPU model\nhost\nrequires KVM.\nIf you start your virtual machine with a GUI tool and experience very bad performance, you should check for proper KVM support, as QEMU may be falling back to software emulation.\nKVM needs to be enabled in order to start Windows 7 or Windows 8 properly without a\nblue screen\n.\nEnabling IOMMU (Intel VT-d/AMD-Vi) support\nFirst enable IOMMU, see\nPCI passthrough via OVMF#Setting up IOMMU\n.\nAdd\n-device intel-iommu\nto create the IOMMU device:\n$ qemu-system-x86_64\n-enable-kvm -machine q35 -device intel-iommu\n-cpu host ..\nNote\nOn Intel CPU based systems creating an IOMMU device in a QEMU guest with\n-device intel-iommu\nwill disable PCI passthrough with an error like:\nDevice at bus pcie.0 addr 09.0 requires iommu notifier which is currently not supported by intel-iommu emulation\nWhile adding the kernel parameter\nintel_iommu=on\nis still needed for remapping IO (e.g.\nPCI passthrough with vfio-pci\n),\n-device intel-iommu\nshould not be set if PCI passthrough is required.\nBooting in UEFI mode\nThe default firmware used by QEMU is\nSeaBIOS\n, which is a Legacy BIOS implementation. QEMU uses\n/usr/share/qemu/bios-256k.bin\n(provided by the\nseabios\npackage) as a default read-only (ROM) image. You can use the\n-bios\nargument to select another firmware file. However, UEFI requires writable memory to work properly, so you need to emulate\nPC System Flash\ninstead.\nOVMF\nis a TianoCore project to enable UEFI support for Virtual Machines. It can be\ninstalled\nwith the\nedk2-ovmf\npackage.\nThere are two ways to use OVMF as a firmware. The first is to copy\n/usr/share/edk2/x64/OVMF.4m.fd\n, make it writable and use as a pflash drive:\n-drive if=pflash,format=raw,file=\n/copy/of/OVMF.4m.fd\nAll changes to the UEFI settings will be saved directly to this file.\nAnother and more preferable way is to split OVMF into two files. The first one will be read-only and store the firmware executable, and the second one will be used as a writable variable store. The advantage is that you can use the firmware file directly without copying, so it will be updated automatically by\npacman\n.\nUse\n/usr/share/edk2/x64/OVMF_CODE.4m.fd\nas a first read-only pflash drive. Copy\n/usr/share/edk2/x64/OVMF_VARS.4m.fd\n, make it writable and use as a second writable pflash drive:\n-drive if=pflash,format=raw,readonly=on,file=/usr/share/edk2/x64/OVMF_CODE.4m.fd \\\n-drive if=pflash,format=raw,file=\n/copy/of/OVMF_VARS.4m.fd\nEnabling Secure Boot\nTo enable Secure Boot, you must use OVMF firmware files that have Secure Boot keys installed, which is not provided by the upstream project\n[1]\n.\nUnlike some other Linux distributions (e.g., Fedora), Arch Linux\ndoes not yet provide\nits own firmware files that are pre-enrolled with Secure Boot enabled:\nThis is still the case as of Nov. 10, 2025\nCheck\narchlinux/packaging/packages/edk2#1\nto track updates on this issue.\nAlthough the firmware file\n/usr/share/edk2/x64/OVMF_CODE.\nsecboot\n.4m.fd\nexists and appears to support Secure Boot, it does not. Using it will result in a non-bootable virtual system until you swap it with another firmware file (or your previous one) to make it bootable again.\nA simple workaround is to use Fedora's\nedk2-ovmf\npackage (which already comes with Secure Boot) by installing the AUR package\nedk2-ovmf-fedora\nAUR\n:\nOnce installed, all firmware files from this package are found at\n/usr/share/edk2/\novmf\n/\nEnsure to use the\nq35\nchipset machine type\nAfterward, use either\n/usr/share/edk2/\novmf\n/OVMF_CODE.secboot.\nfd\nor\n/usr/share/edk2/\novmf\n/OVMF_CODE_4M.secboot.\nqcow2\nas your firmware file\nAnd in case you need NVRAM (optional for Windows 10 & 11 machines), use\n/usr/share/edk2/ovmf/\nOVMF_VARS.secboot.fd\nor\n/usr/share/edk2/ovmf/\nOVMF_VARS_4M.secboot.qcow2\nas your template\nWith that, Secure Boot is now enabled on your VMs!\nAlternatively, you can provide your own OVMF files and manually enroll those with your own keys. See\nKVM#Secure Boot\non how to do this.\nTip\nA more cumbersome (although slightly more\nupstream-aligned\n) workaround to manually enroll keys in a vanilla OVMF_VARS file is described in\nthis forum post\n.\nTrusted Platform Module emulation\nQEMU can emulate\nTrusted Platform Module\n, which is required by some systems such as Windows 11 (which requires TPM 2.0).\nInstall\nthe\nswtpm\npackage, which provides a software TPM implementation. Create some directory for storing TPM data (\n/path/to/mytpm\nwill be used as an example). Run this command to start the emulator:\n$ swtpm socket --tpm2 --tpmstate dir=\n/path/to/mytpm\n--ctrl type=unixio,path=\n/path/to/mytpm/swtpm-sock\n/path/to/mytpm/swtpm-sock\nwill be created by\nswtpm\n: this is a UNIX socket to which QEMU will connect. You can put it in any directory.\nBy default,\nswtpm\nstarts a TPM version 1.2 emulator. The\n--tpm2\noption enables TPM 2.0 emulation.\nFinally, add the following options to QEMU:\n-chardev socket,id=chrtpm,path=\n/path/to/mytpm/swtpm-sock\n\\\n-tpmdev emulator,id=tpm0,chardev=chrtpm \\\n-device tpm-tis,tpmdev=tpm0\nand TPM will be available inside the virtual machine. After shutting down the virtual machine,\nswtpm\nwill be automatically terminated.\nSee\nthe QEMU documentation\nfor more information.\nIf guest OS still does not recognize the TPM device, try to adjust\nCPU Models and Topology\noptions. It might cause problem.\nCommunication between host and guest\nNetwork\nData can be shared between the host and guest OS using any network protocol that can transfer files, such as\nNFS\n,\nSMB\n,\nNBD\n, HTTP,\nFTP\n, or\nSSH\n, provided that you have set up the network appropriately and enabled the appropriate services.\nThe default SLIRP-based user-mode networking allows the guest to access the host OS at the IP address 10.0.2.2. Any servers that you are running on your host OS, such as a SSH server or SMB server, will be accessible at this IP address. So on the guests, you can mount directories exported on the host via\nSMB\nor\nNFS\n, or you can access the host's HTTP server, etc.\nIt will not be possible for the host OS to access servers running on the guest OS, but this can be done with other network configurations (see\n#Tap networking with QEMU\n).\nQEMU's port forwarding\nNote\nQEMU's port forwarding is IPv4-only. IPv6 port forwarding is not implemented and the last patches were proposed in 2018\n[2]\n. If you need full IPv6 support, check\n#passt\nQEMU can forward ports from the host to the guest to enable e.g. connecting from the host to an SSH server running on the guest.\nFor example, to bind port 60022 on the host with port 22 (SSH) on the guest, start QEMU with a command like:\n$ qemu-system-x86_64\ndisk_image\n-nic user,hostfwd=tcp::60022-:22\nMake sure the sshd is running on the guest and connect with:\n$ ssh\nguest-user\n@127.0.0.1 -p 60022\nYou can use\nSSHFS\nto mount the guest's file system at the host for shared read and write access.\nTo forward several ports, you just repeat the\nhostfwd\nin the\n-nic\nargument, e.g. for VNC's port:\n$ qemu-system-x86_64\ndisk_image\n-nic user,hostfwd=tcp::60022-:22,hostfwd=tcp::5900-:5900\nAccessing SSH via vsock\nA secure and convenient way to connect to the VM is to use SSH over\nvsock(7)\n. Your VM needs to be systemd-based for this to work out of the box.\nFirst, launch QEMU with a special device:\n-device vhost-vsock-pci,id=vhost-vsock-pci0,guest-cid=555\nThe\ncid\nneeds to be picked by the user to be a valid 32-bit number (see\nvsock(7)\n). When systemd detects the VM has been launched with a\nvhost-vsock\ndevice, it will automatically launch an SSH server via\nsystemd-ssh-generator\n.\nYou can then connect to the VM like this:\n$ ssh user@vsock/555\nThis works because of\n/etc/ssh/ssh_config.d/20-systemd-ssh-proxy.conf\nwhich tells your SSH client to use\nsystemd-ssh-proxy\nto allow SSH to use vsock.\nFurthermore, using\nsystemd.system-credentials(7)\nwe can inject an authorized keys file for the\nroot\nuser which is very convenient in case we are trying to run a downloaded image. This can be done like so:\n-smbios type=11,value=io.systemd.credential.binary:ssh.authorized_keys.root=c3NoLWVkMjU1MTkgQUFBQUMzTnphQzFsWkRJMU5URTVBQUFBSU9sVFE4ejlpeWxoMTMreCtFVFJ1R1JEaHpIVVRnaCt2ekJLOGY3TEl5eTQ=\nThe public key line has to be provided as a base64-encoded string. This can be done like so:\necho \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOlTQ8z9iylh13+x+ETRuGRDhzHUTgh+vzBK8f7LIyy4\" | base64\nThe same mechanism via\n-smbios type=11,value=io.systemd...\ncan be used to inject a variety of other magical variables that will get acted on by systemd. See also\nsystemd docs: System and Service Credentials\n.\nQEMU's built-in SMB server\nQEMU's documentation says it has a \"built-in\" SMB server, but actually it just starts up\nSamba\non the host with an automatically generated\nsmb.conf\nfile located in\n/tmp/qemu-smb.\nrandom_string\nand makes it accessible to the guest at a different IP address (10.0.2.4 by default). This only works for user networking, and is useful when you do not want to start the normal\nSamba\nservice on the host, which the guest can also access if you have set up shares on it.\nOnly a single directory can be set as shared with the option\nsmb=\n, but adding more directories (even while the virtual machine is running) could be as easy as creating symbolic links in the shared directory if QEMU configured SMB to follow symbolic links. It does not do so, but the configuration of the running SMB server can be changed as described below.\nSamba\nmust be installed on the host. To enable this feature, start QEMU with a command like:\n$ qemu-system-x86_64 -nic user,id=nic0,smb=\nshared_dir_path\ndisk_image\nwhere\nshared_dir_path\nis a directory that you want to share between the guest and host.\nThen, in the guest, you will be able to access the shared directory on the host 10.0.2.4 with the share name \"qemu\". For example, in Windows Explorer you would go to\n\\\\10.0.2.4\\qemu\n.\nNote\nIf you are using sharing options multiple times like\n-net user,smb=\nshared_dir_path1\n-net user,smb=\nshared_dir_path2\nor\n-net user,smb=\nshared_dir_path1\n,smb=\nshared_dir_path2\nthen it will share only the last defined one.\nIf you cannot access the shared folder and the guest system is Windows, check that the NetBIOS protocol is enabled and that a firewall does not block\nports\nused by the NetBIOS protocol.\nIf you cannot access the shared folder and the guest system is Windows 10 Enterprise or Education or Windows Server 2016,\nenable guest access\n.\nIf you use\n#Tap networking with QEMU\n, use\n-device virtio-net,netdev=vmnic -netdev user,id=vmnic,smb=\nshared_dir_path\nto get SMB.\nOne way to share multiple directories and to add or remove them while the virtual machine is running, is to share an empty directory and create/remove symbolic links to the directories in the shared directory. For this to work, the configuration of the running SMB server can be changed with the following script, which also allows the execution of files on the guest that are not set executable on the host:\n#!/bin/sh\neval $(ps h -C smbd -o pid,args | grep /tmp/qemu-smb | gawk '{print \"pid=\"$1\";conf=\"$6}')\necho \"[global]\nallow insecure wide links = yes\n[qemu]\nfollow symlinks = yes\nwide links = yes\nacl allow execute always = yes\" >> \"$conf\"\n# in case the change is not detected automatically:\nsmbcontrol --configfile=\"$conf\" \"$pid\" reload-config\nThis can be applied to the running server started by qemu only after the guest has connected to the network drive the first time. An alternative to this method is to add additional shares to the configuration file like so:\necho \"[\nmyshare\n]\npath=\nanother_path\nread only=no\nguest ok=yes\nforce user=\nusername\n\" >> $conf\nThis share will be available on the guest as\n\\\\10.0.2.4\\\nmyshare\n.\nHost file sharing with 9pfs VirtFS\nNote\n9pfs is fairly slow as it was not specifically developed for high-performance local VM usage. Users are advised to look into\n#Host file sharing with virtiofsd\ninstead which was specifically made with VM performance in mind.\nSee the\nQEMU documentation\n.\nHost file sharing with virtiofsd\nvirtiofsd\nis shipped with the\nvirtiofsd\npackage. It is a modern and high-performance way to conveniently share files between host and guest. See the\nonline documentation\nor\n/usr/share/doc/virtiofsd/README.md\nfor a full list of available options.\nYou can choose to either run virtiofsd as root or as a regular user.\nRunning virtiofsd as a regular user\nFirst, make sure that there is a\nsubuid(5)\nand\nsubgid(5)\nconfiguration entry for the user that will execute virtiofsd. See also the\nrelevant section in the Podman article\n.\nThen, start virtiofsd:\n$ unshare -r --map-auto -- /usr/lib/virtiofsd --socket-path=/tmp/vm-share.sock --shared-dir /tmp/vm-share --sandbox chroot\nunshare -r\ncauses the command after it to be launched in a new user namespace with the current user getting mapped to root in the new command. This is important because virtiofsd expects to be running as root from its point of view.\n/tmp/vm-share.sock\nis a socket file\n/tmp/vm-share\nis a shared directory between the host and the guest virtual machine\nRunning virtiofsd as root\nAdd the user that runs QEMU to the\nkvm\nuser group\n, because it needs to access the virtiofsd socket. You might have to logout for change to take effect.\nStart virtiofsd as root:\n# /usr/lib/virtiofsd --socket-path /tmp/vm-share.sock --socket-group kvm --shared-dir /tmp/vm-share\nwhere\n/tmp/vm-share.sock\nis a socket file\n/tmp/vm-share\nis a shared directory between the host and the guest virtual machine\nLaunching QEMU\nAdd the following configuration options when starting the virtual machine:\n-m 4G\n-object memory-backend-memfd,id=mem,size=4G,share=on\n-numa node,memdev=mem \\\n-chardev socket,id=char0,path=/tmp/vm-share.sock\n-device vhost-user-fs-pci,chardev=char0,tag=myfs\nwhere\nsize=4G\nmust match the size specified with\n-m 4G\noption\n/tmp/vm-share.sock\npoints to socket file started earlier\nmyfs\nis an identifier that you will use later in the guest to mount the share\nBoot rootfs directly\nYou may also boot a rootfs directly via virtiofsd. In addition to the above arguments, append:\n-kernel\n/path/to/vmlinux\n-initrd\n/path/to/initramfs\n-append 'rootfstype=virtiofs root=myfs rootflags=rw,noatime'\nUsing the share in a Linux guest\nOnce logged into the guest as root, you can simply mount the share on any modern distribution:\n# mount -t virtiofs myfs /mnt\nThis directory should now be shared between host and guest.\nUsing the share in a Windows guest\nSee\nrelevant Windows section\n.\nMounting a partition of the guest on the host\nIt can be useful to mount a drive image under the host system, it can be a way to transfer files in and out of the guest. This should be done when the virtual machine is not running.\nThe procedure to mount the drive on the host depends on the type of qemu image,\nraw\nor\nqcow2\n. We detail thereafter the steps to mount a drive in the two formats in\n#Mounting a partition from a raw image\nand\n#Mounting a partition from a qcow2 image\n. For the full documentation see\nWikibooks:QEMU/Images#Mounting an image on the host\n.\nWarning\nYou must unmount the partitions before running the virtual machine again. Otherwise, data corruption is very likely to occur.\nMounting a partition from a raw image\nIt is possible to mount partitions that are inside a raw disk image file by setting them up as loopback devices.\nWith manually specifying byte offset\nOne way to mount a disk image partition is to mount the disk image at a certain offset using a command like the following:\n# mount -o loop,offset=32256\ndisk_image\nmountpoint\nThe\noffset=32256\noption is actually passed to the\nlosetup\nprogram to set up a loopback device that starts at byte offset 32256 of the file and continues to the end. This loopback device is then mounted. You may also use the\nsizelimit\noption to specify the exact size of the partition, but this is usually unnecessary.\nDepending on your disk image, the needed partition may not start at offset 32256. Run\nfdisk -l\ndisk_image\nto see the partitions in the image. fdisk gives the start and end offsets in 512-byte sectors, so multiply by 512 to get the correct offset to pass to\nmount\n.\nWith loop module autodetecting partitions\nThe Linux loop driver actually supports partitions in loopback devices, but it is disabled by default. To enable it, do the following:\nGet rid of all your loopback devices (unmount all mounted images, etc.).\nUnload\nthe\nloop\nkernel module, and load it with the\nmax_part=15\nparameter set. Additionally, the maximum number of loop devices can be controlled with the\nmax_loop\nparameter.\nTip\nYou can put an entry in\n/etc/modprobe.d\nto load the loop module with\nmax_part=15\nevery time, or you can put\nloop.max_part=15\non the kernel command-line, depending on whether you have the\nloop.ko\nmodule built into your kernel or not.\nSet up your image as a loopback device:\n# losetup -f -P\ndisk_image\nThen, if the device created was\n/dev/loop0\n, additional devices\n/dev/loop0p\nX\nwill have been automatically created, where X is the number of the partition. These partition loopback devices can be mounted directly. For example:\n# mount /dev/loop0p1\nmountpoint\nTo mount the disk image with\nudisksctl\n, see\nUdisks#Mount loop devices\n.\nWith kpartx\nkpartx\nfrom the\nmultipath-tools\npackage can read a partition table on a device and create a new device for each partition. For example:\n# kpartx -a\ndisk_image\nThis will setup the loopback device and create the necessary partition(s) device(s) in\n/dev/mapper/\n.\nMounting a partition from a qcow2 image\nWe will use\nqemu-nbd\n, which lets us use the NBD (\nnetwork block device\n) protocol to share the disk image.\nFirst, we need the\nnbd\nmodule loaded:\n# modprobe nbd max_part=16\nThen, we can share the disk and create the device entries:\n# qemu-nbd -c /dev/nbd0\n/path/to/image.qcow2\nDiscover the partitions:\n# partprobe /dev/nbd0\nfdisk\ncan be used to get information regarding the different partitions in\nnbd0\n:\n# fdisk -l /dev/nbd0\nDisk /dev/nbd0: 25.2 GiB, 27074281472 bytes, 52879456 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0xa6a4d542\nDevice      Boot   Start      End  Sectors  Size Id Type\n/dev/nbd0p1 *       2048  1026047  1024000  500M  7 HPFS/NTFS/exFAT\n/dev/nbd0p2      1026048 52877311 51851264 24.7G  7 HPFS/NTFS/exFAT\nThen mount any partition of the drive image, for example the partition 2:\n# mount /dev/nbd0\np2\nmountpoint\nAfter the usage, it is important to unmount the image and reverse previous steps, i.e. unmount the partition and disconnect the nbd device:\n# umount\nmountpoint\n# qemu-nbd -d /dev/nbd0\nNetworking\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nNetwork topologies (sections\n#Host-only networking\n,\n#Internal networking\nand info spread out across other sections) should not be described alongside the various virtual interfaces implementations, such as\n#User-mode networking\n,\n#Tap networking with QEMU\n,\nQEMU/Advanced networking#Networking with VDE2\n. (Discuss in\nTalk:QEMU\n)\nThe performance of virtual networking should be better with tap devices and bridges than with user-mode networking or vde because tap devices and bridges are implemented in-kernel.\nIn addition, networking performance can be improved by assigning virtual machines a\nvirtio\nnetwork device rather than the default emulation of an e1000 NIC. See\n#Using virtio drivers\nfor more information.\nLink-level address caveat\nBy giving the\n-net nic\nargument to QEMU, it will, by default, assign a virtual machine a network interface with the link-level address\n52:54:00:12:34:56\n. However, when using bridged networking with multiple virtual machines, it is essential that each virtual machine has a unique link-level (MAC) address on the virtual machine side of the tap device. Otherwise, the bridge will not work correctly, because it will receive packets from multiple sources that have the same link-level address. This problem occurs even if the tap devices themselves have unique link-level addresses because the source link-level address is not rewritten as packets pass through the tap device.\nMake sure that each virtual machine has a unique link-level address, but it should always start with\n52:54:\n. Use the following option, replace\nX\nwith arbitrary hexadecimal digit:\n$ qemu-system-x86_64 -net nic,macaddr=52:54:\nXX:XX:XX:XX\n-net vde\ndisk_image\nGenerating unique link-level addresses can be done in several ways:\nManually specify unique link-level address for each NIC. The benefit is that the DHCP server will assign the same IP address each time the virtual machine is run, but it is unusable for large number of virtual machines.\nGenerate random link-level address each time the virtual machine is run. Practically zero probability of collisions, but the downside is that the DHCP server will assign a different IP address each time. You can use the following command in a script to generate random link-level address in a\nmacaddr\nvariable:\nprintf -v macaddr \"52:54:%02x:%02x:%02x:%02x\" $(( $RANDOM & 0xff)) $(( $RANDOM & 0xff )) $(( $RANDOM & 0xff)) $(( $RANDOM & 0xff ))\nqemu-system-x86_64 -net nic,macaddr=\"$macaddr\" -net vde\ndisk_image\nUse the following script\nqemu-mac-hasher.py\nto generate the link-level address from the virtual machine name using a hashing function. Given that the names of virtual machines are unique, this method combines the benefits of the aforementioned methods: it generates the same link-level address each time the script is run, yet it preserves the practically zero probability of collisions.\nqemu-mac-hasher.py\n#!/usr/bin/env python\n# usage: qemu-mac-hasher.py <VMName>\nimport sys\nimport zlib\ncrc = str(hex(zlib.crc32(sys.argv[1].encode(\"utf-8\")))).replace(\"x\", \"\")[-8:]\nprint(\"52:54:%s%s:%s%s:%s%s:%s%s\" % tuple(crc))\nIn a script, you can use for example:\nvm_name=\"\nVM Name\n\"\nqemu-system-x86_64 -name \"$vm_name\" -net nic,macaddr=$(qemu-mac-hasher.py \"$vm_name\") -net vde\ndisk_image\nUser-mode networking\nSLIRP\nBy default, without any\n-netdev\narguments, QEMU will use\nSLIRP-based\nuser-mode networking with a built-in DHCP server. Your virtual machines will be assigned an IP address when they run their DHCP client, and they will be able to access the physical host's network through IP masquerading done by QEMU.\nNote\nICMPv6 will not work, as support for it is not implemented:\nSlirp: external icmpv6 not supported yet\n.\nPinging\nan IPv6 address will not work.\nThis default configuration allows your virtual machines to easily access the Internet, provided that the host is connected to it, but the virtual machines will not be directly visible on the external network, nor will virtual machines be able to talk to each other if you start up more than one concurrently.\nQEMU's user-mode networking can offer more capabilities such as built-in TFTP or SMB servers, redirecting host ports to the guest (for example to allow SSH connections to the guest) or attaching guests to VLANs so that they can talk to each other. See the QEMU documentation on the\n-net user\nflag for more details.\nHowever, SLIRP-based user-mode networking has limitations in both utility and performance. More advanced network configurations require the use of tap devices or other methods.\nTip\nTo use the virtio driver with user-mode networking, the option is:\n-nic user,model=virtio-net-pci\n.\nYou can isolate user-mode networking from the host and the outside world by adding\nrestrict=y\n, for example:\n-net user,restrict=y\npasst\nUsers can choose to use\npasst-based\nuser-mode networking. passt has several advantages over SLIRP such as better performance, full IPv6 support (including ICMPv6), better security, and more control.\nTo get started, install\npasst\n. There are two ways to launch it: Either via socket-based communication or via shared vhost-user. The latter method has better performance.\nFor the socket-based way, first launch\npasst\n:\n$ passt -f\nThen, for your QEMU command, add these parameters:\n-device virtio-net-pci,netdev=s\n-netdev stream,id=s,server=off,addr.type=unix,addr.path=/tmp/passt_1.socket\nFor the vhost-user way, launch\npasst\nwith\n--vhost-user\n$ passt -f --vhost-user\nThen, for your QEMU command, add these parameters:\n-m 4G\n-chardev socket,id=chr0,path=/tmp/passt_1.socket\n-netdev vhost-user,id=netdev0,chardev=chr0\n-device virtio-net,netdev=netdev0\n-object memory-backend-memfd,id=memfd0,share=on,size=4G\n-numa node,memdev=memfd0\nNotice the memory sizes of\n-m 4G\nand\nsize=4G\nhave to match exactly.\nTap networking with QEMU\nTap devices\nare a Linux kernel feature that allows you to create virtual network interfaces that appear as real network interfaces. Packets sent to a tap interface are delivered to a userspace program, such as QEMU, that has bound itself to the interface.\nQEMU can use tap networking for a virtual machine so that packets sent to the tap interface will be sent to the virtual machine and appear as coming from a network interface (usually an Ethernet interface) in the virtual machine. Conversely, everything that the virtual machine sends through its network interface will appear on the tap interface.\nTap devices are supported by the Linux bridge drivers, so it is possible to bridge together tap devices with each other and possibly with other host interfaces such as\neth0\n. This is desirable if you want your virtual machines to be able to talk to each other, or if you want other machines on your LAN to be able to talk to the virtual machines.\nWarning\nIf you bridge together tap device and some host interface, such as\neth0\n, your virtual machines will appear directly on the external network, which will expose them to possible attack. Depending on what resources your virtual machines have access to, you may need to take all the\nprecautions\nyou normally would take in securing a computer to secure your virtual machines. If the risk is too great, virtual machines have little resources or you set up multiple virtual machines, a better solution might be to use\nhost-only networking\nand set up NAT. In this case you only need one firewall on the host instead of multiple firewalls for each guest.\nAs indicated in the user-mode networking section, tap devices offer higher networking performance than user-mode. If the guest OS supports virtio network driver, then the networking performance will be increased considerably as well. Supposing the use of the tap0 device, that the virtio driver is used on the guest, and that no scripts are used to help start/stop networking, next is part of the qemu command one should see:\n-device virtio-net,netdev=network0 -netdev tap,id=network0,ifname=tap0,script=no,downscript=no\nBut if already using a tap device with virtio networking driver, one can even boost the networking performance by enabling vhost, like:\n-device virtio-net,netdev=network0 -netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on\nSee\n[3]\nfor more information.\nHost-only networking\nIf the bridge is given an IP address and traffic destined for it is allowed, but no real interface (e.g.\neth0\n) is connected to the bridge, then the virtual machines will be able to talk to each other and the host system. However, they will not be able to talk to anything on the external network, provided that you do not set up IP masquerading on the physical host. This configuration is called\nhost-only networking\nby other virtualization software such as\nVirtualBox\n.\nTip\nIf you want to set up IP masquerading, e.g. NAT for virtual machines, see the\nInternet sharing#Enable NAT\npage.\nSee\nNetwork bridge\nfor information on creating bridge.\nYou may want to have a DHCP server running on the bridge interface to service the virtual network. For example, to use the\n172.20.0.1/16\nsubnet with\ndnsmasq\nas the DHCP server:\n# ip addr add 172.20.0.1/16 dev br0\n# ip link set br0 up\n# dnsmasq -C /dev/null --interface=br0 --bind-interfaces --dhcp-range=172.20.0.2,172.20.255.254\nInternal networking\nIf you do not give the bridge an IP address, then the virtual machines will be able to talk to each other, but not to the physical host or to the outside network. This configuration is called\ninternal networking\nby other virtualization software such as\nVirtualBox\n. You will need to either assign static IP addresses to the virtual machines or run a DHCP server on one of them.\nBridged networking using qemu-bridge-helper\nThis method does not require a start-up script and readily accommodates multiple taps and multiple bridges. It uses\n/usr/lib/qemu/qemu-bridge-helper\nbinary, which allows creating tap devices on an existing bridge.\nTip\nSee\nNetwork bridge\nfor information on creating bridge.\nSee\nhttps://wiki.qemu.org/Features/HelperNetworking\nfor more information on QEMU's network helper.\nFirst, create a configuration file containing the names of all bridges to be used by QEMU:\n/etc/qemu/bridge.conf\nallow\nbr0\nallow\nbr1\n...\nMake sure\n/etc/qemu/\nhas\n755\npermissions\n.\nQEMU issues\nand\nGNS3 issues\nmay arise if this is not the case.\nNow start the virtual machine; the most basic usage to run QEMU with the default network helper and default bridge\nbr0\n:\n$ qemu-system-x86_64 -nic bridge\n[...]\nUsing the bridge\nbr1\nand the virtio driver:\n$ qemu-system-x86_64 -nic bridge,br=\nbr1\n,model=virtio-net-pci\n[...]\nAdvanced network configuration\nIf you need more control over your virtual machine's networking or you have very specific needs that arent covered in the previous setctions, see\nQEMU/Advanced networking\n.\nShorthand configuration\nIf you are using QEMU with various networking options a lot, you probably have created a lot of\n-netdev\nand\n-device\nargument pairs, which gets quite repetitive. You can instead use the\n-nic\nargument to combine\n-netdev\nand\n-device\ntogether, so that, for example, these arguments:\n-netdev tap,id=network0,ifname=tap0,script=no,downscript=no,vhost=on -device virtio-net-pci,netdev=network0\nbecome:\n-nic tap,script=no,downscript=no,vhost=on,model=virtio-net-pci\nNotice the lack of network IDs, and that the device was created with\nmodel=\n. The first half of the\n-nic\nparameters are\n-netdev\nparameters, whereas the second half (after\nmodel=\n) are related with the device. The same parameters (for example,\nsmb=\n) are used. To completely disable the networking use\n-nic none\n.\nSee\nQEMU networking documentation\nfor more information on parameters you can use.\nGraphics card\nQEMU can emulate a standard graphics card text mode using\n-display curses\ncommand line option. This allows to type text and see text output directly inside a text terminal. Alternatively,\n-nographic\nserves a similar purpose.\nQEMU can emulate several types of VGA card. The card type is passed in the\n-vga\ntype\ncommand line option and can be\nstd\n,\nqxl\n,\nvmware\n,\nvirtio\n,\ncirrus\nor\nnone\n.\nstd\nWith\n-vga std\nyou can get a resolution of up to 2560 x 1600 pixels without requiring guest drivers. This is the default since QEMU 2.2.\nqxl\nQXL is a paravirtual graphics driver with 2D support. To use it, pass the\n-vga qxl\noption and install drivers in the guest. You may want to use\n#SPICE\nfor improved graphical performance when using QXL.\nOn Linux guests, the\nqxl\nand\nbochs_drm\nkernel modules must be loaded in order to gain a decent performance.\nDefault VGA memory size for QXL devices is 16M which is sufficient to drive resolutions approximately up to QHD (2560x1440). To enable higher resolutions,\nincrease vga_memmb\n.\nvmware\nAlthough it is a bit buggy, it performs better than std and cirrus. Install the VMware drivers\nxf86-video-vmware\nAUR\nand\nxf86-input-vmmouse\nfor Arch Linux guests.\nvirtio\nvirtio-vga\n/\nvirtio-gpu\nis a paravirtual 3D graphics driver based on\nvirgl\n. It's mature, currently supporting only Linux guests with\nmesa\ncompiled with the option\ngallium-drivers=virgl\n.\nTo enable 3D acceleration on the guest system, select this vga with\n-device virtio-vga-gl\nand enable the OpenGL context in the display device with\n-display sdl,gl=on\nor\n-display gtk,gl=on\nfor the SDL and GTK display output respectively. Successful configuration can be confirmed looking at the kernel log in the guest:\n# dmesg | grep drm\n[drm] pci: virtio-vga detected\n[drm] virgl 3d acceleration enabled\nTo enable\nVulkan\nsupport in the guest, use options like\n-device virtio-vga-gl,hostmem=2G,blob=true,venus=true\nand\ninstall\nthe\nvulkan-virtio\nin the guest system\n[4]\n.\ncirrus\nThe cirrus graphical adapter was the default\nbefore 2.2\n. It\nshould not\nbe used on modern systems.\nnone\nThis is like a PC that has no VGA card at all. You would not even be able to access it with the\n-vnc\noption. Also, this is different from the\n-nographic\noption which lets QEMU emulate a VGA card, but disables the SDL display.\nSPICE\nThe\nSPICE project\naims to provide a complete open source solution for remote access to virtual machines in a seamless way.\nEnabling SPICE support on the host\nThe following is an example of booting with SPICE as the remote desktop protocol, including the support for copy and paste from host:\n$ qemu-system-x86_64 -vga qxl -device virtio-serial-pci -spice port=5930,disable-ticketing=on -device virtserialport,chardev=spicechannel0,name=com.redhat.spice.0 -chardev spicevmc,id=spicechannel0,name=vdagent\nThe parameters have the following meaning:\n-device virtio-serial-pci\nadds a virtio-serial device\n-spice port=5930,disable-ticketing=on\nset TCP port\n5930\nfor spice channels listening and allow client to connect without authentication\nTip\nUsing\nUnix sockets\ninstead of TCP ports does not involve using network stack on the host system. It does not imply that packets are encapsulated and decapsulated to use the network and the related protocol. The sockets are identified solely by the inodes on the hard drive. It is therefore considered better for performance. Use instead\n-spice unix=on,addr=/tmp/vm_spice.socket,disable-ticketing=on\n.\n-device virtserialport,chardev=spicechannel0,name=com.redhat.spice.0\nopens a port for spice vdagent in the virtio-serial device,\n-chardev spicevmc,id=spicechannel0,name=vdagent\nadds a spicevmc chardev for that port. It is important that the\nchardev=\noption of the\nvirtserialport\ndevice matches the\nid=\noption given to the\nchardev\noption (\nspicechannel0\nin this example). It is also important that the port name is\ncom.redhat.spice.0\n, because that is the namespace where vdagent is looking for in the guest. And finally, specify\nname=vdagent\nso that spice knows what this channel is for.\nConnecting to the guest with a SPICE client\nA SPICE client is necessary to connect to the guest. In Arch, the following clients are available:\nvirt-viewer\n— SPICE client recommended by the protocol developers, a subset of the virt-manager project.\nhttps://virt-manager.org/\n||\nvirt-viewer\nspice-gtk\n— SPICE GTK client, a subset of the SPICE project. Embedded into other applications as a widget.\nhttps://www.spice-space.org/\n||\nspice-gtk\nFor clients that run on smartphone or on other platforms, refer to the\nOther clients\nsection in\nspice-space download\n.\nManually running a SPICE client\nOne way of connecting to a guest listening on Unix socket\n/tmp/vm_spice.socket\nis to manually run the SPICE client using\n$ remote-viewer spice+unix:///tmp/vm_spice.socket\nor\n$ spicy --uri=\"spice+unix:///tmp/vm_spice.socket\"\n, depending on the desired client. Since QEMU in SPICE mode acts similarly to a remote desktop server, it may be more convenient to run QEMU in daemon mode with the\n-daemonize\nparameter.\nTip\nTo connect to the guest through SSH tunneling, the following type of command can be used:\n$ ssh -fL 5999:localhost:5930\nmy.domain.org\nsleep 10; spicy -h 127.0.0.1 -p 5999\nThis example connects\nspicy\nto the local port\n5999\nwhich is forwarded through SSH to the guest's SPICE server located at the address\nmy.domain.org\n, port\n5930\n.\nNote the\n-f\noption that requests ssh to execute the command\nsleep 10\nin the background. This way, the ssh session runs while the client is active and auto-closes once the client ends.\nRunning a SPICE client with QEMU\nQEMU can automatically start a SPICE client with an appropriate socket, if the display is set to SPICE with the\n-display spice-app\nparameter. This will use the system's default SPICE client as the viewer, determined by your\nmimeapps.list\nfiles.\nEnabling SPICE support on the guest\nFor\nArch Linux guests\n, for improved support for multiple monitors or clipboard sharing, the following packages should be installed:\nspice-vdagent\n: Spice agent xorg client that enables copy and paste between client and X-session and more. (Refer to this\nissue\n, until fixed, for workarounds to get this to work on non-GNOME desktops.)\nxf86-video-qxl\n: Xorg X11 qxl video driver\nx-resize\nAUR\n: Desktop environments other than GNOME do not react automatically when the SPICE client window is resized. This package uses a\nudev\nrule and\nxrandr\nto implement auto-resizing for all X11-based desktop environments and window managers.\nFor guests under\nother operating systems\n, refer to the\nGuest\nsection in spice-space\ndownload\n.\nPassword authentication with SPICE\nIf you want to enable password authentication with SPICE you need to remove\ndisable-ticketing\nfrom the\n-spice\nargument and instead add\npassword=\nyourpassword\n. For example:\n$ qemu-system-x86_64 -vga qxl -spice port=5900,password=\nyourpassword\n-device virtio-serial-pci -device virtserialport,chardev=spicechannel0,name=com.redhat.spice.0 -chardev spicevmc,id=spicechannel0,name=vdagent\nYour SPICE client should now ask for the password to be able to connect to the SPICE server.\nTLS encrypted communication with SPICE\nYou can also configure TLS encryption for communicating with the SPICE server. First, you need to have a directory which contains the following files (the names must be exactly as indicated):\nca-cert.pem\n: the CA master certificate.\nserver-cert.pem\n: the server certificate signed with\nca-cert.pem\n.\nserver-key.pem\n: the server private key.\nAn example of generation of self-signed certificates with your own generated CA for your server is shown in the\nSpice User Manual\n.\nAfterwards, you can run QEMU with SPICE as explained above but using the following\n-spice\nargument:\n-spice tls-port=5901,password=\nyourpassword\n,x509-dir=\n/path/to/pki_certs\n, where\n/path/to/pki_certs\nis the directory path that contains the three needed files shown earlier.\nIt is now possible to connect to the server using\nvirt-viewer\n:\n$ remote-viewer spice://\nhostname\n?tls-port=5901 --spice-ca-file=\n/path/to/ca-cert.pem\n--spice-host-subject=\"C=\nXX\n,L=\ncity\n,O=\norganization\n,CN=\nhostname\n\" --spice-secure-channels=all\nKeep in mind that the\n--spice-host-subject\nparameter needs to be set according to your\nserver-cert.pem\nsubject. You also need to copy\nca-cert.pem\nto every client to verify the server certificate.\nTip\nYou can get the subject line of the server certificate in the correct format for\n--spice-host-subject\n(with entries separated by commas) using the following command:\n$ openssl x509 -noout -subject -in server-cert.pem | cut -d' ' -f2- | sed 's/\\///' | sed 's/\\//,/g'\nThe equivalent\nspice-gtk\ncommand is:\n$ spicy -h\nhostname\n-s 5901 --spice-ca-file=ca-cert.pem --spice-host-subject=\"C=\nXX\n,L=\ncity\n,O=\norganization\n,CN=\nhostname\n\" --spice-secure-channels=all\nVNC\nOne can add the\n-vnc :\nX\noption to have QEMU redirect the VGA display to the VNC session. Substitute\nX\nfor the number of the display (0 will then listen on 5900, 1 on 5901...).\n$ qemu-system-x86_64 -vnc :0\nAn example is also provided in the\n#Starting QEMU virtual machines on boot\nsection.\nWarning\nThe default VNC server setup does not use any form of authentication. Any user can connect from any host.\nBasic password authentication\nAn access password can be setup easily by using the\npassword\noption. The password must be indicated in the QEMU monitor and connection is only possible once the password is provided.\n$ qemu-system-x86_64 -vnc :0,password -monitor stdio\nIn the QEMU monitor, password is set using the command\nchange vnc password\nand then indicating the password.\nThe following command line directly runs vnc with a password:\n$ printf \"change vnc password\\n%s\\n\" MYPASSWORD | qemu-system-x86_64 -vnc :0,password -monitor stdio\nNote\nThe password is limited to 8 characters and can be guessed through brute force attack. More elaborated protection is strongly recommended for public network.\nAudio\nCreating an audio backend\nThe\n-audiodev\nflag sets the audio backend driver on the host and its options.\nTo list availabe audio backend drivers:\n$ qemu-system-x86_64 -audiodev help\nTheir optional settings are detailed in the\nqemu(1)\nman page.\nAt the bare minimum, one need to choose an audio backend and set an id, for\nPulseAudio\nfor example:\n-audiodev pa,id=snd0\nUsing the audio backend\nIntel HD Audio\nFor Intel HD Audio emulation, add both controller and codec devices. To list the available Intel HDA Audio devices:\n$ qemu-system-x86_64 -device help | grep hda\nAdd the audio controller:\n-device ich9-intel-hda\nAlso, add the audio codec and map it to a host audio backend id:\n-device hda-output,audiodev=snd0\nIntel 82801AA AC97\nFor AC97 emulation just add the audio card device and map it to a host audio backend id:\n-device AC97,audiodev=snd0\nNote\nIf the audiodev backend is not provided, QEMU looks up for it and adds it automatically, this only works for a single audiodev. For example\n-device intel-hda -device hda-duplex\nwill emulate\nintel-hda\non the guest using the default audiodev backend.\nVideo graphics card emulated drivers for the guest machine may also cause a problem with the sound quality. Test one by one to make it work. You can list possible options with\nqemu-system-x86_64 -h | grep vga\n.\nVirtIO sound\nVirtIO sound is also available since QEMU 8.2.0. The usage is:\n-device virtio-sound-pci,audiodev=my_audiodev -audiodev alsa,id=my_audiodev\nMore information can be found in\nQEMU documentation\n.\nUsing virtio drivers\nQEMU offers guests the ability to use paravirtualized block and network devices using the\nvirtio\ndrivers, which provide better performance and lower overhead.\nA virtio block device requires the option\n-drive\nfor passing a disk image, with parameter\nif=virtio\n:\n$ qemu-system-x86_64 -drive file=\ndisk_image\n,if=\nvirtio\nAlmost the same goes for the network:\n$ qemu-system-x86_64 -nic user,model=\nvirtio-net-pci\nNote\nThis will only work if the guest machine has drivers for virtio devices. Linux does, and the required drivers are included in Arch Linux, but there is no guarantee that virtio devices will work with other operating systems.\nPreparing an Arch Linux guest\nTo use virtio devices after an Arch Linux guest has been installed, the following modules must be loaded in the guest:\nvirtio\n,\nvirtio_pci\n,\nvirtio_blk\n,\nvirtio_net\n, and\nvirtio_ring\n. For 32-bit guests, the specific \"virtio\" module is not necessary.\nIf you want to boot from a virtio disk, the initial ramdisk must contain the necessary modules. By default, this is handled by\nmkinitcpio\n's\nautodetect\nhook. Otherwise use the\nMODULES\narray in\n/etc/mkinitcpio.conf\nto include the necessary modules and rebuild the initial ramdisk.\n/etc/mkinitcpio.conf\nMODULES=(virtio virtio_blk virtio_pci virtio_net)\nVirtio disks are recognized with the prefix\nv\n(e.g.\nv\nda\n,\nv\ndb\n, etc.); therefore, changes must be made in at least\n/etc/fstab\nand\n/boot/grub/grub.cfg\nwhen booting from a virtio disk.\nTip\nWhen referencing disks by\nUUID\nin both\n/etc/fstab\nand boot loader, nothing has to be done.\nFurther information on paravirtualization with KVM can be found\nhere\n.\nYou might also want to install\nqemu-guest-agent\nto implement support for QMP commands that will enhance the hypervisor management capabilities.\nMemory ballooning\nIn order to allow the guest's memory foot print to shrink as seen from the host, it needs to report to the host which pages are not needed anymore by the guest. The kernel has an API for that called\nFree Page Reporting\nand since it is built-in, it is as easy as starting QEMU like this:\n$ qemu-system-x86_64 ... -device virtio-balloon,free-page-reporting=on\nAfter this, you should see the guest memory increasing and then shrinking again after running workloads in it.\nHowever, while this parameter will indeed take care of shrinking the guest's memory usage from the host's perspective when pages are freed, it will not be able to automatically make use of memory that the guest is using for cache. This is an important consideration as a guest is likely to eventually use its entire unused memory for caching, making\nfree-page-reporting=on\nuseless. Read the next section to mitigate this problem.\nUsing virtio pmem to bypass the guest's page cache\nYou might want to rely on the host's page cache instead of the guest's in order to allow for more efficient memory usage. Coupled with\nKSM\n, this allows you to make your virtual machines quite memory efficient, duplicating only few pages.\nOne way to achieve this is to use a\nfile-mapped virtio pmem device\n. Add this config to your QEMU:\n-object memory-backend-file,id=mem1,share,mem-path=./virtio_pmem.img,size=32G\n-device virtio-pmem-pci,memdev=mem1,id=nv1\n-m 64G,maxmem=96G\nwhereby\nvirtio_pmem.img\nis a local file on the host that will serve as our memory backend in side the guest. The\n-m\npart is important here: Set the\nmaxmem\nparameter so that it is\nregular memory + memory-backend-file size\n. In this case:\n64G + 32G = 96G\n.\nStart the guest with those options. Inside the guest, you will find a new device at\n/dev/pmem0\nwhich we will need to format with a\nDAX-compatible filesystem\nsuch as ext4 (btrfs is not supported):\n# mkfs.ext4 /dev/pmem0\nmount /dev/pmem0 /mnt -o dax=always\nAny files you write into\n/mnt\nwill then bypass the guest's page cache.\nIt's also possible to have the whole root filesystem DAX-enabled in this way.\nPreparing a Windows guest\nVirtio drivers for Windows\nWindows does not come with the virtio drivers. The latest and stable versions of the drivers are regularly built by Fedora, details on downloading the drivers are given on\nvirtio-win on GitHub\n. In the following sections we will mostly use the stable ISO file provided here:\nvirtio-win.iso\n. Alternatively, use\nvirtio-win\nAUR\n.\nBlock device drivers\nNew Install of Windows\nThe drivers need to be loaded during installation, the procedure is to load the ISO image with the virtio drivers in a cdrom device along with the primary disk device and the Windows ISO install media:\n$ qemu-system-x86_64 ... \\\n-drive file=\ndisk_image\n,index=0,media=disk,if=virtio \\\n-drive file=\nwindows.iso\n,index=2,media=cdrom \\\n-drive file=\nvirtio-win.iso\n,index=3,media=cdrom \\\n...\nDuring the installation, at some stage, the Windows installer will ask \"Where do you want to install Windows?\", it will give a warning that no disks are found. Follow the example instructions below (based on Windows Server 2012 R2 with Update).\nSelect the option\nLoad Drivers\n.\nUncheck the box for\nHide drivers that are not compatible with this computer's hardware\n.\nClick the browse button and open the CDROM for the virtio iso, usually named \"virtio-win-XX\".\nNow browse to\nE:\\viostor\\[your-os]\\amd64\n, select it, and confirm.\nYou should now see your virtio disk(s) listed here, ready to be selected, formatted and installed to.\nChange existing Windows virtual machine to use virtio\nModifying an existing Windows guest for booting from virtio disk requires that the virtio driver is loaded by the guest at boot time.\nWe will therefore need to teach Windows to load the virtio driver at boot time before being able to boot a disk image in virtio mode.\nTo achieve that, first create a new disk image that will be attached in virtio mode and trigger the search for the driver:\n$ qemu-img create -f qcow2\ndummy.qcow2\n1G\nRun the original Windows guest with the boot disk still in IDE mode, the fake disk in virtio mode and the driver ISO image.\n$ qemu-system-x86_64 -m 4G -drive file=\ndisk_image\n,if=ide -drive file=\ndummy.qcow2\n,if=virtio -cdrom virtio-win.iso\nWindows will detect the fake disk and look for a suitable driver. If it fails, go to\nDevice Manager\n, locate the SCSI drive with an exclamation mark icon (should be open), click\nUpdate driver\nand select the virtual CD-ROM. Do not navigate to the driver folder within the CD-ROM, simply select the CD-ROM drive and Windows will find the appropriate driver automatically (tested for Windows 7 SP1).\nRequest Windows to boot in safe mode next time it starts up. This can be done using the\nmsconfig.exe\ntool in Windows. In safe mode all the drivers will be loaded at boot time including the new virtio driver. Once Windows knows that the virtio driver is required at boot it will memorize it for future boot.\nOnce instructed to boot in safe mode, you can turn off the virtual machine and launch it again, now with the boot disk attached in virtio mode:\n$ qemu-system-x86_64 -m 4G -drive file=\ndisk_image\n,if=virtio\nYou should boot in safe mode with virtio driver loaded, you can now return to\nmsconfig.exe\ndisable safe mode boot and restart Windows.\nNote\nIf you encounter the blue screen of death using the\nif=virtio\nparameter, it probably means the virtio disk driver is not installed or not loaded at boot time, reboot in safe mode and check your driver configuration.\nNetwork drivers\nUsing virtio network drivers is a bit easier, simply add the\n-nic\nargument.\n$ qemu-system-x86_64 -m 4G -drive file=\nwindows_disk_image\n,if=virtio -nic user,model=virtio-net-pci -cdrom virtio-win.iso\nWindows will detect the network adapter and try to find a driver for it. If it fails, go to the\nDevice Manager\n, locate the network adapter with an exclamation mark icon (should be open), click\nUpdate driver\nand select the virtual CD-ROM. Do not forget to select the checkbox which says to search for directories recursively.\nBalloon driver\nIf you want to track your guest memory state (for example via\nvirsh\ncommand\ndommemstat\n) or change guest's memory size in runtime (you still will not be able to change memory size, but can limit memory usage via inflating balloon driver) you will need to install guest balloon driver.\nFor this you will need to go to\nDevice Manager\n, locate\nPCI standard RAM Controller\nin\nSystem devices\n(or unrecognized PCI controller from\nOther devices\n) and choose\nUpdate driver\n. In opened window you will need to choose\nBrowse my computer...\nand select the CD-ROM (and do not forget the\nInclude subdirectories\ncheckbox). Reboot after installation. This will install the driver and you will be able to inflate the balloon (for example via hmp command\nballoon\nmemory_size\n, which will cause balloon to take as much memory as possible in order to shrink the guest's available memory size to\nmemory_size\n). However, you still will not be able to track guest memory state. In order to do this you will need to install\nBalloon\nservice properly. For that open command line as administrator, go to the CD-ROM,\nBalloon\ndirectory and deeper, depending on your system and architecture. Once you are in\namd64\n(\nx86\n) directory, run\nblnsrv.exe -i\nwhich will do the installation. After that\nvirsh\ncommand\ndommemstat\nshould be outputting all supported values.\nUsing a virtiofsd share\nBefore you progress in this section, make sure you followed the section about\nsetting up host file sharing with virtiofsd\nfirst.\nFirst, follow the\nupstream instructions\n. Once configured, Windows will have the\nZ:\ndrive mapped automatically with shared directory content.\nYour Windows 11 guest system is properly configured if it has:\nVirtioFSSService windows service,\nWinFsp.Launcher windows service,\nVirtIO FS Device driver under \"System devices\" in Windows \"Device Manager\".\nIf the above installed and\nZ:\ndrive is still not listed, try repairing \"Virtio-win-guest-tools\" in Windows\nAdd/Remove programs\n.\nPreparing a FreeBSD guest\nInstall the\nemulators/virtio-kmod\nport if you are using FreeBSD 8.3 or later up until 10.0-CURRENT where they are included into the kernel. After installation, add the following to your\n/boot/loader.conf\nfile:\nvirtio_load=\"YES\"\nvirtio_pci_load=\"YES\"\nvirtio_blk_load=\"YES\"\nif_vtnet_load=\"YES\"\nvirtio_balloon_load=\"YES\"\nThen modify your\n/etc/fstab\nby doing the following:\n# sed -ibak \"s/ada/vtbd/g\" /etc/fstab\nAnd verify that\n/etc/fstab\nis consistent. If anything goes wrong, just boot into a rescue CD and copy\n/etc/fstab.bak\nback to\n/etc/fstab\n.\nQEMU monitor\nWhile QEMU is running, a monitor console is provided in order to provide several ways to interact with the virtual machine running. The QEMU monitor offers interesting capabilities such as obtaining information about the current virtual machine, hotplugging devices, creating snapshots of the current state of the virtual machine, etc. To see the list of all commands, run\nhelp\nor\n?\nin the QEMU monitor console or review the relevant section of the\nofficial QEMU documentation\n.\nAccessing the monitor console\nGraphical view\nWhen using the\nstd\ndefault graphics option, one can access the QEMU monitor by pressing\nCtrl+Alt+2\nor by clicking\nView > compatmonitor0\nin the QEMU window. To return to the virtual machine graphical view either press\nCtrl+Alt+1\nor click\nView > VGA\n.\nHowever, the standard method of accessing the monitor is not always convenient and does not work in all graphic outputs QEMU supports.\nTelnet\nTo enable\ntelnet\n, run QEMU with the\n-monitor telnet:127.0.0.1:\nport\n,server,nowait\nparameter. When the virtual machine is started you will be able to access the monitor via telnet:\n$ telnet 127.0.0.1\nport\nNote\nIf\n127.0.0.1\nis specified as the IP to listen it will be only possible to connect to the monitor from the same host QEMU is running on. If connecting from remote hosts is desired, QEMU must be told to listen\n0.0.0.0\nas follows:\n-monitor telnet:0.0.0.0:\nport\n,server,nowait\n. Keep in mind that it is recommended to have a\nfirewall\nconfigured in this case or make sure your local network is completely trustworthy since this connection is completely unauthenticated and unencrypted.\nUNIX socket\nRun QEMU with the\n-monitor unix:\nsocketfile\n,server,nowait\nparameter. Then you can connect with either\nsocat\n,\nnmap\nor\nopenbsd-netcat\n.\nFor example, if QEMU is run via:\n$ qemu-system-x86_64 -monitor unix:/tmp/monitor.sock,server,nowait\n[...]\nIt is possible to connect to the monitor with:\n$ socat - UNIX-CONNECT:/tmp/monitor.sock\nOr with:\n$ nc -U /tmp/monitor.sock\nAlternatively with\nnmap\n:\n$ ncat -U /tmp/monitor.sock\nTCP\nYou can expose the monitor over TCP with the argument\n-monitor tcp:127.0.0.1:\nport\n,server,nowait\n. Then connect with\nopenbsd-netcat\nby running:\n$ nc 127.0.0.1\nport\nNote\nIn order to be able to connect to the tcp socket from other devices other than the same host QEMU is being run on you need to listen to\n0.0.0.0\nlike explained in the telnet case. The same security warnings apply in this case as well.\nStandard I/O\nIt is possible to access the monitor automatically from the same terminal QEMU is being run by running it with the argument\n-monitor stdio\n.\nSending keyboard presses to the virtual machine using the monitor console\nSome combinations of keys may be difficult to perform on virtual machines due to the host intercepting them instead in some configurations (a notable example is the\nCtrl+Alt+F*\nkey combinations, which change the active tty). To avoid this problem, the problematic combination of keys may be sent via the monitor console instead. Switch to the monitor and use the\nsendkey\ncommand to forward the necessary keypresses to the virtual machine. For example:\n(qemu) sendkey ctrl-alt-f2\nCreating and managing snapshots via the monitor console\nNote\nThis feature will\nonly\nwork when the virtual machine disk image is in\nqcow2\nformat. It will not work with\nraw\nimages.\nIt is sometimes desirable to save the current state of a virtual machine and having the possibility of reverting the state of the virtual machine to that of a previously saved snapshot at any time. The QEMU monitor console provides the user with the necessary utilities to create snapshots, manage them, and revert the machine state to a saved snapshot.\nUse\nsavevm\nname\nin order to create a snapshot with the tag\nname\n.\nUse\nloadvm\nname\nto revert the virtual machine to the state of the snapshot\nname\n.\nUse\ndelvm\nname\nto delete the snapshot tagged as\nname\n.\nUse\ninfo snapshots\nto see a list of saved snapshots. Snapshots are identified by both an auto-incremented ID number and a text tag (set by the user on snapshot creation).\nRunning the virtual machine in immutable mode\nIt is possible to run a virtual machine in a frozen state so that all changes will be discarded when the virtual machine is powered off just by running QEMU with the\n-snapshot\nparameter. When the disk image is written by the guest, changes will be saved in a temporary file in\n/tmp\nand will be discarded when QEMU halts.\nHowever, if a machine is running in frozen mode it is still possible to save the changes to the disk image if it is afterwards desired by using the monitor console and running the following command:\n(qemu) commit all\nIf snapshots are created when running in frozen mode they will be discarded as soon as QEMU is exited unless changes are explicitly commited to disk, as well.\nPause and power options via the monitor console\nSome operations of a physical machine can be emulated by QEMU using some monitor commands:\nsystem_powerdown\nwill send an ACPI shutdown request to the virtual machine. This effect is similar to the power button in a physical machine.\nsystem_reset\nwill reset the virtual machine similarly to a reset button in a physical machine. This operation can cause data loss and file system corruption since the virtual machine is not cleanly restarted.\nstop\nwill pause the virtual machine.\ncont\nwill resume a virtual machine previously paused.\nTaking screenshots of the virtual machine\nScreenshots of the virtual machine graphic display can be obtained in the PPM format by running the following command in the monitor console:\n(qemu) screendump\nfile.ppm\nQEMU machine protocol\nThe QEMU machine protocol (QMP) is a JSON-based protocol which allows applications to control a QEMU instance. Similarly to the\n#QEMU monitor\nit offers ways to interact with a running machine and the JSON protocol allows to do it programmatically. The description of all the QMP commands can be found in\nqmp-commands\n.\nStart QMP\nThe usual way to control the guest using the QMP protocol, is to open a TCP socket when launching the machine using the\n-qmp\noption. Here it is using for example the TCP port 4444:\n$ qemu-system-x86_64\n[...]\n-qmp tcp:localhost:4444,server,nowait\nThen one way to communicate with the QMP agent is to use\nnetcat\n:\nnc localhost 4444\n{\"QMP\": {\"version\": {\"qemu\": {\"micro\": 0, \"minor\": 1, \"major\": 3}, \"package\": \"\"}, \"capabilities\": []} }\nAt this stage, the only command that can be recognized is\nqmp_capabilities\n, so that QMP enters into command mode. Type:\n{\"execute\": \"qmp_capabilities\"}\nNow, QMP is ready to receive commands, to retrieve the list of recognized commands, use:\n{\"execute\": \"query-commands\"}\nLive merging of child image into parent image\nIt is possible to merge a running snapshot into its parent by issuing a\nblock-commit\ncommand. In its simplest form the following line will commit the child into its parent:\n{\"execute\": \"block-commit\", \"arguments\": {\"device\": \"\ndevicename\n\"}}\nUpon reception of this command, the handler looks for the base image and converts it from read only to read write mode and then runs the commit job.\nOnce the\nblock-commit\noperation has completed, the event\nBLOCK_JOB_READY\nwill be emitted, signalling that the synchronization has finished. The job can then be gracefully completed by issuing the command\nblock-job-complete\n:\n{\"execute\": \"block-job-complete\", \"arguments\": {\"device\": \"\ndevicename\n\"}}\nUntil such a command is issued, the\ncommit\noperation remains active.\nAfter successful completion, the base image remains in read write mode and becomes the new active layer. On the other hand, the child image becomes invalid and it is the responsibility of the user to clean it up.\nTip\nThe list of device and their names can be retrieved by executing the command\nquery-block\nand parsing the results. The device name is in the\ndevice\nfield, for example\nide0-hd0\nfor the hard disk in this example:\n{\"execute\": \"query-block\"}\n{\"return\": [{\"io-status\": \"ok\", \"device\": \"\nide0-hd0\n\", \"locked\": false, \"removable\": false, \"inserted\": {\"iops_rd\": 0, \"detect_zeroes\": \"off\", \"image\": {\"backing-image\": {\"virtual-size\": 27074281472, \"filename\": \"parent.qcow2\", ... }\nLive creation of a new snapshot\nTo create a new snapshot out of a running image, run the command:\n{\"execute\": \"blockdev-snapshot-sync\", \"arguments\": {\"device\": \"\ndevicename\n\",\"snapshot-file\": \"\nnew_snapshot_name\n.qcow2\"}}\nThis creates an overlay file named\nnew_snapshot_name\n.qcow2\nwhich then becomes the new active layer.\nTips and tricks\nImprove virtual machine performance\nThere are a number of techniques that you can use to improve the performance of the virtual machine. For example:\nApply\n#Enabling KVM\nfor full virtualization.\nUse the\n-cpu host\noption to make QEMU emulate the host's exact CPU rather than a more generic CPU.\nEspecially for Windows guests, enable\nHyper-V enlightenments\n:\n-cpu host,hv_relaxed,hv_spinlocks=0x1fff,hv_vapic,hv_time\n. See the\nQEMU documentation\nfor more information and flags.\nmultiple cores can be assigned to the guest using the\n-smp cores=x,threads=y,sockets=1,maxcpus=z\noption. The threads parameter is used to assign\nSMT cores\n. Leaving a physical core for QEMU, the hypervisor and the host system to operate unimpeded is highly beneficial.\nMake sure you have assigned the virtual machine enough memory. By default, QEMU only assigns 128 MiB of memory to each virtual machine. Use the\n-m\noption to assign more memory. For example,\n-m 1024\nruns a virtual machine with 1024 MiB of memory.\nIf supported by drivers in the guest operating system, use virtio for network and/or block devices, see\n#Using virtio drivers\n.\nUse TAP devices instead of user-mode networking, see\n#Tap networking with QEMU\n.\nIf the guest OS is doing heavy writing to its disk, you may benefit from certain mount options on the host's file system. For example, you can mount an\next4 file system\nwith the option\nbarrier=0\n. You should read the documentation for any options that you change because sometimes performance-enhancing options for file systems come at the cost of data integrity.\nIf you have a raw disk or partition, you may want to disable the cache:\n$ qemu-system-x86_64 -drive file=/dev/\ndisk\n,if=virtio,\ncache=none\nUse the native Linux AIO:\n$ qemu-system-x86_64 -drive file=\ndisk_image\n,if=virtio\n,aio=native,cache.direct=on\nIf you are running multiple virtual machines concurrently that all have the same operating system installed, you can save memory by enabling\nkernel same-page merging\n. See\n#Enabling KSM\n.\nIn some cases, memory can be reclaimed from running virtual machines by running a memory ballooning driver in the guest operating system. See\n#Memory ballooning\n.\nIt is possible to use a emulation layer for an ICH-9 AHCI controller (although it may be unstable). The AHCI emulation supports\nNCQ\n, so multiple read or write requests can be outstanding at the same time:\n$ qemu-system-x86_64 -drive id=disk,file=\ndisk_image\n,if=none -device ich9-ahci,id=ahci -device ide-drive,drive=disk,bus=ahci.0\nSee\nhttps://www.linux-kvm.org/page/Tuning_KVM\nfor more information.\nUsing any real partition as the single primary partition of a hard disk image\nSometimes, you may wish to use one of your system partitions from within QEMU. Using a raw partition for a virtual machine will improve performance, as the read and write operations do not go through the file system layer on the physical host. Such a partition also provides a way to share data between the host and guest.\nIn Arch Linux, device files for raw partitions are, by default, owned by\nroot\nand the\ndisk\ngroup. If you would like to have a non-root user be able to read and write to a raw partition, you must either change the owner of the partition's device file to that user, add that user to the\ndisk\ngroup, or use\nACL\nfor more fine-grained access control.\nWarning\nAlthough it is possible, it is not recommended to allow virtual machines to alter critical data on the host system, such as the root partition.\nYou must not mount a file system on a partition read-write on both the host and the guest at the same time. Otherwise, data corruption will result.\nAfter doing so, you can attach the partition to a QEMU virtual machine as a virtual disk.\nHowever, things are a little more complicated if you want to have the\nentire\nvirtual machine contained in a partition. In that case, there would be no disk image file to actually boot the virtual machine since you cannot install a boot loader to a partition that is itself formatted as a file system and not as a partitioned device with an MBR. Such a virtual machine can be booted either by:\n#Specifying kernel and initramfs manually\n,\n#Simulating a virtual disk with MBR\n,\n#Using the device-mapper\n,\n#Using a linear RAID\nor\n#Using a Network Block Device\n.\nSpecifying kernel and initramfs manually\nQEMU supports loading\nLinux kernels\nand\ninitial RAM file systems\ndirectly, thereby circumventing boot loaders such as\nGRUB\n. It then can be launched with the physical partition containing the root file system as the virtual disk, which will not appear to be partitioned. This is done by issuing a command similar to the following:\nNote\nIn this example, it is the\nhost's\nimages that are being used, not the guest's. If you wish to use the guest's images, either mount\n/dev/sda3\nread-only (to protect the file system from the host) and specify the\n/full/path/to/images\nor use some kexec hackery in the guest to reload the guest's kernel (extends boot time).\n$ qemu-system-x86_64 -kernel /boot/vmlinuz-linux -initrd /boot/initramfs-linux.img -append root=/dev/sda /dev/sda3\nIn the above example, the physical partition being used for the guest's root file system is\n/dev/sda3\non the host, but it shows up as\n/dev/sda\non the guest.\nYou may, of course, specify any kernel and initramfs that you want, and not just the ones that come with Arch Linux.\nWhen there are multiple\nkernel parameters\nto be passed to the\n-append\noption, they need to be quoted using single or double quotes. For example:\n... -append 'root=/dev/sda1 console=ttyS0'\nSimulating a virtual disk with MBR\nA more complicated way to have a virtual machine use a physical partition, while keeping that partition formatted as a file system and not just having the guest partition the partition as if it were a disk, is to simulate an MBR for it so that it can boot using a boot loader such as GRUB.\nFor the following, suppose you have a plain, unmounted\n/dev/hda\nN\npartition with some file system on it you wish to make part of a QEMU disk image. The trick is to dynamically prepend a master boot record (MBR) to the real partition you wish to embed in a QEMU raw disk image. More generally, the partition can be any part of a larger simulated disk, in particular a block device that simulates the original physical disk but only exposes\n/dev/hda\nN\nto the virtual machine.\nA virtual disk of this type can be represented by a VMDK file that contains references to (a copy of) the MBR and the partition, but QEMU does not support this VMDK format. For instance, a virtual disk\ncreated by\n$ VBoxManage internalcommands createrawvmdk -filename\n/path/to/file.vmdk\n-rawdisk /dev/hda\nwill be rejected by QEMU with the error message\nUnsupported image type 'partitionedDevice'\nNote that\nVBoxManage\ncreates two files,\nfile.vmdk\nand\nfile-pt.vmdk\n, the latter being a copy of the MBR, to which the text file\nfile.vmdk\npoints. Read operations outside the target partition or the MBR would give zeros, while written data would be discarded.\nUsing the device-mapper\nA method that is similar to the use of a VMDK descriptor file uses the\ndevice-mapper\nto prepend a loop device attached to the MBR file to the target partition. In case we do not need our virtual disk to have the same size as the original, we first create a file to hold the MBR:\n$ dd if=/dev/zero of=\n/path/to/mbr\ncount=2048\nHere, a 1 MiB (2048 * 512 bytes) file is created in accordance with partition alignment policies used by modern disk partitioning tools. For compatibility with older partitioning software, 63 sectors instead of 2048 might be required. The MBR only needs a single 512 bytes block, the additional free space can be used for a BIOS boot partition and, in the case of a hybrid partitioning scheme, for a GUID Partition Table. Then, we attach a loop device to the MBR file:\n# losetup --show -f\n/path/to/mbr\n/dev/loop0\nIn this example, the resulting device is\n/dev/loop0\n. The device mapper is now used to join the MBR and the partition:\n# echo \"0 2048 linear /dev/loop0 0\n2048 `blockdev --getsz /dev/hda\nN\n` linear /dev/hda\nN\n0\" | dmsetup create qemu\nThe resulting\n/dev/mapper/qemu\nis what we will use as a QEMU raw disk image. Additional steps are required to create a partition table (see the section that describes the use of a linear RAID for an example) and boot loader code on the virtual disk (which will be stored in\n/path/to/mbr\n).\nThe following setup is an example where the position of\n/dev/hda\nN\non the virtual disk is to be the same as on the physical disk and the rest of the disk is hidden, except for the MBR, which is provided as a copy:\n# dd if=/dev/hda count=1 of=\n/path/to/mbr\n# loop=`losetup --show -f\n/path/to/mbr\n`\n# start=`blockdev --report /dev/hda\nN\n| tail -1 | awk '{print $5}'`\n# size=`blockdev --getsz /dev/hda\nN\n`\n# disksize=`blockdev --getsz /dev/hda`\n# echo \"0 1 linear $loop 0\n1 $((start-1)) zero\n$start $size linear /dev/hda\nN\n0\n$((start+size)) $((disksize-start-size)) zero\" | dmsetup create qemu\nThe table provided as standard input to\ndmsetup\nhas a similar format as the table in a VMDK descriptor file produced by\nVBoxManage\nand can alternatively be loaded from a file with\ndmsetup create qemu --table\ntable_file\n. To the virtual machine, only\n/dev/hda\nN\nis accessible, while the rest of the hard disk reads as zeros and discards written data, except for the first sector. We can print the table for\n/dev/mapper/qemu\nwith\ndmsetup table qemu\n(use\nudevadm info -rq name /sys/dev/block/\nmajor\n:\nminor\nto translate\nmajor\n:\nminor\nto the corresponding\n/dev/\nblockdevice\nname). Use\ndmsetup remove qemu\nand\nlosetup -d $loop\nto delete the created devices.\nA situation where this example would be useful is an existing Windows XP installation in a multi-boot configuration and maybe a hybrid partitioning scheme (on the physical hardware, Windows XP could be the only operating system that uses the MBR partition table, while more modern operating systems installed on the same computer could use the GUID Partition Table). Windows XP supports hardware profiles, so that that the same installation can be used with different hardware configurations alternatingly (in this case bare metal vs. virtual) with Windows needing to install drivers for newly detected hardware only once for every profile. Note that in this example the boot loader code in the copied MBR needs to be updated to directly load Windows XP from\n/dev/hda\nN\ninstead of trying to start the multi-boot capable boot loader (like GRUB) present in the original system. Alternatively, a copy of the boot partition containing the boot loader installation can be included in the virtual disk the same way as the MBR.\nUsing a linear RAID\nYou can also do this using software\nRAID\nin linear mode (you need the\nlinear.ko\nkernel driver) and a loopback device:\nFirst, you create some small file to hold the MBR:\n$ dd if=/dev/zero of=\n/path/to/mbr\ncount=32\nHere, a 16 KiB (32 * 512 bytes) file is created. It is important not to make it too small (even if the MBR only needs a single 512 bytes block), since the smaller it will be, the smaller the chunk size of the software RAID device will have to be, which could have an impact on performance. Then, you setup a loopback device to the MBR file:\n# losetup -f\n/path/to/mbr\nLet us assume the resulting device is\n/dev/loop0\n, because we would not already have been using other loopbacks. Next step is to create the \"merged\" MBR +\n/dev/hda\nN\ndisk image using software RAID:\n# modprobe linear\n# mdadm --build --verbose /dev/md0 --chunk=16 --level=linear --raid-devices=2 /dev/loop0 /dev/hda\nN\nThe resulting\n/dev/md0\nis what you will use as a QEMU raw disk image (do not forget to set the permissions so that the emulator can access it). The last (and somewhat tricky) step is to set the disk configuration (disk geometry and partitions table) so that the primary partition start point in the MBR matches the one of\n/dev/hda\nN\ninside\n/dev/md0\n(an offset of exactly 16 * 512 = 16384 bytes in this example). Do this using\nfdisk\non the host machine, not in the emulator: the default raw disc detection routine from QEMU often results in non-kibibyte-roundable offsets (such as 31.5 KiB, as in the previous section) that cannot be managed by the software RAID code. Hence, from the host:\n# fdisk /dev/md0\nPress\nX\nto enter the expert menu. Set number of 's'ectors per track so that the size of one cylinder matches the size of your MBR file. For two heads and a sector size of 512, the number of sectors per track should be 16, so we get cylinders of size 2x16x512=16k.\nNow, press\nR\nto return to the main menu.\nPress\nP\nand check that the cylinder size is now 16k.\nNow, create a single primary partition corresponding to\n/dev/hda\nN\n. It should start at cylinder 2 and end at the end of the disk (note that the number of cylinders now differs from what it was when you entered fdisk.\nFinally, 'w'rite the result to the file: you are done. You now have a partition you can mount directly from your host, as well as part of a QEMU disk image:\n$ qemu-system-x86_64 -hdc /dev/md0\n[...]\nYou can, of course, safely set any boot loader on this disk image using QEMU, provided the original\n/dev/hda\nN\npartition contains the necessary tools.\nUsing a Network Block Device\nWith\nNetwork Block Device\n, Linux can use a remote server as one of its block device. You may use\nnbd-server\n(from the\nnbd\npackage) to create an MBR wrapper for QEMU.\nAssuming you have already set up your MBR wrapper file like above, rename it to\nwrapper.img.0\n. Then create a symbolic link named\nwrapper.img.1\nin the same directory, pointing to your partition. Then put the following script in the same directory:\n#!/bin/sh\ndir=\"$(realpath \"$(dirname \"$0\")\")\"\ncat >wrapper.conf <<EOF\n[generic]\nallowlist = true\nlistenaddr = 127.713705\nport = 10809\n[wrap]\nexportname = $dir/wrapper.img\nmultifile = true\nEOF\nnbd-server \\\n-C wrapper.conf \\\n-p wrapper.pid \\\n\"$@\"\nThe\n.0\nand\n.1\nsuffixes are essential; the rest can be changed. After running the above script (which you may need to do as root to make sure nbd-server is able to access the partition), you can launch QEMU with:\nqemu-system-x86_64 -drive file=nbd:127.713705:10809:exportname=wrap\n[...]\nStarting QEMU virtual machines on boot\nWith libvirt\nIf a virtual machine is set up with\nlibvirt\n, it can be configured with\nvirsh autostart\nor through the\nvirt-manager\nGUI to start at host boot by going to the Boot Options for the virtual machine and selecting \"Start virtual machine on host boot up\".\nWith systemd service\nTo run QEMU virtual machines on boot, you can use following systemd unit and config.\n/etc/systemd/system/qemu@.service\n[Unit]\nDescription=QEMU virtual machine\n[Service]\nEnvironment=\"haltcmd=kill -INT $MAINPID\"\nEnvironmentFile=/etc/conf.d/qemu.d/%i\nExecStart=/usr/bin/qemu-system-x86_64 -name %i -enable-kvm -m 512 -nographic $args\nExecStop=/usr/bin/bash -c ${haltcmd}\nExecStop=/usr/bin/bash -c 'while nc localhost 7100; do sleep 1; done'\n[Install]\nWantedBy=multi-user.target\nNote\nThis service will wait for the console port to be released, which means that the virtual machine has been shutdown, to graciously end.\nThen create per-VM configuration files, named\n/etc/conf.d/qemu.d/\nvm_name\n, with the variables\nargs\nand\nhaltcmd\nset. Example configs:\n/etc/conf.d/qemu.d/one\nargs=\"-hda /dev/vg0/vm1 -serial telnet:localhost:7000,server,nowait,nodelay \\\n-monitor telnet:localhost:7100,server,nowait,nodelay -vnc :0\"\nhaltcmd=\"echo 'system_powerdown' | nc localhost 7100\" # or netcat/ncat\n/etc/conf.d/qemu.d/two\nargs=\"-hda /srv/kvm/vm2 -serial telnet:localhost:7001,server,nowait,nodelay -vnc :1\"\nhaltcmd=\"ssh powermanager@vm2 sudo poweroff\"\nThe description of the variables is the following:\nargs\n- QEMU command line arguments to be used.\nhaltcmd\n- Command to shut down a virtual machine safely. In the first example, the QEMU monitor is exposed via telnet using\n-monitor telnet:..\nand the virtual machines are powered off via ACPI by sending\nsystem_powerdown\nto monitor with the\nnc\ncommand. In the other example, SSH is used.\nTo set which virtual machines will start on boot-up,\nenable\nthe\nqemu@\nvm_name\n.service\nsystemd unit.\nMouse integration\nTo prevent the mouse from being grabbed when clicking on the guest operating system's window, add the options\n-usb -device usb-tablet\n. This means QEMU is able to report the mouse position without having to grab the mouse. This also overrides PS/2 mouse emulation when activated. For example:\n$ qemu-system-x86_64 -hda\ndisk_image\n-m 512 -usb -device usb-tablet\nIf that does not work, try using\n-vga qxl\nparameter, also look at the instructions\nQEMU/Troubleshooting#Mouse cursor is jittery or erratic\n.\nPass-through host USB device\nIt is possible to access the physical device connected to a USB port of the host from the guest. The first step is to identify where the device is connected, this can be found running the\nlsusb\ncommand. For example:\n$ lsusb\n...\nBus\n003\nDevice\n007\n: ID\n0781\n:\n5406\nSanDisk Corp. Cruzer Micro U3\nThe outputs in bold above will be useful to identify respectively the\nhost_bus\nand\nhost_addr\nor the\nvendor_id\nand\nproduct_id\n.\nIn qemu, the idea is to emulate an EHCI (USB 2) or XHCI (USB 1.1   USB 2   USB 3) controller with the option\n-device usb-ehci,id=ehci\nor\n-device qemu-xhci,id=xhci\nrespectively and then attach the physical device to it with the option\n-device usb-host,..\n. We will consider that\ncontroller_id\nis either\nehci\nor\nxhci\nfor the rest of this section.\nThen, there are two ways to connect to the USB of the host with qemu:\nIdentify the device and connect to it on any bus and address it is attached to on the host, the generic syntax is:\n-device usb-host,bus=\ncontroller_id\n.0,vendorid=0x\nvendor_id\n,productid=0x\nproduct_id\nApplied to the device used in the example above, it becomes:\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,vendorid=0x\n0781\n,productid=0x\n5406\nOne can also add the\n...,port=\nport_number\nsetting to the previous option to specify in which physical port of the virtual controller the device should be attached, useful in the case one wants to add multiple USB devices to the virtual machine. Another option is to use the new\nhostdevice\nproperty of\nusb-host\nwhich is available since QEMU 5.1.0, the syntax is:\n-device qemu-xhci,id=xhci -device usb-host,hostdevice=/dev/bus/usb/003/007\nAttach whatever is connected to a given USB bus and address, the syntax is:\n-device usb-host,bus=\ncontroller_id\n.0,hostbus=\nhost_bus\n,host_addr=\nhost_addr\nApplied to the bus and the address in the example above, it becomes:\n-device usb-ehci,id=ehci -device usb-host,bus=ehci.0,hostbus=\n3\n,hostaddr=\n7\nSee\nQEMU/USB emulation\nfor more information.\nNote\nIf you encounter permission errors when running QEMU, see\nudev#Introduction to udev rules\nfor information on how to set permissions of the device.\nUSB redirection with SPICE\nWhen using\n#SPICE\nit is possible to redirect USB devices from the client to the virtual machine without needing to specify them in the QEMU command. It is possible to configure the number of USB slots available for redirected devices (the number of slots will determine the maximum number of devices which can be redirected simultaneously). The main advantages of using SPICE for redirection compared to the previously-mentioned\n-usbdevice\nmethod is the possibility of hot-swapping USB devices after the virtual machine has started, without needing to halt it in order to remove USB devices from the redirection or adding new ones. This method of USB redirection also allows us to redirect USB devices over the network, from the client to the server. In summary, it is the most flexible method of using USB devices in a QEMU virtual machine.\nWe need to add one EHCI/UHCI controller per available USB redirection slot desired as well as one SPICE redirection channel per slot. For example, adding the following arguments to the QEMU command you use for starting the virtual machine in SPICE mode will start the virtual machine with three available USB slots for redirection:\n-device ich9-usb-ehci1,id=usb \\\n-device ich9-usb-uhci1,masterbus=usb.0,firstport=0,multifunction=on \\\n-device ich9-usb-uhci2,masterbus=usb.0,firstport=2 \\\n-device ich9-usb-uhci3,masterbus=usb.0,firstport=4 \\\n-chardev spicevmc,name=usbredir,id=usbredirchardev1 -device usb-redir,chardev=usbredirchardev1,id=usbredirdev1 \\\n-chardev spicevmc,name=usbredir,id=usbredirchardev2 -device usb-redir,chardev=usbredirchardev2,id=usbredirdev2 \\\n-chardev spicevmc,name=usbredir,id=usbredirchardev3 -device usb-redir,chardev=usbredirchardev3,id=usbredirdev3\nSee\nSPICE/usbredir\nfor more information.\nBoth\nspicy\nfrom\nspice-gtk\n(\nInput > Select USB Devices for redirection\n) and\nremote-viewer\nfrom\nvirt-viewer\n(\nFile > USB device selection\n) support this feature. Please make sure that you have installed the necessary SPICE Guest Tools on the virtual machine for this functionality to work as expected (see the\n#SPICE\nsection for more information).\nWarning\nKeep in mind that when a USB device is redirected from the client, it will not be usable from the client operating system itself until the redirection is stopped. It is specially important to never redirect the input devices (namely mouse and keyboard), since it will be then difficult to access the SPICE client menus to revert the situation, because the client will not respond to the input devices after being redirected to the virtual machine.\nAutomatic USB forwarding with udev\nNormally, forwarded devices must be available at the boot time of the virtual machine to be forwarded. If that device is disconnected, it will not be forwarded anymore.\nYou can use\nudev rules\nto automatically attach a device when it comes online. Create a\nhostdev\nentry somewhere on disk.\nchown\nit to root to prevent other users modifying it.\n/usr/local/hostdev-mydevice.xml\n<hostdev mode='subsystem' type='usb'>\n<source>\n<vendor id='0x03f0'/>\n<product id='0x4217'/>\n</source>\n</hostdev>\nThen create a\nudev\nrule which will attach/detach the device:\n/usr/lib/udev/rules.d/90-libvirt-mydevice\nACTION==\"add\", \\\nSUBSYSTEM==\"usb\", \\\nENV{ID_VENDOR_ID}==\"03f0\", \\\nENV{ID_MODEL_ID}==\"4217\", \\\nRUN+=\"/usr/bin/virsh attach-device GUESTNAME /usr/local/hostdev-mydevice.xml\"\nACTION==\"remove\", \\\nSUBSYSTEM==\"usb\", \\\nENV{ID_VENDOR_ID}==\"03f0\", \\\nENV{ID_MODEL_ID}==\"4217\", \\\nRUN+=\"/usr/bin/virsh detach-device GUESTNAME /usr/local/hostdev-mydevice.xml\"\nSource and further reading\n.\nEnabling KSM\nKernel Samepage Merging (KSM) is a feature of the Linux kernel that allows for an application to register with the kernel to have its pages merged with other processes that also register to have their pages merged. The KSM mechanism allows for guest virtual machines to share pages with each other. In an environment where many of the guest operating systems are similar, this can result in significant memory savings.\nNote\nAlthough KSM may reduce memory usage, it may increase CPU usage. Also note some security issues may occur, see\nWikipedia:Kernel same-page merging\n.\nTo enable KSM:\n# echo 1 > /sys/kernel/mm/ksm/run\nTo make it permanent, use\nsystemd's temporary files\n:\n/etc/tmpfiles.d/ksm.conf\nw /sys/kernel/mm/ksm/run - - - - 1\nIf KSM is running, and there are pages to be merged (i.e. at least two similar virtual machines are running), then\n/sys/kernel/mm/ksm/pages_shared\nshould be non-zero. See\nhttps://docs.kernel.org/admin-guide/mm/ksm.html\nfor more information.\nTip\nAn easy way to see how well KSM is performing is to simply print the contents of all the files in that directory:\n$ grep -r . /sys/kernel/mm/ksm/\nMulti-monitor support\nThe Linux QXL driver supports four heads (virtual screens) by default. This can be changed via the\nqxl.heads=N\nkernel parameter.\nThe default VGA memory size for QXL devices is 16M (VRAM size is 64M). This is not sufficient if you would like to enable two 1920x1200 monitors since that requires 2 × 1920 × 4 (color depth) × 1200 = 17.6 MiB VGA memory. This can be changed by replacing\n-vga qxl\nby\n-vga none -device qxl-vga,vgamem_mb=32\n. If you ever increase vgamem_mb beyond 64M, then you also have to increase the\nvram_size_mb\noption.\nCustom display resolution\nA custom display resolution can be set with\n-device VGA,edid=on,xres=1280,yres=720\n(see\nEDID\nand\ndisplay resolution\n).\nCopy and paste\nSPICE\nOne way to share the clipboard between the host and the guest is to enable the SPICE remote desktop protocol and access the client with a SPICE client.\nOne needs to follow the steps described in\n#SPICE\n. A guest run this way will support copy paste with the host.\nqemu-vdagent\nQEMU provides its own implementation of the spice vdagent chardev called\nqemu-vdagent\n. It interfaces with the spice-vdagent guest service and allows the guest and host share a clipboard.\nTo access this shared clipboard with QEMU's GTK display, you will need to compile QEMU\nfrom source\nwith the\n--enable-gtk-clipboard\nconfigure parameter. It is sufficient to replace the installed\nqemu-ui-gtk\npackage.\nNote\nFeature request\nFS#79716\nsubmitted to enable the functionality in the official package.\nThe shared clipboard in qemu-ui-gtk has been pushed back to experimental as it can\nfreeze guests under certain circumstances\n. A fix has been proposed to solve the issue upstream.\nAdd the following QEMU command line arguments:\n-device virtio-serial,packed=on,ioeventfd=on\n-device virtserialport,name=com.redhat.spice.0,chardev=vdagent0\n-chardev qemu-vdagent,id=vdagent0,name=vdagent,clipboard=on,mouse=off\nThese arguments are also valid if converted to\nlibvirt form\n.\nNote\nWhile the spicevmc chardev will start the spice-vdagent service of the guest automatically, the qemu-vdagent chardev may not.\nOn linux guests, you may\nstart\nthe\nspice-vdagent.service\nuser unit\nmanually. On Windows guests, set the spice-agent startup type to automatic.\nWindows-specific notes\nQEMU can run any version of Windows from Windows 95 through Windows 11.\nIt is possible to run\nWindows PE\nin QEMU.\nFast startup\nNote\nAn administrator account is required to change power settings.\nFor Windows 8 (or later) guests it is better to disable \"Turn on fast startup (recommended)\" from the Power Options of the Control Panel as explained in the following\nforum page\n, as it causes the guest to hang during every other boot.\nFast Startup may also need to be disabled for changes to the\n-smp\noption to be properly applied.\nRemote Desktop Protocol\nIf you use a MS Windows guest, you might want to use RDP to connect to your guest virtual machine. If you are using a VLAN or are not in the same network as the guest, use:\n$ qemu-system-x86_64 -nographic -nic user,hostfwd=tcp::5555-:3389\nThen connect with either\nrdesktop\nor\nfreerdp\nto the guest. For example:\n$ xfreerdp -g 2048x1152 localhost:5555 -z -x lan\nTime standard\nBy default, Windows assumes the firmware clock is set to local time, but this is usually not the case when using QEMU.\nTo remedy this you can\nconfigure Windows to use UTC\nafter the installation, or you can set the virtual clock to localtime by adding\n-rtc base=localtime\nto your command line.\nClone Linux system installed on physical equipment\nLinux system installed on physical equipment can be cloned for running on a QEMU virtual machine. See\nClone Linux system from hardware for QEMU virtual machine\nChrooting into arm/arm64 environment from x86_64\nSometimes it is easier to work directly on a disk image instead of the real ARM based device. This can be achieved by mounting an SD card/storage containing the\nroot\npartition and chrooting into it.\nAnother use case for an ARM chroot is building ARM packages on an x86_64 machine. Here, the chroot environment can be created from an image tarball from\nArch Linux ARM\n- see\n[5]\nfor a detailed description of this approach.\nEither way, from the chroot it should be possible to run\npacman\nand install more packages, compile large libraries etc. Since the executables are for the ARM architecture, the translation to x86 needs to be performed by QEMU.\nInstall\nqemu-user-static\non the x86_64 machine/host, and\nqemu-user-static-binfmt\nto register the qemu binaries to binfmt service.\nqemu-user-static\nis used to allow the execution of compiled programs from other architectures. This is similar to what is provided by\nqemu-emulators-full\n, but the \"static\" variant is required for chroot. Examples:\nqemu-arm-static path_to_sdcard/usr/bin/ls\nqemu-aarch64-static path_to_sdcard/usr/bin/ls\nThese two lines execute the\nls\ncommand compiled for 32-bit ARM and 64-bit ARM respectively. Note that this will not work without chrooting, because it will look for libraries not present in the host system.\nqemu-user-static-binfmt\nallows automatically prefixing the ARM executable with\nqemu-arm-static\nor\nqemu-aarch64-static\n.\nMake sure that the ARM executable support is active:\n$ ls /proc/sys/fs/binfmt_misc\nqemu-aarch64  qemu-arm\t  qemu-cris  qemu-microblaze  qemu-mipsel  qemu-ppc64\t    qemu-riscv64  qemu-sh4    qemu-sparc\tqemu-sparc64  status\nqemu-alpha    qemu-armeb  qemu-m68k  qemu-mips\t      qemu-ppc\t   qemu-ppc64abi32  qemu-s390x\t  qemu-sh4eb  qemu-sparc32plus\tregister\nEach executable must be listed.\nIf it is not active,\nrestart\nsystemd-binfmt.service\n.\nMount the SD card to\n/mnt/sdcard\n(the device name may be different).\n# mount --mkdir /dev/mmcblk0p2 /mnt/sdcard\nMount boot partition if needed (again, use the suitable device name):\n# mount /dev/mmcblk0p1 /mnt/sdcard/boot\nFinally\nchroot\ninto the SD card root as described in\nChange root#Using chroot\n:\n# chroot /mnt/sdcard /bin/bash\nAlternatively, you can use\narch-chroot\nfrom\narch-install-scripts\n, as it will provide an easier way to get network support:\n# arch-chroot /mnt/sdcard /bin/bash\nYou can also use\nsystemd-nspawn\nto chroot into the ARM environment:\n# systemd-nspawn -D /mnt/sdcard -M myARMMachine --bind-ro=/etc/resolv.conf\n--bind-ro=/etc/resolv.conf\nis optional and gives a working network DNS inside the chroot\nsudo in chroot\nIf you install\nsudo\nin the chroot and receive the following error when trying to use it:\nsudo: effective uid is not 0, is /usr/bin/sudo on a file system with the 'nosuid' option set or an NFS file system without root privileges?\nthen you may need to modify the binfmt flags, for example for\naarch64\n:\n# cp /usr/lib/binfmt.d/qemu-aarch64-static.conf /etc/binfmt.d/\n# vi /etc/binfmt.d/qemu-aarch64-static.conf\nand add a\nC\nat the end of this file:\n:qemu-aarch64:M::\\x7fELF\\x02\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\xb7\\x00:\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff:/usr/bin/qemu-aarch64-static:FPC\nThen\nrestart\nsystemd-binfmt.service\nand check that the changes have taken effect (note the\nC\non the\nflags\nline):\n# cat /proc/sys/fs/binfmt_misc/qemu-aarch64\nenabled\ninterpreter /usr/bin/qemu-aarch64-static\nflags: POCF\noffset 0\nmagic 7f454c460201010000000000000000000200b700\nmask ffffffffffffff00fffffffffffffffffeffffff\nSee the \"flags\" section of the\nkernel binfmt documentation\nfor more information.\nNot grabbing mouse input\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nIt is not explained what the option actually does. Is it causing or avoiding the side effect? (Discuss in\nTalk:QEMU\n)\nTablet mode has side effect of not grabbing mouse input in QEMU window:\n-usb -device usb-tablet\nIt works with several\n-vga\nbackends one of which is virtio.\nTroubleshooting\nSee\nQEMU/Troubleshooting\n.\nSee also\nOfficial QEMU website\nOfficial KVM website\nQEMU Emulator User Documentation\nQEMU Wikibook\nHardware virtualization with QEMU\nby AlienBOB (last updated in 2008)\nBuilding a Virtual Army\nby Falconindy\nQEMU documentation\nQEMU on Windows\nWikipedia\nDebian Wiki - QEMU\nNetworking QEMU Virtual BSD Systems\nQEMU on gnu.org\nQEMU on FreeBSD as host\nManaging Virtual Machines with QEMU - openSUSE documentation\nKVM on IBM Knowledge Center\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=QEMU&oldid=853553\n\"\nCategories\n:\nEmulation\nHypervisors\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Style\nSearch\nSearch\nQEMU\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/QEMU"}}
{"text": "KVM - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nKVM\n4 languages\nEspañol\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nCategory:Hypervisors\nLibvirt\nKVM\n,\nKernel-based Virtual Machine\n, is a\nhypervisor\nbuilt into the Linux kernel. It is similar to\nXen\nin purpose but much simpler to get running. Unlike native\nQEMU\n, which uses emulation, KVM is a special operating mode of QEMU that uses CPU extensions (\nHVM\n) for virtualization via a kernel module.\nUsing KVM, one can run multiple virtual machines running unmodified GNU/Linux, Windows, or any other operating system. (See\nGuest Support Status\nfor more information.) Each virtual machine has private virtualized hardware: a network card, disk, graphics card, etc.\nDifferences between KVM and\nXen\n,\nVMware\n, or QEMU can be found at the\nKVM FAQ\n.\nThis article does not cover features common to multiple emulators using KVM as a backend. You should see related articles for such information.\nChecking support for KVM\nHardware support\nKVM requires that the virtual machine host's processor has virtualization support (named VT-x for Intel processors and AMD-V for AMD processors). You can check whether your processor supports hardware virtualization with the following command:\n$ LC_ALL=C.UTF-8 lscpu | grep Virtualization\nAlternatively:\n$ grep -E --color=auto 'vmx|svm|0xc0f' /proc/cpuinfo\nIf nothing is displayed after running either command, then your processor does\nnot\nsupport hardware virtualization, and you will\nnot\nbe able to use KVM.\nNote\nYou may need to enable virtualization support in your BIOS.  All x86_64 processors manufactured by AMD and Intel in the last 10 years support virtualization.  If it looks like your processor does not support virtualization, it is almost certainly turned off in the BIOS.\nKernel support\nArch Linux kernels provide the required\nkernel modules\nto support KVM.\nOne can check if the necessary modules,\nkvm\nand either\nkvm_amd\nor\nkvm_intel\n, are available in the kernel with the following command:\n$ zgrep CONFIG_KVM= /proc/config.gz\nThe module is available only if it is set to either\ny\nor\nm\n.\nThen, ensure that the kernel modules are automatically loaded, with the command:\n$ lsmod | grep kvm\nkvm_intel             245760  0\nkvmgt                  28672  0\nmdev                   20480  2 kvmgt,vfio_mdev\nvfio                   32768  3 kvmgt,vfio_mdev,vfio_iommu_type1\nkvm                   737280  2 kvmgt,kvm_intel\nirqbypass              16384  1 kvm\nIf the command returns nothing, the module needs to be loaded manually; see\nKernel modules#Manual module handling\n.\nTip\nIf modprobing\nkvm_intel\nor\nkvm_amd\nfails but modprobing\nkvm\nsucceeds, and\nlscpu\nclaims that hardware acceleration is supported, check the BIOS settings. Some vendors, especially laptop vendors, disable these processor extensions by default. To determine whether there is no hardware support or whether the extensions are disabled in BIOS, the output from\ndmesg\nafter having failed to modprobe will tell.\nPara-virtualization with Virtio\nPara-virtualization provides a fast and efficient means of communication for guests to use devices on the host machine. KVM provides para-virtualized devices to virtual machines using the\nVirtio\nAPI as a layer between the hypervisor and guest.\nAll Virtio devices have two parts: the host device and the guest driver.\nKernel support\nUse the following command\ninside the virtual machine\nto check if the VIRTIO modules are available in the kernel:\n$ zgrep VIRTIO /proc/config.gz\nThen, check if the kernel modules are automatically loaded with the command:\n$ lsmod | grep virtio\nIn case the above commands return nothing, you need to\nload the kernel modules\nmanually.\nList of para-virtualized devices\nnetwork device (virtio-net)\nblock device (virtio-blk)\ncontroller device (virtio-scsi)\nserial device (virtio-serial)\nballoon device (virtio-balloon)\nHow to use KVM\nSee the main article:\nQEMU\n.\nTips and tricks\nNote\nSee\nQEMU#Tips and tricks\nand\nQEMU/Troubleshooting\nfor general tips and tricks.\nNested virtualization\nNested virtualization enables existing virtual machines to be run on third-party hypervisors and on other clouds without any modifications to the original virtual machines or their networking.\nOn host, enable nested feature for\nkvm_intel\n:\nNote\nthe same can be done for AMD, just replace\nintel\nwith\namd\nwhere necessary\n# modprobe -r kvm_intel\n# modprobe kvm_intel nested=1\nTo make it permanent (see\nKernel modules#Setting module options\n):\n/etc/modprobe.d/kvm_intel.conf\noptions kvm_intel nested=1\nVerify that feature is activated:\n$ cat /sys/module/kvm_intel/parameters/nested\nY\nEnable the \"host passthrough\" mode to forward all CPU features to the guest system:\nIf using\nQEMU\n, run the guest virtual machine with the following command:\nqemu-system-x86_64 -enable-kvm -cpu host\n.\nIf using\nvirt-manager\n, change the CPU model to\nhost-passthrough\n.\nIf using\nvirsh\n, use\nvirsh edit\nvm-name\nand change the CPU line to\n<cpu mode='host-passthrough' check='partial'/>\nBoot the virtual machine and check if the\nvmx\nflag is present:\n$ grep -E --color=auto 'vmx|svm' /proc/cpuinfo\nEnabling huge pages\nThis article or section is a candidate for merging with\nQEMU\n.\nNotes:\nqemu-kvm no longer exists. After the above issue is cleared, I suggest merging this section into\nQEMU\n. (Discuss in\nTalk:KVM\n)\nYou may also want to enable hugepages to improve the performance of your virtual machine.\nWith an up to date Arch Linux and a running KVM, you probably already have everything you need. Check if you have the directory\n/dev/hugepages\n. If not, create it.\nNow we need the right permissions to use this directory. The default permission is root's uid and gid with 0755, but we want anyone in the kvm group to have access to hugepages.\nAdd to your\n/etc/fstab\n:\n/etc/fstab\nhugetlbfs       /dev/hugepages  hugetlbfs       mode=01770,gid=kvm        0 0\nInstead of specifying the group name directly, with\ngid=kvm\n, you can of course specify the gid as a number, but it must match the\nkvm\ngroup. The mode of\n1770\nallows anyone in the group to create files but not unlink or rename each other's files. Make sure\n/dev/hugepages\nis mounted properly:\n# umount /dev/hugepages\n# mount /dev/hugepages\n$ mount | grep huge\nhugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime,mode=1770,gid=78)\nNow you can calculate how many hugepages you need. Check how large your hugepages are:\n$ grep Hugepagesize /proc/meminfo\nNormally that should be 2048 kB ≙ 2 MB. Let us say you want to run your virtual machine with 1024 MB. 1024 / 2 = 512. Add a few extra so we can round this up to 550. Now tell your machine how many hugepages you want:\n# sysctl -w vm.nr_hugepages=550\nIf you had enough free memory, you should see:\n$ grep HugePages_Total /proc/meminfo\nHugesPages_Total:  550\nIf the number is smaller, close some applications or start your virtual machine with less memory (number_of_pages x 2):\n$ qemu-system-x86_64 -enable-kvm -m 1024 -mem-path /dev/hugepages -hda <disk_image> [...]\nNote the\n-mem-path\nparameter. This will make use of the hugepages.\nNow you can check, while your virtual machine is running, how many pages are used:\n$ grep HugePages /proc/meminfo\nHugePages_Total:     550\nHugePages_Free:       48\nHugePages_Rsvd:        6\nHugePages_Surp:        0\nNow that everything seems to work, you can enable hugepages by default if you like. Add to your\n/etc/sysctl.d/40-hugepage.conf\n:\n/etc/sysctl.d/40-hugepage.conf\nvm.nr_hugepages = 550\nSee also:\nSummary of hugetlbpage support in the Linux kernel\nDebian Wiki - Hugepages\nSecure Boot\nThis article or section is a candidate for merging with\nQEMU#Enabling Secure Boot\n.\nNotes:\nThis is not KVM-specific and would be a great addition to what is already described there. (Discuss in\nTalk:KVM\n)\nKVM Secure boot has a few requirements before it can be enabled:\nYou must use a UEFI with secure boot support compiled in.\nThe UEFI must have keys enrolled.\nNote\nArch Linux does not currently have a secure boot key unlike distributions like Fedora. If you intend to secure boot Arch Linux you must create your own signing key and sign your kernel after following the steps below. See\nUnified Extensible Firmware Interface/Secure Boot\nfor more information.\nTo enable UEFI with secure boot support, install\nedk2-ovmf\nand set your virtual machine to use the secure boot enabled UEFI. If you are using\nlibvirt\n, you can do this by adding the following to the XML configuration of your virtual machine.\n<os firmware=\"efi\">\n<loader readonly=\"yes\" secure=\"yes\" type=\"pflash\">/usr/share/edk2/x64/OVMF_CODE.secboot.4m.fd</loader>\n</os>\nNext you need to enroll some keys. In this example we will enroll Microsoft and Redhat's secure boot keys. Install\nvirt-firmware\nand run the following. Replace\nvm_name\nwith the name of your virtual machine.\n$ virt-fw-vars --input /usr/share/edk2/x64/OVMF_VARS.4m.fd --output /var/lib/libvirt/qemu/nvram/\nvm_name\n_SECURE_VARS.fd --secure-boot --enroll-redhat\nThen edit the libvirt XML configuration of your virtual machine to point to the new VARS file.\n<os firmware=\"efi\">\n<loader readonly=\"yes\" secure=\"yes\" type=\"pflash\">/usr/share/edk2/x64/OVMF_CODE.secboot.4m.fd</loader>\n<nvram template=\"/usr/share/edk2/x64/OVMF_VARS.4m.fd\">/var/lib/libvirt/qemu/nvram/\n{vm-name}\n_SECURE_VARS.fd</nvram>\n</os>\nAfter this secure boot should automatically be enabled. You can double check by entering the virtual machine's BIOS by pressing\nF2\nwhen you see the UEFI boot logo.\nSee also\nKVM Howto\nKVM FAQ\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=KVM&oldid=832342\n\"\nCategories\n:\nHypervisors\nKernel\nHidden category:\nPages or sections flagged with Template:Merge\nSearch\nSearch\nKVM\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/KVM"}}
{"text": "libvirt - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nlibvirt\n2 languages\n日本語\n中文（简体）\nFrom ArchWiki\nRelated articles\nCategory:Hypervisors\nPCI passthrough via OVMF\nLibvirt is a collection of software that provides a convenient way to manage virtual machines and other virtualization functionality, such as storage and network interface management. These software pieces include a long term stable C API, a daemon (libvirtd), and a command line utility (virsh). A primary goal of libvirt is to provide a single way to manage multiple different virtualization providers/hypervisors, such as the\nKVM/QEMU\n,\nXen\n,\nLXC\n,\nOpenVZ\nor\nVirtualBox\nhypervisors\n(\namong others\n).\nSome of the major libvirt features are:\nVirtual machine management\n: Various domain lifecycle operations such as start, stop, pause, save, restore, and migrate. Hotplug operations for many device types including disk and network interfaces, memory, and CPUs.\nRemote machine support\n: All libvirt functionality is accessible on any machine running the libvirt daemon, including remote machines. A variety of network transports are supported for connecting remotely, with the simplest being SSH, which requires no extra explicit configuration.\nStorage management\n: Any host running the libvirt daemon can be used to manage various types of storage: create file images of various formats (qcow2, vmdk, raw, ...), mount NFS shares, enumerate existing LVM volume groups, create new LVM volume groups and logical volumes, partition raw disk devices, mount iSCSI shares, and much more.\nNetwork interface management\n: Any host running the libvirt daemon can be used to manage physical and logical network interfaces. Enumerate existing interfaces, as well as configure (and create) interfaces, bridges, vlans, and bond devices.\nVirtual NAT and Route based networking\n: Any host running the libvirt daemon can manage and create virtual networks. Libvirt virtual networks use firewall rules to act as a router, providing virtual machines transparent access to the host machines network.\nInstallation\nBecause of its daemon/client architecture, libvirt needs only be installed on the machine which will host the virtualized system. Note that the server and client can be the same physical machine.\nServer\nInstall\nthe\nlibvirt\npackage, as well as at least one hypervisor:\nThe\nlibvirt KVM/QEMU driver\nis the primary\nlibvirt\ndriver and if\nKVM is enabled\n, fully virtualized, hardware accelerated guests will be available. See the\nQEMU\narticle for more information.\nOther\nsupported hypervisors\ninclude\nLXC\n,\nVirtualBox\nand\nXen\n. See the respective articles for installation instructions. With respect to\nlibvirtd\ninstallation note:\nThe\nlibvirt LXC driver\nhas no dependency on the\nLXC\nuserspace tools provided by\nlxc\n, therefore there is no need to install the package if planning on using the driver.\nlibvirtd\nneeds to be running to use\nlibvirt-lxc\nconnection.\nXen\nsupport is available, but not by default (\nFS#27356\n). You need to use the\nABS\nto modify\nlibvirt\n's\nPKGBUILD\nand build it without the\n-Ddriver_libxl=disabled\noption.\nFor network connectivity, install:\ndnsmasq\nfor the\ndefault\nNAT/DHCP networking.\nopenbsd-netcat\nfor remote management over\nSSH\n.\nOther optional dependencies may provide desired or extended features, such as\ndmidecode\nfor DMI system info support. Install the ones you may need\nas dependencies\nafter reading pacman's output for\nlibvirt\n.\nNote\nIf you are using\nfirewalld\n, as of\nlibvirt\n5.1.0 and\nfirewalld\n0.7.0 you no longer need to change the firewall backend to\niptables\n.\nlibvirt\nnow installs a zone called 'libvirt' in\nfirewalld\nand manages its required network rules there. See\nFirewall and network filtering in libvirt\n.\nClient\nThe client is the user interface that will be used to manage and access the virtual machines.\nvirsh\n— Command line program for managing and configuring domains.\nhttps://libvirt.org/\n||\nlibvirt\nBoxes\n— Simple GNOME application to access virtual systems. Part of\ngnome-extra\n.\nhttps://apps.gnome.org/Boxes/\n||\ngnome-boxes\nLibvirt Sandbox\n— Application sandbox toolkit.\nhttps://sandbox.libvirt.org/\n||\nlibvirt-sandbox\nAUR\nVirt Viewer\n— Simple remote display client.\nhttps://gitlab.com/virt-viewer/virt-viewer\n||\nvirt-viewer\nvirt-manager\n— Graphically manage KVM, Xen, or LXC via libvirt.\nhttps://virt-manager.org/\n||\nvirt-manager\nCockpit\n— Web-based system administration tool with plugin to manage virtual machines.\nhttps://cockpit-project.org/\n||\ncockpit-machines\nA list of libvirt-compatible software can be found\nhere\n.\nConfiguration\nLibvirt can manage QEMU virtual machines in two modes, system and session\n[1]\n[2]\n:\nsystem\nURIs connect to the libvirtd daemon running as root which is launched at system startup. Virtual machines created and run using 'system' are usually launched as root, unless configured otherwise (for example in\n/etc/libvirt/qemu.conf\n)\nsession\nURIs launch a libvirtd instance as your local user, and all virtual machines are run with local user permissions.\nRegarding their pros and cons:\nVirtual machine auto-starting on host boot only works for 'system', and the root libvirtd instance has necessary permissions to use proper networking via bridges or virtual networks.\nqemu:///system\nis generally what tools like virt-manager default to.\nqemu:///session\nhas a serious drawback: since the libvirtd instance does not have sufficient privileges, the only out of the box network option is qemu's usermode networking, which has non-obvious limitations, so its usage is discouraged (\nmore info on qemu networking options\n)\nThe benefit of\nqemu:///session\nis that permission issues vanish: disk images can easily be stored in $HOME, serial PTYs are owned by the user, etc.\nFor\nsystem\n-level administration (i.e. global settings and image-\nvolume\nlocation), libvirt minimally requires\nsetting up authorization\n, and\nstarting the daemon\n.\nFor user-\nsession\nadministration, daemon setup and configuration is\nnot\nrequired; however, authorization is limited to local abilities; the front-end will launch a local instance of the\nlibvirtd\ndaemon.\nSet up authentication\nFrom\nlibvirt: Connection authentication\n:\nThe libvirt daemon allows the administrator to choose the authentication mechanisms used for client connections on each network socket independently. This is primarily controlled via the libvirt daemon master config file in\n/etc/libvirt/libvirtd.conf\n. Each of the libvirt sockets can have its authentication mechanism configured independently. There is currently a choice of\nnone\n,\npolkit\nand\nsasl\n.\nUsing libvirt group\nThe easiest way to ensure your user has access to libvirt daemon is to add member to\nlibvirt\nuser group\n.\nMembers of the\nlibvirt\ngroup have password-less access to the RW daemon socket by default.\nUsing polkit\nBecause\nlibvirt\npulls\npolkit\nas a dependency during installation,\npolkit\nis used as the default value for the\nunix_sock_auth\nparameter (\nsource\n).\nFile-based permissions\nremain nevertheless available.\nNote\nA system reboot may be required before authenticating with\npolkit\nworks correctly.\nThe\nlibvirt\ndaemon provides two\npolkit actions\nin\n/usr/share/polkit-1/actions/org.libvirt.unix.policy\n:\norg.libvirt.unix.manage\nfor full management access (RW daemon socket), and\norg.libvirt.unix.monitor\nfor monitoring only access (read-only socket).\nThe default policy for the RW daemon socket will require to authenticate as an admin. This is akin to\nsudo\nauth, but does not require that the client application ultimately run as root. Default policy will still allow any application to connect to the RO socket.\nArch defaults to consider anybody in the\nwheel\ngroup as an administrator: this is defined in\n/usr/share/polkit-1/rules.d/50-default.rules\n(see\nPolkit#Administrator identities\n). Therefore there is no need to create a new group and rule file\nif your user is a member of the\nwheel\ngroup\n: upon connection to the RW socket (e.g. via\nvirt-manager\n) you will be prompted for your user's password.\nNote\nPrompting for a password relies on the presence of an\nauthentication agent\non the system. Console users may face an issue with the default\npkttyagent\nagent which may or may not work properly.\nTip\nIf you want to configure password-less authentication, see\nPolkit#Bypass password prompt\n.\nYou may change the group authorized to access the RW daemon socket. As an example, to authorize the\nmykvm\ngroup, create the following file:\n/etc/polkit-1/rules.d/50-libvirt.rules\n/* Allow users in mykvm group to manage the libvirt\ndaemon without authentication */\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.libvirt.unix.manage\" &&\nsubject.isInGroup(\"mykvm\")) {\nreturn polkit.Result.YES;\n}\n});\nThen\nadd yourself\nto the\nmykvm\ngroup and relogin. Replace\nmykvm\nwith any group of your preference just make sure it exists and that your user is a member of it (see\nUsers and groups\nfor more information).\nDo not forget to relogin for group changes to take effect.\nAuthenticate with file-based permissions\nTo define file-based permissions for users in the\nlibvirt\ngroup to manage virtual machines, uncomment and define:\n/etc/libvirt/libvirtd.conf\n#unix_sock_group = \"libvirt\"\n#unix_sock_ro_perms = \"0777\"  # set to 0770 to deny non-group libvirt users\n#unix_sock_rw_perms = \"0770\"\n#auth_unix_ro = \"none\"\n#auth_unix_rw = \"none\"\nWhile some guides mention changed permissions of certain libvirt directories to ease management, keep in mind permissions are lost on package update. To edit these system directories, root user is expected.\nDaemon\nNote\nLibvirt is moving from a single monolithic daemon to separate modular daemons, with the intention to remove the monolithic daemon in the future. See\nLibvirt daemons\nfor more information.\nStart\nboth\nlibvirtd.service\nand\nvirtlogd.service\n. Optionally\nenable\nlibvirtd.service\n(which will also enable\nvirtlogd.socket\nand\nvirtlockd.socket\nunits\n, so there is NO need to also enable\nvirtlogd.service\n).\nAnother possibility is to only\nstart/enable\nlibvirtd.socket\nand\nvirtlogd.socket\nfor on-demand socket activation.\nUnencrypt TCP/IP sockets\nWarning\nThis method is used to help remote domain, connection speed for trusted networks.  This is the least secure connection method.  This should\nonly\nbe used for testing or use over a secure, private, and trusted network. SASL is not enabled here, so all TCP traffic is\ncleartext\n. For real world use\nalways\nenable SASL.\nEdit\n/etc/libvirt/libvirtd.conf\n:\n/etc/libvirt/libvirtd.conf\nlisten_tls = 0\nlisten_tcp = 1\nauth_tcp=\"none\"\nIt is also necessary to start the server in listening mode by editing\n/etc/conf.d/libvirtd\n:\n/etc/conf.d/libvirtd\nLIBVIRTD_ARGS=\"--listen\"\nAccess virtual machines using their hostnames\nFor host access to guests on non-isolated, bridged networks, enable the\nlibvirt\nand/or\nlibvirt_guest\nNSS modules provided by\nlibvirt\n. For the comparison of the two modules and technical details, see\nlibvirt documentation\n.\nAdd desired modules in\nnsswitch.conf(5)\n:\n/etc/nsswitch.conf\nhosts: files\nlibvirt libvirt_guest\ndns myhostname\nNote\nWhile commands such as\nping\nand\nssh\nshould work with virtual machine hostnames, commands such as\nhost\nand\nnslookup\nmay fail or produce unexpected results because they rely on DNS. Use\ngetent hosts\nvm-hostname\ninstead.\nTest\nTo test if libvirt is working properly on a\nsystem\nlevel:\n$ virsh -c qemu:///system\nTo test if libvirt is working properly for a user-\nsession\n:\n$ virsh -c qemu:///session\nManagement\nLibvirt management is done mostly with three tools:\nvirt-manager\n(GUI),\nvirsh\n, and\nguestfish\n(which is part of\nlibguestfs\n).\nTip\nTo specify a default hypervisor connection, set its URI in the\nLIBVIRT_DEFAULT_URI\nenvironment variable\n[3]\n. By default, libvirt uses\nqemu:///session\nfor regular users and\nqemu:///system\nfor root.\nvirsh\nThe\nvirsh\nprogram is for managing guest\ndomains\n(virtual machines) and works well for scripting, virtualization administration.  Though most virsh commands require root privileges to run due to the communication channels used to talk to the hypervisor, typical management, creation, and running of domains (like that done with VirtualBox) can be done as a regular user.\nThe\nvirsh\nprogram includes an interactive terminal that can be entered if no commands are passed (options are allowed though):\nvirsh\n.  The interactive terminal has support for tab completion.\nFrom the command line:\n$ virsh [option] <command> [argument]...\nFrom the interactive terminal:\nvirsh # <command> [argument]...\nHelp is available:\n$ virsh help [option*] or [group-keyword*]\nStorage pools\nA pool is a location where storage\nvolumes\ncan be kept.  What libvirt defines as\nvolumes\nothers may define as \"virtual disks\" or \"virtual machine images\".  Pool locations may be a directory, a network filesystem, or partition (this includes a\nLVM\n).  Pools can be toggled active or inactive and allocated for space.\nOn the\nsystem\n-level,\n/var/lib/libvirt/images/\nwill be activated by default; on a user-\nsession\n,\nvirt-manager\ncreates\n$XDG_DATA_HOME/images\n.\nPrint active and inactive storage pools:\n$ virsh pool-list --all\nCreate a new pool using virsh\nIf one wanted to\nadd\na storage pool, here are examples of the command form, adding a directory, and adding a LVM volume:\n$ virsh pool-define-as name type [source-host] [source-path] [source-dev] [source-name] [<target>] [--source-format format]\n$ virsh pool-define-as\npoolname\ndir - - - - /home/\nusername\n/.local/libvirt/images\n$ virsh pool-define-as\npoolname\nfs - -\n/dev/vg0/images\n-\nmntpoint\nThe above command defines the information for the pool, to build it:\n$ virsh pool-build\npoolname\n$ virsh pool-start\npoolname\n$ virsh pool-autostart\npoolname\nTo remove it:\n$ virsh pool-undefine\npoolname\nTip\nFor LVM storage pools:\nIt is a good practice to dedicate a volume group to the storage pool only.\nChoose a LVM volume group that differs from the pool name, otherwise when the storage pool is deleted the LVM group will be too.\nCreate a new pool using virt-manager\nFirst, connect to a hypervisor (e.g. QEMU/KVM\nsystem\n, or user-\nsession\n).  Then, right-click on a connection and select\nDetails\n; select the\nStorage\ntab, push the\n+\nbutton on the lower-left, and follow the wizard.\nStorage volumes\nOnce the pool has been created, volumes can be created inside the pool.\nIf building a new domain (virtual machine), this step can be skipped as a volume can be created in the domain creation process.\nCreate a new volume with virsh\nCreate volume, list volumes, resize, and delete:\n$ virsh vol-create-as\npoolname\nvolumename\n10GiB --format aw|bochs|raw|qcow|qcow2|vmdk\n$ virsh vol-upload  --pool\npoolname\nvolumename\nvolumepath\n$ virsh vol-list\npoolname\n$ virsh vol-resize  --pool\npoolname\nvolumename\n12GiB\n$ virsh vol-delete  --pool\npoolname\nvolumename\n$ virsh vol-dumpxml --pool\npoolname\nvolumename\n# for details.\nDomains\nVirtual machines are called\ndomains\n.  If working from the command line, use\nvirsh\nto list, create, pause, shutdown domains, etc.\nvirt-viewer\ncan be used to view domains started with\nvirsh\n.  Creation of domains is typically done either graphically with\nvirt-manager\nor with\nvirt-install\n(a command line program installed as part of the\nvirt-install\npackage).\nCreating a new domain typically involves using some installation media, such as an\n.iso\nfrom the storage pool or an optical drive.\nPrint active and inactive domains:\n# virsh list --all\nNote\nSELinux\nhas a built-in exemption for libvirt that allows volumes in\n/var/lib/libvirt/images/\nto be accessed.  If using SELinux and there are issues with the volumes, ensure that volumes are in that directory, or ensure that other storage pools are correctly labeled.\nCreate a new domain using virt-install\nThe factual accuracy of this article or section is disputed.\nReason:\n/usr/share/libosinfo\nis not provided by any official packages, including\nlibosinfo\n. (Discuss in\nTalk:Libvirt#Where_is_'/usr/share/libosinfo/db/oses/os.xml'？\n)\nFor an extremely detailed domain (virtual machine) setup, it is easier to\n#Create a new domain using virt-manager\n.  However, basics can easily be done with\nvirt-install\nand still run quite well.  Minimum specifications are\n--name\n,\n--memory\n, guest storage (\n--disk\n,\n--filesystem\n, or\n--nodisks\n), and an install method (generally an\n.iso\nor CD). See\nvirt-install(1)\nfor more details and information about unlisted options.\nArch Linux install (two GiB, qcow2 format volume create; user-networking):\n$ virt-install  \\\n--name arch-linux_testing \\\n--memory 1024             \\\n--vcpus=2,maxvcpus=4      \\\n--cpu host                \\\n--cdrom $HOME/Downloads/arch-linux_install.iso \\\n--disk size=2,format=qcow2  \\\n--network user            \\\n--virt-type kvm\nFedora testing (Xen hypervisor, non-default pool, do not originally view):\n$ virt-install  \\\n--connect xen:///     \\\n--name fedora-testing \\\n--memory 2048         \\\n--vcpus=2             \\\n--cpu=host            \\\n--cdrom /tmp/fedora20_x84-64.iso      \\\n--os-type=linux --os-variant=fedora20 \\\n--disk pool=testing,size=4            \\\n--network bridge=br0                  \\\n--graphics=vnc                        \\\n--noautoconsole\n$ virt-viewer --connect xen:/// fedora-testing\nWindows:\n$ virt-install \\\n--name=windows7           \\\n--memory 2048             \\\n--cdrom /dev/sr0          \\\n--os-variant=win7         \\\n--disk /mnt/storage/domains/windows7.qcow2,size=20GiB \\\n--network network=vm-net  \\\n--graphics spice\nTip\nRun\nosinfo-query --fields=name,short-id,version os\nto get argument for\n--os-variant\n; this will help define some specifications for the domain.  However,\n--memory\nand\n--disk\nwill need to be entered; one can look within the appropriate\n/usr/share/libosinfo/db/oses/\nos\n.xml\nif needing these specifications.  After installing, it will likely be preferable to install the\nSpice Guest Tools\nthat include the\nVirtIO drivers\n. For a Windows VirtIO network driver there is also\nvirtio-win\nAUR\n. These drivers are referenced by a\n<model type='virtio' />\nin the guest's\n.xml\nconfiguration section for the device. A bit more information can also be found on the\nQEMU article\n.\nImport existing volume:\n$ virt-install  \\\n--name demo  \\\n--memory 512 \\\n--disk /home/user/VMs/mydisk.img \\\n--import\nCreate a new domain using virt-manager\nFirst, connect to the hypervisor (e.g. QEMU/KVM\nsystem\nor user\nsession\n), right click on a connection and select\nNew\n, and follow the wizard.\nOn the\nfourth step\n, de-selecting\nAllocate entire disk now\nwill make setup quicker and can save disk space in the interum;\nhowever\n, it may cause volume fragmentation over time.\nOn the\nfifth step\n, open\nAdvanced options\nand make sure that\nVirt Type\nis set to\nkvm\n(this is usually the preferred method).  If additional hardware setup is required, select the\nCustomize configuration before install\noption.\nManage a domain\nStart a domain:\n$ virsh start\ndomain\n$ virt-viewer --connect qemu:///session\ndomain\nGracefully attempt to shutdown a domain; force off a domain:\n$ virsh shutdown\ndomain\n$ virsh destroy\ndomain\nAutostart domain on libvirtd start:\n$ virsh autostart\ndomain\n$ virsh autostart\ndomain\n--disable\nShutdown domain on host shutdown:\nRunning domains can be automatically suspended/shutdown at host shutdown using the\nlibvirt-guests.service\nsystemd service. This same service will resume/startup the suspended/shutdown domain automatically at host startup. See\nlibvirt-guests(8)\nfor details and service options.\nEdit a domain's XML configuration:\n$ virsh edit\ndomain\nTo know more about XML configurations read the\nXML format\nsection of the libvirt wiki.\nNote\nVirtual Machines started directly by QEMU are not manageable by libvirt tools.\nWindows requirements\nRecent Windows client and server versions have specific requirements for a machine. From Windows 11 onwards, it is necessary to configure the domain for UEFI mode, as it does not support BIOS mode. Windows Server can still be installed in a non-UEFI environment; it is however recommended by Microsoft to use UEFI mode at least for Windows Server 2022 and newer. See\n#UEFI support\nfor how to achieve this.\nAdditionally, Windows 11 requires a Trusted Platform Module to be provided to the domain. Again, for Windows Server this is still optional, but recommended. Please note that TPM version 1.2 is not supported from Windows 11 onwards, and the domain has to be set up with a TPM version 2.0. A TPM emulator can be used, as described in\n#TPM support\nhere.\nLastly, Windows recommends using Secure Boot, and libvirt can provide an adequate environment. See\n#UEFI support\nin this article and\nKVM#Secure Boot\nabout how to enroll the Microsoft keys in the firmware storage of the domain with\nvirt-firmware\n. Alternatively,\nthis guide\ncan be used to achieve the same thing manually. Secure Boot is not a strict requirement though, and this can be deployed after the domain has been installed as well.\nRecent Windows versions, especially Windows 11 and Windows Server 2025, ship a security feature called\nVirtualization-based security (VBS)\n. This technology uses hardware virtualisation itself to isolate parts of the kernel. It is possible to run Windows with VBS in a libvirt domain using QEMU/KVM if nested virtualisation is available for a domain, see\n#Nested virtualisation\nfor how to enable it.\nNetworking\nVirtual networks\nVirtual networks are used to connect domains to either internal or external networks. The bridge device is used to define the virtual network. Additionally, the forwarding mode is used to define the internal or external networks a domain is able to reach.\nForwarding modes\nSome common forwarding modes are listed below:\nMode\nDescription\nBridge\nThe virtual network is connected to the same network segment as the host.\nNAT\nThe virtual network uses the host's networking stack, uses NAT, and inbound connections are restricted.\nRouted\nThe virtual network uses the host's networking stack, and inbound connections are restricted.\nOpen\nThe virtual network uses the host's networking stack.\nIsolated\nNo other networks are reachable from the virtual network.\nUsing iptables\nIf\niptables\nis to be used and\nnot\nnftables\n, it is necessary to specify this accordingly in the configuration file:\n/etc/libvirt/network.conf\n.\nFor example':\n# default: #firewall_backend = \"nftables\"\nfirewall_backend = \"iptables\"\nRetrieving a domain IP address\nIf using the\ndefault\nnetwork and addresses are assigned using DHCP:\n$ virsh net-dhcp-leases default\nIf the domain is using the\nqemu-guest-agent\n:\n$ virsh domifaddr --source agent\ndomain\nUsing nftables\nWhen using network type NAT in combination with a simple nftables firewall, you may need to allow forwarding to/from the virtual network interface, and allow DNS/DHCP requests for DHCP clients from the virtual network interface to the host.\nThe relevant sections of\nnftables.conf\nare below:\n/etc/nftables.conf\n# ...\ntable inet filter {\nchain input {\ntype filter hook input priority filter\npolicy drop\n# ...\niifname virbr0 udp dport {53, 67} accept comment \"allow VM dhcp/dns requests to host\"\n# ...\n}\nchain forward {\ntype filter hook forward priority filter\npolicy drop\niifname virbr0 accept\noifname virbr0 accept\n}\n}\nAdding an IPv6 address\nWhen adding an IPv6 address through any of the configuration tools, you will likely receive the following error:\nCheck the host setup: enabling IPv6 forwarding with RA routes without accept_ra set to 2 is likely to cause routes loss. Interfaces to look at:\neth0\nFix this by running the following command (replace\neth0\nwith the name of your physical interface):\n# sysctl net.ipv6.conf.eth0.accept_ra=2\nPort forwarding to domains\nDetails on how to do this can be found in the libvirt\nNAT forwarding\ndocumentation.\nWarning\nIf using the\nNAT\nnetwork type, incoming connections will be prohibited. It is therefore recommended to use the\nroute\nor\nopen\nnetwork types.\nSnapshots\nSnapshots take the disk, memory, and device state of a domain at a point-of-time, and save it for future use.  They have many uses, from saving a \"clean\" copy of an OS image to saving a domain's state before a potentially destructive operation.  Snapshots are identified with a unique name.\nSnapshots are saved within the volume itself and the volume must be the format: qcow2 or raw.  Snapshots use deltas in order not to take as much space as a full copy would.\nCreate a snapshot\nThis article or section is out of date.\nReason:\nSome of this data appears to be dated. (Discuss in\nTalk:Libvirt\n)\nOnce a snapshot is taken it is saved as a new block device and the original snapshot is taken offline.  Snapshots can be chosen from and also merged into another (even without shutting down the domain).\nPrint a running domain's volumes (running domains can be printed with\nvirsh list\n):\n# virsh domblklist\ndomain\nTarget     Source\n------------------------------------------------\nvda        /vms/domain.img\nTo see a volume's physical properties:\n# qemu-img info /vms/domain.img\nimage: /vms/domain.img\nfile format: qcow2\nvirtual size: 50G (53687091200 bytes)\ndisk size: 2.1G\ncluster_size: 65536\nCreate a disk-only snapshot (the option\n--atomic\nwill prevent the volume from being modified if snapshot creation fails):\n# virsh snapshot-create-as\ndomain\nsnapshot1 --disk-only --atomic\nList snapshots:\n# virsh snapshot-list\ndomain\nName                 Creation Time             State\n------------------------------------------------------------\nsnapshot1           2012-10-21 17:12:57 -0700 disk-snapshot\nOne can then copy the original image with\ncp --sparse=true\nor\nrsync -S\nand then merge the original back into snapshot:\n# virsh blockpull --domain\ndomain\n--path /vms/\ndomain\n.snapshot1\ndomain.snapshot1\nbecomes a new volume.  After this is done the original volume (\ndomain.img\nand snapshot metadata can be deleted.   The\nvirsh blockcommit\nwould work opposite to\nblockpull\nbut it seems to be currently under development (including\nsnapshot-revert feature\n, scheduled to be released sometime next year.\nOther management\nList virtual machines in the system mode:\n$ virsh --connect qemu:///system list --all\nConnect to a non-default hypervisor:\n$ virsh --connect xen:///\nvirsh # uri\nxen:///\nConnect to a QEMU hypervisor over SSH; and the same with logging:\n$ virsh --connect qemu+ssh://\nusername\n@\nhost\n/system\n$ LIBVIRT_DEBUG=1 virsh --connect qemu+ssh://\nusername\n@\nhost\n/system\nConnect a graphic console over SSH:\n$ virt-viewer  --connect qemu+ssh://\nusername\n@\nhost\n/system\ndomain\n$ virt-manager --connect qemu+ssh://\nusername\n@\nhost\n/system\ndomain\nNote\nIf you are having problems connecting to a remote RHEL server (or anything other than Arch, really), try the two workarounds mentioned in\nFS#30748\nand\nFS#22068\n.\nConnect to the system's VirtualBox hypervisor (\nVirtualBox support in libvirt is not stable yet and may cause\nlibvirtd\nto crash\n):\n$ virsh --connect vbox:///system\nList and dump network configuration:\n$ virsh -c qemu:///system net-list --all\n$ virsh -c qemu:///system net-dumpxml default\nHooks\nHooks are scripts that are triggered by different events happening while starting and running the libvirt daemon.\nThey can be used to execute commands needed in preparation to launch a guest like setup networks or reserve memory.\nThe following hooks exists:\ndaemon - occasions to trigger: start, shutdown, reload\nqemu - occasions to trigger: prepare, prepare, start, started, stopped, release, migrate, restore, reconnect, attach\nlxc - occasions to trigger: prepare, start, started, stopped, release, reconnect\nlibxl - occasions to trigger: prepare, start, started, stopped, release migrate, reconnect\nnetwork - occasions to trigger: start, started, stopped, port-created, updated, port-deleted\nSee\nthe libvirt Documentation\nfor details about each hook and trigger.\nCreate a hook\nHooks are represented by scripts located at\n/etc/libvirt/hooks\n. If the folder does not exist, you have to create it.\nEach hook is represented by a script in this folder with the same name (e.g.\n/etc/libvirt/hooks/qemu\n) or a sub-folder (e.g.\n/etc/libvirt/hooks/qemu.d/\n). The later can contain different scripts, which are all run at the trigger points. The scripts are run like any other scripts, so they need to start with the declaration of the command interpreter to use (e.g.\n#!/bin/bash\n) and be\nexecutable\nby the libvirt user.\nEvery time a trigger point is met, the script is run. For example, the daemon script would run at least two times in a start/stop cycle of the system, at start and at shutdown. To run an command only at a given point, you have to implement conditions in the script. To do this, libvirt passes parameters which can be used to identify the current trigger condition.\nAccording to the libvirt documentation these parameters are defined as follows:\nParameter 1: The name of the object involved in the operation\nParameter 2: The name of the operation being performed\nParameter 3: Used if a sub-operation is to be named\nParameter 4: An extra argument if needed\nIf one of the arguments is not applicable, a dash is passed.\nNote\nIf the hooks are not working after creating your script, try restarting the libvirt daemon. With the new modular daemons, the daemon to restart depends on the hook (e.g.\nvirtqemud\nfor the\nqemu\nhook).\nExample\nTo run an command every time you start an qemu guest, before any resources are allocated, you can use the qemu hook. At this point, libvirt runs the hooks like this:\n/etc/libvirt/hooks/qemu <guest_name> prepare begin -\nThe script for this could like this:\n/etc/libvirt/hooks/qemu\n#!/bin/bash\nguest_name=\"$1\"\nlibvirt_task=\"$2\"\nif [ \"$libvirt_task\" = \"prepare\" ]; then\n<run some important code here>\nfi\nIf the guest is stopped, the same script would be run, but this time the daemon would start the command like this:\n/etc/libvirt/hooks/qemu <guest_name> stopped end -\nSharing data between host and guest\nVirtio-FS\nSharing files with Virtio-FS\nlists an overview of the supported options to enable filesharing with the guest.\nSet up the memory backend\nMemory backends must be allocated before using virtiofs. memfd and file-backed memory backends can be used in system sessions and unprivileged QEMU/KVM user sessions. Hugepages only supports system sessions.\nmemfd\nTo use memfd memory backend, you need to add the following domain XML elements:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<memoryBacking>\n<source type='memfd'/>\n<access mode='shared'/>\n</memoryBacking>\n...\n</domain>\nfile-backed\nAdd the following domain XML elements:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<memoryBacking>\n<access mode='shared'/>\n</memoryBacking>\n...\n</domain>\nYou can configure where the backing file is stored with the\nmemory_backing_dir\noption in\n/etc/libvirt/qemu.conf\nor, if you are running a user session, in\n$XDG_CONFIG_HOME/libvirt/qemu.conf\n:\nmemory_backing_dir = \"/dev/shm/\"\nhugepage\nNote\nhugepage is not supported in QEMU/KVM user sessions.\nFirst you need to\nenable hugepages\nwhich are used by the virtual machine:\n/etc/sysctl.d/40-hugepage.conf\nvm.nr_hugepages =\nnr_hugepages\nTo determine the number of hugepages needed check the size of the hugepages:\n$ grep Hugepagesize /proc/meminfo\nThe number of hugepages is\nmemory size of virtual machine / Hugepagesize\n. Add to this value some additional pages. You have to reboot after this step, so that the hugepages are allocated.\nNow you have to prepare the configuration of the virtual machine:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<memoryBacking>\n<hugepages/>\n</memoryBacking>\n...\n<cpu ...>\n<numa>\n<cell memory='memory size of virtual machine' unit='KiB' memAccess='shared'/>\n</numa>\n</cpu>\n...\n</domain>\nIt is necessary to add the NUMA definition so that the memory access can be declared as shared. id and cpus values for NUMA will be inserted by virsh.\nConfigure filesystem passthrough\nAdd the following domain XML elements:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<devices>\n...\n<filesystem type='mount' accessmode='passthrough'>\n<driver type='virtiofs'/>\n<source dir='path/to/folder/on/host'/>\n<target dir='mount_tag'/>\n</filesystem>\n...\n</devices>\n</domain>\nReplace\npath/to/folder/on/host\nwith the directory you want to share, and\nmount_tag\nwith an arbitrary string that will be used to identify the shared file system in the guest.\nIt should now be possible to mount the folder in the shared machine:\n# mount -t virtiofs\nmount_tag\n/mnt/mount/path\nAdd the following\nfstab\nentry to mount the folder automatically at boot:\n/etc/fstab\n...\nmount_tag\n/mnt/mount/path virtiofs rw,noatime 0 0\nMapping user/group IDs in unprivileged mode\nBy default, the root user (id 0) in the guest is mapped to the current user on the host.\nOther IDs are mapped to the subordinate user IDs specified in\nsubuid(5)\nand\nsubgid(5)\n.\nYou can also configure this mapping manually using idmap tag:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<devices>\n...\n<filesystem type='mount' accessmode='passthrough'>\n<idmap>\n<uid start=\"2000\" target=\"1000\" count=\"1\"/>\n<gid start=\"2000\" target=\"1000\" count=\"1\"/>\n</idmap>\n</filesystem>\n...\n</devices>\n</domain>\n9p\nFile system directories can be shared using the\n9P protocol\n. Details are available in\nQEMU's documentation of 9psetup\n.\nConfigure the virtual machine as follows:\n<domain>\n...\n<devices>\n...\n<filesystem type=\"mount\" accessmode=\"mapped\">\n<source dir=\"\n/path/on/host\n\"/>\n<target dir=\"\nmount_tag\n\"/>\n</filesystem>\n</devices>\n</domain>\nBoot the guest and\nmount\nthe shared directory from it using:\n# mount -t 9p -o trans=virtio,version=9p2000.L\nmount_tag\n/path/to/mount_point/on/guest\nSee\nhttps://docs.kernel.org/filesystems/9p.html\nfor more mount options.\nTo mount it at boot, add it to the guest's\nfstab\n:\n/etc/fstab\n...\nmount_tag\n/path/to/mount_point/on/guest\n9p\ttrans=virtio,version=9p2000.L\t0 0\nThe module for the 9p transport (i.e.\n9pnet_virtio\nfor\ntrans=virtio\n) will not be automatically loaded, so mounting the file system from\n/etc/fstab\nwill fail and you will encounter an error like\n9pnet: Could not find request transport: virtio\n. The solution is to\npreload the module during boot\n:\n/etc/modules-load.d/9pnet_virtio.conf\n9pnet_virtio\nSamba / SMB\nAn other easy way to share data between guest and host is to use the smb protocol. While performance and latency may not be as good as in the other described ways, its sufficient for simple tasks like transfering simple files like images or documents from and to the guest.\nThe smb server can be set up directly on either the host, or the guest, for example using\nSamba\n, eliminating the need for a dedicated file server. Windows guests have the ability to create smb shares included right after installation (\nMicrosoft Supportpage\n).\nOne possible way to access the share under linux (either from the host, or from the guest, depending, where you have installed your server) is to create an entry in your fstab. The\nsamba\npackage is required.\n/etc/fstab\n#Accessing a samba share on my vm from the host\n//my_vm/my_share /home/archuser/my_vm cifs _netdev,noauto,nofail,user,credentials=/home/archuser/.config/my_vm.key,gid=1000,uid=984 0 0\n_netdev,noauto,nofail\nensures that the share is only mounted when needed without causing issues if the virtual machine is not booted.\nuser,credentials=/home/user/.config/my_vm.key,gid=1000,uid=984\ngives you the ability to mount the share on the fly while first accessing it,\nwithout needing a password\n.\nUEFI support\nLibvirt can support UEFI virtual machines through QEMU and\nOVMF\n.\nInstall the\nedk2-ovmf\npackage.\nNote\nAs of 16/11/25,\nedk2-ovmf\n202505-1 or newer causes hanging on boot for many Linux distributions using GRUB. See\nQEMU/Troubleshooting#Linux_guest_boot_hangs_with_GRUB_in_UEFI_mode\nfor workarounds.\nRestart\nlibvirtd\n.\nNow you are ready to create a UEFI virtual machine. Create a new virtual machine through\nvirt-manager\n. When you get to the final page of the\nNew VM\nwizard, do the following:\nClick\nCustomize configuration before install\n, then select\nFinish\n.\nIn the\nOverview\nscreen, change the\nFirmware\nfield to:\nUEFI x86_64: /usr/share/edk2/x64/OVMF_CODE.4m.fd\nfor x64 UEFI without Secure Boot support,\nUEFI x86_64: /usr/share/edk2/x64/OVMF_CODE.secboot.4m.fd\nfor x64 UEFI with Secure Boot support (without any pre-enrolled certificates).\nClick\nApply\n.\nClick\nBegin Installation\n.\nSee\nFedora:Using UEFI with QEMU\nfor more information.\nFor enrolling keys\nvirt-firmware\ncan be used, see\nKVM#Secure Boot\n.\nTPM support\nQEMU can provide a\nTrusted Platform Module\nto the guest. This can be either a passthrough device, i.e. using a physical TPM in a virtual machines or an emulator. For using an emulator, the\nswtpm\npackage has to be installed. It is possible to provide TPM versions 1.2 or 2.0 to the guest, but 2.0 requires the domain to use UEFI.\nIn its simplest form, to provide a useable TPM 2.0 for the guest machine with an emulator, the following block in the domain specification will work:\n<tpm model='tpm-crb'>\n<backend type='emulator' version='2.0'/>\n<alias name='tpm0'/>\n</tpm>\nFor additional information and options, please see the libvirt documentation\nfound here\n.\nHyper-V enlightenments\nQEMU supports various Hyper-V compatible enlightenments that improve performance for Windows guests and add some additional features, see the\nQEMU documentation\n.\nThese enlightenments can also be activated through libvirt, depending on the QEMU and libvirt version present. The upstream documentation listing the currently supported enlightenments can be found\nin this section of the libvirt documentation\n. In general, they can all be enabled, but doing so will put requirements on the QEMU and libvirt versions used, which can be an issue if domain migration is desired.\nNote\nIt is also possible but not recommended to use `passthrough` instead of specifying features. Doing so will enable all enlightenments the QEMU version supports but will make migration dangerous and unreliable. This is not a particular issue if only one host is being yet still discouraged. libvirt usually takes some time to implement the most recent QEMU enlightenments so this can be useful if a particular new feature is desired but for most users not recommended.\nTips and tricks\nUsing an entire physical disk device inside the virtual machine\nYou may have a second disk with a different OS (like Windows) on it and may want to gain the ability to also boot it inside a virtual machine.\nSince the disk access is raw, the disk will perform quite well inside the virtual machine.\nWindows virtual machine boot prerequisites\nBe sure to install the\nvirtio drivers\ninside the OS on that disk before trying to boot it in the virtual machine.\nFor Win 7 use version\n0.1.173-4\n.\nSome singular drivers from newer virtio builds may be used on Win 7 but you will have to install them manually via device manager.\nFor Win 10 you can use the latest virtio build.\nSet up the windows disk interface drivers\nYou may get a\n0x0000007B\nbluescreen when trying to boot the virtual machine. This means Windows can not access the drive during the early boot stage because the disk interface driver it would need for that is not loaded / is set to start manually.\nThe solution is to\nenable these drivers to start at boot\n.\nIn\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Services\n, find the folders\naliide, amdide, atapi, cmdide, iastor (may not exist), iastorV, intelide, LSI_SAS, msahci, pciide and viaide\n.\nInside each of those, set all their \"start\" values to 0 in order to enable them at boot.\nIf your drive is a PCIe NVMe drive, also enable that driver (should it exist).\nFind the unique path of your disk\nRun\nls /dev/disk/by-id/\n: tere you pick out the ID of the drive you want to insert into the virtual machine, for example\nata-TS512GMTS930L_C199211383\n.\nNow add that ID to\n/dev/disk/by-id/\nso you get\n/dev/disk/by-id/ata-TS512GMTS930L_C199211383\n.\nThat is the unique path to that disk.\nAdd the disk in QEMU CLI\nIn QEMU CLI that would probably be\n-drive file=/dev/disk/by-id/ata-TS512GMTS930L_C199211383,format=raw,media=disk\n.\nJust modify\nfile=\nto be the unique path of your drive.\nAdd the disk in libvirt\nIn libvirt XML that translates to\n$ virsh edit\nvmname\n...\n<disk type=\"block\" device=\"disk\">\n<driver name=\"qemu\" type=\"raw\" cache=\"none\" io=\"native\"/>\n<source dev=\"/dev/disk/by-id/ata-TS512GMTS930L_C199211383\"/>\n<target dev=\"sda\" bus=\"sata\"/>\n<address type=\"drive\" controller=\"0\" bus=\"0\" target=\"0\" unit=\"0\"/>\n</disk>\n...\nJust modify \"source dev\" to be the unique path of your drive.\nAdd the disk in virt-manager\nWhen creating a virtual machine, select \"import existing drive\" and just paste that unique path.\nIf you already have the virtual machine, add a device, storage, then select or create custom storage.\nNow paste the unique path.\nPython connectivity code\nThe\nlibvirt-python\npackage provides a Python API in\n/usr/lib/python3.x/site-packages/libvirt.py\n.\nGeneral examples are given in\n/usr/share/doc/libvirt-python-\nyour_libvirt_version\n/examples/\nUnofficial example using\nqemu-desktop\nand\nopenssh\n:\n#! /usr/bin/env python3\nimport socket\nimport sys\nimport libvirt\nconn = libvirt.open(\"qemu+ssh://xxx/system\")\nprint(\"Trying to find node on xxx\")\ndomains = conn.listDomainsID()\nfor domainID in domains:\ndomConnect = conn.lookupByID(domainID)\nif domConnect.name() == 'xxx-node':\nprint(\"Found shared node on xxx with ID {}\".format(domainID))\ndomServ = domConnect\nbreak\nAdvanced Format 4K native disk\nTo turn a disk into an\nAdvanced Format\n4Kn disk, both its physical and logical sector size needs to be set to 4 KiB. For virtio-blk and virtio-scsi this can be done by setting the\nlogical_block_size\nand\nphysical_block_size\noptions with the\n<blockio> element\n. For example:\n# virsh edit\nname_of_virtual_machine\n<domain>\n...\n<devices>\n...\n<disk type='file' device='disk'>\n..\n<blockio logical_block_size='4096' physical_block_size='4096'/>\n</disk>\n...\n</devices>\n</domain>\nNested virtualisation\nlibvirt can provide nested virtualisation to its domains when running QEMU/KVM. In order to do this, KVM must be configured appropriately, see\nKVM#Nested virtualization\n.\nThe only change to be made in the libvirt configuration is to set CPU model of the domain to either `host-model` or `host-passthrough`.\nCommanding QEMU\nLibvirt is capable of passing on QEMU command line arguments to the underlying QEMU instance running the virtual machine.\nThis functionality is highly useful when libvirt does not provide\nQEMU features\n(yet). For examples, see the entire\nIntel GVT-g\narticle.\nModify virtual machine XML schema for QEMU\nThis serves to enable QEMU-specific elements. Change\n$ virsh edit\nvmname\n<domain type='kvm'>\nto\n$ virsh edit\nvmname\n<domain xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0' type='kvm'>\nQEMU command line arguments\nIn libvirt, QEMU command line arguments separated by whitespaces need to be provided separately.\nThe correct location to insert them is at the end of the\n<domain>\nelement, i. e. right above the closing\n</domain>\ntag.\n-display gtk,gl=es,zoom-to-fit=off\nBecomes\n$ virsh edit\nvmname\n...\n</devices>\n<qemu:commandline>\n<qemu:arg value=\"-display\"/>\n<qemu:arg value=\"gtk,gl=es,zoom-to-fit=off\"/>\n</qemu:commandline>\n</domain>\nTroubleshooting\nPulseAudio on system instance\nThe PulseAudio daemon normally runs under your regular user account, and will only accept connections from the same user. This can be a problem if QEMU is being run as root through libvirt. To run QEMU as a regular user, edit\n/etc/libvirt/qemu.conf\nand set the\nuser\noption to your username.\nuser = \"dave\"\nYou will also need to tell QEMU to use the PulseAudio backend and identify the server to connect to. Add the following section to your domain configuration using\nvirsh edit\n.\n<audio id=\"1\" type=\"pulseaudio\" serverName=\"/run/user/1000/pulse/native\">\n<input latency=\"20000\"/>\n<output latency=\"20000\"/>\n</audio>\n1000\nis your user id. Change it if necessary.\nYou can omit the latency settings (in microseconds) but using the defaults might result in crackling.\nHypervisor CPU use\nDefault virtual machine configuration generated by virt-manager may cause rather high (10-20%) CPU use caused by the QEMU process.\nIf you plan to run the virtual machine in headless mode, consider removing some of the unnecessary devices.\nVirtual machine cannot be un-paused on virt-manager\nIf you are using a disk image format such as\nqcow2\nwhich has a specified virtual capacity, but only stores what is needed, then you need to have space on the host partition for the image to grow. If you see I/O related errors when attempting to start the virtual machine, it is possible that the host partition holding the virtual disk image is full. You can run\ndf -h\non the host to verify how much free space is available.\nIf this is the case, see\nSystem maintenance#Clean the filesystem\nfor ways to free up space.\nRedirect USB Device is greyed out in virt-manager\nIf the\nRedirect USB Device\nmenu item is greyed out, check that the following hardware is configured for the virtual machine:\nA USB Controller.\nOne or more USB Redirectors.\nError starting domain: Requested operation is not valid\nWhen you try to open a virtual machine this error may pop up. This is because when you try to open a existing virtual machine libvirt tries to search for the default network which is not available. To make it available you have to autostart your network interface so that whenever your restart your computer your network interface is always active. See\nlibvirt networking page\n.\nLook at the name of your network interface with the following command:\n# virsh net-list --all\nTo autostart your network interface:\n# virsh net-autostart\nname_of_the_network\nTo start your network interface:\n# virsh net-start\nname_of_the_network\nVirt Manager Error 'Virt Manager doesn't have search permissions'\nEnsure the folder containing your virtual machine files and installation ISO are owned by the\nlibvirt-qemu\ngroup\n# chown -R $USER:libvirt-qemu /\npath\n/\nto\n/\nvirtual\n/\nmachine\nError starting domain: Requested operation is not valid: network 'default' is not active\nIf for any reason the default network is deactivated, you will not be able to start any guest virtual machines which are configured to use the network. Your first attempt can be simply trying to start the network with virsh.\n# virsh net-start default\nFor additional troubleshooting steps, see\n[4]\n.\nSee also\nOfficial libvirt web site\nRed Hat Virtualization Deployment and Administration Guide\nRed Hat Virtualization Tuning and Optimization Guide\nSlackware KVM and libvirt\nIBM KVM\nlibvirt Networking Handbook\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Libvirt&oldid=852933\n\"\nCategory\n:\nVirtualization\nHidden categories:\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nlibvirt\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Libvirt"}}
{"text": "VirtualBox - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nVirtualBox\n6 languages\nDeutsch\nEspañol\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\n/Install Arch Linux as a guest\nMoving an existing install into (or out of) a virtual machine\nPhpVirtualBox\nRemoteBox\nVirtualBox\nis a\nhypervisor\nused to run operating systems in a special environment, called a\nvirtual machine\n, on top of the existing operating system.\nVirtualBox\nis in constant development and new features are implemented continuously. It comes with a\nQt\ngraphical user interface, as well as\nheadless\nand\nSDL\ncommand-line tools for managing and running virtual machines.\nIn order to integrate functions of the host system to the guests, including shared folders and clipboard, video acceleration and a seamless window integration mode,\nguest additions\nare provided for some guest operating systems.\nFor more information, see the\nofficial documentation\n.\nInstallation steps for Arch Linux hosts\nIn order to launch VirtualBox virtual machines on your Arch Linux box, follow these installation steps.\nInstall the core packages\nInstall\nthe\nvirtualbox\npackage. You will also need to choose a package to provide host modules:\nfor the\nlinux\nkernel, choose\nvirtualbox-host-modules-arch\n,\nfor the\nlinux-lts\nkernel, choose\nvirtualbox-host-modules-lts\n,\nfor any other\nkernel\n, choose\nvirtualbox-host-dkms\n.\nTo compile the VirtualBox modules provided by\nvirtualbox-host-dkms\n, it will also be necessary to install the appropriate headers package(s) for your installed kernel(s) (e.g.\nlinux-rt-headers\nfor\nlinux-rt\n).\n[1]\nWhen either VirtualBox or the kernel is updated, the kernel modules will be automatically recompiled thanks to the\nDKMS\npacman hook\n.\nSign modules\nWhen using a custom kernel with\nCONFIG_MODULE_SIG_FORCE\noption enabled, you must sign your modules with a key generated during kernel compilation.\nYou can sign the modules by executing the following command as root:\n# find \"/lib/modules/$(uname -r)/\" '(' -name 'vboxdrv.ko*' -o -name 'vboxnetadp.ko*' -o -name 'vboxnetflt.ko*' ')' -exec /lib/modules/$(uname -r)/build/scripts/sign-file sha256 /lib/modules/$(uname -r)/build/certs/signing_key.pem /lib/modules/$(uname -r)/build/certs/signing_key.x509 {} ';'\nNote\nHashing algorithm does not have to match the one configured, but it must be built into the kernel.\nIf you experience an error such as the following:\nAt main.c:171:\n- SSL error:FFFFFFFF80000002:system library::No such file or directory: crypto/bio/bss_file.c:67\n- SSL error:10000080:BIO routines::no such file: crypto/bio/bss_file.c:75\nsign-file: certs/signing_key.pem\nThen run the command\ncd /lib/modules/$(uname -r)/build\nto navigate to your kernel tree folder and check if the\ncerts\nfolder actually has a\nsigning_key.pem\nfile. If not, create a file somewhere on your system (doesn't have to be in the kernel tree folder) named\nx509.genkey\nwith the following contents (based on\n[2]\n):\n[ req ]\ndefault_bits = 4096\ndistinguished_name = req_distinguished_name\nprompt = no\nstring_mask = utf8only\nx509_extensions = myexts\n[ req_distinguished_name ]\nCN = Modules\n[ myexts ]\nbasicConstraints=critical,CA:FALSE\nkeyUsage=digitalSignature\nsubjectKeyIdentifier=hash\nauthorityKeyIdentifier=keyid\nThen run\nopenssl req -new -nodes -utf8 -sha512 -days 36500 -batch -x509 -config x509.genkey -outform DER -out signing_key.x509 -keyout signing_key.pem\nin the directory you created the\nx509.genkey\nfile and move the resulting files to the\ncerts\ndirectory in the kernel tree folder. You should then be able to rerun the signing command without an error.\nIf this still doesn't work, try updating your kernel to a newer version that has signing files already available (most kernel packages should), or if you're\ncompiling your own\n, make sure that you copy the\nsrc/(kernel version)/certs/signing_key.x509\nand\nsrc/(kernel version)/certs/signing_key.pem\nfrom the folder you're building the kernel with to the\n/lib/modules/$(uname -r)/build/certs\ndirectory after you've built the kernel and are running it.\nLoad the VirtualBox kernel modules\nvirtualbox-host-modules-arch\nand\nvirtualbox-host-dkms\nuse\nsystemd-modules-load.service\nto load VirtualBox modules automatically at boot time. For the modules to be loaded after installation, either reboot or load the modules once manually; the list of modules can be found in\n/usr/lib/modules-load.d/virtualbox-host-modules-arch.conf\n,\n/usr/lib/modules-load.d/virtualbox-host-modules-lts.conf\nor\n/usr/lib/modules-load.d/virtualbox-host-dkms.conf\n.\nNote\nIf you do not want the VirtualBox modules to be automatically loaded at boot time, you have to mask the default\n/usr/lib/modules-load.d/virtualbox-host-modules-arch.conf\n,\n/usr/lib/modules-load.d/virtualbox-host-modules-lts.conf\nor\n/usr/lib/modules-load.d/virtualbox-host-dkms.conf\nby creating an empty file (or symlink to\n/dev/null\n) with the same name in\n/etc/modules-load.d/\n.\nAmong the\nkernel modules\nVirtualBox uses, there is a mandatory module named\nvboxdrv\n, which must be loaded before any virtual machines can run.\nTo load the module manually, run:\n# modprobe vboxdrv\nThe following modules are only required in advanced configurations:\nvboxnetadp\nand\nvboxnetflt\nare both needed when you intend to use the\nbridged\nor\nhost-only networking\nfeature. More precisely,\nvboxnetadp\nis needed to create the host interface in the VirtualBox global preferences, and\nvboxnetflt\nis needed to launch a virtual machine using that network interface.\nNote\nIf the VirtualBox kernel modules were loaded in the kernel while you updated the modules, you need to reload them manually to use the new updated version. To do it, run\nvboxreload\nas root.\nAccessing host USB devices in guest\nTo use the USB ports of your host machine in your virtual machines, add users that will be authorized to use this feature to the\nvboxusers\nuser group\n.\nGuest additions\nIt is also recommended to install the\nvirtualbox-guest-iso\npackage on the host running VirtualBox. This package will act as a disc image that can be used to install the guest additions onto guest systems other than Arch Linux. The\n.iso\nfile will be located at\n/usr/lib/virtualbox/additions/VBoxGuestAdditions.iso\n, and may have to be mounted manually inside the virtual machine. Once mounted, you can run the guest additions installer inside the guest. For Arch Linux guest also see\nVirtualBox/Install Arch Linux as a guest#Install the Guest Additions\n.\nExtension pack\nThe\nOracle VM VirtualBox Extension Pack\nprovides\nadditional features\nand is released under a non-free license\nonly available for personal use\n. To install it, the\nvirtualbox-ext-oracle\nAUR\npackage is available, and a prebuilt version can be found in the\nseblu\nrepository.\nIf you prefer to use the traditional and manual way: download the extension pack manually and install it via the GUI (\nFile > Tools > Extension Pack Manager\n) or via\nVBoxManage extpack install\n<.vbox-extpack>\n, make sure you have a toolkit like\nPolkit\nto grant privileged access to VirtualBox. The installation of extension pack\nrequires root access\n.\nYou can also install the\nextension pack\nwithout using Polkit via the following command:\n# vboxmanage extpack install\npath-to-extension-pack\nOne of the non-free extension pack features is support for the Remote Desktop Protocol (RDP). This part of functionality can also be obtained with the open source\nVNC Extension Pack\n, by installing the\nvirtualbox-ext-vnc\npackage.\nFront-ends\nVirtualBox comes with four front-ends:\nIf you want to use VirtualBox with the regular GUI, use\nVirtualBox\n.\nIf you want to launch and manage your virtual machines from the command-line, use the\nVBoxSDL\ncommand, which only provides a plain window for the virtual machine without any overlays.\nIf you want to use VirtualBox without running any GUI (e.g. on a server), use the\nVBoxHeadless\ncommand. With the VRDP extension you can still remotely access the displays of your virtual machines.\nIf you want to remotely manage virtual machines, the\nVirtualBox web service\n(\nvboxwebsrv\n) provides the server side backend. It can be used with\nRemoteBox\n(GUI) or\nphpVirtualBox\n(WebUI).\nRefer to the\nVirtualBox manual\nto learn how to create virtual machines.\nWarning\nIf you intend to store virtual disk images on a\nBtrfs\nfile system, before creating any images, you should consider disabling\ncopy-on-write\nfor the destination directory of these images.\nA security feature in Wayland (i.e. when using GDM) disallows VirtualBox to grab all keyboard input. This is annoying when you want to pass window manager shortcuts to your guest operating system. It can be bypassed by whitelisting VirtualBox:\n$ gsettings get org.gnome.mutter.wayland xwayland-grab-access-rules\n$ gsettings set org.gnome.mutter.wayland xwayland-grab-access-rules \"['VirtualBox Machine']\"\nThe first command will show if any other applications are already whitelisted. If so, add\nVirtualBox Machine\nto that list, rather than having it as the only one.\nInstallation steps for Arch Linux guests\nSee\nVirtualBox/Install Arch Linux as a guest\n.\nVirtual disks management\nSee also\n#Import/export VirtualBox virtual machines from/to other hypervisors\n.\nFormats supported by VirtualBox\nVirtualBox supports the following virtual disk formats:\nVDI\n: The Virtual Disk Image is the VirtualBox own open container used by default when you create a virtual machine with VirtualBox.\nVMDK\n: The Virtual Machine Disk has been initially developed by VMware for their products. The specification was initially closed source, but has since become an open format which is fully supported by VirtualBox. This format offers the ability to be split into several 2GB files. This feature is especially useful if you want to store the virtual machine on machines which do not support very large files. Other formats, excluding the HDD format from Parallels, do not provide such an equivalent feature.\nVHD\n: The Virtual Hard Disk is the format used by Microsoft in Windows Virtual PC and Hyper-V. If you intend to use any of these Microsoft products, you will have to choose this format.\nTip\nSince Windows 7, this format can be mounted directly without any additional application.\nVHDX\n(read only): This is the eXtended version of the Virtual Hard Disk format developed by Microsoft, which has been released on 2012-09-04 with Hyper-V 3.0 coming with Windows Server 2012. This new version of the disk format does offer enhanced performance (better block alignment), larger blocks size, and journal support which brings power failure resiliency. VirtualBox\nshould support this format in read only\n.\nHDD\n(version 2): The HDD format is developed by Parallels Inc and used in their hypervisor solutions like Parallels Desktop for Mac. Newer versions of this format (i.e. 3 and 4) are not supported due to the lack of documentation for this proprietary format.\nNote\nThere is currently a controversy regarding the support of the version 2 of the format. While the official VirtualBox manual\nonly reports the second version of the HDD file format as supported\n, Wikipedia's contributors are\nreporting the first version may work too\n. Help is welcome if you can perform some tests with the first version of the HDD format.\nQED\n: The QEMU Enhanced Disk format is an old file format for QEMU, another free and open source hypervisor. This format was designed from 2010 in a way to provide a superior alternative to QCOW2 and others. This format features a fully asynchronous I/O path, strong data integrity, backing files, and sparse files. QED format is supported only for compatibility with virtual machines created with old versions of QEMU.\nQCOW\n: The QEMU Copy On Write format is the current format for QEMU. The QCOW format does support zlib-based transparent compression and encryption (the latter is flawed and is not recommended). QCOW is available in two versions: QCOW and QCOW2. QCOW2 tends to supersede the first one. QCOW is\ncurrently fully supported by VirtualBox\n. QCOW2 comes in two revisions: QCOW2 0.10 and QCOW2 1.1 (which is the default when you create a virtual disk with QEMU). VirtualBox does not support QCOW2.\nOVF\n: The Open Virtualization Format is an open format which has been designed for interoperability and distributions of virtual machines between different hypervisors. VirtualBox supports all revisions of this format via the\nVBoxManage import/export feature\nbut with\nknown limitations\n.\nRAW\n: This is the mode when the virtual disk is exposed directly to the disk without being contained in a specific file format container. VirtualBox supports this feature in several ways: converting RAW disk\nto a specific format\n, or by\ncloning a disk to RAW\n, or by using directly a VMDK file\nwhich points to a physical disk or a simple file\n.\nDisk image format conversion\nVBoxManage clonehd\ncan be used to convert between VDI, VMDK, VHD and RAW.\n$ VBoxManage clonehd\ninputfile\noutputfile\n--format\noutputformat\nFor example to convert VDI to VMDK:\n$ VBoxManage clonehd\nsource.vdi\ndestination.vmdk\n--format VMDK\nQCOW\nVirtualBox does not support\nQEMU\n's QCOW2 disk image format. To use a QCOW2 disk image with VirtualBox you therefore need to convert it, which you can do with\nqemu-img\n.\nqemu-img\ncan convert QCOW to / from VDI, VMDK, VHDX, RAW and various other formats (which you can see by running\nqemu-img --help\n).\n$ qemu-img convert -O\noutput_fmt\ninputfile\noutputfile\nFor example to convert QCOW2 to VDI:\n$ qemu-img convert -O vdi\nsource.qcow2\ndestination.vdi\nTip\nThe\n-p\nparameter is used to get the progression of the conversion task.\nThere are two revisions of QCOW2: 0.10 and 1.1. You can specify the revision to use with\n-o compat=\nrevision\n.\nMount virtual disks\nVDI\nMounting VDI images only works with fixed size images (a.k.a. static images); dynamic (dynamically size allocating) images are not easily mountable.\nThe offset of the partition (within the VDI) is needed, then add the value of\noffData\nto\n32256\n(e.g. 69632 + 32256 = 101888):\n$ VBoxManage internalcommands dumphdinfo\nstorage\n.vdi | grep \"offData\"\nThe storage can now be mounted with:\n# mount -t ext4 -o rw,noatime,noexec,loop,offset=101888\nstorage\n.vdi /mntpoint/\nFor VDI disks with more partitions you can also use\nlosetup\n:\n# losetup -o $offData -Pf\nAfter this you should find the partitions under\n/dev/loop*\n(e.g.\n/dev/loop0p1\n). Then you can mount them as usual (e.g.\nmount mount /dev/loop0p1 /mnt/\n).\nYou can also use\nmount.vdi\nscript that, which you can use as (install script itself to\n/usr/bin/\n):\n# mount -t vdi -o fstype=ext4,rw,noatime,noexec\nvdi_file_location\n/mnt/\nAlternately you can use the nbd kernel module and\nqemu-nbd\nfrom\nqemu-img\n[3]\n:\n# modprobe nbd max_part=16\n# qemu-nbd -c /dev/nbd0\nstorage\n.vdi\n# mount /dev/nbd0p1 /mnt/dir/\nAnd then to unmount:\n# umount /mnt/dir/\n# qemu-nbd -d /dev/nbd0\nIf the partition nodes are not propagated try using\npartprobe /dev/nbd0\n; otherwise, a VDI partition can be mapped directly to a node by:\nqemu-nbd -P 1 -c /dev/nbd0\nstorage\n.vdi\n.\nVHD\nLike VDI, VHD images can be mounted with\nQEMU\n's nbd module:\n# modprobe nbd\n# qemu-nbd -c /dev/nbd0\nstorage\n.vhd\n# mount /dev/nbd0p1 /mnt\nTo unmount:\n# umount /mnt\n# qemu-nbd -d /dev/nbd0\nCompact virtual disks\nCompacting virtual disks only works with\n.vdi\nfiles and basically consists of the following steps.\nBoot your virtual machine and remove all bloat manually or by using cleaning tools like\nbleachbit\nwhich is\navailable for Windows systems too\n.\nWiping free space with zeroes can be achieved with several tools:\nIf you were previously using Bleachbit, check the checkbox\nSystem > Free disk space\nin the GUI, or use\nbleachbit -c system.free_disk_space\nin CLI;\nOn UNIX-based systems, by using\ndd\nor preferably\ndcfldd\nAUR\n(see\nhere\nto learn the differences):\n# dcfldd if=/dev/zero of=\n/fillfile\nbs=4M\nWhen\nfillfile\nreaches the limit of the partition, you will get a message like\n1280 blocks (5120Mb) written.dcfldd:: No space left on device\n. This means that all of the user-space and non-reserved blocks of the partition will be filled with zeros. Using this command as root is important to make sure all free blocks have been overwritten. Indeed, by default, when using partitions with ext filesystem, a specified percentage of filesystem blocks is reserved for the super-user (see the\n-m\nargument in the\nmkfs.ext4\nman pages or use\ntune2fs -l\nto see how much space is reserved for root applications).\nWhen the aforementioned process has completed, you can remove the file\nfillfile\nyou created.\nOn Windows, there are two tools available:\nsdelete\nfrom the\nSysinternals Suite\n, type\nsdelete -s -z\nc:\n, where you need to reexecute the command for each drive you have in your virtual machine;\nor, if you love scripts, there is a\nPowerShell solution\n, but which still needs to be repeated for all drives.\nPS> ./Write-ZeroesToFreeSpace.ps1 -Root\nc:\\\n-PercentFree 0\nNote\nThis script must be run in a PowerShell environment with administrator privileges. By default, scripts cannot be run, ensure the execution policy is at least on\nRemoteSigned\nand not on\nRestricted\n. This can be checked with\nGet-ExecutionPolicy\nand the required policy can be set with\nSet-ExecutionPolicy RemoteSigned\n.\nOnce the free disk space have been wiped, shut down your virtual machine.\nThe next time you boot your virtual machine, it is recommended to do a filesystem check.\nOn UNIX-based systems, you can use\nfsck\nmanually;\nOn GNU/Linux systems, and thus on Arch Linux, you can force a disk check at boot\nthanks to a kernel boot parameter\n;\nOn Windows systems, you can use:\neither\nchkdsk\nc:\n/F\nwhere\nc:\nneeds to be replaced by each disk you need to scan and fix errors;\nor\nFsckDskAll\nfrom here\nwhich is basically the same software as\nchkdsk\n, but without the need to repeat the command for all drives;\nNow, remove the zeros from the\n.vdi\nfile with\nVBoxManage modifyhd\n:\n$ VBoxManage modifyhd\nyour_disk.vdi\n--compact\nNote\nIf your virtual machine has snapshots, you need to apply the above command on each\n.vdi\nfile you have.\nThis concept of writing zeroes and compacting/reclaiming/cleanup space only works if there is no encryption on the virtual disk.\nOn Windows you can check whether BitLocker is enabled using the\nmanage-bde -status\ncommand and disable it with\nmanage-bde -off c:\n, where\nc:\nrefers to the encrypted drive. After that, repeat the steps mentioned above.\nTRIM\nVirtualBox offers simulation of TRIM in VDI files via an experimental \"discard\" attachment option. This option is undocumented and can be accessed by\ncommandline or .vbox file editing\n. When enabled, TRIM commands from the guest operating system causes the corresponding part of the VDI file to be compacted away.\nWarning\nUsing this option without Host I/O Cache is known to cause lockups.\nIncrease virtual disks\nGeneral procedure\nIf you are running out of space due to the small hard drive size you selected when you created your virtual machine, the solution adviced by the VirtualBox manual is to use\nVBoxManage modifyhd\n. However this command only works for VDI and VHD disks and only for the dynamically allocated variants. If you want to resize a fixed size virtual disk disk too, read on this trick which works either for a Windows or UNIX-like virtual machine.\nFirst, create a new virtual disk next to the one you want to increase:\n$ VBoxManage createmedium disk -filename\nnew.vdi\n--size\n10000\nwhere size is in MiB, in this example 10000MiB ~= 10GiB, and\nnew.vdi\nis name of new hard drive to be created.\nNote\nBy default, this command uses the\nStandard\n(corresponding to dynamic allocated) file format variant and thus will not use the same file format variant as your source virtual disk. If your\nold.vdi\nhas a fixed size and you want to keep this variant, add the parameter\n--variant Fixed\n.\nNext, the old virtual disk needs to be cloned to the new one which this may take some time:\n$ VBoxManage clonemedium disk\nold.vdi\nnew.vdi\n--existing\nDetach the old hard drive and attach new one, replace all mandatory italic arguments by your own:\n$ VBoxManage storageattach\nvirtual_machine_name\n--storagectl\nSATA\n--port\n0\n--medium none\n$ VBoxManage storageattach\nvirtual_machine_name\n--storagectl\nSATA\n--port\n0\n--medium\nnew.vdi\n--type hdd\nTo get the storage controller name and the port number, you can use the command\nVBoxManage showvminfo\nvirtual_machine_name\n. Among the output you will get such a result (what you are looking for is in italic):\n[...]\nStorage Controller Name (0):            IDE\nStorage Controller Type (0):            PIIX4\nStorage Controller Instance Number (0): 0\nStorage Controller Max Port Count (0):  2\nStorage Controller Port Count (0):      2\nStorage Controller Bootable (0):        on\nStorage Controller Name (1):            SATA\nStorage Controller Type (1):            IntelAhci\nStorage Controller Instance Number (1): 0\nStorage Controller Max Port Count (1):  30\nStorage Controller Port Count (1):      1\nStorage Controller Bootable (1):        on\nIDE (1, 0): Empty\nSATA\n(\n0\n, 0): /home/wget/IT/Virtual_machines/GNU_Linux_distributions/ArchLinux_x64_EFI/Snapshots/{6bb17af7-e8a2-4bbf-baac-fbba05ebd704}.vdi (UUID: 6bb17af7-e8a2-4bbf-baac-fbba05ebd704)\n[...]\nDownload\nGParted live image\nand mount it as a virtual CD/DVD disk file, boot your virtual machine, increase/move your partitions, umount GParted live and reboot.\nNote\nOn GPT disks, increasing the size of the disk will result in the backup GPT header not being at the end of the device. GParted will ask to fix this, click on\nFix\nboth times. On MBR disks, you do not have such a problem as this partition table as no trailer at the end of the disk.\nFinally, unregister the virtual disk from VirtualBox and remove the file:\n$ VBoxManage closemedium disk\nold.vdi\n$ rm\nold.vdi\nIncreasing the size of VDI disks\nIf your disk is a VDI one, run:\n$ VBoxManage modifymedium disk\nyour_virtual_disk.vdi\n--resize\nthe_new_size\nThen jump back to the Gparted step, to increase the size of the partition on the virtual disk.\nReplace a virtual disk manually from the .vbox file\nIf you think that editing a simple\nXML\nfile is more convenient than playing with the GUI or with\nVBoxManage\nand you want to replace (or add) a virtual disk to your virtual machine, in the\n.vbox\nconfiguration file corresponding to your virtual machine, simply replace the GUID, the file location and the format to your needs:\nArchLinux_vm.vbox\n<HardDisk uuid=\"\n{670157e5-8bd4-4f7b-8b96-9ee412a712b5}\n\" location=\"\nArchLinux_vm.vdi\n\" format=\"\nVDI\n\" type=\"Normal\"/>\nthen in the\n<AttachedDevice>\nsub-tag of\n<StorageController>\n, replace the GUID by the new one.\nArchLinux_vm.vbox\n<AttachedDevice type=\"HardDisk\" port=\"0\" device=\"0\">\n<Image uuid=\"\n{670157e5-8bd4-4f7b-8b96-9ee412a712b5}\n\"/>\n</AttachedDevice>\nNote\nIf you do not know the GUID of the drive you want to add, you can use the\nVBoxManage showhdinfo\nfile\n. If you previously used\nVBoxManage clonehd\nto copy/convert your virtual disk, this command should have outputted the GUID just after the copy/conversion completed. Using a random GUID does not work, as each\nUUID is stored inside each disk image\n.\nTransfer between Linux host and other operating system\nThe information about path to harddisks and the snapshots is stored between\n<HardDisks> .... </HardDisks>\ntags in the file with the\n.vbox\nextension. You can edit them manually or use this script where you will need change only the path or use defaults, assumed that\n.vbox\nis in the same directory with a virtual harddisk and the snapshots folder. It will print out new configuration to stdout.\n#!/bin/sh\nNewPath=\"${PWD}/\"\nSnapshots=\"Snapshots/\"\nFilename=\"$1\"\nawk -v SetPath=\"$NewPath\" -v SnapPath=\"$Snapshots\" '{if(index($0,\"<HardDisk uuid=\") != 0){A=$3;split(A,B,\"=\");\nL=B[2];\ngsub(/\\\"/,\"\",L);\nsub(/^.*\\//,\"\",L);\nsub(/^.*\\\\/,\"\",L);\nif(index($3,\"{\") != 0){SnapS=SnapPath}else{SnapS=\"\"};\nprint $1\" \"$2\" location=\"\\\"SetPath SnapS L\"\\\" \"$4\" \"$5}\nelse print $0}' \"$Filename\"\nNote\nIf you will prepare virtual machine for use in Windows host then in the path name end you should use backslash\n\\\ninstead of\n/\n.\nThe script detects snapshots by looking for\n{\nin the file name.\nTo make it run on a new host you will need to add it first to the register by clicking on\nMachine > Add...\nor use hotkeys\nCtrl+a\nand then browse to\n.vbox\nfile that contains configuration or use command line\nVBoxManage registervm\nfilename\n.vbox\nClone a virtual disk and assigning a new UUID to it\nUUIDs are widely used by VirtualBox. Each virtual machines and each virtual disk of a virtual machine must have a different UUID. When you launch a virtual machine in VirtualBox, VirtualBox will keep track of all UUIDs of your virtual machine instance. See the\nVBoxManage list\nto list the items registered with VirtualBox.\nIf you cloned a virtual disk manually by copying the virtual disk file, you will need to assign a new UUID to the cloned virtual drive if you want to use the disk in the same virtual machine or even in another (if that one has already been opened, and thus registered, with VirtualBox).\nYou can use this command to assign a new UUID to a virtual disk:\n$ VBoxManage internalcommands sethduuid\n/path/to/disk.vdi\nTip\nTo avoid copying the virtual disk and assigning a new UUID to your file manually you can use\nVBoxManage clonehd\n.\nNote\nThe commands above support all\nvirtual disk formats supported by VirtualBox\n.\nTips and tricks\nImport/export VirtualBox virtual machines from/to other hypervisors\nIf you plan to use your virtual machine on another hypervisor or want to import in VirtualBox a virtual machine created with another hypervisor, you might be interested in reading the following steps.\nRemove additions\nGuest additions are available in most hypervisor solutions: VirtualBox comes with the\nGuest Additions\n, VMware with the VMware Tools, Parallels with the Parallels Tools, etc. These additional components are designed to be installed inside a virtual machine after the guest operating system has been installed. They consist of device drivers and system applications that optimize the guest operating system for better performance and usability\nby providing these features\n.\nIf you have installed the additions to your virtual machine, please uninstall them first. Your guest, especially if it is using an operating system from the Windows family, might behave weirdly, crash or even might not boot at all if you are still using the specific drivers in another hypervisor.\nUse the right virtual disk format\nThis step will depend on the ability to convert the virtual disk image directly or not.\nAutomatic tools\nSome companies provide tools which offer the ability to create virtual machines from a Windows or GNU/Linux operating system located either in a virtual machine or even in a native installation. With such a product, you do not need to apply this and the following steps and can stop reading here.\nParallels Transporter\nwhich is non free, is a product from Parallels Inc. This solution basically consists in an piece of software called\nagent\nthat will be installed in the guest you want to import/convert. Then, Parallels Transporter,\nwhich only works on OS X\n, will create a virtual machine from that\nagent\nwhich is contacted either by USB or Ethernet network.\nVMware vCenter Converter\n[\ndead link\n2024-07-30—HTTP 404]\nwhich is free upon registration on the VMware website, works nearly the same way as Parallels Transporter, but the piece of software that will gather the data to create the virtual machine only works on a Windows platform.\nManual conversion\nFirst, familiarize yourself with the\nformats supported by VirtualBox\nand\nthose supported by third-party hypervisors\n.\nImporting or exporting a virtual machine from/to a VMware solution is not a problem at all if you use the VMDK or OVF disk format, otherwise converting\nVMDK to VDI and VDI to VMDK\nis possible and the aforementioned VMware vCenter Converter tool is available.\nImporting or exporting from/to QEMU is not a problem neither: some QEMU formats are supported directly by VirtualBox and conversion between\nQCOW2 to VDI and VDI to QCOW2\nis still available if needed.\nImporting or exporting from/to Parallels hypervisor is the hardest way: Parallels does only support its own HDD format (even the standard and portable OVF format is not supported!).\nTo export your virtual machine to Parallels, you will need to use the Parallels Transporter tool described above.\nTo import your virtual machine to VirtualBox, you will need to use the VMware vCenter Converter described above to convert the virtual machine to the VMware format first. Then, apply the solution to migrate from VMware.\nCreate the virtual machine configuration for your hypervisor\nEach hypervisor have their own virtual machine configuration file:\n.vbox\nfor VirtualBox,\n.vmx\nfor VMware, a\nconfig.pvs\nfile located in the virtual machine bundle (\n.pvm\nfile), etc. You will have thus to recreate a new virtual machine in your new destination hypervisor and specify its hardware configuration as close as possible as your initial virtual machine.\nPay a close attention to the firmware interface (BIOS or UEFI) used to install the guest operating system. While an option is available to choose between these 2 interfaces on VirtualBox and on Parallels solutions, on VMware, you will have to add manually the following line to your\n.vmx\nfile.\nArchLinux_vm.vmx\nfirmware = \"efi\"\nFinally, ask your hypervisor to use the existing virtual disk you have converted and launch the virtual machine.\nTip\nOn VirtualBox, if you do not want to browse the whole GUI to find the right location to add your new virtual drive device, you can\nReplace a virtual disk manually from the .vbox file\n, or use the\nVBoxManage storageattach\ndescribed in\n#Increasing the size of VDI disks\nor in the\nVirtualBox manual page\n.\nSimilarly, in VMware products, you can replace the location of the current virtual disk location by adapting the\n.vmdk\nfile location in your\n.vmx\nconfiguration file.\nVirtual machine launch management\nStarting virtual machines with a service (autostart)\nFind hereafter the implementation details of a systemd service that will be used to consider a virtual machine as a service.\n/etc/systemd/system/vboxvmservice@.service\n[Unit]\nDescription=VBox Virtual Machine %i Service\nRequires=systemd-modules-load.service\nAfter=systemd-modules-load.service\n[Service]\nUser=\nusername\nGroup=vboxusers\nExecStart=/usr/bin/VBoxManage startvm %i --type\nstartmode\nExecStop=/usr/bin/VBoxManage controlvm %i\nstopmode\nRemainAfterExit=yes\n[Install]\nWantedBy=multi-user.target\nNote\nReplace\nusername\nwith a user that is a member of the\nvboxusers\ngroup. Make sure the user chosen is the same user that will create/import virtual machines, otherwise the user will not see the virtual machine appliances.\nReplace\nstartmode\nwith a virtual machine frontend type, usually\ngui\n,\nheadless\nor\nseparate\nReplace\nstopmode\nwith desired state switch, usually\nsavestate\nor\nacpipowerbutton\nIf you have multiple virtual machines managed by systemd and they are not stopping properly, try to add\nKillMode=none\nand\nTimeoutStopSec=40\nat the end of\n[Service]\nsection.\nEnable\nthe\nvboxvmservice@\nyour_virtual_machine_name\nsystemd unit in order to launch the virtual machine at next boot. To launch it directly, simply\nstart\nthe systemd unit.\nVirtualBox 4.2 introduces\na new way\nfor UNIX-like systems to have virtual machines started automatically, other than using a systemd service.\nStarting virtual machines with a keyboard shortcut\nIt can be useful to start virtual machines directly with a keyboard shortcut instead of using the VirtualBox interface (GUI or CLI). For that, you can simply define key bindings in\n.xbindkeysrc\n. Please refer to\nXbindkeys\nfor more details.\nExample, using the\nFn\nkey of a laptop with an unused battery key (\nF3\non the computer used in this example):\n\"VBoxManage startvm 'Windows 7'\"\nm:0x0 + c:244\nXF86Battery\nNote\nIf you have a space in the name of your virtual machine, then enclose it with single apostrophes like made in the example just above.\nUse specific device in the virtual machine\nUsing USB webcam / microphone\nNote\nYou will need to have\nextension pack\ninstalled before following the steps below.\nMake sure the virtual machine is not running and your webcam / microphone is not being used.\nBring up the main VirtualBox window and go to settings for Arch machine. Go to USB section.\nMake sure\nEnable USB Controller\nis selected. Also make sure that\nEnable USB 2.0 (EHCI) Controller\nis selected too.\nClick the\nAdd filter from device\nbutton (the cable with the\n+\nicon).\nSelect your USB webcam/microphone device from the list.\nNow click OK and start your virtual machine.\nNote\nIf your Microphone does not show up in the \"Add filter from device\" menu, try the USB 3.0 and 1.1 options instead (In Step 3).\nDetecting web-cams and other USB devices\nNote\nThis will not do much if you are running a Linux/Unix operating system inside of your virtual machine, as most do not have autodetection features.\nIf the device that you are looking for does not show up on any of the menus in the section above and you have tried all three USB controller options,\nboot up your virtual machine three separate times. Once using the USB 1.1 controller, another using the USB 2.0 controller, etc. Leave the virtual machine running for at least 5 minutes after startup. Sometimes Windows will autodetect the device for you. Be sure you filter any devices that are not a keyboard or a mouse so they do not start up at boot. This ensures that Windows will detect the device at start-up.\nAccess a guest server\nTo access\nApache server\non a Virtual Machine from the host machine\nonly\n, simply execute the following lines on the host:\n$ VBoxManage setextradata GuestName \"VBoxInternal/Devices/\npcnet\n/0/LUN#0/Config/Apache/HostPort\"\n8888\n$ VBoxManage setextradata GuestName \"VBoxInternal/Devices/\npcnet\n/0/LUN#0/Config/Apache/GuestPort\"\n80\n$ VBoxManage setextradata GuestName \"VBoxInternal/Devices/\npcnet\n/0/LUN#0/Config/Apache/Protocol\" TCP\nwhere\n8888\nis the port the host should listen on and\n80\nis the port the virtual machine will send Apache's signal on.\nTo use a port lower than 1024 on the host machine, changes need to be made to the firewall on that host machine. This can also be set up to work with SSH or any other services by changing \"Apache\" to the corresponding service and ports.\nNote\npcnet\nrefers to the network card of the virtual machine. If you use an Intel card in your virtual machine settings, change\npcnet\nto\ne1000\n.\nTo communicate between the VirtualBox guest and host using ssh, the server port must be forwarded under Settings > Network. When connecting from the client/host, connect to the IP address of the client/host machine, as opposed to the connection of the other machine. This is because the connection will be made over a virtual adapter.\nD3D acceleration in Windows guests\nRecent versions of VirtualBox have support for accelerating OpenGL inside guests. This can be enabled with a simple checkbox in the machine's settings, right below where video ram is set, and installing the VirtualBox\nguest additions\n. However, most Windows games use Direct3D (part of DirectX), not OpenGL, and are thus not helped by this method. However, it is possible to gain accelerated Direct3D in your Windows guests by borrowing the d3d libraries from Wine, which translate d3d calls into OpenGL, which is then accelerated. These libraries are now part of VirtualBox guest additions.\nAfter enabling OpenGL acceleration as described above, reboot the guest into safe mode (press F8 before the Windows screen appears but after the VirtualBox screen disappears), and install VirtualBox\nguest additions\n, during install enable checkbox\nDirect3D support\n. Reboot back to normal mode and you should have accelerated Direct3D.\nNote\nThis hack may or may not work for some games depending on what hardware checks they make and what parts of D3D they use.\nThis was tested on Windows XP, 7 and 8.1. If method does not work on your Windows version please add data here.\nVirtualBox on a USB key\nWhen using VirtualBox on a USB key, for example to start an installed machine with an ISO image, you will manually have to create VMKDs from the existing drives. However, once the new VMDKs are saved and you move on to another machine, you may experience problems launching an appropriate machine again. To get rid of this issue, you can use the following script to launch VirtualBox. This script will clean up and unregister old VMDK files and it will create new, proper VMDKs for you:\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nThe following script parses the output of ls, which is\nvery brittle\nand\nknown to break\n. (Discuss in\nTalk:VirtualBox\n)\n#!/bin/sh\n# Erase old VMDK entries\nrm ~/.VirtualBox/*.vmdk\n# Clean up VBox-Registry\nsed -i '/sd/d' ~/.VirtualBox/VirtualBox.xml\n# Remove old harddisks from existing machines\nfind ~/.VirtualBox/Machines -name \\*.xml | while read -r file; do\nline=$(grep -e \"type\\=\\\"HardDisk\\\"\" -n \"$file\" | cut -d ':' -f 1)\nif [ -n \"$line\" ]; then\nsed -i \"${line}\"d \"$file\"\nsed -i \"${line}\"d \"$file\"\nsed -i \"${line}\"d \"$file\"\nfi\nsed -i \"/rg/d\" \"$file\"\ndone\n# Delete prev-files created by VirtualBox\nfind ~/.VirtualBox/Machines -name \\*-prev -exec rm '{}' \\;\n# Recreate VMDKs\nls -l /dev/disk/by-uuid | cut -d ' ' -f 9,11 | while read -r ln; do\nif [ -n \"$ln\" ]; then\nuuid=$(echo \"$ln\" | cut -d ' ' -f 1)\ndevice=$(echo \"$ln\" | cut -d ' ' -f 2 | cut -d '/' -f 3 | cut -b 1-3)\n# determine whether drive is mounted already\ncheckstr1=$(mount | grep \"$uuid\")\ncheckstr2=$(mount | grep \"$device\")\ncheckstr3=$(ls ~/.VirtualBox/*.vmdk | grep \"$device\")\nif [ -z \"$checkstr1\" ] && [ -z \"$checkstr2\" ] && [ -z \"$checkstr3\" ]; then\nVBoxManage internalcommands createrawvmdk -filename ~/.VirtualBox/\"$device\".vmdk -rawdisk /dev/\"$device\" -register\nfi\nfi\ndone\n# Start VirtualBox\nVirtualBox\nNote that your user has to be added to the \"disk\" group to create VMDKs out of existing drives.\nRun a native Arch Linux installation inside VirtualBox\nIf you have a dual boot system between Arch Linux and another operating system, it can become tedious to switch back and forth if you need to work in both. You may also experience performance or compatibility issues when using a virtual machine, which can impact your ability to do certain tasks.\nThis guide will let you reuse, in a virtual machine, your native Arch Linux installation when you are running your second operating system. This way, you keep the ability to run each operating system natively, but have the option to run your Arch Linux installation inside a virtual machine.\nMake sure you have a persistent naming scheme\nDepending on your hard drive setup, device files representing your hard drives may appear differently when you will run your Arch Linux installation natively or in virtual machine. This problem occurs when using\nFakeRAID\nfor example. The fake RAID device will be mapped in\n/dev/mapper/\nwhen you run your GNU/Linux distribution natively, while the devices are still accessible separately. However, in your virtual machine, it can appear without any mapping in\n/dev/sdaX\nfor example, because the drivers controlling the fake RAID in your host operating system (e.g. Windows) are abstracting the fake RAID device.\nTo circumvent this problem, we will need to use an addressing scheme that is persistent to both systems. This can be achieved using\nUUIDs\n. Make sure your\nboot loader\nand\nfstab\nfile is using UUIDs, otherwise fix this issue. Read\nfstab\nand\nPersistent block device naming\n.\nWarning\nMake sure your host partition is only accessible in read only from your Arch Linux virtual machine, this will avoid risk of corruptions if you were to corrupt that host partition by writing on it due to lack of attention.\nYou should NEVER allow VirtualBox to boot from the entry of your second operating system, which, as a reminder, is used as the host for this virtual machine! Take thus a special care especially if your default boot loader/boot manager entry is your other operating system. Give a more important timeout or put it below in the order of preferences.\nMake sure your mkinitcpio image is correct\nMake sure your\nmkinitcpio\nconfiguration uses the\nHOOK\nblock\n:\n/etc/mkinitcpio.conf\n...\nHOOKS=(base udev autodetect microcode modconf kms keyboard keymap consolefont\nblock\nfilesystems fsck)\n...\nIf it is not present, add it and\nregenerate the initramfs\n.\nCreate a virtual machine configuration to boot from the physical drive\nCreate a raw disk VMDK image\nNow, we need to create a new virtual machine which will use a\nRAW disk\nas virtual drive, for that we will use a ~ 1Kio VMDK file which will be mapped to a physical disk. Unfortunately, VirtualBox does not have this option in the GUI, so we will have to use the console and use an internal command of\nVBoxManage\n.\nBoot the host which will use the Arch Linux virtual machine. The command will need to be adapted according to the host you have.\nOn a GNU/Linux host\nThere are 3 ways to achieve this: login as root, changing the access right of the device with\nchmod\n, adding your user to the\ndisk\ngroup. The latter way is the more elegant, let us proceed that way:\n# gpasswd -a\nyour_user\ndisk\nApply the new group settings with:\n$ newgrp\nNow, you can use the command:\n$ VBoxManage internalcommands createrawvmdk -filename\n/path/to/file.vmdk\n-rawdisk\n/dev/sdb\n-register\nAdapt the above command to your need, especially the path and filename of the VMDK location and the raw disk location to map which contain your Arch Linux installation.\nOn a Windows host\nOpen a command prompt must be run as administrator.\nTip\nOn Windows, open your start menu/start screen, type\ncmd\n, and type\nCtrl+Shift+Enter\n, this is a shortcut to execute the selected program with admin rights.\nOn Windows, as the disk filename convention is different from UNIX, use this command to determine what drives you have in your Windows system and their location:\n# wmic diskdrive get name,size,model\nModel                               Name                Size\nWDC WD40EZRX-00SPEB0 ATA Device     \\\\.\\PHYSICALDRIVE1  4000783933440\nKINGSTON SVP100S296G ATA Device     \\\\.\\PHYSICALDRIVE0  96024821760\nHitachi HDT721010SLA360 ATA Device  \\\\.\\PHYSICALDRIVE2  1000202273280\nInnostor Ext. HDD USB Device        \\\\.\\PHYSICALDRIVE3  1000202273280\nIn this example, as the Windows convention is\n\\\\.\\PhysicalDriveX\nwhere X is a number from 0,\n\\\\.\\PHYSICALDRIVE1\ncould be analogous to\n/dev/sdb\nfrom the Linux disk terminology.\nTo use the\nVBoxManage\ncommand on Windows, you can either, change the current directory to your VirtualBox installation folder first with\ncd C:\\Program Files\\Oracle\\VirtualBox\\\n# .\\VBoxManage.exe internalcommands createrawvmdk -filename C:\\file.vmdk -rawdisk \\\\.\\PHYSICALDRIVE1\nor use the absolute path name:\n# \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage.exe\" internalcommands createrawvmdk -filename C:\\file.vmdk -rawdisk \\\\.\\PHYSICALDRIVE1\nOn another operating system host\nThere are other limitations regarding the aforementioned command when used in other operating systems like OS X, please thus\nread carefully the manual page\n, if you are concerned.\nCreate the virtual machine configuration file\nNote\nTo make use of the VBoxManage command on Windows, you need to change the current directory to your VirtualBox installation folder first:\ncd C:\\Program Files\\Oracle\\VirtualBox\\\n.\nWindows makes use of backslashes instead of slashes, please replace all slashes\n/\noccurrences by backslashes\n\\\nin the commands that follow when you will use them.\nAfter, we need to create a new machine (replace the\nvirtual_machine_name\nto your convenience) and register it with VirtualBox.\n$ VBoxManage createvm -name\nvirtual_machine_name\n-register\nThen, the newly raw disk needs to be attached to the machine. This will depend if your computer or actually the root of your native Arch Linux installation is on an IDE or a SATA controller.\nIf you need an IDE controller:\n$ VBoxManage storagectl\nvirtual_machine_name\n--name \"IDE Controller\" --add ide\n$ VBoxManage storageattach\nvirtual_machine_name\n--storagectl \"IDE Controller\" --port 0 --device 0 --type hdd --medium /path/to/file.vmdk\notherwise:\n$ VBoxManage storagectl\nvirtual_machine_name\n--name \"SATA Controller\" --add sata\n$ VBoxManage storageattach\nvirtual_machine_name\n--storagectl \"SATA Controller\" --port 0 --device 0 --type hdd --medium /path/to/file.vmdk\nWhile you continue using the CLI, it is recommended to use the VirtualBox GUI, to personalise the virtual machine configuration. Indeed, you must specify its hardware configuration as close as possible as your native machine: turning on the 3D acceleration, increasing video memory, setting the network interface, etc.\nFinally, you may want to seamlessly integrate your Arch Linux with your host operating system and allow copy pasting between both operating systems. Please refer to\nVirtualBox/Install Arch Linux as a guest#Install the Guest Additions\nfor that, since this Arch Linux virtual machine is basically an Arch Linux guest.\nWarning\nFor\nXorg\nto work in natively and in the virtual machine, since obviously it will be using different drivers, it is best if there is no\n/etc/X11/xorg.conf\n, so Xorg will pick up everything it needs on the fly. However, if you really do need your own Xorg configuration, maybe is it worth to set your default systemd target to\nmulti-user.target\nwith\nsystemctl isolate graphical.target\nas root (more details at\nsystemd#Targets\nand\nsystemd#Change current target\n). In that way, the graphical interface is disabled (i.e. Xorg is not launched) and after you logged in, you can\nstartx\n} manually with a custom\nxorg.conf\n.\nInstall a native Arch Linux system from VirtualBox\nIn some cases it may be useful to install a native Arch Linux system while running another operating system: one way to accomplish this is to perform the installation through VirtualBox on a\nraw disk\n. If the existing operating system is Linux based, you may want to consider following\nInstall from existing Linux\ninstead.\nThis scenario is very similar to\n#Run a native Arch Linux installation inside VirtualBox\n, but will follow those steps in a different order: start by\n#Create a raw disk VMDK image\n, then\n#Create the virtual machine configuration file\n.\nNow, you should have a working virtual machine configuration whose virtual VMDK disk is tied to a real disk. The installation process is exactly the same as the steps described in\nVirtualBox/Install Arch Linux as a guest\n, but\n#Make sure you have a persistent naming scheme\nand\n#Make sure your mkinitcpio image is correct\n.\nWarning\nFor BIOS systems and MBR disks, do not install a boot loader inside your virtual machine, this will not work since the MBR is not linked to the MBR of your real machine and your virtual disk is only mapped to a real partition without the MBR.\nFor UEFI systems without\nCSM\nand GPT disks, the installation will not work at all since:\nthe\nEFI system partition\nis not mapped to your virtual disk and Arch Linux requires to have the Linux kernel on it to boot as an EFI application (see\nEFI boot stub\nfor details);\nand the efivars, if you are installing Arch Linux using the EFI mode brought by VirtualBox, are not the one of your real system: the bootmanager entries will hence not be registered.\nThis is why, it is recommended to create your partitions in a native installation first, otherwize the partitions will not be taken into consideration in your MBR/GPT partition table.\nAfter completing the installation, boot your computer natively with an GNU/Linux installation media (whether it be Arch Linux or not),\nchroot\ninto your installed Arch Linux installation and install and configure a\nboot loader\n.\nInstall MacOS guest\nBefore starting the virtual machine, run the following commands on the host machine\n[4]\n:\n$ VBoxManage modifyvm \"MyMacVM\" --cpuid-set 00000001 000106e5 00100800 0098e3fd bfebfbff\n$ VBoxManage setextradata \"MyMacVM\" \"VBoxInternal/Devices/efi/0/Config/DmiSystemProduct\" \"iMac11,3\"\n$ VBoxManage setextradata \"MyMacVM\" \"VBoxInternal/Devices/efi/0/Config/DmiSystemVersion\" \"1.0\"\n$ VBoxManage setextradata \"MyMacVM\" \"VBoxInternal/Devices/efi/0/Config/DmiBoardProduct\" \"Iloveapple\"\n$ VBoxManage setextradata \"MyMacVM\" \"VBoxInternal/Devices/smc/0/Config/DeviceKey\" \"ourhardworkbythesewordsguardedpleasedontsteal(c)AppleComputerInc\"\n$ VBoxManage setextradata \"MyMacVM\" \"VBoxInternal/Devices/smc/0/Config/GetKeyFromRealSMC\" 1\n$ VBoxManage setextradata \"MyMacVM\" VBoxInternal2/EfiGopMode 4\nIf you use an AMD processor and the first boot gets stuck, you also have to run\n$ VBoxManage modifyvm \"MyMacVM\" --cpu-profile \"Intel Core i7-6700K\"\nNo keyboard/mouse input when attempting to install Mojave\nIf you are attempting to install Mojave, after doing the aforementioned steps, the installer will load up but you might not be able to send keyboard or mouse input. The reason seems to be that Mojave no longer supports the USB 1.1 controllers and in order to fix the issue you need to emulating USB 3.0. To do that first install the\nextension pack\n.\nThen go to\nMachine > Settings > USB\nand select\nUSB 3.0\n. Input should work from this point onwards.\nUEFI interactive shell after restart\nIf the installer is unable to properly format the bootable drive during installation and you end up in an UEFI shell, enter the following:\nType\nexit\nat the UEFI prompt\nSelect\nBoot Maintenance Manager\nSelect\nBoot From File\nYou will now be brought to couple of obscure PCI paths. The first one is the one that you just attempted to boot from and it did not work. The second (or third) one should be the one with the MacOS recovery partition that you need to load to continue the installation. Click the second Entry. If it is empty, press\nEsc\nto go back and select the third entry. Once you get one with folders click though the folders. It should be something like\nmacOS Install Data > Locked Files > Boot Files > boot.efi\n. Once you click enter on the\nboot.efi\nyou should boot into the MacOS installer and resume installation. Note that some of the subdirectories might be missing. Remember that you need to get to a\nboot.efi\n.\n[5]\nMove a native Windows installation to a virtual machine\nIf you want to migrate an existing native Windows installation to a virtual machine which will be used with VirtualBox on GNU/Linux, this use case is for you. This section only covers native Windows installation using the MSDOS/Intel partition scheme. Your Windows installation must reside on the first MBR partition for this operation to success. Operation for other partitions are available but have been untested (see\n#Known limitations\nfor details).\nWarning\nIf you are using an OEM version of Windows, this process is unauthorized by the end user license license. Indeed, the OEM license typically states the Windows install is tied with the hardware together. Transferring a Windows install to a virtual machine removes this link. Make thus sure you have a full Windows install or a volume license model before continuing. If you have a full Windows license but the latter is not coming in volume, nor as a special license for several PCs, this means you will have to remove the native installation after the transfer operation has been achieved.\nA couple of tasks are required to be done inside your native Windows installation first, then on your GNU/Linux host.\nTasks on Windows\nThe first three following points comes from\nthis outdated VirtualBox wiki page\n, but are updated here.\nRemove IDE/ATA controllers checks (Windows XP only): Windows memorize the IDE/ATA drive controllers it has been installed on and will not boot if it detects these have changed. The solution proposed by Microsoft is to reuse the same controller or use one of the same serial, which is impossible to achieve since we are using a Virtual Machine.\nMergeIDE\n, a German tool, developped upon another other solution proposed by Microsoft can be used. That solution basically consists in taking all IDE/ATA controller drivers supported by Windows XP from the initial driver archive (the location is hard coded, or specify it as the first argument to the\n.bat\nscript), installing them and registering them with the regedit database.\nUse the right type of Hardware Abstraction Layer (old 32 bits Windows versions): Microsoft ships 3 default versions:\nHal.dll\n(Standard PC),\nHalacpi.dll\n(ACPI HAL) and\nHalaacpi.dll\n(ACPI HAL with IO APIC). Your Windows install could come installed with the first or the second version. In that way, please\ndisable the\nEnable IO/APIC\nVirtualBox extended feature\n.\nDisable any AGP device driver (only outdated Windows versions): If you have the files\nagp440.sys\nor\nintelppm.sys\ninside the\nC:\\Windows\\SYSTEM32\\drivers\\\ndirectory, remove it. As VirtualBox uses a PCI virtual graphics card, this can cause problems when this AGP driver is used.\nCreate a Windows recovery disk: In the following steps, if things turn bad, you will need to repair your Windows installation. Make sure you have an install media at hand, or create one with\nCreate a recovery disk\nfrom Vista SP1,\nCreate a system repair disc\non Windows 7 or\nCreate a recovery drive\non Windows 8.x).\nUsing Disk2vhd to clone Windows partition\nBoot into Windows, clean up the installation (with\nCCleaner\nfor example), use\ndisk2vhd\ntool to create a VHD image. Include a reserved system partition (if present) and the actual Windows partition (usually disk C:). The size of Disk2vhd-created image will be the sum of the actual files on the partition (used space), not the size of a whole partition. If all goes well, the image should just boot in a virtual machine and you will not have to go through the hassle with MBR and Windows boot loader, as in the case of cloning an entire partition.\nTasks on GNU/Linux\nTip\nSkip the partition-related parts if you created VHD image with\nDisk2vhd\n.\nReduce the native Windows partition size to the size Windows actually needs with\nntfsresize\navailable from\nntfs-3g\n. The size you will specify will be the same size of the VDI that will be created in the next step. If this size is too low, you may break your Windows install and the latter might not boot at all.\nUse the\n--no-action\noption first to run a test:\n# ntfsresize --no-action --size\n52Gi\n/dev/sda1\nIf only the previous test succeeded, execute this command again, but this time without the aforementioned test flag.\nInstall VirtualBox on your GNU/Linux host (see\n#Installation steps for Arch Linux hosts\nif your host is Arch Linux).\nCreate the Windows disk image from the beginning of the drive to the end of the first partition where is located your Windows installation. Copying from the beginning of the disk is necessary because the MBR space at the beginning of the drive needs to be on the virtual drive along with the Windows partition. In this example two following partitions\nsda2\nand\nsda3\nwill be later removed from the partition table and the MBR boot loader will be updated.\n# sectnum=$(( $(cat /sys/block/\nsda/sda1\n/start) + $(cat /sys/block/\nsda/sda1\n/size) ))\nUsing\ncat /sys/block/\nsda/sda1\n/size\nwill output the number of total sectors of the first partition of the disk\nsda\n. Adapt where necessary.\n# dd if=\n/dev/sda\nbs=512 count=$sectnum | VBoxManage convertfromraw stdin\nwindows.vdi\n$(( $sectnum * 512 ))\nWe need to display the size in byte,\n$(( $sectnum * 512 ))\nwill convert the sector numbers to bytes.\nSince you created your disk image as root, set the right ownership to the virtual disk image:\n# chown\nyour_user\n:\nyour_group\nwindows.vdi\nCreate your virtual machine configuration file and use the virtual disk created previously as the main virtual hard disk.\nTry to boot your Windows virtual machine, it may just work. First though remove and repair disks from the boot process as it may interfere (and likely will) booting into safe-mode.\nAttempt to boot your Windows virtual machine in safe mode (press the F8 key before the Windows logo shows up)... if running into boot issues, read\n#Fix MBR and Microsoft boot loader\n. In safe-mode, drivers will be installed likely by the Windows plug-and-play detection mechanism\nview\n. Additionally, install the VirtualBox\nGuest Additions\nvia the menu\nDevices\n>\nInsert Guest Additions CD image...\n. If a new disk dialog does not appear, navigate to the CD drive and start the installer manually.\nYou should finally have a working Windows virtual machine. Do not forget to read the\n#Known limitations\n.\nPerformance tip: according to\nVirtualBox manual\n, SATA controller has a better performance than IDE. If you cannot boot Windows off virtual SATA controller right away, it is probably due to the lack of SATA drivers. Attach virtual disk to IDE controller, create an empty SATA controller and boot the virtual machine - Windows should automatically install SATA drivers for the controller. You can then shutdown the virtual machine, detach virtual disk from IDE controller and attach it to SATA controller instead.\nFix MBR and Microsoft boot loader\nIf your Windows virtual machine refuses to boot, you may need to apply the following modifications to your virtual machine.\nBoot a GNU/Live live distribution inside your virtual machine before Windows starts up.\nRemove other partitions entries from the virtual disk MBR. Indeed, since we copied the MBR and only the Windows partition, the entries of the other partitions are still present in the MBR, but the partitions are not available anymore. Use\nfdisk\nto achieve this for example.\nfdisk ''/dev/sda''\nCommand (m for help): a\nPartition number (''1-3'', default ''3''): ''1''\nWrite the updated partition table to the disk (this will recreate the MBR) using the\nm\ncommand inside\nfdisk\n.\nUse\ntestdisk\n(see\nhere\nfor details) to add a generic MBR:\n# testdisk >\nDisk /dev/sda...\n> [Proceed] > [Intel] Intel/PC partition > [MBR Code] Write TestDisk MBR to first sector > Write a new copy of MBR code to first sector? (Y/n) > Y > Write a new copy of MBR code, confirm? (Y/N) > A new copy of MBR code has been written. You have to reboot for the change to take effect. > [OK]\nWith the new MBR and updated partition table, your Windows virtual machine should be able to boot. If you are still encountering issues, boot your Windows recovery disk from on of the previous step, and inside your Windows RE environment, execute the commands\ndescribed here\n.\nKnown limitations\nYour virtual machine can sometimes hang and overrun your RAM, this can be caused by conflicting drivers still installed inside your Windows virtual machine. Good luck to find them!\nAdditional software expecting a given driver beneath may either not be disabled/uninstalled or needs to be uninstalled first as the drivers that are no longer available.\nYour Windows installation must reside on the first partition for the above process to work. If this requirement is not met, the process might be achieved too, but this had not been tested. This will require either copying the MBR and editing in hexadecimal see\nVirtualBox: booting cloned disk\nor will require to fix the partition table\nmanually\nor by repairing Windows with the recovery disk you created in a previous step. Let us consider our Windows installation on the second partition; we will copy the MBR, then the second partition where to the disk image.\nVBoxManage convertfromraw\nneeds the total number of bytes that will be written: calculated thanks to the size of the MBR (the start of the first partition) plus the size of the second (Windows) partition.\n{ dd if=/dev/sda bs=512 count=$(cat /sys/block/sda/sda1/start) ; dd if=/dev/sda2 bs=512 count=$(cat /sys/block/sda/sda2/size) ; } | VBoxManage convertfromraw stdin windows.vdi $(( ($(cat /sys/block/sda/sda1/start) + $(cat /sys/block/sda/sda2/size)) * 512 ))\n.\nRun a native Windows installation inside VirtualBox\nNote\nThe technique outlined in this section only applies to\nUEFI\nsystems.\nIn some cases, it is useful to be able to\ndual boot with Windows\nand\naccess the partition in a virtual machine. This process is significantly different from\n#Move a native Windows installation to a virtual machine\nin several ways:\nThe Windows partition is not copied to a virtual disk image. Instead, a raw VMDK file is created;\nChanges in the virtual machine will be mirrored in the partition, and vice versa;\nOEM licenses should still be satisfied, since the Windows partition still boots directly on the hardware.\nWarning\nSome of the commands used here can corrupt either the Windows partition, the Arch Linux partition, or both. Use extreme caution when executing commands, and double check that they are being run in the correct shell. It would be a good idea to have a backup of the entire drive ready before beginning this process.\nNote\nBefore proceeding be sure to have access to a Windows installation media (such as the\nWindows 11 ISO\n).\nCreating the virtual machine\nA VirtualBox virtual machine must be manually created. As of now do not add any storage device any disk to the virtual machine, it will be done manually later.\nConfigure the virtual machine with the following settings (settings panel can be opened by clicking the \"Settings\" button in the main toolbar):\nView: System:\nTab: Motherboard:\nmark\nEnable I/O APIC\n;\nmark\nEnable EFI\n;\nmark\nHardware Clock in UTC Time\nif is your case.\nTab: Processor:\nmark\nEnable PAE/NX\n;\nmark\nEnable Nested VT-x/AMD-V\n;\nTab: Acceleration:\nChoose the paravirtualization interface\nHyper-V\nfrom the drop down menu;\nmark\nEnable Nested Paging\n.\nOptionally you can enable also the following settings:\nView: Display\nTab: Screen\nmark\nEnable 3D Acceleration\n. Note that it could cause glitches.\nNote\nThe\nHyper-V\nsetting is not required in order for the system to operate correctly, but it may help avoid licensing issues.\nCreating virtual machine disks\nTo access the Windows partitions, create a\nraw VMDK file\npointing to the relevant Windows partitions (root privileges are required to read disk partition table):\n# VBoxManage createmedium disk -filename\nVM_DIRECTORY\n/windows.vmdk --format=VMDK --variant RawDisk --property RawDrive=\nDISK\n--property Partitions=\nRESERVED_PARTITION_NUMBER\n,\nBASIC_DATA_PARTITION_NUMBER\nReplace capitalized placeholder strings as follow:\nVM_DIRECTORY\nwith the path of the virtual machine folder (usually a subdirectory of\n~/VirtualBox VMs\n;\nDISK\nmust be replaced with the block device containing all the Windows partitions (e.g.:\n/dev/sda\nor\n/dev/nvme0n1\n);\nRESERVED_PARTITION_NUMBER\nmust be replaced with the number of partition labeled \"Microsoft reserved partition\" (e.g.: if the partition is the\n/dev/sda2\nthe number will be\n2\n);\nBASIC_DATA_PARTITION_NUMBER\nmust be replaced with the partition containing the Windows installation (e.g.: if the partition is the\n/dev/sda3\nthe number will be\n3\n);\nExample:\n# VBoxManage createmedium disk -filename \"/home/user/VirtualBox VMs/windows.vmdk\" --format=VMDK --variant RawDisk --property RawDrive=/dev/nvme0n1 --property Partitions=2,3\nThe command will also create an extra file inside the virtual machine folder, \"windows-pt.vmdk\", that will be just ignored.\nNote\nwindows.vmdk\nmust be re-created if the partition table is changed.\nTip\nPartition numbers can be found also by running this command and looking at the MIN column:\nlsblk --output NAME,PARTLABEL,FSTYPE,MAJ:MIN,SIZE\nNAME        PARTLABEL                    FSTYPE UUID                                 MAJ:MIN   SIZE\nnvme0n1                                                                              259:0   931,5G\n├─nvme0n1p1 EFI system partition         vfat   90DC-A6B3                            259:1     100M\n├─nvme0n1p2 Microsoft reserved partition                                             259:2      16M\n├─nvme0n1p3 Basic data partition         ntfs   D2A2A104A2A0EE63                     259:3     200G\n...\nNow change the virtual disk owner to give access the user and group running VirtualBox.\n# chown\nVIRTUALBOX_RUNNING_USER\n:\nVIRTUALBOX_RUNNING_GROUP\nVM_DIRECTORY\n/windows.vmdk\nVM_DIRECTORY\n/windows-pt.vmdk\nReplace\nVIRTUALBOX_RUNNING_USER\nand\nVIRTUALBOX_RUNNING_GROUP\nwith the user and the group that will run VirtualBox, which most likely will be your user.\nAllowing VirtualBox to read physical partitions\nVirtualBox must have\nraw disk access\nin order to run a Windows partition. Normally, this would require VirtualBox to be run with full root privileges, but more elegant options are available.\nHigher security option: using a dedicated group for the Windows partitions\nHere\nudev\nis configured to restrict the access to partitions Windows partitions to the\nvboxusers\ngroup, and then the user running VirtualBox is added to the group.\nAssigning the disks to the\nvboxusers\ngroup can be done automatically by creating the following file:\n/etc/udev/rules.d/99-vbox.rules\n#\n# Rules to give VirtualBox users raw access to Windows partitions\n#\n# Microsoft Reserved partition\nSUBSYSTEM==\"block\", ENV{ID_PART_ENTRY_TYPE}==\"e3c9e316-0b5c-4db8-817d-f92df00215ae\", GROUP=\"vboxusers\"\n# Windows partition\nSUBSYSTEM==\"block\", ENV{ID_PART_ENTRY_TYPE}==\"ebd0a0a2-b9e5-4433-87c0-68b6b72699c7\", GROUP=\"vboxusers\"\n#\n# Rules to give VirtualBox users raw access to Windows disk\n#\n# sdb\nENV{ID_PART_TABLE_UUID}==\"WINDOWS_DISK_ID_PART_TABLE_UUID\", GROUP=\"vboxusers\"\nWINDOWS_DISK_ID_PART_TABLE_UUID\nmust be replaced with the value obtained from\nudevadm info /dev/WINDOWS_DISK\n(replace\nWINDOWS_DISK\nwith the disk containing Windows partitions). The UUIDs in these rules correspond to particular\nGPT partition types\nwhile the other capitalized strings are supposed to be written that way, so those does not have to be replaced.\nThen the user running VirtualBox must be added to the\nvboxusers\ngroup. This can be done with the following command:\n# usermod -aG vboxusers VIRTUALBOX_RUNNING_USER\nReplace\nVIRTUALBOX_RUNNING_USER\nand with the user that will run VirtualBox, which most likely will be your user.\nLower security option: using 'disk' group\nTo be able to add the VMDK file in VirtualBox Virtual Media Manager without running VirtualBox as root, the user running VirtualBox need to be in\nvboxusers\nand\ndisk\ngroups.\n# usermod -aG disk,vboxusers VIRTUALBOX_RUNNING_USER\nReplace\nVIRTUALBOX_RUNNING_USER\nand with the user that will run VirtualBox, which most likely will be your user.\nWarning\nBe aware of the potential security implications of this edit, as you are giving your user account full read-write access all storage devices owned by the disk group.\nSetting up a separate EFI system partition\nVirtual machine EFI boot files will refer to different disks than the ones in the physical EFI system partition, so VirtualBox must not make use of the latter but instead of an EFI system partition inside a dedicated virtual disk. This disk can be created with the following command:\n$ VBoxManage createmedium disk --filename\nVM_DIRECTORY/esp.vmdk\n--size 512 --format VMDK\nReplace\nVM_DIRECTORY\nwith the folder containing the virtual machine being built.\nAdding virtual disks to the virtual machine\nConfigure the virtual machine storage devices (Settings panel - Storage) as following:\nadd\nesp.vmdk\nas a SATA hard disk attached to the \"SATA Port 0\";\nadd\nwindows.vmdk\nas a SATA hard disk attached to the \"SATA Port 1\";\nmount Windows installation iso into the virtual optical drive .\nNote\nfor adding a SATA hard disk use the second button on the right of the \"Controller: SATA\" device;\nthe virtual optical drive should already be there as \"Optical Drive\".\nConfiguring the virtual UEFI firmware and creating Windows boot files\nNow start the virtual machine and it should automatically boot from Windows installation disk. After choosing the installation locales click on the \"Repair your computer\" link, then choose \"Troubleshoot\" and then \" Command Prompt\" in order to launch a command prompt from the install media.\nEnter the following commands to create a new GPT table in the esp.vmdk disk and install the Windows boot loader onto it using configuration from the existing Windows partition:\nOpen Diskpart:\nX:\\ diskpart\nList all disks identified by the system:\nDISKPART> list disk\nThe\nesp.vmkd\ndisk should be labeled as\ndisk 0\ndue to the fact that was attached to the SATA port 0, ~512 MiB in size and unpartitioned. The\nwindows.vmdk\ndisk should be labeled as\ndisk 1\n; note that the column \"Size\" displays the disk size, not the partition one.\nSelect the esp.vmdk disk:\nDISKPART> select Disk 0\nNow create a GPT partition table, an EFI system partition, big as the whole disk, and assign to it a label and drive letter:\nDISKPART> clean\nDISKPART> convert gpt\nDISKPART> create partition efi size=500\nDISKPART> format quick fs=fat32 label=\"System\"\nDISKPART> assign letter=\"S\"\nCheck that the partition has been correctly created:\nDISKPART> list volume\nOur newly created EFI system partition will be labeled as \"SYSTEM\" with letter as \"S\".\nTake note of the Windows installation volume letter because it will be used in next steps. Usually its\nD\nbut it could be different: you can infer it from its label and its size. The size is the same as the Windows installation partition size on your physical hard disk.\nExit diskpart:\nDISKPART> exit\nInstall the Windows boot loader into the EFI system partition.\nD:\ncd Windows\\System32\nbcdboot D:\\Windows /s S: /f UEFI\nNow close the command prompt, power off the virtual machine and detach the Windows installation disk (from \"Preferences > Devices\" remove the optical disk). The virtual machine should now boot from the newly installed boot partition and load the physical Windows installation. It may show some UEFI related errors on the top of the virtual machine window and the first boot may take a while, but if everything has been done correctly you will be able to access your windows installation.\nRun an entire physical disk in VirtualBox\nNote\nYou may refer to VirtualBox official documentation\n9.8.1. Using a Raw Host Hard Disk From a Guest\n.\nThis works the same way as\n#Run a native Windows installation inside VirtualBox\nbut the vmdk will contain the entire disk rather than one partition, and so you will not need to create a separate ESP or MBR partition as the one in the physical disk will be used.\nCreate the raw disk:\n# VBoxManage internalcommands createrawvmdk -filename /path/to/file.vmdk -rawdisk /dev/sdb\nThen follow the same method as in\n#Run a native Windows installation inside VirtualBox\nfor the configuration and virtual disk attachement.\nSet guest starting resolution\nTypically after installing Guest Additions, a fullscreen Arch guest running X will be set to the optimal resolution for your display; however, the virtual console's framebuffer will be set to a standard, often smaller, resolution detected from VirtualBox's custom VESA driver.\nTo use the virtual consoles at optimal resolution, Arch needs to recognize that resolution as valid, which in turn requires VirtualBox to pass this information along to the guest OS.\nFirst, check if your desired resolution is not already recognized by running the command (\nhwinfo\nneed to be installed):\nhwinfo --framebuffer\nIf the optimal resolution does not show up, then you will need to run the\nVBoxManage\ntool on the host machine and add \"extra resolutions\" to your virtual machine (on a Windows host, go to the VirtualBox installation directory to find\nVBoxManage.exe\n). For example:\n$ VBoxManage setextradata \"Arch Linux\" \"CustomVideoMode1\" \"1360x768x24\"\nThe parameters \"Arch Linux\" and \"1360x768x24\" in the example above should be replaced with your virtual machine name and the desired framebuffer resolution. Incidentally, this command allows for defining up to 16 extra resolutions (\"CustomVideoMode1\" through \"CustomVideoMode16\"). Recommended resolutions are 1280x720, 1920x1080, 2048x1080, 2560x1440, 3840x2160, 1280x800, 1280x1024, 1440x900, 1600x900.\nAfterwards, restart the virtual machine and run\nhwinfo --framebuffer\nonce more to verify that the new resolutions have been recognized by your guest system (which does not guarantee they will all work, depending on your hardware limitations).\nNote\nAs of VirtualBox 5.2,\nhwinfo --framebuffer\nmight not show any output, but you should still be able to set a custom resolution following this procedure.\nFinally, add a\nvideo=\nresolution\nkernel parameter\nto set the framebuffer to the new resolution, for example:\nvideo=1360x768\nAdditionally you may want to configure your\nboot loader\nto use the same resolution. If you use GRUB, see\nGRUB/Tips and tricks#Setting the framebuffer resolution\n.\nNote\nNeither the kernel parameter\nvga\nnor the boot loader's resolution settings (e.g. GRUB's\nGRUB_GFXPAYLOAD_LINUX\n) will fix the framebuffer, since they are overriden by virtue of Kernel Mode Setting. The framebuffer resolution must be set by the kernel parameter\nvideo\nas described above.\nSSH from host to guest\nThe network tab of the virtual machine settings contains, in \"Advanced\", a tool to create port forwarding.\nIt is possible to use it to forward the Guest ssh port\n22\nto a Host port, e.g.\n3022\n:\nuser@host$ ssh -p 3022 $USER@localhost\nwill establish a connection from Host to Guest.\nSSHFS as alternative to shared folders\nUsing this port forwarding and\nSSHFS\nit is straightforward to mount the Guest filesystem onto the Host one:\nuser@host$ sshfs -p 3022 $USER@localhost:$HOME ~/shared_folder\nand then transfer files between both.\nTroubleshooting\nKeyboard and mouse are locked into virtual machine\nThis means your virtual machine has captured the input of your keyboard and your mouse. Simply press the right\nCtrl\nkey and your input should control your host again.\nTo control transparently your virtual machine with your mouse going back and forth your host, without having to press any key, and thus have a seamless integration, install the\nguest additions\ninside the guest. Read from\nVirtualBox/Install Arch Linux as a guest#Install the Guest Additions\nif your guest is Arch Linux, otherwise read the official VirtualBox help.\nNo 64-bit operating system client options\nWhen launching a virtual machine client, and no 64-bit options are available, make sure your CPU virtualization capabilities (usually named\nVT-x\n) are enabled in the BIOS.\nIf you are using a Windows host, you may need to disable Hyper-V, as it prevents VirtualBox from using VT-x.\n[6]\nVirtualBox GUI does not match host GTK theme\nSee\nUniform look for Qt and GTK applications\nfor information about theming Qt-based applications like VirtualBox.\nCannot send Ctrl+Alt+Fn to guest\nYour guest operating system is a GNU/Linux distribution and you want to open a new TTY shell by hitting\nCtrl+Alt+F2\nor exit your current X session with\nCtrl+Alt+Backspace\n. If you type these keyboard shortcuts without any adaptation, the guest will not receive any input and the host (if it is a GNU/Linux distribution too) will intercept these shortcut keys. To send\nCtrl+Alt+F2\nto the guest for example, simply hit your\nHost Key\n(usually the right\nCtrl\nkey) and press\nF2\nsimultaneously.\nUSB subsystem not working\nYour user must be in the\nvboxusers\ngroup and you need to install the\nextension pack\nif you want USB 2 support. Then you will be able to enable USB 2 in the virtual machine settings and add one or several filters for the devices you want to access from the guest operating system.\nIf\nVBoxManage list usbhost\ndoes not show any USB devices even if run as root, make sure that there is no old udev rules (from VirtualBox 4.x) in\n/etc/udev/rules.d/\n. VirtualBox 5.0 installs udev rules to\n/usr/lib/udev/rules.d/\n. You can use command like\npacman -Qo /usr/lib/udev/rules.d/60-vboxdrv.rules\nto determine if the udev rule file is outdated.\nSometimes, on old Linux hosts, the USB subsystem is not auto-detected resulting in an error\nCould not load the Host USB Proxy service: VERR_NOT_FOUND\nor in a not visible USB drive on the host,\neven when the user is in the\nvboxusers\ngroup\n. This problem is due to the fact that VirtualBox switched from\nusbfs\nto\nsysfs\nin version 3.0.8. If the host does not understand this change, you can revert to the old behaviour by defining the following environment variable in any file that is sourced by your shell (e.g. your\n~/.bashrc\nif you are using\nbash\n):\n~/.bashrc\nVBOX_USB=usbfs\nThen make sure, the environment has been made aware of this change (reconnect, source the file manually, launch a new shell instance or reboot).\nAlso make sure that your user is a member of the\nstorage\ngroup.\nUSB modem not working on host\nIf you have a USB modem which is being used by the guest operating system, killing the guest operating system can cause the modem to become unusable by the host system. Killing and restarting\nVBoxSVC\nshould fix this problem.\nUSB device crashes guest\nIf attaching a USB device to the guest causes a crash or any other erroneous behavior, try switching the USB controller from USB 2 (EHCI) to USB 3 (xHCI) or vice versa.\nHost freezes on virtual machine start\nGenerally, such issues are observed after upgrading VirtualBox or Linux kernel. Downgrading them to the previous versions of theirs might solve the problem.\nAnalog microphone not working\nIf the audio input from an analog microphone is working correctly on the host, but no sound seems to get through to the guest, despite the microphone device apparently being detected normally, installing a\nsound server\nsuch as\nPulseAudio\non the host might fix the problem.\nIf after installing\nPulseAudio\nthe microphone still refuses to work, setting\nHost Audio Driver\n(under\nVirtualBox > Machine > Settings > Audio\n) to\nALSA Audio Driver\nmight help.\nProblems with images converted to ISO\nSome image formats cannot be reliably converted to ISO. For instance,\nccd2iso\nignores .ccd and .sub files, which can result in disk images with broken files.\nIn this case, you will either have to use\nCDemu\nfor Linux inside VirtualBox or any other utility used to mount disk images.\nFailed to create the host-only network interface\nMake sure all required kernel modules are loaded. See\n#Load the VirtualBox kernel modules\n.\nIf all required kernel modules are loaded and you are still unable to create the host-only adapter, navigate to\nFile > Host Network Manager\nand click the\nCreate\nbutton to add the network interface.\nFailed to insert module\nWhen you get the following error when trying to load modules:\nFailed to insert 'vboxdrv': Required key not available\nSign\nyour modules or disable\nCONFIG_MODULE_SIG_FORCE\nin your kernel config.\nVBOX_E_INVALID_OBJECT_STATE (0x80BB0007)\nThis can occur if a virtual machine is exited ungracefully. Run the following command:\n$ VBoxManage controlvm\nvirtual_machine_name\npoweroff\nNS_ERROR_FAILURE and missing menu items\nThis error might appear if\nextension pack\nhas not been updated and becomes incompatible with a newly released VirtualBox version.\nThis error also happens sometimes when selecting\nQCOW\n/\nQCOW2\n/\nQED\ndisk format when creating a new virtual disk.\nIf you encounter this message the first time you start the virtual machine:\nFailed to open a session for the virtual machine debian.\nCould not open the medium '/home/.../VirtualBox VMs/debian/debian.qcow'.\nQCow: Reading the L1 table for image '/home/.../VirtualBox VMs/debian/debian.qcow' failed (VERR_EOF).\nVD: error VERR_EOF opening image file '/home/.../VirtualBox VMs/debian/debian.qcow' (VERR_EOF).\nResult Code:\nNS_ERROR_FAILURE (0x80004005)\nComponent:\nMedium\nExit VirtualBox, delete all files of the new machine and from VirtualBox configuration file remove the last line in\nMachineRegistry\nmenu (or the offending machine you are creating):\n~/.config/VirtualBox/VirtualBox.xml\n...\n<MachineRegistry>\n<MachineEntry uuid=\"{00000000-0000-0000-0000-000000000000}\" src=\"/home/void/VirtualBox VMs/debian/debian.vbox\"/>\n<MachineEntry uuid=\"{00000000-0000-0000-0000-000000000000}\" src=\"/home/void/VirtualBox VMs/ubuntu/ubuntu.vbox\"/>\n<MachineEntry uuid=\"{00000000-0000-0000-0000-000000000000}\" src=\"/home/void/VirtualBox VMs/lastvmcausingproblems/lastvmcausingproblems.qcow\"/>\n</MachineRegistry>\n...\nOpenBSD unusable when virtualisation instructions unavailable\nWhile OpenBSD is reported to work fine on other hypervisors without virtualisation instructions (VT-x AMD-V) enabled, an OpenBSD virtual machine running on VirtualBox without these instructions will be unusable, manifesting with a bunch of segmentation faults. Starting VirtualBox with the\n-norawr0\nargument\nmay solve the problem\n. You can do it like this:\n$ VBoxSDL -norawr0 -vm\nname_of_OpenBSD_virtual_machine\nWindows: \"The specified path does not exist. Check the path and then try again.\"\nThis error message may appear when running an\n.exe\nfile which requires administrator privileges from a shared folder in windows guests.\n[7]\nAs a workaround, copy the file to the virtual drive or use\nUNC paths\n(\n\\\\vboxsvr\n). See\n[8]\nfor more information.\nWindows 8.x error code 0x000000C4\nIf you get this error code while booting, even if you choose operating system type Win 8, try to enable the\nCMPXCHG16B\nCPU instruction:\n$ vboxmanage setextradata\nvirtual_machine_name\nVBoxInternal/CPUM/CMPXCHG16B 1\nWindows 8, 8.1 or 10 fails to install, boot or has error \"ERR_DISK_FULL\"\nUpdate the virtual machine's settings by going to\nSettings > Storage > Controller:SATA\nand check\nUse Host I/O Cache\n.\nWinXP: Bit-depth cannot be greater than 16\nIf you are running at 16-bit color depth, then the icons may appear fuzzy/choppy. However, upon attempting to change the color depth to a higher level, the system may restrict you to a lower resolution or simply not enable you to change the depth at all. To fix this, run\nregedit\nin Windows and add the following key to the Windows XP virtual machine's registry:\n[HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows NT\\Terminal Services]\n\"ColorDepth\"=dword:00000004\nThen update the color depth in the \"desktop properties\" window. If nothing happens, force the screen to redraw through some method (i.e.\nHost+f\nto redraw/enter full screen).\nWindows: Screen flicker if 3D acceleration enabled\nVirtualBox > 4.3.14 has a regression in which Windows guests with 3D acceleration flicker. Since r120678 a patch has been implemented to recognize an\nenvironment variable\nsetting, launch VirtualBox like this:\n$ CR_RENDER_FORCE_PRESENT_MAIN_THREAD=0 VirtualBox\nMake sure no VirtualBox services are still running. See\nVirtualBox bug 13653\n.\nCannot launch VirtualBox with Wayland: Segmentation fault\nThis problem is caused by Qt detecting Wayland (e.g., if\nXDG_SESSION_TYPE=wayland\n), while VirtualBox does not work on Wayland yet. See\nFS#58761\nand the\nupstream bug\n.\nThe Qt platform detection can be disabled and X11 forced over Wayland by setting the\nenvironment variable\nQT_QPA_PLATFORM=xcb\n.\nTo not affect the other Qt applications (which usually work well with Wayland),\nQT_QPA_PLATFORM=xcb\nshould only be set when launching VirtualBox.\nIf starting through the\ndesktop entry\n, follow the instructions in\nDesktop entries#Modify environment variables\nand change the lines starting with\nExec=VirtualBox ...\nto\nExec=env QT_QPA_PLATFORM=xcb VirtualBox ...\n. If starting from the shell, alias (\nBash#Aliases\n)\nvirtualbox\nto\nenv QT_QPA_PLATFORM=xcb virtualbox\n.\nNote\nIf you have mouse or keyboard related issue in Wayland, you can try above setting too.\nRandom freezing in guests with Intel GPU\nWith Intel CPU and graphics, allocating more processors for the guest can lower render performance, thus cause random freezing. Allocating less processors can help.\nUnable to view desktop in fullscreen mode\nDisable the Mini Toolbar by selecting\nMachine > Settings\n, select the\nUser Interface\ntab and uncheck the\nMini Toolbar\ncheckbox\nRandom crashes with Windows 10 guest operating system with Intel Tiger Lake chipset\nDisable split lock detection by adding\nsplit_lock_detect=off\nto the\nkernel parameters\n.\nDetails are described in VirtualBox's\nTicket #20180\n.\nFailed to save the settings when enabling Secure Boot\nIn VirtualBox 7.0.0, enabling Secure Boot in a virtual machine that was created in a previous VirtualBox version will fail with a nondescript error (\nFS#76234\n):\nFailed to save the settings.\nThe solution is to click the\nReset Keys to Default\nbutton right below the\nEnable Secure Boot\ncheckbox.\nFailed to start VirtualBox machine after using Android Studio emulator\nKVM and VirtualBox kernel modules can be loaded but not used simultaneously. Android Studio emulator is a QEMU emulator, which uses KVM for acceleration. So Android Studio emulator and VirtualBox machine (if hardware acceleration is enabled) cannot run at the same time. We have to use one after the other stopped completely.\nSometimes, VirtualBox kernel module can still be used unexpectedly by some process, and keep all VirtualBox machines failing to start, the error message on VirtualBox GUI is \"A critical error has occurred\".\nAt this time, we can check and reload VirtualBox kernel modules using\nvboxreload\nas root. If it saying some modules is still be in use, you need to manually kill related process and rerun the command.\n3D Acceleration is not working\nMake sure guest additions are installed on guest, and the host modules are installed on the host\nMake sure the guest additions and host kernel modules versions match\nhost:\nmodinfo vboxdrv | grep '^version:'\nguest: open logs of your VM, find \"Guest Additions information report\"\nMake sure vulkan is installed and\nworking\non the host\nVirtualBox UI elements are improperly rendered with Kvantum installed\nOn some configurations of Kvantum (\nkvantum\n) with third party themes, some UI elements such as toolbars and menus are rendered black or improperly. This seems to be limited to translucent windows being enabled. See Kvantum's issue\n#418\n.\nTo fix this behavior, do one of:\nDisable\nTranslucent windows\nunder section\nConfigure Active Theme > Compositing & General Look\nof\nKvantum Manager\n.\nAdd\nVirtualBox,VirtualBoxVM\nin\nKvantum Manager\n, to the\nConfigure Active Theme > Compositing & General Look > Opaque apps:\nmenu field.\nThis makes an exception for virtualbox windows to be ignored.\nVirtualBox is taking exclusive control of an audio device, preventing PipeWire from accessing it while the virtual machine is running\nBy default, VirtualBox should auto-select the best audio driver. However, on PipeWire systems this often falls back to ALSA (see\nPipewire issue\n).\nIt could cause journal records like these:\npipewire[2370]: spa.audioadapter: params Spa:Enum:ParamId:EnumFormat: 1:0 (convert format) Device or reso>\npipewire[2370]: pw.node: (alsa_output.pci-0000_00_1f.3-platform-skl_hda_dsp_generic.HiFi__Speaker__sink-6>\npipewire[2370]: spa.alsa: '_ucm0001.hw:sofhdadsp': playback open failed: Device or resource busy\nThe solution is to configure VirtualBox to use the PulseAudio backend (which PipeWire will handle\nvia pipewire-pulse\n):\n$ VBoxManage modifyvm \"\nYour_virtual_machine_name\n\" --audio-driver pulse --audio-controller hda\nSee also\nUser Guide\non a single HTML page\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=VirtualBox&oldid=852699\n\"\nCategories\n:\nHypervisors\nOracle\nHidden categories:\nPages with dead links\nPages or sections flagged with Template:Style\nSearch\nSearch\nVirtualBox\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/VirtualBox"}}
{"text": "Python - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPython\n6 languages\nDeutsch\n日本語\nPortuguês\nРусский\nУкраїнська\n中文（简体）\nFrom ArchWiki\nRelated articles\n/Virtual environment\nDjango\nList of applications/Utilities#Python IDEs\nPython package guidelines\nmod_wsgi\nFrom\nWhat is Python?\n:\nit is an interpreted, interactive, object-oriented programming language;\nit incorporates modules, exceptions, dynamic typing, very high level dynamic data types, and classes;\nit supports multiple programming paradigms beyond object-oriented programming, such as procedural and functional programming;\nit combines remarkable power with very clear syntax;\nit has interfaces to many system calls and libraries, as well as to various window systems, and is extensible in C or C++;\nit is also usable as an extension language for applications that need a programmable interface;\nit is portable—it runs on many Unix variants including Linux and macOS, and on Windows.\nInstallation\nInstall\nthe\npython\npackage.\nOther versions\nPrevious and future versions of Python are available via the\nArch User Repository\n(AUR). These are useful for applications or projects that require specific versions, or just for curiosity:\nNote\nPython versions before 3.9 have reached end of life and are unmaintained.\nTip\nSee also\nStatus of Python versions\n.\nPython 3.14:\npython314\nAUR\n(pre-release)\nPython 3.14:\npython314-freethreaded\nAUR\n(\nfree-threaded\n—with\nGlobal Interpreter Lock\n, or GIL, disabled)\nPython 3.13:\npython313-freethreaded\nAUR\n(free-threaded)\nPython 3.12:\npython312\nAUR\nPython 3.11:\npython311\nAUR\nPython 3.10:\npython310\nAUR\nPython 3.9:\npython39\nAUR\nPython 3.8:\npython38\nAUR\n(\nunmaintained\n)\nPython 3.7:\npython37\nAUR\n(\nunmaintained\n)\nPython 3.6:\npython36\nAUR\n(\nunmaintained\n)\nPython 2.7:\npython2\nAUR\n(\nunmaintained\n)\nEach of these packages installs a distinct binary named after the version number, e.g.\npython3.13\nfor Python 3.13, allowing multiple versions to coexist on a system. You can also use\npyenv(1)\nor\nuv\nto easily install and switch between multiple versions of Python.\nExtra modules and libraries for old versions of Python may be found in the AUR by searching for\npython<\nversion without period\n>\n, e.g. searching for\npython39\nfor Python 3.9 modules.\nYou can also download the source for any release on the\nhttps://www.python.org/downloads/\npage.\nAlternative implementations\nThe\npython\npackage installs\nCPython\n, the reference implementation of Python. However, there are also other implementations available. These implementations are usually based on older versions of Python and are not fully compatible with CPython.\nImplementations available on Arch Linux include:\nPyPy\n—  A Python implementation written in Python. It has speed and memory usage advantages compared to CPython.\nhttps://www.pypy.org\n||\npypy\n,\npypy3\nJython\n— An implementation of the Python language written in Java. It can be used to embed Python scripting into Java programs or use Java libraries in Python programs.\nhttps://www.jython.org/\n||\njython\nmicropython\n— Python for microcontrollers. It includes a small subset of the Python standard library and is optimized to run on microcontrollers and in constrained environments.\nhttps://micropython.org/\n||\nmicropython\nAUR\nIronPython\n— An implementation of the Python programming language which is tightly integrated with\n.NET\n. It can use .NET libraries and allows .NET programs to use Python libraries.\nhttps://ironpython.net\n||\nironpython-git\nAUR\nMore implementations exist\n. Some, such\nCinder\n, are used internally at large technology companies. Others are historically notable but are no longer maintained due to improvements in the most popular implementations.\nAlternative shells\nThe\npython\npackage includes an interactive Python shell/REPL which can be launched with the\npython\ncommand. The following shells are also available:\nbpython\n— A fancy interface for the Python interpreter.\nhttps://bpython-interpreter.org/\n||\nbpython\nIPython\n— A powerful interactive Python shell.\nhttps://ipython.org/\n||\nipython\nJupyter\n— A web-based computation application powered by IPython.\nhttps://jupyter.org/\n||\njupyterlab\n,\njupyter-notebook\nptpython\n— An advanced Python REPL built with\nprompt-toolkit\n.\nhttps://github.com/prompt-toolkit/ptpython\n||\nptpython\nAUR\nPackage management\nThere are several ways to install Python packages on Arch Linux.\nArch repositories\nA large number of popular packages are available in the\nofficial repositories\nand\nAUR\n. This is\nthe preferred way\nto install system-wide packages, and the only method officially supported on Arch Linux.\nThird-party packages\nDevelopers working with Python may need to use packages or package versions not available in the Arch repositories. The recommended practice is to use a separate\nvirtual environment\nto isolate each project, preventing conflicts with system packages in\n/usr\n. Various tools are available to install packages within a virtual environment:\npip(1)\n— The official package installer for Python.\nhttps://pip.pypa.io/\n||\npython-pip\npipx\n— A specialized package installer that can only be used to install packages with CLI entrypoints (but not library packages).\nhttps://pipx.pypa.io\n||\npython-pipx\nPoetry\n— Python dependency management and packaging made easy. Poetry is a single tool to develop, build, publish, and track dependencies for Python projects.\nhttps://python-poetry.org/\n||\npython-poetry\nConda\n— Conda provides package, dependency, and environment management for any language. Conda was originally created for Python, and is popular for scientific computing, data science and machine learning. Conda is the package manager of the\nminiforge\ncommunity distribution and the\nAnaconda\nand\nMiniconda\ndistributions.\nhttps://docs.conda.io\n||\npython-conda\nAUR\nuv\n— An extremely fast Python package installer and resolver, written in Rust. A single tool to replace\npip\n, pip-tools,\npipx\n,\npoetry\n,\npyenv\n,\ntwine\n,\nvirtualenv\n, and more.\nhttps://docs.astral.sh/uv/\n||\nuv\npip\n,\npipx\n,\npoetry\nand\nuv\ninstall packages from the\nPython Package Index\nand other indexes. Conda and Miniconda use the\nAnaconda repositories\n.\nAs an alternative to virtual environments,\npip install --user\ncan be used to install packages into the\nuser scheme\ninstead of\n/usr\n. This separates packages per-user rather than per-project. Virtual environments are usually the better choice.\nSee the\nPython Packaging User Guide\nfor the official best practices for package management.\nNote\nThere are also tools integrating\npip\nwith\npacman\nby automatically generating PKGBUILDs for specified PyPI packages: see\nCreating packages#PKGBUILD generators\n.\nTip\npipenv\nprovides a single CLI for\nPipfile\n,\npip\nand\nvirtualenv\n. It is available as\npython-pipenv\n.\nHistorical notes\nHistorically,\neasy_install\n(part of\npython-setuptools\n) was used to install packages distributed as\nEggs\n.\neasy_install\nand Eggs have been replaced with\npip\nand\nWheels\n. See\npip vs easy_install\nand\nPackage Formats\nfor more information.\nPrevious versions of\npip\ncould install third-party packages system-wide, but this caused a number of problems outlined in\nPEP668\n. The system-wide environment is now marked as an\nexternally managed environment\n, and\npip\nno longer allows system-wide installation.\nWidget bindings\nThe following\nwidget toolkit\nbindings are available:\nTkinter\n— The standard Python interface to the\nTk\nGUI toolkit.\nhttps://docs.python.org/3/library/tkinter.html\n||\npython\nQt for Python (PySide2)\n— The official Python bindings for\nQt\n5.\nhttps://www.qt.io/qt-for-python\n||\npyside2\nAUR\n,\npyside2-tools\nAUR\nQt for Python (PySide6)\n— The official Python bindings for\nQt\n6.\nhttps://www.qt.io/qt-for-python\n||\npyside6\n,\npyside6-tools\npyQt\n— A set of Python bindings for Qt.\nhttps://riverbankcomputing.com/software/pyqt/intro\n||\npython-pyqt5\n,\npython-pyqt6\nPyGObject\n— Python bindings for GObject based libraries such as\nGTK\n,\nGStreamer\n, WebKitGTK, GLib, and GIO.\nhttps://pygobject.readthedocs.io/\n||\npython-gobject\nwxPython\n— A cross-platform GUI toolkit for Python which wraps\nwxWidgets\n.\nhttps://wxpython.org/\n||\npython-wxpython\nTo use these with Python, you may also need to install the associated widget toolkit packages (e.g.\ntk\nmust also be installed to use Tkinter).\nTips and tricks\nVirtual environment\nPython provides tools to create isolated\nvirtual environments\ninto which packages may be installed without conflicting with other virtual environments or the system packages. Virtual environments can also run applications with different versions of Python on the same system.\nSee\nPython/Virtual environment\nfor details.\nTab completion in Python shell\nTab completion\nis available in the interactive shell by default. Note that the readline completer will only complete names in the global namespace. You can use\npython-jedi\nfor a richer tab completion experience\n[1]\n.\nList packages built for a specific Python version\nSometimes it is useful to know which installed packages were built for a specific version of Python. For example,\n$ pacman -Qoq /usr/lib/python3.12\nwill list all those built for Python version 3.12. This is especially useful when the official Python version is updated and one wants to get a list of packages from the\nAUR\nthat need rebuilding because they were built for a possibly no longer installed Python version, see\n#Module not found after Python version update\n.\nTroubleshooting\nModule not found after Python version update\nA Python-based application might output\nNo module named\nmodule_name\nfor an installed dependency named\nmodule_name\nafter having upgraded the\npython\npackage to a new minor version (e.g. from version 3.10 to 3.11).\nThe above scenario happens when a dependency is not available for that Python version or not installed at all. Python packages are installed in a versioned site-packages directory (\n/usr/lib/python\nX.Y\n/site-packages\nif system-wide, or\n~/.local/lib/python\nX.Y\n/site-packages/\nif per-user, where\nX.Y\nis a version like \"3.11\"). So whenever there is a new minor version upgrade, the Python-based package built with previous Python version must be rebuilt against the new one in order to be properly used.\nPlease notice it is the user's responsibility to rebuild non-official packages, including Python-based packages installed from AUR. See\nAUR#Updating packages\nand\nFAQ#What if I run a full system upgrade and there will be an update for a shared library, but not for the applications that depend on it?\nSee also\nOfficial\nOfficial Python documentation\n(Can be installed with the\npython-docs\npackage for offline access.)\nOfficial Python tutorial\nThird-Party\nAutomate the Boring Stuff with Python\n- Creative Commons book\nAwesome Python\n- A curated list of Python resources\nA Byte of Python\n- Creative Commons book\nCracking Codes With Python\n- Free online book\nCrash into Python\n- Free tutorial\nPython Debugging With Pdb\n- Guide to using\npdb\n, the Python debugger\nDive Into Python\n- Creative Commons book\nFluent Python\n- Commercial book\nIntroducing Python\n- Commercial book\nInvent Your Own Computer Games with Python\n- Free online book\nLearn Python\n- Free interactive tutorial\nLearn Python the Hard Way\n- Commercial book\nPythonspot Python Tutorials\n- Free online tutorials\nThink Python\n- Creative Commons book\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Python&oldid=844646\n\"\nCategory\n:\nProgramming languages\nSearch\nSearch\nPython\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Python"}}
{"text": "Rust - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nRust\n4 languages\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nRust package guidelines\nFrom\nWikipedia\n:\nRust\nis a multi-paradigm, general-purpose programming language that emphasizes performance, type safety, and concurrency. It enforces memory safety—meaning that all references point to valid memory—without a garbage collector. To simultaneously enforce memory safety and prevent data races, its \"borrow checker\" tracks the object lifetime of all references in a program during compilation. Rust was influenced by ideas from functional programming, including immutability, higher-order functions, and algebraic data types. It is popular for systems programming.\nCore language\nRust Core Library\nThe\nRust Core Library\nis the dependency-free foundation of the Rust Standard Library. It interfaces directly with LLVM primitives, which allows Rust to be platform and hardware-agnostic. It is this integration with LLVM that allows Rust to obtain greater performance than equivalent C applications compiled with Clang, making Rust software designed with libcore lower level than C. It contains only basic platform-independent types such as\nOption\n,\nResult\n, and\nIterator\n. Developers looking to target software for embedded platforms may forego the standard library with\n#![no_std]\nto exclusively use the no-batteries-included core library for smaller binary sizes and improved performance. However, using\n#![no_std]\nlimits the amount of software support that you can get from the larger Rust community as a majority of libraries require the standard library.\nRust Standard Library\nThe\nRust Standard Library\nprovides the convenient high level abstractions by which a majority of portable Rust software is created with. It includes the\nVec\nand\nString\ntypes; a vast amount of methods for language primitives; a large number of standard macros; I/O and multithreading support; heap allocations with\nBox\n; and many more high level features not available in the core library.\nRelease cycle\nRust follows a regular six-week release cycle, similar to the release cycle of Firefox. With each new release, the core and standard libraries are improved to support more platforms, improve performance, and stabilize new features for use with stable Rust.\nInstallation\nThe two main ways to install Rust are:\nThe Native installation, recommended if you only use Rust for building or installing software made with Rust\nThe Rustup installation, recommended if you intend to program anything in Rust\nNative installation\nTo\ninstall\nthe latest stable version of Rust from the official Arch Linux software repository,\ninstall\nthe\nrust\npackage. This will install the\nrustc\ncompiler and\nCargo\n.\nThere is also a development version of the Rust compiler available:\nrust-nightly-bin\nAUR\nfor prebuilt generic binaries or\nrust-git\nAUR\nto build the compiler with system libraries.\nRustup\nThe official and recommended method of installing Rust for the purpose of developing software is to use the\nRustup toolchain manager\n, written in Rust.\nThe benefit of using the Rustup toolchain manager instead of the standalone prepackaged Rust in the software repository is the ability to install multiple toolchains (stable, beta, nightly) for multiple targets (windows, mac, android) and architectures (x86, x86_64, arm). It should be noted that installing rustup does not automatically install a rust toolchain with it, nor does updating rustup through any method automatically provide the latest toolchain release of rust.  See\n#Usage\nor\nrustup toolchain documentation\nfor more on toolchains.\nThere are two choices for a Rustup installation, one is supported by Arch Linux via pacman, while the other is officially supported by Rust via their installation script.\nArch Linux package\nrustup\nis available on the Arch Linux software repository. Note that\nrustup self update\nwill\nnot\nwork when installed this way, the package needs to be updated by pacman. However, this change does not extend to other rustup functionality, such as\nrustup update\nfor updating rust toolchains.\nThis package has the advantage that the various Rust executables live in\n/usr/bin\n, instead of\n~/.cargo/bin\n, removing the need to add another directory to your\nPATH\n.\nNote\nThe\nrustup\npackage does\nnot\ninstall a toolchain by default. It provides instead symlinks between\n/usr/bin/rustup\nto the common binaries such as\n/usr/bin/rustc\nand\n/usr/bin/cargo\n. As stated above, the user still needs to install a toolchain manually for these Rust commands to do anything.\nIn order to install the toolchain, you need to tell rustup which version to use, between\nstable\nand\nnightly\n:\n$ rustup default stable\nBuilding rust against a new version of llvm\nSince rust builds using a bootstrap strategy, a functional rust package is required.  In the case of building a version of\nllvm\nwhich is\nnewer\nthan the version in the official repos, users will encounter the need to have a shared object from a previous version of\nllvm-libs\n(one which was used to build the repo version of rust) in order to build against the newer version of llvm.\nExample: the official repos offer llvm-18.1.8 and the goal is to build llvm-19.1.6.\nThe bootstrap step requires\n/usr/lib/libLLVM.so.18.1\nfrom llvm-libs-18.1.8.  This file can be manually placed in the build root or placed by a package such as\nllvm15-libs\n.\nUpstream installation script\nRustup\nis also available to download and install manually via\nrustup's official web page\n.\nDownload the file with\ncurl --proto '=https' --tlsv1.3 -sSf https://sh.rustup.rs -o rust.sh\n, view it:\nless ./rust.sh\n, and run the script\n./rust.sh\nto start rustup installation. The script makes PATH changes only to login shell\nconfiguration files\n.  You need to\nsource ~/.cargo/env\nuntil you logout and login back into the system. To update rustup afterwards, run\nrustup self update\n.\nThe script installs and activates the default toolchain by default (the one used by the\nrust\npackage), so there is no need to manually install it to start using Rust.\nWarning\nRunning\ncurl\nsome-url\n| sh\n, as the Rust documentation suggests, is considered a security risk, because it executes unknown code, that might even be corrupted during the download. Therefore it is recommended to manually download the script and check it, before executing it.\nNote\nPlease make sure that\n~/.cargo/bin\nis in your\nPATH\nwhen you run\nrustup\n.\nUsage\nYou might need to manually install a toolchain, e.g.\nstable\n,\nbeta\n,\nnightly\nor\n1.58.0\n. You also need to do this if you want to use/test another toolchain.\n$ rustup toolchain install\ntoolchain\nYou can now run the Rust commands by running,\nrustup run\ntoolchain\ncommand\n. However, to use these commands directly, you need to activate the toolchain:\n$ rustup default\ntoolchain\nCheck the installed Rust version using\nrustc -V\n:\n$ rustc -V\nrustc 1.58.0 (02072b482 2022-01-11)\nNote\nRust does not do its own linking, and so you’ll need to have a linker installed. You can use\ngcc\n, otherwise Rust will generate the following\nerror: linker `cc` not found.\nNote\nRustup does not automatically update provided toolchains.  If users are wishing to use the latest releases of Rust, crates, and other relevant packages, they may occasionally wish to update their toolchains with\nrustup update\n.  See\nOfficial rustup documentation\nfor more.\nTest your installation\nCheck that Rust is installed correctly by building a simple program, as follows:\n~/hello.rs\nfn main() {\nprintln!(\"Hello, World!\");\n}\nYou can compile it with\nrustc\n, then run it:\n$ rustc hello.rs && ./hello\nHello, World!\nCross compiling\nUsing rustup\nYou can easily cross-compile using Rustup. Rustup supports many cross-compile targets. A full list can be found running\nrustup target list\n.\nFor instance, if you want to install Rust using the stable channel for Windows, using the GNU Compiler, you will need to do:\n$ rustup toolchain install stable-x86_64-pc-windows-gnu\nThis will only install Rust and its tools for your target architecture, but some additional tools might be needed for cross-compiling.\nWindows\nIn this section,\n$ARCH\nis the target architecture (either\nx86_64\nor\ni686\n). It will explain how to cross compile using rustup.\nInstall\nmingw-w64-gcc\nRun\nrustup target add $ARCH-pc-windows-gnu\nto install Rust standard library for your architecture.\nFinally, tell cargo where to find the MinGW-w64 gcc/ar by adding the following to your\n~/.cargo/config.toml\n:\n~/.cargo/config.toml\n[target.$ARCH-pc-windows-gnu]\nlinker = \"/usr/bin/$ARCH-w64-mingw32-gcc\"\nar = \"/usr/bin/$ARCH-w64-mingw32-ar\"\nFinally, you can cross compile for windows by passing the\n--target $ARCH-pc-windows-gnu\nto cargo:\n$ # Build\n$ cargo build --release --target \"$ARCH-pc-windows-gnu\"\n$ # Run unit tests under wine\n$ cargo test --target \"$ARCH-pc-windows-gnu\"\nCurrently building executables using MinGW 6 and the toolchains installed by rustup is broken. To fix it, execute\nfor lib in crt2.o dllcrt2.o libmsvcrt.a; do cp -v /usr/x86_64-w64-mingw32/lib/$lib $HOME/.rustup/toolchains/$CHANNEL-x86_64-unknown-linux-gnu/lib/rustlib/x86_64-pc-windows-gnu/lib/; done\nwhere\nCHANNEL\nis the update channel (\nstable\n,\nbeta\nor\nnightly\n)\nUnofficial packages\nThe\nunofficial repository archlinuxcn\nhas rust-nightly and Rust std library for i686, ARM, ARMv7, Windows 32 and 64 so you can just install the one you want then enjoy cross-compiling. However, you have to find an ARM toolchain by yourself. For Windows 32bit targets, you will need to get a libgcc_s_dw2-1.dll (provided by\nmingw-w64-gcc\n) to build and run.\nCargo\nCargo\n, Rust's package manager, is part of the\nrust\npackage. The nightly version is available in the AUR as part of\nrust-nightly-bin\nAUR\n. If you use\nrustup\n, it already includes cargo.\nCargo is a tool that allows Rust projects to declare their various dependencies, and ensure that you will always get a repeatable build. You are encouraged to read the\nofficial guide\n.\nUsage\nTo create a new project using Cargo:\n$ cargo new hello_world\nThis creates a directory with a default\nCargo.toml\nfile, set to build an executable.\nNote\nCargo uses this\nCargo.toml\nas a manifest containing all of the metadata required to compile your project.\nCargo.toml\n[package]\nname = \"hello_world\"\nversion = \"0.1.0\"\nedition = \"2021\"\n[dependencies]\nOptimizing for native CPU platform\nIn order to instruct Cargo to always compile optimal code for your CPU platform, you can achieve this by adding a flag to\n~/.cargo/config.toml\n. Please be aware that the resulting binaries can not be distributed for use on other computers, and might even fail on your own system if you decide to change your CPU in the future.\nFind out which target platform is used by default on your installation:\n$ rustup toolchain list\nstable-x86_64-unknown-linux-gnu (default)\nIn this example, we are using\nstable\nRust on the\nx86_64-unknown-linux-gnu\nplatform.\nInstruct Cargo to always compile code optimized for the native CPU platform:\n~/.cargo/config.toml\n[target.x86_64-unknown-linux-gnu]\nrustflags = [\"-C\", \"target-cpu=native\"]\nsccache\nCompilation times can be greatly reduced by using\nsccache\n(\nsccache\npackage). This will maintain a local cache of compiler artifacts, eliminating the need to recompile code that has not changed since the last time it was compiled.\nTo enable sccache, you can use\nRUSTC_WRAPPER\nenvironment variable\n:\n$ export RUSTC_WRAPPER=sccache\n$ cargo build\nor\n$ RUSTC_WRAPPER=sccache cargo build\nAlternatively, add the following configuration to\n~/.cargo/config.toml\n:\n~/.cargo/config.toml\n[build]\nrustc-wrapper = \"sccache\"\nIDE support\nTools\nSee\nhttps://www.rust-lang.org/tools\nfor the recommended tools of the Rust project.\nrust-analyzer\nrust-analyzer\nis the official Language Server Protocol implementation for Rust which has replaced\nRLS\n.\nIt is available as the\nrust-analyzer\npackage, and the latest Git version is available as\nrust-analyzer-git\nAUR\n. Alternatively, if you have\nrustup\ninstalled, you can install rust-analyzer with:\n$ rustup component add rust-analyzer\nrust-analyzer needs the source code of the standard library. If it is not present, rust-analyzer will attempt to install it automatically using rustup. To install the source code manually using rustup, run the following command:\n$ rustup component add rust-src\nClippy\nClippy\ntakes advantage of compiler plugin support to provide a large number of additional lints for detecting and warning about a larger variety of errors and non-idiomatic Rust.\nClippy is included in the\nrust\npackage. To install it with rustup use:\n$ rustup component add clippy\nRustfmt\nRustfmt\nis a tool to format Rust code according to the official style guidelines.\nRustfmt is included in the\nrust\npackage. To install it with rustup use:\n$ rustup component add rustfmt\nEditors\nEmacs\nEmacs\nsupport for Rust can be obtained via the official\nrust-mode\nplugin.\nGNOME Builder\nGNOME Builder support for Rust is achieved using Language Server Protocol. It uses\nrust-analyzer\nby default; all you need to do is install it along with the Rust source.\nHelix\nHelix\neditor is written in Rust and has the Rust language server protocol included. Helix is inspired by Neovim and Kakoune.\nKate\nKate support for Rust is achieved using Language Server Protocol. It uses\nrust-analyzer\nby default; all you need to do is install it along with the Rust source.\nIntelliJ IDEA\nIntelliJ IDEA\nhas a\nRust plugin\n. The same plugin also works with CLion.\nIf using rustup, use rustup to download the source (\nrustup component add rust-src\n), and then select\n~/.rustup/toolchains/<your toolchain>/bin\nas the toolchain location.\nIf using Rust from the official Arch Linux software repository, select\n/usr/bin\nas the toolchain location and\n/usr/lib/rustlib/src/rust/library/\nas the stdlib sources location.\nJetbrains RustRover\nJetbrains\nis also working on a special Editor just for Rust. It can be found and downloaded under their official\nWebsite\nor in the AUR under\nrustrover\nAUR\nand\nrustrover-eap\nAUR\n.\nVisual Studio Code\nVisual Studio Code\nsupport for Rust can be obtained via\nrust-analyzer\nwith the\nrust-lang.rust-analyzer\nextension.\nVim\nVim\nsupport for Rust can be obtained via the official\nrust.vim\nplugin, which provides file detection, syntax highlighting, formatting and support for the\nSyntastic\nsyntax checking plugin. Many completion engines have Rust support, like\ncoc\n(via the\ncoc-rust-analyzer\nplugin) and\nYouCompleteMe\n.\nSee also\nOfficial website of the Rust Programming Language\nRust Documentation\nOfficial Rust Book\nStandard Library API Lookup\nExamples with small descriptions\nPage listing of Rust tutorials\nLibraries(crates) available through Cargo\nThis Week in Rust\nThe Rust Programming Language Blog\nThe Rust Users Forum\nThe Rust Internals Forum\nAwesome Rust: A curated list of Rust libraries and resources\nWikipedia:Rust (programming language)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Rust&oldid=854270\n\"\nCategory\n:\nProgramming languages\nSearch\nSearch\nRust\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Rust"}}
{"text": "Go - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nGo\n4 languages\nEspañol\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nGo package guidelines\nGo\nis an open source programming language supported by Google.\nFrom the Go\ndocumentation\n:\nit is a statically typed, compiled language that feels like a dynamically typed, interpreted language:\nit compiles to machine code yet has the convenience of garbage collection and the power of run-time reflection;\nits concurrency mechanisms make it easy to write programs that get the most out of multicore and networked machines, while its novel type system enables flexible and modular program construction.\nInstallation\nInstall\nthe\ngo\npackage, which includes the standard Go compiler and other development tools. See the\ngo(1)\ncommand documentation\nfor a list of included subcommands.\nAlternative compilers\ngccgo\nA frontend for\nGCC\ncalled\ngccgo\nis provided by the\ngcc-go\npackage.\ngccgo\nmay produce faster binaries than the standard (\"gc\") compiler in some cases and can target additional operating systems and architectures.\nIn practice, gc produces faster binaries than\ngccgo\nfor almost all workloads.\nTinyGo\nTinyGo\nis an\nLLVM\nbased compiler designed to produce very small binaries for embedded systems and WebAssembly. It is provided by the\ntinygo\npackage.\nTools\nThe following packages provide developer tools for Go:\nDelve\n— A debugger for the Go programming language.\nhttps://github.com/go-delve/delve\n||\ndelve\nGo tools\n— Various tools and Go packages mostly for static analysis of Go programs.\nhttps://cs.opensource.google/go/x/tools\n||\ngo-tools\ngopls\n— The official Go language server.\nhttps://pkg.go.dev/golang.org/x/tools/gopls\n||\ngopls\nGoReleaser\n— A release automation tool for Go projects.\nhttps://goreleaser.com/\n||\ngoreleaser\ngox\n— A tool for Go cross compilation that will parallelize builds for multiple platforms.\nhttps://github.com/mitchellh/gox\n||\ngox\nko\n— A container image builder for Go applications.\nhttps://github.com/ko-build/ko\n||\nko\nrevive\n— A fast, configurable, extensible, flexible, and beautiful linter for Go.\nhttps://revive.run/\n||\nrevive\nStaticcheck\n— A state of the art linter for the Go programming language.\nhttps://staticcheck.io/\n||\nstaticcheck\nYaegi\n— A Go interpreter. Includes the\nyaegi\ncommand-line interpreter/REPL.\nhttps://github.com/traefik/yaegi\n||\nyaegi\nYou can also install and run developer tools within modules using\ngo get -tool\nand\ngo tool\n. See the\nofficial documentation on tool dependencies\nfor instructions.\nInstall directory\nThe\ngo install\ncommand installs Go executables in the directory named by the\nGOBIN\nenvironment variable\n.\nGOBIN\ndefaults to\n$GOPATH/bin\n, or\n~/go/bin\nif the\nGOPATH\nenvironment variable is not set.\nTip\nYou can see all Go variables by running\ngo env\n.\nFor convenience, add the bin subdirectory to\nPATH\n:\n$ export PATH=\"$PATH:$(go env GOBIN):$(go env GOPATH)/bin\"\nSee\nHow to Write Go Code\nand\ngo help install\nfor more information.\nTips and Tricks\nCompiling source code\nYou can write a Hello World program as follows:\nhello.go\npackage main\nimport \"fmt\"\nfunc main() {\nfmt.Println(\"Hello, Arch!\")\n}\nThen run it with the\ngo\ntool:\n$ go run hello.go\nHello, Arch!\nCompilation with the standard compiler (same as\ngo build -compiler=gc hello.go\n):\n$ go build hello.go\nCompilation with\ngccgo\n(same as\ngo build -compiler=gccgo hello.go\n):\n$ gccgo hello.go -o hello\nCompilation with\ntinygo\n:\n$ tinygo build -o hello ./hello.go\nCross compiling to other platforms\nThe standard compiler can natively cross-compile to\na number of platforms\n. The procedure varies depending on whether the source code calls C code using\ncgo\n.\nWithout cgo\nIf cgo is not required for your build, then simply specify the target OS and architecture as\nenvironment variables\nto\ngo build\n:\n$ GOOS=linux GOARCH=arm64 go build .\nSee\nthe official documentation\nfor the valid combinations of\nGOOS\nand\nGOARCH\n.\nWith cgo\nIf cgo is required for your build, you have to provide the path to your C/C++ cross-compilers, via the\nCC\n/\nCXX\nenvironment variables.\nSay you want to cross-compile for\nGOOS=linux\nand\nGOARCH=arm64\n.\nYou need first to install the\naarch64-linux-gnu-gcc\ncross-compiler.\nHere is a sample program that requires cgo, so that we can test the cross-compilation process:\nhello.go\npackage main\n// #include <stdio.h>\n// void hello() { puts(\"Hello, Arch!\"); }\nimport \"C\"\nfunc main() {\nC.hello()\n}\nThen, you can cross-compile it like this:\n$ GOOS=linux GOARCH=arm64 CGO_ENABLED=1 CC=/usr/bin/aarch64-linux-gnu-gcc go build hello.go\nYou can check that the architecture of the generated binary is actually aarch64:\n$ file hello\nhello: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=b1d92ae8840a019f36cc2aee4606b6ae4a581bf1, for GNU/Linux 3.7.0, not stripped\nIf you copy\nhello\nto a suitable host, you can test-run it:\n[alarm@rpi3 ~]$ uname -a\nLinux alarm 5.3.8-1-ARCH #1 SMP Tue Oct 29 19:31:23 MDT 2019 aarch64 GNU/Linux\n[alarm@arpi3 ~]$ ./hello\nHello, Arch!\nUsing an alternate Go module mirror\nBy default, Go uses Google's service\nproxy.golang.org\nas a module mirror.\nIf an alternate mirror is desired, it can be changed with the\nenvironment variable\nGOPROXY\n, for example:\n$ export GOPROXY=\nhttps://goproxy.io/\nA number of public module mirrors are available, see for example:\nGo and Hugo Proxy Servers\n.\nTroubleshooting\nJetBrains Go Plugin\nIf you are using a JetBrains IDE and the Go plugin cannot find your Go SDK path, you might be using an incompatible package. Remove the\ngcc-go\npackage and replace it with\ngo\n. If your\nGOPATH\nis set, the IDE should now be able to find your Go SDK at\n/usr/lib/go\n.\nSee also\nOfficial wiki\nExamples with small descriptions\nInteractive Go training tour\nGo cross compilation\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Go&oldid=848310\n\"\nCategory\n:\nProgramming languages\nSearch\nSearch\nGo\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Go"}}
{"text": "Node.js - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nNode.js\n3 languages\nMagyar\n日本語\n中文（简体）\nFrom ArchWiki\nThe factual accuracy of this article or section is disputed.\nReason:\nRunning foreign package managers (in this case\nnpm\n) as root\nwill\ncause conflicts with\npacman\n(Discuss in\nTalk:Node.js\n)\nNode.js\nis a\nJavaScript\nruntime environment\ncombined with useful\nlibraries\n.\nNode.js\nuses\nGoogle\nV8 engine\nto execute code outside of the\nweb browser\n. Due to its event-driven, non-blocking I/O model, it is suitable for real-time web applications.\nInstallation\nInstall\nthe\nnodejs\npackage. There are\nlong-term support\n(LTS) releases, too:\nnodejs-lts-jod\n—version 22.x\nnodejs-lts-iron\n—version 20.x\nNode Version Manager\nIt is not uncommon to need or desire to work in different versions of Node.js. A preferred method among Node.js users is to use\nNode Version Manager\n(\nnvm\n), which allows for cheap and easy alternative installs. You can set\nnvm\nup by adding this to your\nCommand-line shell#Configuration files\n:\n. /usr/share/nvm/init-nvm.sh\nUsage is well documented on the project's GitHub but is as simple as:\n$ nvm install 8.0\nDownloading and installing node v8.0.0...\n[..]\n$ nvm use 8.0\nNow using node v8.0.0 (npm v5.0.0)\nTip\nIf you decide to use\nnvm\n, previously it was suggested to use\nnodejs-fake\npackage from\nAUR\n, which is now\ndeleted\n. Suggested way is to use\n--assume-installed nodejs=<version>\n, as per the manual\npacman(8) § TRANSACTION OPTIONS (APPLY TO -S, -R AND -U)\n.\nIf you want to run\nnvm use\nautomatically every time there is a\n.nvmrc\nfile on the directory, add\nthis\nin\nshell initialization files\n.\nNode Packaged Modules\nnpm\nis the official package manager for Node.js. It can be\ninstalled\nwith the\nnpm\npackage.\nManaging packages with npm\nInstalling packages\nThis article or section is being considered for removal.\nReason:\nRepetition and bad practices see edit page for more info (Discuss in\nTalk:Node.js\n)\nAny package can be installed using:\n$ npm install packageName\nThis command installs the package in the current directory under\nnode_modules\nand executables under\nnode_modules/.bin\n.\nFor a system-wide installation global switch\n-g\ncan be used:\n# npm -g install packageName\nBy default this command installs the package under\n/usr/lib/node_modules/npm\nand requires root privileges to do so. (If using a secure umask like\numask 0077\n, you will need to set up a\npermissive sudo umask\nfor the package to be usable.)\nAllow user-wide installations\nTo allow\nglobal\npackage installations for the current\nuser\n, set the\nnpm_config_prefix\nenvironment variable\n. This is used by both npm and\nyarn\n.\n~/.profile\nPATH=\"$HOME/.local/bin:$PATH\"\nexport npm_config_prefix=\"$HOME/.local\"\nRe-login or\nsource\nto update changes.\nNote\nbin\nand\nlib\ndirectories will be automatically created in your prefix directory once you install a package globally.\nYou can also specify the\n--prefix\nparameter for\nnpm install\n. However, this is\nnot\nrecommended, since you will need to add it every time you install a global package.\n$ npm -g install packageName --prefix ~/.local\nAnother option is to set\nprefix\nfield in\n$HOME/.npmrc\n. This achieves the same effect as using\nnpm_config_prefix=\"$HOME/.local\"\nin one's\n.profile\n:\n$ npm set prefix=\"$HOME/.local\"\nNote\nThe last method is specific to\nnpm\nonly.\nUpdating packages\nUpdating packages is as simple as\n$ npm update packageName\nFor the case of globally installed packages (\n-g\n)\n# npm update -g packageName\nNote\nRemember that globally installed packages require administrator privileges unless\nprefix\nis set to a user-writable directory\nUpdating all packages\nHowever, sometimes you may just wish to update all packages, either locally or globally. Leaving off the packageName\nnpm\nwill attempt to update all packages\n$ npm update\nor add the\n-g\nflag to update globally installed packages\n# npm update -g\nRemoving packages\nTo remove a package installed with the\n-g\nswitch simply use:\n# npm -g uninstall packageName\nNote\nRemember that globally installed packages require administrator privileges\nto remove a local package drop the switch and run:\n$ npm uninstall packageName\nListing packages\nTo show a tree view of the installed globally packages use:\n$ npm -g list\nThis tree is often quite deep. To only display the top level packages use:\n$ npm -g list --depth=0\nTo display obsolete packages that may need to be updated:\n$ npm -g outdated\nManaging packages with pacman\nSome Node.js packages can be found in\nArch User Repository\n(AUR) with the name\nnodejs-\npackage_name\n.\nSee the\nNode.js package guidelines\nfor best practices in packaging Node.js packages for AUR.\nTroubleshooting\nnpm help does not display documentation\nUsing\nnpm help\ntopic\nmay not display the documentation for\ntopic\n.  Instead, use\nman npm-\ntopic\n.  For example:\n$ npm help install\nTop hits for \"install\"\n...\n$ man npm-install\n... shows the documentation for the npm install subcommand\nThis is\na bug\nwith Arch's npm package.\nnode-gyp errors\nIn case of errors like\ngyp WARN EACCES user \"root\" does not have permission to access the ... dir\n,\n--unsafe-perm\noption might help:\n# npm install --unsafe-perm -g node-inspector\nCannot find module ... errors\nSince npm 5.x.x. package-lock.json file is generated along with the package.json file. Conflictions may arise when the two files refer to different package versions. A temporary method to solving this problem has been:\n$ rm package-lock.json\n$ npm install\nHowever, fixes were made after npm 5.1.0 or above. For further information, see:\nmissing dependencies\nSee also\nNode.js\ndocumentation\nnpm\ndocumentation\nIRC channel\n#node.js on\nLibera Chat\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Node.js&oldid=849405\n\"\nCategory\n:\nDevelopment\nHidden categories:\nPages or sections flagged with Template:Accuracy\nSections flagged with Template:Remove\nSearch\nSearch\nNode.js\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Node.js"}}
