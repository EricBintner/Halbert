{"text": "PostgreSQL: Documentation: 18: Part I. Tutorial\nNovember 13, 2025:\nPostgreSQL 18.1, 17.7, 16.11, 15.15, 14.20, and 13.23 Released!\nDocumentation\n→\nPostgreSQL 18\nSupported Versions:\nCurrent\n(\n18\n)\n/\n17\n/\n16\n/\n15\n/\n14\nDevelopment Versions:\ndevel\nUnsupported versions:\n13\n/\n12\n/\n11\n/\n10\n/\n9.6\n/\n9.5\n/\n9.4\n/\n9.3\n/\n9.2\n/\n9.1\n/\n9.0\n/\n8.4\n/\n8.3\n/\n8.2\n/\n8.1\n/\n8.0\n/\n7.4\n/\n7.3\n/\n7.2\n/\n7.1\nPart I. Tutorial\nPrev\nUp\nPostgreSQL 18.1 Documentation\nHome\nNext\nPart I. Tutorial\nWelcome to the\nPostgreSQL\nTutorial. The tutorial is intended to give an introduction to\nPostgreSQL\n, relational database concepts, and the SQL language. We assume some general knowledge about how to use computers and no particular Unix or programming experience is required. This tutorial is intended to provide hands-on experience with important aspects of the\nPostgreSQL\nsystem. It makes no attempt to be a comprehensive treatment of the topics it covers.\nAfter you have successfully completed this tutorial you will want to read the\nPart II\nsection to gain a better understanding of the SQL language, or\nPart IV\nfor information about developing applications with\nPostgreSQL\n. Those who provision and manage their own PostgreSQL installation should also read\nPart III\n.\nTable of Contents\n1. Getting Started\n1.1. Installation\n1.2. Architectural Fundamentals\n1.3. Creating a Database\n1.4. Accessing a Database\n2. The\nSQL\nLanguage\n2.1. Introduction\n2.2. Concepts\n2.3. Creating a New Table\n2.4. Populating a Table With Rows\n2.5. Querying a Table\n2.6. Joins Between Tables\n2.7. Aggregate Functions\n2.8. Updates\n2.9. Deletions\n3. Advanced Features\n3.1. Introduction\n3.2. Views\n3.3. Foreign Keys\n3.4. Transactions\n3.5. Window Functions\n3.6. Inheritance\n3.7. Conclusion\nPrev\nUp\nNext\n5. Bug Reporting Guidelines\nHome\nChapter 1. Getting Started\nSubmit correction\nIf you see anything in the documentation that is not correct, does not match\nyour experience with the particular feature or requires further clarification,\nplease use\nthis form\nto report a documentation issue.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.postgresql.org/docs/current/tutorial.html"}}
{"text": "PostgreSQL: Documentation: 18: Part III. Server Administration\nNovember 13, 2025:\nPostgreSQL 18.1, 17.7, 16.11, 15.15, 14.20, and 13.23 Released!\nDocumentation\n→\nPostgreSQL 18\nSupported Versions:\nCurrent\n(\n18\n)\n/\n17\n/\n16\n/\n15\n/\n14\nDevelopment Versions:\ndevel\nUnsupported versions:\n13\n/\n12\n/\n11\n/\n10\n/\n9.6\n/\n9.5\n/\n9.4\n/\n9.3\n/\n9.2\n/\n9.1\n/\n9.0\n/\n8.4\n/\n8.3\n/\n8.2\n/\n8.1\n/\n8.0\n/\n7.4\n/\n7.3\n/\n7.2\n/\n7.1\nPart III. Server Administration\nPrev\nUp\nPostgreSQL 18.1 Documentation\nHome\nNext\nPart III. Server Administration\nThis part covers topics that are of interest to a\nPostgreSQL\nadministrator. This includes installation, configuration of the server, management of users and databases, and maintenance tasks. Anyone running\nPostgreSQL\nserver, even for personal use, but especially in production, should be familiar with these topics.\nThe information attempts to be in the order in which a new user should read it. The chapters are self-contained and can be read individually as desired. The information is presented in a narrative form in topical units. Readers looking for a complete description of a command are encouraged to review the\nPart VI\n.\nThe first few chapters are written so they can be understood without prerequisite knowledge, so new users who need to set up their own server can begin their exploration. The rest of this part is about tuning and management; that material assumes that the reader is familiar with the general use of the\nPostgreSQL\ndatabase system. Readers are encouraged review the\nPart I\nand\nPart II\nparts for additional information.\nTable of Contents\n16. Installation from Binaries\n17. Installation from Source Code\n17.1. Requirements\n17.2. Getting the Source\n17.3. Building and Installation with Autoconf and Make\n17.4. Building and Installation with Meson\n17.5. Post-Installation Setup\n17.6. Supported Platforms\n17.7. Platform-Specific Notes\n18. Server Setup and Operation\n18.1. The\nPostgreSQL\nUser Account\n18.2. Creating a Database Cluster\n18.3. Starting the Database Server\n18.4. Managing Kernel Resources\n18.5. Shutting Down the Server\n18.6. Upgrading a\nPostgreSQL\nCluster\n18.7. Preventing Server Spoofing\n18.8. Encryption Options\n18.9. Secure TCP/IP Connections with SSL\n18.10. Secure TCP/IP Connections with GSSAPI Encryption\n18.11. Secure TCP/IP Connections with\nSSH\nTunnels\n18.12. Registering\nEvent Log\non\nWindows\n19. Server Configuration\n19.1. Setting Parameters\n19.2. File Locations\n19.3. Connections and Authentication\n19.4. Resource Consumption\n19.5. Write Ahead Log\n19.6. Replication\n19.7. Query Planning\n19.8. Error Reporting and Logging\n19.9. Run-time Statistics\n19.10. Vacuuming\n19.11. Client Connection Defaults\n19.12. Lock Management\n19.13. Version and Platform Compatibility\n19.14. Error Handling\n19.15. Preset Options\n19.16. Customized Options\n19.17. Developer Options\n19.18. Short Options\n20. Client Authentication\n20.1. The\npg_hba.conf\nFile\n20.2. User Name Maps\n20.3. Authentication Methods\n20.4. Trust Authentication\n20.5. Password Authentication\n20.6. GSSAPI Authentication\n20.7. SSPI Authentication\n20.8. Ident Authentication\n20.9. Peer Authentication\n20.10. LDAP Authentication\n20.11. RADIUS Authentication\n20.12. Certificate Authentication\n20.13. PAM Authentication\n20.14. BSD Authentication\n20.15. OAuth Authorization/Authentication\n20.16. Authentication Problems\n21. Database Roles\n21.1. Database Roles\n21.2. Role Attributes\n21.3. Role Membership\n21.4. Dropping Roles\n21.5. Predefined Roles\n21.6. Function Security\n22. Managing Databases\n22.1. Overview\n22.2. Creating a Database\n22.3. Template Databases\n22.4. Database Configuration\n22.5. Destroying a Database\n22.6. Tablespaces\n23. Localization\n23.1. Locale Support\n23.2. Collation Support\n23.3. Character Set Support\n24. Routine Database Maintenance Tasks\n24.1. Routine Vacuuming\n24.2. Routine Reindexing\n24.3. Log File Maintenance\n25. Backup and Restore\n25.1.\nSQL\nDump\n25.2. File System Level Backup\n25.3. Continuous Archiving and Point-in-Time Recovery (PITR)\n26. High Availability, Load Balancing, and Replication\n26.1. Comparison of Different Solutions\n26.2. Log-Shipping Standby Servers\n26.3. Failover\n26.4. Hot Standby\n27. Monitoring Database Activity\n27.1. Standard Unix Tools\n27.2. The Cumulative Statistics System\n27.3. Viewing Locks\n27.4. Progress Reporting\n27.5. Dynamic Tracing\n27.6. Monitoring Disk Usage\n28. Reliability and the Write-Ahead Log\n28.1. Reliability\n28.2. Data Checksums\n28.3. Write-Ahead Logging (\nWAL\n)\n28.4. Asynchronous Commit\n28.5.\nWAL\nConfiguration\n28.6. WAL Internals\n29. Logical Replication\n29.1. Publication\n29.2. Subscription\n29.3. Logical Replication Failover\n29.4. Row Filters\n29.5. Column Lists\n29.6. Generated Column Replication\n29.7. Conflicts\n29.8. Restrictions\n29.9. Architecture\n29.10. Monitoring\n29.11. Security\n29.12. Configuration Settings\n29.13. Upgrade\n29.14. Quick Setup\n30. Just-in-Time Compilation (\nJIT\n)\n30.1. What Is\nJIT\ncompilation?\n30.2. When to\nJIT\n?\n30.3. Configuration\n30.4. Extensibility\n31. Regression Tests\n31.1. Running the Tests\n31.2. Test Evaluation\n31.3. Variant Comparison Files\n31.4. TAP Tests\n31.5. Test Coverage Examination\nPrev\nUp\nNext\n15.4. Parallel Safety\nHome\nChapter 16. Installation from Binaries\nSubmit correction\nIf you see anything in the documentation that is not correct, does not match\nyour experience with the particular feature or requires further clarification,\nplease use\nthis form\nto report a documentation issue.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.postgresql.org/docs/current/admin.html"}}
{"text": "PostgreSQL: Documentation: 18: Part II. The SQL Language\nNovember 13, 2025:\nPostgreSQL 18.1, 17.7, 16.11, 15.15, 14.20, and 13.23 Released!\nDocumentation\n→\nPostgreSQL 18\nSupported Versions:\nCurrent\n(\n18\n)\n/\n17\n/\n16\n/\n15\n/\n14\nDevelopment Versions:\ndevel\nUnsupported versions:\n13\n/\n12\n/\n11\n/\n10\n/\n9.6\n/\n9.5\n/\n9.4\n/\n9.3\n/\n9.2\n/\n9.1\n/\n9.0\n/\n8.4\n/\n8.3\n/\n8.2\n/\n8.1\n/\n8.0\n/\n7.4\n/\n7.1\nPart II. The SQL Language\nPrev\nUp\nPostgreSQL 18.1 Documentation\nHome\nNext\nPart II. The SQL Language\nThis part describes the use of the\nSQL\nlanguage in\nPostgreSQL\n. We start with describing the general syntax of\nSQL\n, then how to create tables, how to populate the database, and how to query it. The middle part lists the available data types and functions for use in\nSQL\ncommands. Lastly, we address several aspects of importance for tuning a database.\nThe information is arranged so that a novice user can follow it from start to end and gain a full understanding of the topics without having to refer forward too many times. The chapters are intended to be self-contained, so that advanced users can read the chapters individually as they choose. The information is presented in narrative form with topical units. Readers looking for a complete description of a particular command are encouraged to review the\nPart VI\n.\nReaders should know how to connect to a\nPostgreSQL\ndatabase and issue\nSQL\ncommands. Readers that are unfamiliar with these issues are encouraged to read\nPart I\nfirst.\nSQL\ncommands are typically entered using the\nPostgreSQL\ninteractive terminal\npsql\n, but other programs that have similar functionality can be used as well.\nTable of Contents\n4. SQL Syntax\n4.1. Lexical Structure\n4.2. Value Expressions\n4.3. Calling Functions\n5. Data Definition\n5.1. Table Basics\n5.2. Default Values\n5.3. Identity Columns\n5.4. Generated Columns\n5.5. Constraints\n5.6. System Columns\n5.7. Modifying Tables\n5.8. Privileges\n5.9. Row Security Policies\n5.10. Schemas\n5.11. Inheritance\n5.12. Table Partitioning\n5.13. Foreign Data\n5.14. Other Database Objects\n5.15. Dependency Tracking\n6. Data Manipulation\n6.1. Inserting Data\n6.2. Updating Data\n6.3. Deleting Data\n6.4. Returning Data from Modified Rows\n7. Queries\n7.1. Overview\n7.2. Table Expressions\n7.3. Select Lists\n7.4. Combining Queries (\nUNION\n,\nINTERSECT\n,\nEXCEPT\n)\n7.5. Sorting Rows (\nORDER BY\n)\n7.6.\nLIMIT\nand\nOFFSET\n7.7.\nVALUES\nLists\n7.8.\nWITH\nQueries (Common Table Expressions)\n8. Data Types\n8.1. Numeric Types\n8.2. Monetary Types\n8.3. Character Types\n8.4. Binary Data Types\n8.5. Date/Time Types\n8.6. Boolean Type\n8.7. Enumerated Types\n8.8. Geometric Types\n8.9. Network Address Types\n8.10. Bit String Types\n8.11. Text Search Types\n8.12.\nUUID\nType\n8.13.\nXML\nType\n8.14.\nJSON\nTypes\n8.15. Arrays\n8.16. Composite Types\n8.17. Range Types\n8.18. Domain Types\n8.19. Object Identifier Types\n8.20.\npg_lsn\nType\n8.21. Pseudo-Types\n9. Functions and Operators\n9.1. Logical Operators\n9.2. Comparison Functions and Operators\n9.3. Mathematical Functions and Operators\n9.4. String Functions and Operators\n9.5. Binary String Functions and Operators\n9.6. Bit String Functions and Operators\n9.7. Pattern Matching\n9.8. Data Type Formatting Functions\n9.9. Date/Time Functions and Operators\n9.10. Enum Support Functions\n9.11. Geometric Functions and Operators\n9.12. Network Address Functions and Operators\n9.13. Text Search Functions and Operators\n9.14. UUID Functions\n9.15. XML Functions\n9.16. JSON Functions and Operators\n9.17. Sequence Manipulation Functions\n9.18. Conditional Expressions\n9.19. Array Functions and Operators\n9.20. Range/Multirange Functions and Operators\n9.21. Aggregate Functions\n9.22. Window Functions\n9.23. Merge Support Functions\n9.24. Subquery Expressions\n9.25. Row and Array Comparisons\n9.26. Set Returning Functions\n9.27. System Information Functions and Operators\n9.28. System Administration Functions\n9.29. Trigger Functions\n9.30. Event Trigger Functions\n9.31. Statistics Information Functions\n10. Type Conversion\n10.1. Overview\n10.2. Operators\n10.3. Functions\n10.4. Value Storage\n10.5.\nUNION\n,\nCASE\n, and Related Constructs\n10.6.\nSELECT\nOutput Columns\n11. Indexes\n11.1. Introduction\n11.2. Index Types\n11.3. Multicolumn Indexes\n11.4. Indexes and\nORDER BY\n11.5. Combining Multiple Indexes\n11.6. Unique Indexes\n11.7. Indexes on Expressions\n11.8. Partial Indexes\n11.9. Index-Only Scans and Covering Indexes\n11.10. Operator Classes and Operator Families\n11.11. Indexes and Collations\n11.12. Examining Index Usage\n12. Full Text Search\n12.1. Introduction\n12.2. Tables and Indexes\n12.3. Controlling Text Search\n12.4. Additional Features\n12.5. Parsers\n12.6. Dictionaries\n12.7. Configuration Example\n12.8. Testing and Debugging Text Search\n12.9. Preferred Index Types for Text Search\n12.10.\npsql\nSupport\n12.11. Limitations\n13. Concurrency Control\n13.1. Introduction\n13.2. Transaction Isolation\n13.3. Explicit Locking\n13.4. Data Consistency Checks at the Application Level\n13.5. Serialization Failure Handling\n13.6. Caveats\n13.7. Locking and Indexes\n14. Performance Tips\n14.1. Using\nEXPLAIN\n14.2. Statistics Used by the Planner\n14.3. Controlling the Planner with Explicit\nJOIN\nClauses\n14.4. Populating a Database\n14.5. Non-Durable Settings\n15. Parallel Query\n15.1. How Parallel Query Works\n15.2. When Can Parallel Query Be Used?\n15.3. Parallel Plans\n15.4. Parallel Safety\nPrev\nUp\nNext\n3.7. Conclusion\nHome\nChapter 4. SQL Syntax\nSubmit correction\nIf you see anything in the documentation that is not correct, does not match\nyour experience with the particular feature or requires further clarification,\nplease use\nthis form\nto report a documentation issue.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.postgresql.org/docs/current/sql.html"}}
{"text": "PostgreSQL: Documentation: 18: Part VI. Reference\nNovember 13, 2025:\nPostgreSQL 18.1, 17.7, 16.11, 15.15, 14.20, and 13.23 Released!\nDocumentation\n→\nPostgreSQL 18\nSupported Versions:\nCurrent\n(\n18\n)\n/\n17\n/\n16\n/\n15\n/\n14\nDevelopment Versions:\ndevel\nUnsupported versions:\n13\n/\n12\n/\n11\n/\n10\n/\n9.6\n/\n9.5\n/\n9.4\n/\n9.3\n/\n9.2\n/\n9.1\n/\n9.0\n/\n8.4\n/\n8.3\n/\n8.2\n/\n8.1\n/\n8.0\n/\n7.4\n/\n7.3\n/\n7.2\n/\n7.1\nPart VI. Reference\nPrev\nUp\nPostgreSQL 18.1 Documentation\nHome\nNext\nPart VI. Reference\nThe entries in this Reference are meant to provide in reasonable length an authoritative, complete, and formal summary about their respective subjects. More information about the use of\nPostgreSQL\n, in narrative, tutorial, or example form, can be found in other parts of this book. See the cross-references listed on each reference page.\nThe reference entries are also available as traditional\n“\nman\n”\npages.\nTable of Contents\nI. SQL Commands\nABORT\n— abort the current transaction\nALTER AGGREGATE\n— change the definition of an aggregate function\nALTER COLLATION\n— change the definition of a collation\nALTER CONVERSION\n— change the definition of a conversion\nALTER DATABASE\n— change a database\nALTER DEFAULT PRIVILEGES\n— define default access privileges\nALTER DOMAIN\n— change the definition of a domain\nALTER EVENT TRIGGER\n— change the definition of an event trigger\nALTER EXTENSION\n— change the definition of an extension\nALTER FOREIGN DATA WRAPPER\n— change the definition of a foreign-data wrapper\nALTER FOREIGN TABLE\n— change the definition of a foreign table\nALTER FUNCTION\n— change the definition of a function\nALTER GROUP\n— change role name or membership\nALTER INDEX\n— change the definition of an index\nALTER LANGUAGE\n— change the definition of a procedural language\nALTER LARGE OBJECT\n— change the definition of a large object\nALTER MATERIALIZED VIEW\n— change the definition of a materialized view\nALTER OPERATOR\n— change the definition of an operator\nALTER OPERATOR CLASS\n— change the definition of an operator class\nALTER OPERATOR FAMILY\n— change the definition of an operator family\nALTER POLICY\n— change the definition of a row-level security policy\nALTER PROCEDURE\n— change the definition of a procedure\nALTER PUBLICATION\n— change the definition of a publication\nALTER ROLE\n— change a database role\nALTER ROUTINE\n— change the definition of a routine\nALTER RULE\n— change the definition of a rule\nALTER SCHEMA\n— change the definition of a schema\nALTER SEQUENCE\n— change the definition of a sequence generator\nALTER SERVER\n— change the definition of a foreign server\nALTER STATISTICS\n— change the definition of an extended statistics object\nALTER SUBSCRIPTION\n— change the definition of a subscription\nALTER SYSTEM\n— change a server configuration parameter\nALTER TABLE\n— change the definition of a table\nALTER TABLESPACE\n— change the definition of a tablespace\nALTER TEXT SEARCH CONFIGURATION\n— change the definition of a text search configuration\nALTER TEXT SEARCH DICTIONARY\n— change the definition of a text search dictionary\nALTER TEXT SEARCH PARSER\n— change the definition of a text search parser\nALTER TEXT SEARCH TEMPLATE\n— change the definition of a text search template\nALTER TRIGGER\n— change the definition of a trigger\nALTER TYPE\n— change the definition of a type\nALTER USER\n— change a database role\nALTER USER MAPPING\n— change the definition of a user mapping\nALTER VIEW\n— change the definition of a view\nANALYZE\n— collect statistics about a database\nBEGIN\n— start a transaction block\nCALL\n— invoke a procedure\nCHECKPOINT\n— force a write-ahead log checkpoint\nCLOSE\n— close a cursor\nCLUSTER\n— cluster a table according to an index\nCOMMENT\n— define or change the comment of an object\nCOMMIT\n— commit the current transaction\nCOMMIT PREPARED\n— commit a transaction that was earlier prepared for two-phase commit\nCOPY\n— copy data between a file and a table\nCREATE ACCESS METHOD\n— define a new access method\nCREATE AGGREGATE\n— define a new aggregate function\nCREATE CAST\n— define a new cast\nCREATE COLLATION\n— define a new collation\nCREATE CONVERSION\n— define a new encoding conversion\nCREATE DATABASE\n— create a new database\nCREATE DOMAIN\n— define a new domain\nCREATE EVENT TRIGGER\n— define a new event trigger\nCREATE EXTENSION\n— install an extension\nCREATE FOREIGN DATA WRAPPER\n— define a new foreign-data wrapper\nCREATE FOREIGN TABLE\n— define a new foreign table\nCREATE FUNCTION\n— define a new function\nCREATE GROUP\n— define a new database role\nCREATE INDEX\n— define a new index\nCREATE LANGUAGE\n— define a new procedural language\nCREATE MATERIALIZED VIEW\n— define a new materialized view\nCREATE OPERATOR\n— define a new operator\nCREATE OPERATOR CLASS\n— define a new operator class\nCREATE OPERATOR FAMILY\n— define a new operator family\nCREATE POLICY\n— define a new row-level security policy for a table\nCREATE PROCEDURE\n— define a new procedure\nCREATE PUBLICATION\n— define a new publication\nCREATE ROLE\n— define a new database role\nCREATE RULE\n— define a new rewrite rule\nCREATE SCHEMA\n— define a new schema\nCREATE SEQUENCE\n— define a new sequence generator\nCREATE SERVER\n— define a new foreign server\nCREATE STATISTICS\n— define extended statistics\nCREATE SUBSCRIPTION\n— define a new subscription\nCREATE TABLE\n— define a new table\nCREATE TABLE AS\n— define a new table from the results of a query\nCREATE TABLESPACE\n— define a new tablespace\nCREATE TEXT SEARCH CONFIGURATION\n— define a new text search configuration\nCREATE TEXT SEARCH DICTIONARY\n— define a new text search dictionary\nCREATE TEXT SEARCH PARSER\n— define a new text search parser\nCREATE TEXT SEARCH TEMPLATE\n— define a new text search template\nCREATE TRANSFORM\n— define a new transform\nCREATE TRIGGER\n— define a new trigger\nCREATE TYPE\n— define a new data type\nCREATE USER\n— define a new database role\nCREATE USER MAPPING\n— define a new mapping of a user to a foreign server\nCREATE VIEW\n— define a new view\nDEALLOCATE\n— deallocate a prepared statement\nDECLARE\n— define a cursor\nDELETE\n— delete rows of a table\nDISCARD\n— discard session state\nDO\n— execute an anonymous code block\nDROP ACCESS METHOD\n— remove an access method\nDROP AGGREGATE\n— remove an aggregate function\nDROP CAST\n— remove a cast\nDROP COLLATION\n— remove a collation\nDROP CONVERSION\n— remove a conversion\nDROP DATABASE\n— remove a database\nDROP DOMAIN\n— remove a domain\nDROP EVENT TRIGGER\n— remove an event trigger\nDROP EXTENSION\n— remove an extension\nDROP FOREIGN DATA WRAPPER\n— remove a foreign-data wrapper\nDROP FOREIGN TABLE\n— remove a foreign table\nDROP FUNCTION\n— remove a function\nDROP GROUP\n— remove a database role\nDROP INDEX\n— remove an index\nDROP LANGUAGE\n— remove a procedural language\nDROP MATERIALIZED VIEW\n— remove a materialized view\nDROP OPERATOR\n— remove an operator\nDROP OPERATOR CLASS\n— remove an operator class\nDROP OPERATOR FAMILY\n— remove an operator family\nDROP OWNED\n— remove database objects owned by a database role\nDROP POLICY\n— remove a row-level security policy from a table\nDROP PROCEDURE\n— remove a procedure\nDROP PUBLICATION\n— remove a publication\nDROP ROLE\n— remove a database role\nDROP ROUTINE\n— remove a routine\nDROP RULE\n— remove a rewrite rule\nDROP SCHEMA\n— remove a schema\nDROP SEQUENCE\n— remove a sequence\nDROP SERVER\n— remove a foreign server descriptor\nDROP STATISTICS\n— remove extended statistics\nDROP SUBSCRIPTION\n— remove a subscription\nDROP TABLE\n— remove a table\nDROP TABLESPACE\n— remove a tablespace\nDROP TEXT SEARCH CONFIGURATION\n— remove a text search configuration\nDROP TEXT SEARCH DICTIONARY\n— remove a text search dictionary\nDROP TEXT SEARCH PARSER\n— remove a text search parser\nDROP TEXT SEARCH TEMPLATE\n— remove a text search template\nDROP TRANSFORM\n— remove a transform\nDROP TRIGGER\n— remove a trigger\nDROP TYPE\n— remove a data type\nDROP USER\n— remove a database role\nDROP USER MAPPING\n— remove a user mapping for a foreign server\nDROP VIEW\n— remove a view\nEND\n— commit the current transaction\nEXECUTE\n— execute a prepared statement\nEXPLAIN\n— show the execution plan of a statement\nFETCH\n— retrieve rows from a query using a cursor\nGRANT\n— define access privileges\nIMPORT FOREIGN SCHEMA\n— import table definitions from a foreign server\nINSERT\n— create new rows in a table\nLISTEN\n— listen for a notification\nLOAD\n— load a shared library file\nLOCK\n— lock a table\nMERGE\n— conditionally insert, update, or delete rows of a table\nMOVE\n— position a cursor\nNOTIFY\n— generate a notification\nPREPARE\n— prepare a statement for execution\nPREPARE TRANSACTION\n— prepare the current transaction for two-phase commit\nREASSIGN OWNED\n— change the ownership of database objects owned by a database role\nREFRESH MATERIALIZED VIEW\n— replace the contents of a materialized view\nREINDEX\n— rebuild indexes\nRELEASE SAVEPOINT\n— release a previously defined savepoint\nRESET\n— restore the value of a run-time parameter to the default value\nREVOKE\n— remove access privileges\nROLLBACK\n— abort the current transaction\nROLLBACK PREPARED\n— cancel a transaction that was earlier prepared for two-phase commit\nROLLBACK TO SAVEPOINT\n— roll back to a savepoint\nSAVEPOINT\n— define a new savepoint within the current transaction\nSECURITY LABEL\n— define or change a security label applied to an object\nSELECT\n— retrieve rows from a table or view\nSELECT INTO\n— define a new table from the results of a query\nSET\n— change a run-time parameter\nSET CONSTRAINTS\n— set constraint check timing for the current transaction\nSET ROLE\n— set the current user identifier of the current session\nSET SESSION AUTHORIZATION\n— set the session user identifier and the current user identifier of the current session\nSET TRANSACTION\n— set the characteristics of the current transaction\nSHOW\n— show the value of a run-time parameter\nSTART TRANSACTION\n— start a transaction block\nTRUNCATE\n— empty a table or set of tables\nUNLISTEN\n— stop listening for a notification\nUPDATE\n— update rows of a table\nVACUUM\n— garbage-collect and optionally analyze a database\nVALUES\n— compute a set of rows\nII. PostgreSQL Client Applications\nclusterdb\n— cluster a\nPostgreSQL\ndatabase\ncreatedb\n— create a new\nPostgreSQL\ndatabase\ncreateuser\n— define a new\nPostgreSQL\nuser account\ndropdb\n— remove a\nPostgreSQL\ndatabase\ndropuser\n— remove a\nPostgreSQL\nuser account\necpg\n— embedded SQL C preprocessor\npg_amcheck\n— checks for corruption in one or more\nPostgreSQL\ndatabases\npg_basebackup\n— take a base backup of a\nPostgreSQL\ncluster\npgbench\n— run a benchmark test on\nPostgreSQL\npg_combinebackup\n— reconstruct a full backup from an incremental backup and dependent backups\npg_config\n— retrieve information about the installed version of\nPostgreSQL\npg_dump\n— export a\nPostgreSQL\ndatabase as an SQL script or to other formats\npg_dumpall\n— extract a\nPostgreSQL\ndatabase cluster into a script file\npg_isready\n— check the connection status of a\nPostgreSQL\nserver\npg_receivewal\n— stream write-ahead logs from a\nPostgreSQL\nserver\npg_recvlogical\n— control\nPostgreSQL\nlogical decoding streams\npg_restore\n— restore a\nPostgreSQL\ndatabase from an archive file created by\npg_dump\npg_verifybackup\n— verify the integrity of a base backup of a\nPostgreSQL\ncluster\npsql\n—\nPostgreSQL\ninteractive terminal\nreindexdb\n— reindex a\nPostgreSQL\ndatabase\nvacuumdb\n— garbage-collect and analyze a\nPostgreSQL\ndatabase\nIII. PostgreSQL Server Applications\ninitdb\n— create a new\nPostgreSQL\ndatabase cluster\npg_archivecleanup\n— clean up\nPostgreSQL\nWAL archive files\npg_checksums\n— enable, disable or check data checksums in a\nPostgreSQL\ndatabase cluster\npg_controldata\n— display control information of a\nPostgreSQL\ndatabase cluster\npg_createsubscriber\n— convert a physical replica into a new logical replica\npg_ctl\n— initialize, start, stop, or control a\nPostgreSQL\nserver\npg_resetwal\n— reset the write-ahead log and other control information of a\nPostgreSQL\ndatabase cluster\npg_rewind\n— synchronize a\nPostgreSQL\ndata directory with another data directory that was forked from it\npg_test_fsync\n— determine fastest\nwal_sync_method\nfor\nPostgreSQL\npg_test_timing\n— measure timing overhead\npg_upgrade\n— upgrade a\nPostgreSQL\nserver instance\npg_waldump\n— display a human-readable rendering of the write-ahead log of a\nPostgreSQL\ndatabase cluster\npg_walsummary\n— print contents of WAL summary files\npostgres\n—\nPostgreSQL\ndatabase server\nPrev\nUp\nNext\n50.3. OAuth Validator Callbacks\nHome\nSQL Commands\nSubmit correction\nIf you see anything in the documentation that is not correct, does not match\nyour experience with the particular feature or requires further clarification,\nplease use\nthis form\nto report a documentation issue.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.postgresql.org/docs/current/reference.html"}}
{"text": "Getting Started with Indexes Guide | Server | MariaDB Documentation\nE-book:  A Practical Guide to AI and Vector Search in Relational Databases\nRead Now\nCtrl\nk\nGitBook Assistant\nDownload MariaDB\nContact Us\nMore\nGitBook Assistant\nGitBook Assistant\nWorking...\nThinking...\nGitBook Assistant\nGood evening\nI'm here to help you with the docs.\nWhat is this page about?\nWhat should I read next?\nCan you give an example?\nCtrl\ni\nAI\nBased on your context\nSend\nMariaDB Server Documentation\nQuickstart Guides\nInstalling MariaDB Server Guide\nAdding & Changing Data Guide\nEssential Queries Guide\nBasics Guide\nAltering Tables Guide\nConnecting to MariaDB Guide\nTroubleshooting Connection Issues Guide\nDoing Time Guide\nImporting Data Guide\nEssentials of an Index Guide\nGetting Started with Indexes Guide\nJoining Tables with JOIN Clauses Guide\nConfiguring MariaDB for Remote Client Access Guide\nGetting Data Guide\nBasic SQL Statements Guide\nBasic SQL Debugging Guide\nMariaDB String Functions Guide\nRestoring Data from Dump Files Guide\nChanging Times in MariaDB\nMaking Backups with mariadb-dump Guide\nA MariaDB Primer Guide\nCreating & Using Views Guide\nDatabase Applications\nServer Usage\nServer Management\nSecurity\nArchitecture\nClients & Utilities\nHA & Performance\nReference\nPowered by GitBook\nOn this page\nIndex Types Overview\nPrimary Key\nUnique Index\nPlain Indexes (Regular Indexes)\nFull-Text Indexes\nChoosing Indexes\nViewing Indexes\nWhen to Remove an Index\nWas this helpful?\nGitBook Assistant\nAsk\nGetting Started with Indexes Guide\nUnderstand the different types of indexes in MariaDB, such as Primary Keys and Unique Indexes, and learn how to create and manage them for performance.\nThis guide explains the different types of indexes in MariaDB, their characteristics, and how they are used. Learn to create and manage Primary Keys, Unique Indexes, and Plain Indexes, along with key considerations for choosing and maintaining effective indexes for optimal query performance.\nIn MariaDB, the terms\nKEY\nand\nINDEX\nare generally used interchangeably in SQL statements.\nIndex Types Overview\nThere are four main kinds of indexes:\nPrimary Keys:\nUnique and not NULL.\nUnique Indexes:\nMust be unique but can contain NULL values.\nPlain Indexes (or Regular Indexes):\nNot necessarily unique.\nFull-Text Indexes:\nUsed for full-text searching capabilities.\nPrimary Key\nA primary key uniquely identifies each record in a table. Its values must be unique, and it cannot contain\nNULL\nvalues. Each table can have only one primary key.\nInnoDB Considerations:\nIn InnoDB tables, the primary key is included as a suffix in all other indexes. Therefore, keeping the primary key compact (e.g., using an appropriate integer type) is important for performance and storage efficiency.\nIf a table has no explicitly defined primary key and no\nUNIQUE\nindexes, InnoDB automatically creates an invisible 6-byte clustered index.\nUsing\nAUTO_INCREMENT\n:\nThe\nAUTO_INCREMENT\nattribute is commonly used with numeric primary keys to automatically generate a unique ID for each new row.\nCopy\nCREATE\nTABLE\n`\nEmployees\n` (\n`ID`\nTINYINT\n(\n3\n) UNSIGNED\nNOT NULL\nAUTO_INCREMENT,\n`First_Name`\nVARCHAR\n(\n25\n)\nNOT NULL\n,\n`Last_Name`\nVARCHAR\n(\n25\n)\nNOT NULL\n,\n`Position`\nVARCHAR\n(\n25\n)\nNOT NULL\n,\nPRIMARY KEY\n(\n`ID`\n)\n);\nNote: The column defined as a primary key (or part of it) must be explicitly declared as\nNOT NULL\n.\nAdding a Primary Key to an Existing Table:\nUse\nALTER TABLE\n. You cannot create a primary key with\nCREATE INDEX\n.\nCopy\nALTER TABLE Employees ADD PRIMARY KEY(ID);\nFinding Tables Without Primary Keys:\nThis query uses the\ninformation_schema\ndatabase to find tables lacking primary keys:\nCopy\nSELECT t.TABLE_SCHEMA, t.TABLE_NAME\nFROM information_schema.TABLES AS t\nLEFT JOIN information_schema.KEY_COLUMN_USAGE AS c\nON t.TABLE_SCHEMA = c.CONSTRAINT_SCHEMA\nAND t.TABLE_NAME = c.TABLE_NAME\nAND c.CONSTRAINT_NAME = 'PRIMARY'\nWHERE t.TABLE_SCHEMA NOT IN ('information_schema', 'performance_schema', 'mysql', 'sys')\nAND c.CONSTRAINT_NAME IS NULL;\nUnique Index\nA unique index ensures that all values in the indexed column (or combination of columns) are unique. However, unlike a primary key, columns in a unique index can store\nNULL\nvalues.\nEach key value uniquely identifies a row, but not every row needs to be represented if\nNULL\ns are allowed.\nCopy\n### INSERT INTO `securedb`.`t_long_keys`\n### SET\n###   @1=1 /* INT meta=0 nullable=0 is_null=0 */\n###   @2='a' /* VARSTRING(4073) meta=4073 nullable=1 is_null=0 */\n###   @3=580 /* LONGINT meta=0 nullable=1 is_null=0 */\nBehavior (MariaDB 10.5+):\nIf the index type is not specified,\nUNIQUE\ntypically creates a BTREE index, usable by the optimizer.\nIf a key exceeds the maximum length for the storage engine and the engine supports long unique indexes, a HASH key might be created to enforce uniqueness.\nCreating Unique Indexes:\nDuring table creation:\nCopy\nCREATE TABLE `Employees` (\n`ID` TINYINT(3) UNSIGNED NOT NULL,\n`Employee_Code` VARCHAR(25) NOT NULL,\n`First_Name` VARCHAR(25) NOT NULL,\nPRIMARY KEY (`ID`),\nUNIQUE KEY `UK_EmpCode` (`Employee_Code`) -- Naming the unique key is good practice\n);\nAfter table creation using\nALTER TABLE\n:\nCopy\nALTER TABLE Employees ADD UNIQUE `UK_HomePhone` (`Home_Phone`);\nAfter table creation using\nCREATE UNIQUE INDEX\n:\nCopy\nCREATE UNIQUE INDEX `IX_Position` ON Employees(Position);\nMulti-Column Unique Indexes:\nAn index can span multiple columns. MariaDB can use the leftmost part(s) of such an index if it cannot use the whole index (except for HASH indexes).\nCopy\nCREATE TABLE t1 (a INT NOT NULL, b INT, UNIQUE (a,b));\nINSERT INTO t1 VALUES (1,1), (2,2);\nINSERT INTO t1 VALUES (2,1); -- Valid: (2,1) is unique, though '2' in 'a' and '1' in 'b' are not individually unique here.\nSELECT * FROM t1;\nCopy\n+---+------+\n| a | b    |\n+---+------+\n| 1 |    1 |\n| 2 |    1 |\n| 2 |    2 |\n+---+------+\nNULL\nValues in Unique Indexes:\nA\nUNIQUE\nconstraint allows multiple\nNULL\nvalues because in SQL,\nNULL\nis never equal to another\nNULL\n.\nCopy\nINSERT INTO t1 VALUES (3,NULL), (3, NULL); -- Both rows are inserted\nSELECT * FROM t1;\nCopy\n+---+------+\n| a | b    |\n+---+------+\n| 1 |    1 |\n| 2 |    1 |\n| 2 |    2 |\n| 3 | NULL |\n| 3 | NULL |\n+---+------+\nVerification:\nCopy\nSELECT (3, NULL) = (3, NULL);\nCopy\n+-----------------------+\n| (3, NULL) = (3, NULL) |\n+-----------------------+\n|                     0 | -- 0 means false\n+-----------------------+\nConditional Uniqueness with Virtual Columns:\nYou can enforce uniqueness over a subset of rows using unique indexes on\nvirtual columns\n. This example ensures\nuser_name\nis unique for 'Active' or 'On-Hold' users, but allows duplicate names for 'Deleted' users:\nCopy\nCREATE TABLE Table_1 (\nuser_name VARCHAR(10),\nstatus ENUM('Active', 'On-Hold', 'Deleted'),\ndel CHAR(0) AS (IF(status IN ('Active', 'On-Hold'), '', NULL)) PERSISTENT,\nUNIQUE(user_name, del)\n);\nTrailing Pad Characters:\nIf a unique index is on a column where trailing pad characters are stripped or ignored (e.g.,\nCHAR\nvs\nVARCHAR\nbehavior), inserts where values differ only by the number of trailing pad characters can result in duplicate-key errors.\nLong Keys and HASH Indexes (MariaDB 10.4+):\nFor engines like InnoDB,\nUNIQUE\ncan be used with various column types and numbers. If a key's length exceeds the engine's maximum, a HASH key may be created.\nCopy\n-- Example table definition (simplified for brevity)\nCREATE TABLE t_long_keys (\na INT PRIMARY KEY,\nb BLOB,\nc1 VARCHAR(1000),\nUNIQUE KEY `uk_b` (b),\nUNIQUE KEY `uk_c1` (c1)\n) ENGINE=InnoDB;\n-- SHOW CREATE TABLE might reveal 'USING HASH' for uk_b or uk_c1 if they exceed length limits\nSHOW CREATE TABLE t_long_keys\\G\nExample output snippet showing\nUSING HASH\n:\nCopy\n...\nUNIQUE KEY `uk_b` (`b`) USING HASH,\n...\nPlain Indexes (Regular Indexes)\nPlain indexes do not enforce uniqueness; they are primarily used to speed up data retrieval.\nCopy\nCREATE TABLE t2 (a INT NOT NULL, b INT, INDEX `idx_a_b` (a,b));\nINSERT INTO t2 VALUES (1,1), (2,2), (2,2); -- Duplicate (2,2) is allowed\nSELECT * FROM t2;\nCopy\n+---+------+\n| a | b    |\n+---+------+\n| 1 |    1 |\n| 2 |    2 |\n| 2 |    2 |\n+---+------+\nFull-Text Indexes\nFull-text indexes are used for performing full-text searches on text data. For details, see the\nFull-Text Indexes\ndocumentation.\nChoosing Indexes\nIndex for Queries:\nAdd indexes that match the\nWHERE\nclauses,\nJOIN\nconditions, and\nORDER BY\nclauses of your application's queries.\nAvoid Over-Indexing:\nExtra indexes consume storage and can slow down\nINSERT\n,\nUPDATE\n, and\nDELETE\noperations.\nImpact of Table Size:\nIndexes provide more significant speed-ups on large tables (larger than buffer sizes) than on very small tables.\nUse\nEXPLAIN\n:\nAnalyze your queries with the\nEXPLAIN\nstatement to determine if indexes are being used effectively and identify columns that might benefit from indexing.\nLIKE '%word%'\n:\nQueries using a leading wildcard in a\nLIKE\nclause (e.g.,\nLIKE '%word%'\n) typically cannot use standard BTREE indexes effectively and may result in full table scans unless a full-text index is used.\nDelayed Writes:\nFor tables with many reads and writes, consider storage engine options or server configurations related to delayed writes to potentially improve performance by batching disk I/O. (This is an advanced topic.)\nCreating Indexes on Existing Tables:\nUse\nCREATE INDEX index_name ON table_name (column_list);\nLarge Tables:\nFor very large tables, it's often faster to load data into the table first and then create indexes, rather than creating indexes on an empty table and then loading data.\nViewing Indexes\nSHOW INDEX FROM table_name;\n: Displays information about all indexes on a table.SQL\nCopy\nSHOW INDEX FROM Employees;\nSHOW CREATE TABLE table_name;\n: Shows the\nCREATE TABLE\nstatement, which includes definitions for all indexes.SQL\nCopy\nSHOW CREATE TABLE Employees\\G\nWhen to Remove an Index\nRemove an index if:\nIt is rarely or never used. Unused indexes still incur overhead during data modification operations.\nIdentifying Unused Indexes:\nIf\nuser statistics\nare enabled, query the\ninformation_schema.INDEX_STATISTICS\ntable.\nIf the\nslow query log\nis enabled and the\nlog_queries_not_using_indexes\nserver system variable\nis\nON\n, queries performing full table scans will be logged, which can indicate missing or ineffective indexes.\nThis page is licensed: CC BY-SA / Gnu FDL\nPrevious\nEssentials of an Index Guide\nNext\nJoining Tables with JOIN Clauses Guide\nLast updated\n10 days ago\nWas this helpful?", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://mariadb.com/kb/en/getting-started-with-indexes/"}}
{"text": "Basics Guide | Server | MariaDB Documentation\nE-book:  A Practical Guide to AI and Vector Search in Relational Databases\nRead Now\nCtrl\nk\nGitBook Assistant\nDownload MariaDB\nContact Us\nMore\nGitBook Assistant\nGitBook Assistant\nWorking...\nThinking...\nGitBook Assistant\nGood evening\nI'm here to help you with the docs.\nWhat is this page about?\nWhat should I read next?\nCan you give an example?\nCtrl\ni\nAI\nBased on your context\nSend\nMariaDB Server Documentation\nQuickstart Guides\nInstalling MariaDB Server Guide\nAdding & Changing Data Guide\nEssential Queries Guide\nBasics Guide\nAltering Tables Guide\nConnecting to MariaDB Guide\nTroubleshooting Connection Issues Guide\nDoing Time Guide\nImporting Data Guide\nEssentials of an Index Guide\nGetting Started with Indexes Guide\nJoining Tables with JOIN Clauses Guide\nConfiguring MariaDB for Remote Client Access Guide\nGetting Data Guide\nBasic SQL Statements Guide\nBasic SQL Debugging Guide\nMariaDB String Functions Guide\nRestoring Data from Dump Files Guide\nChanging Times in MariaDB\nMaking Backups with mariadb-dump Guide\nA MariaDB Primer Guide\nCreating & Using Views Guide\nDatabase Applications\nServer Usage\nServer Management\nSecurity\nArchitecture\nClients & Utilities\nHA & Performance\nReference\nPowered by GitBook\nOn this page\nConnecting to MariaDB Server\nCreating a Database Structure\nSQL Syntax Notes\nEntering Data\nRetrieving Data\nChanging & Deleting Data\nWas this helpful?\nGitBook Assistant\nAsk\nBasics Guide\nLearn to connect, create databases, and execute fundamental SQL commands like INSERT, SELECT, and UPDATE.\nWEBINAR\nMariaDB 101: Learning the Basics of MariaDB\nWatch Now\nThe quickstart guide walks you through connecting to a MariaDB server, creating your initial database and table structures, and performing fundamental data operations. It's designed for new users or anyone needing a quick refresher on essential MariaDB commands and basic syntax.\nConnecting to MariaDB Server\nTo interact with the MariaDB server, use a client program. The default command-line client is\nmariadb\n.\nConnect to MariaDB in monitor mode from the Linux command-line:\nCopy\nmariadb\n-u\nroot\n-p\n-h\nlocalhost\nCommon options:\n-u username\n: Specifies the MariaDB user (e.g.,\nroot\n). This is not the OS user.\n-p\n: Prompts for the password. If no password is set, press [Enter].\n-h hostname_or_IP\n: Specifies the server's hostname or IP address if the client is on a different machine than the server. Often not needed if connecting locally.\nIf logged into Linux as\nroot\n, you might only need:\nCopy\nmariadb\n-p\nTo exit the\nmariadb\nmonitor, type\nquit\nor\nexit\nand press [Enter].\nCreating a Database Structure\nFirst, create and select a database.\nCopy\nCREATE\nDATABASE\nbookstore\n;\nUSE\nbookstore;\nThis creates a database named\nbookstore\nand sets it as the default for subsequent operations.\nNext, create tables to hold data.\nCopy\nCREATE TABLE books (\nisbn CHAR(20) PRIMARY KEY,\ntitle VARCHAR(50),\nauthor_id INT,\npublisher_id INT,\nyear_pub CHAR(4),\ndescription TEXT\n);\nThis statement creates a\nbooks\ntable with six columns:\nisbn\n:\nCHAR(20)\n, the primary key for unique identification.\ntitle\n:\nVARCHAR(50)\n, a variable-width string for the book title.\nauthor_id\n,\npublisher_id\n:\nINT\n, for storing numeric IDs.\nyear_pub\n:\nCHAR(4)\n, a fixed-width string for the publication year.\ndescription\n:\nTEXT\n, for longer descriptive text (up to 65,535 bytes).\nTo view the structure of a created table:\nCopy\nDESCRIBE books;\nCopy\n+--------------+-------------+------+-----+---------+-------+\n| Field        | Type        | Null | Key | Default | Extra |\n+--------------+-------------+------+-----+---------+-------+\n| isbn         | char(20)    | NO   | PRI | NULL    |       |\n| title        | varchar(50) | YES  |     | NULL    |       |\n| author_id    | int(11)     | YES  |     | NULL    |       |\n| publisher_id | int(11)     | YES  |     | NULL    |       |\n| year_pub     | char(4)     | YES  |     | NULL    |       |\n| description  | text        | YES  |     | NULL    |       |\n+--------------+-------------+------+-----+---------+-------+\nTo modify an existing table, use the\nALTER TABLE\nstatement (see\nALTER TABLE documentation\n). To delete a table and all its data (irreversibly), use\nDROP TABLE table_name;\n(see\nDROP TABLE documentation\n).\nExample of another table,\nauthors\n, using\nAUTO_INCREMENT\nfor the primary key:\nCopy\nCREATE TABLE authors (\nauthor_id INT AUTO_INCREMENT PRIMARY KEY,\nname_last VARCHAR(50),\nname_first VARCHAR(50),\ncountry VARCHAR(50)\n);\nThe\nauthor_id\nwill automatically generate a unique number for each new author.\nSQL Syntax Notes\nSQL statements typically end with a semicolon (\n;\n) or\n\\G\n.\nStatements can span multiple lines; execution occurs after the terminating character and [Enter].\nTo cancel a partially typed statement in the\nmariadb\nclient, enter\n\\c\nand press [Enter].\nSQL reserved words (e.g.,\nCREATE\n,\nSELECT\n) are often written in uppercase for readability but are case-insensitive in MariaDB.\nDatabase and table names are case-sensitive on Linux systems (as they map to directories and files) but generally not on Windows. Column names are case-insensitive.\nUsing lowercase for table and column names is a common convention.\nEntering Data\nUse the\nINSERT\nstatement (see\nINSERT documentation\n) to add new rows to a table.\nCopy\nINSERT INTO authors (name_last, name_first, country)\nVALUES('Kafka', 'Franz', 'Czech Republic');\nSince\nauthor_id\nin the\nauthors\ntable is\nAUTO_INCREMENT\n(see\nAUTO_INCREMENT documentation\n), its value is assigned automatically. If not all columns are being supplied with data, the column names must be listed, followed by their corresponding values in the\nVALUES\nclause.\nTo insert data for a book, referencing\nauthor_id\n1\n(assuming Kafka's\nauthor_id\nbecame\n1\n):\nCopy\nINSERT INTO books (title, author_id, isbn, year_pub)\nVALUES('The Castle', '1', '0805211063', '1998');\nMultiple rows can be inserted with a single\nINSERT\nstatement:\nCopy\nINSERT INTO books (title, author_id, isbn, year_pub)\nVALUES('The Trial', '1', '0805210407', '1995'),\n('The Metamorphosis', '1', '0553213695', '1995'),\n('America', '1', '0805210644', '1995');\nRetrieving Data\nUse the SELECT statement (see SELECT documentation) to query data from tables.\nTo retrieve all book titles:\nCopy\nSELECT title FROM books;\nTo limit the number of rows returned (e.g., to 5) using\nLIMIT\n(see\nLIMIT documentation\n):\nCopy\nSELECT title FROM books LIMIT 5;\nTo retrieve data from multiple tables, use a\nJOIN\n(see\nJOIN documentation\n). This example lists book titles and author last names by joining\nbooks\nand\nauthors\non their common\nauthor_id\ncolumn:\nCopy\nSELECT title, name_last\nFROM books\nJOIN authors USING (author_id);\nTo filter results, use the\nWHERE\nclause. This example finds books by 'Kafka' and renames the\ntitle\ncolumn\n1\nin the output to 'Kafka Books' using\nAS\n(an alias):\nCopy\nSELECT title AS 'Kafka Books'\nFROM books\nJOIN authors USING (author_id)\nWHERE name_last = 'Kafka';\nCopy\n+-------------------+\n| Kafka Books       |\n+-------------------+\n| The Castle        |\n| The Trial         |\n| The Metamorphosis |\n| America           |\n+-------------------+\nChanging & Deleting Data\nTo modify existing data, use the\nUPDATE\nstatement (see\nUPDATE documentation\n). Always use a\nWHERE\nclause to specify which rows to update.\nCopy\nUPDATE books\nSET title = 'Amerika'\nWHERE isbn = '0805210644';\nThis changes the\ntitle\nfor the book with the specified\nisbn\n. Multiple columns can be updated by separating\ncolumn = value\nassignments with commas within the\nSET\nclause.\nTo remove rows from a table, use the\nDELETE\nstatement (see\nDELETE documentation\n). Use\nWHERE\nto specify which rows to delete.\nCopy\nDELETE FROM books\nWHERE author_id = '2034'; -- Assuming '2034' is the author_id to be deleted\nThis deletes all books associated with\nauthor_id\n'2034'.\nThis page is licensed: CC BY-SA / Gnu FDL\nPrevious\nEssential Queries Guide\nNext\nAltering Tables Guide\nLast updated\n5 months ago\nWas this helpful?", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://mariadb.com/kb/en/mariadb-basics/"}}
{"text": "Open Source | Docs\n{\"categories\":null,\"description\":\"Get started with Redis Open Source\",\"title\":\"Open Source\"}\nRedis for AI\nProducts\nProducts\nRedis Cloud\nFully managed and integrated with Google Cloud, Azure, and\nAWS.\nRedis Software\nSelf-managed software with enterprise-grade compliance and\nreliability.\nRedis Open Source\nIn-memory database for caching & streaming.\nTools\nRedis\nLangCache\nRedis\nInsight\nRedis\nData Integration\nClients\n& Connectors\nGet Redis\nDownloads\nResources\nConnect\nCustomer Stories\nPartners\nSupport\nCommunity\nEvents\n& Webinars\nProfessional Services\nLearn\nDocs\nCommands\nQuick\nstarts\nTutorials\nUniversity\nFAQs\nResources\nBlog\nLatest\nReleases\nNews\n& Updates\nSee how it works\nVisit Demo Center\nDocs\nPricing\nSearch\nLogin\nBook a\nmeeting\nTry Redis\nOpen search\nOpen main menu\nOpen Source\nGet started with Redis Open Source\nRedis is an\nin-memory data store\nused by millions of developers as a cache,\nvector database\n,\ndocument database\n,\nstreaming engine\n, and message broker. Redis has built-in replication and different levels of\non-disk persistence\n. It supports complex\ndata types\n(for example, strings, hashes, lists, sets, sorted sets, and JSON), with atomic operations defined on those data types.\nYou can install Redis from source or from an executable/distribution for your OS.\nInstall Redis on Linux using\nAPT\n,\nRPM\n, or\nSnap\nInstall Redis on macOS\nRun Redis on Windows using Docker\nRun Redis on Docker\nInstall Redis from Source\nInstall Redis with Redis Stack and Redis Insight\nUse cases\nThe following quick start guides will show you how to use Redis for the following specific purposes:\nData structure store\nDocument database\nVector database\nAI agents and chatbots\nRetrieval Augmented Generation (RAG) with Redis\nData integration tools, libraries, and frameworks\nClient API libraries\nRedis Data Integration\nRedis vector library for Python\nRedis Cloud with Amazon Bedrock\nObject-mapping for .NET\nSpring Data Redis for Java\nYou can find a complete list of integrations on the\nintegrations and frameworks hub\n.\nTo learn more, refer to the\ndevelop with Redis\ndocumentation.\nDeployment options\nYou can deploy Redis with the following methods:\nAs a service by using\nRedis Cloud\n, the fastest way to deploy Redis on your preferred cloud platform.\nBy installing\nRedis Enterprise Software\nin an on-premises data center or on Cloud infrastructure.\nOn a variety Kubernetes distributions by using the\nRedis Enterprise operator for Kubernetes\n.\nThe following guides will help you to get started with your preferred deployment method.\nGet started with\nRedis Cloud\nby creating a database:\nThe\nRedis Cloud quick start\nhelps you create a free database.  (Start here if you're new.)\nCreate an Essentials database\nwith a memory limit up to 12 GB.\nCreate a Pro database\nthat suits your workload and offers seamless scaling.\nInstall a\nRedis Enterprise Software\ncluster:\nRedis Enterprise on Linux quick start\nRedis Enterprise on Docker quick start\nGet started with Redis Enterprise's Active-Active feature\nInstall and upgrade Redis Enterprise\nLeverage\nRedis Enterprise for Kubernetes\nto simply deploy a Redis Enterprise cluster on Kubernetes:\nDeploy Redis Enterprise for Kubernetes\nDeploy Redis Enterprise for Kubernetes with OpenShift\nTo learn more, refer to the\nRedis products\ndocumentation.\nProvisioning and observability tools\nPulumi provider for Redis Cloud\nTerraform provider for Redis Cloud\nPrometheus and Grafana with Redis Cloud\nPrometheus and Grafana with Redis Enterprise\nYou can find a complete list of integrations on the\nlibraries and tools hub\n.\nRATE THIS PAGE\n★\n★\n★\n★\n★\nBack to top â\nSubmit\nOn this page\nAll products\nRedis Enterprise\nRedis Cloud\nRedis Open Source\nRedis Insight\nRedis Enterprise for K8s\nRedis Data Integration\nClient Libraries\nESC", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://redis.io/docs/latest/get-started/"}}
{"text": "Commands | Docs\n{\"categories\":null,\"description\":\"\",\"title\":\"Commands\"}\nRedis for AI\nProducts\nProducts\nRedis Cloud\nFully managed and integrated with Google Cloud, Azure, and\nAWS.\nRedis Software\nSelf-managed software with enterprise-grade compliance and\nreliability.\nRedis Open Source\nIn-memory database for caching & streaming.\nTools\nRedis\nLangCache\nRedis\nInsight\nRedis\nData Integration\nClients\n& Connectors\nGet Redis\nDownloads\nResources\nConnect\nCustomer Stories\nPartners\nSupport\nCommunity\nEvents\n& Webinars\nProfessional Services\nLearn\nDocs\nCommands\nQuick\nstarts\nTutorials\nUniversity\nFAQs\nResources\nBlog\nLatest\nReleases\nNews\n& Updates\nSee how it works\nVisit Demo Center\nDocs\nPricing\nSearch\nLogin\nBook a\nmeeting\nTry Redis\nOpen search\nOpen main menu\nCommands\nSearch commands…\nFilter by group…\nBloom filter\nBitmap\nCuckoo filter\nCluster management\nCount-min sketch\nConnection management\nGeneric\nGeospatial indices\nHash\nHyperLogLog\nJSON\nList\nPub/Sub\nScripting and functions\nRedis Query Engine\nServer management\nSet\nSorted set\nStream\nString\nAuto-suggest\nT-digest\nTime series\nTop-k\nTransactions\nVector set\nby version\n(all)\n7.0\n6.2\n6.0\n5.0\n4.0\n3.2\n3.0\n2.9\n2.8\n2.6\n2.4\n2.2\n2.0\n1.2\n1.0\n1.0\n1.0\n2.0\n2.4\n2.2\n2.0\n1.0\n2.0\n1.0\n2.2\n2.0\n1.4\n1.2\n1.1\n1.0\n1.0\n2.4\n1.6\n1.4\n1.0\n2.0\nACL CAT\nLists the ACL categories, or the commands inside a category.\nLearn more â\nRead more\nACL DELUSER\nDeletes ACL users, and terminates their connections.\nLearn more â\nRead more\nACL DRYRUN\nSimulates the execution of a command by a user, without executing the command.\nLearn more â\nRead more\nACL GENPASS\nGenerates a pseudorandom, secure password that can be used to identify ACL users.\nLearn more â\nRead more\nACL GETUSER\nLists the ACL rules of a user.\nLearn more â\nRead more\nACL LIST\nDumps the effective rules in ACL file format.\nLearn more â\nRead more\nACL LOAD\nReloads the rules from the configured ACL file.\nLearn more â\nRead more\nACL LOG\nLists recent security events generated due to ACL rules.\nLearn more â\nRead more\nACL SAVE\nSaves the effective ACL rules in the configured ACL file.\nLearn more â\nRead more\nACL SETUSER\nCreates and modifies an ACL user and its rules.\nLearn more â\nRead more\nACL USERS\nLists all ACL users.\nLearn more â\nRead more\nACL WHOAMI\nReturns the authenticated username of the current connection.\nLearn more â\nRead more\nAPPEND\nAppends a string to the value of a key. Creates the key if it doesn't exist.\nLearn more â\nRead more\nASKING\nSignals that a cluster client is following an -ASK redirect.\nLearn more â\nRead more\nAUTH\nAuthenticates the connection.\nLearn more â\nRead more\nBF.ADD\nAdds an item to a Bloom Filter\nLearn more â\nRead more\nBF.CARD\nReturns the cardinality of a Bloom filter\nLearn more â\nRead more\nBF.EXISTS\nChecks whether an item exists in a Bloom Filter\nLearn more â\nRead more\nBF.INFO\nReturns information about a Bloom Filter\nLearn more â\nRead more\nBF.INSERT\nAdds one or more items to a Bloom Filter. A filter will be created if it does not exist\nLearn more â\nRead more\nBF.LOADCHUNK\nRestores a filter previously saved using SCANDUMP\nLearn more â\nRead more\nBF.MADD\nAdds one or more items to a Bloom Filter. A filter will be created if it does not exist\nLearn more â\nRead more\nBF.MEXISTS\nChecks whether one or more items exist in a Bloom Filter\nLearn more â\nRead more\nBF.RESERVE\nCreates a new Bloom Filter\nLearn more â\nRead more\nBF.SCANDUMP\nBegins an incremental save of the bloom filter\nLearn more â\nRead more\nBGREWRITEAOF\nAsynchronously rewrites the append-only file to disk.\nLearn more â\nRead more\nBGSAVE\nAsynchronously saves the database(s) to disk.\nLearn more â\nRead more\nBITCOUNT\nCounts the number of set bits (population counting) in a string.\nLearn more â\nRead more\nBITFIELD\nPerforms arbitrary bitfield integer operations on strings.\nLearn more â\nRead more\nBITFIELD_RO\nPerforms arbitrary read-only bitfield integer operations on strings.\nLearn more â\nRead more\nBITOP\nPerforms bitwise operations on multiple strings, and stores the result.\nLearn more â\nRead more\nBITPOS\nFinds the first set (1) or clear (0) bit in a string.\nLearn more â\nRead more\nBLMOVE\nPops an element from a list, pushes it to another list and returns it. Blocks until an element is available otherwise. Deletes the list if the last element was moved.\nLearn more â\nRead more\nBLMPOP\nPops the first element from one of multiple lists. Blocks until an element is available otherwise. Deletes the list if the last element was popped.\nLearn more â\nRead more\nBLPOP\nRemoves and returns the first element in a list. Blocks until an element is available otherwise. Deletes the list if the last element was popped.\nLearn more â\nRead more\nBRPOP\nRemoves and returns the last element in a list. Blocks until an element is available otherwise. Deletes the list if the last element was popped.\nLearn more â\nRead more\nBRPOPLPUSH\nDeprecated\nUse BLMOVE with the RIGHT and LEFT arguments instead\nPops an element from a list, pushes it to another list and returns it. Block until an element is available otherwise. Deletes the list if the last element was popped.\nLearn more â\nRead more\nBZMPOP\nRemoves and returns a member by score from one or more sorted sets. Blocks until a member is available otherwise. Deletes the sorted set if the last element was popped.\nLearn more â\nRead more\nBZPOPMAX\nRemoves and returns the member with the highest score from one or more sorted sets. Blocks until a member available otherwise.  Deletes the sorted set if the last element was popped.\nLearn more â\nRead more\nBZPOPMIN\nRemoves and returns the member with the lowest score from one or more sorted sets. Blocks until a member is available otherwise. Deletes the sorted set if the last element was popped.\nLearn more â\nRead more\nCF.ADD\nAdds an item to a Cuckoo Filter\nLearn more â\nRead more\nCF.ADDNX\nAdds an item to a Cuckoo Filter if the item did not exist previously.\nLearn more â\nRead more\nCF.COUNT\nReturn the number of times an item might be in a Cuckoo Filter\nLearn more â\nRead more\nCF.DEL\nDeletes an item from a Cuckoo Filter\nLearn more â\nRead more\nCF.EXISTS\nChecks whether one or more items exist in a Cuckoo Filter\nLearn more â\nRead more\nCF.INFO\nReturns information about a Cuckoo Filter\nLearn more â\nRead more\nCF.INSERT\nAdds one or more items to a Cuckoo Filter. A filter will be created if it does not exist\nLearn more â\nRead more\nCF.INSERTNX\nAdds one or more items to a Cuckoo Filter if the items did not exist previously. A filter will be created if it does not exist\nLearn more â\nRead more\nCF.LOADCHUNK\nRestores a filter previously saved using SCANDUMP\nLearn more â\nRead more\nCF.MEXISTS\nChecks whether one or more items exist in a Cuckoo Filter\nLearn more â\nRead more\nCF.RESERVE\nCreates a new Cuckoo Filter\nLearn more â\nRead more\nCF.SCANDUMP\nBegins an incremental save of the bloom filter\nLearn more â\nRead more\nCLIENT CACHING\nInstructs the server whether to track the keys in the next request.\nLearn more â\nRead more\nCLIENT GETNAME\nReturns the name of the connection.\nLearn more â\nRead more\nCLIENT GETREDIR\nReturns the client ID to which the connection's tracking notifications are redirected.\nLearn more â\nRead more\nCLIENT ID\nReturns the unique client ID of the connection.\nLearn more â\nRead more\nCLIENT INFO\nReturns information about the connection.\nLearn more â\nRead more\nCLIENT KILL\nTerminates open connections.\nLearn more â\nRead more\nCLIENT LIST\nLists open connections.\nLearn more â\nRead more\nCLIENT NO-EVICT\nSets the client eviction mode of the connection.\nLearn more â\nRead more\nCLIENT NO-TOUCH\nControls whether commands sent by the client affect the LRU/LFU of accessed keys.\nLearn more â\nRead more\nCLIENT PAUSE\nSuspends commands processing.\nLearn more â\nRead more\nCLIENT REPLY\nInstructs the server whether to reply to commands.\nLearn more â\nRead more\nCLIENT SETINFO\nSets information specific to the client or connection.\nLearn more â\nRead more\nCLIENT SETNAME\nSets the connection name.\nLearn more â\nRead more\nCLIENT TRACKING\nControls server-assisted client-side caching for the connection.\nLearn more â\nRead more\nCLIENT TRACKINGINFO\nReturns information about server-assisted client-side caching for the connection.\nLearn more â\nRead more\nCLIENT UNBLOCK\nUnblocks a client blocked by a blocking command from a different connection.\nLearn more â\nRead more\nCLIENT UNPAUSE\nResumes processing commands from paused clients.\nLearn more â\nRead more\nCLUSTER ADDSLOTS\nAssigns new hash slots to a node.\nLearn more â\nRead more\nCLUSTER ADDSLOTSRANGE\nAssigns new hash slot ranges to a node.\nLearn more â\nRead more\nCLUSTER BUMPEPOCH\nAdvances the cluster config epoch.\nLearn more â\nRead more\nCLUSTER COUNT-FAILURE-REPORTS\nReturns the number of active failure reports active for a node.\nLearn more â\nRead more\nCLUSTER COUNTKEYSINSLOT\nReturns the number of keys in a hash slot.\nLearn more â\nRead more\nCLUSTER DELSLOTS\nSets hash slots as unbound for a node.\nLearn more â\nRead more\nCLUSTER DELSLOTSRANGE\nSets hash slot ranges as unbound for a node.\nLearn more â\nRead more\nCLUSTER FAILOVER\nForces a replica to perform a manual failover of its master.\nLearn more â\nRead more\nCLUSTER FLUSHSLOTS\nDeletes all slots information from a node.\nLearn more â\nRead more\nCLUSTER FORGET\nRemoves a node from the nodes table.\nLearn more â\nRead more\nCLUSTER GETKEYSINSLOT\nReturns the key names in a hash slot.\nLearn more â\nRead more\nCLUSTER INFO\nReturns information about the state of a node.\nLearn more â\nRead more\nCLUSTER KEYSLOT\nReturns the hash slot for a key.\nLearn more â\nRead more\nCLUSTER LINKS\nReturns a list of all TCP links to and from peer nodes.\nLearn more â\nRead more\nCLUSTER MEET\nForces a node to handshake with another node.\nLearn more â\nRead more\nCLUSTER MIGRATION\nStart, monitor, and cancel atomic slot migration tasks.\nLearn more â\nRead more\nCLUSTER MYID\nReturns the ID of a node.\nLearn more â\nRead more\nCLUSTER MYSHARDID\nReturns the shard ID of a node.\nLearn more â\nRead more\nCLUSTER NODES\nReturns the cluster configuration for a node.\nLearn more â\nRead more\nCLUSTER REPLICAS\nLists the replica nodes of a master node.\nLearn more â\nRead more\nCLUSTER REPLICATE\nConfigure a node as replica of a master node.\nLearn more â\nRead more\nCLUSTER RESET\nResets a node.\nLearn more â\nRead more\nCLUSTER SAVECONFIG\nForces a node to save the cluster configuration to disk.\nLearn more â\nRead more\nCLUSTER SET-CONFIG-EPOCH\nSets the configuration epoch for a new node.\nLearn more â\nRead more\nCLUSTER SETSLOT\nBinds a hash slot to a node.\nLearn more â\nRead more\nCLUSTER SHARDS\nReturns the mapping of cluster slots to shards.\nLearn more â\nRead more\nCLUSTER SLAVES\nDeprecated\nUse CLUSTER REPLICAS instead\nLists the replica nodes of a master node.\nLearn more â\nRead more\nCLUSTER SLOT-STATS\nReturn an array of slot usage statistics for slots assigned to the current node.\nLearn more â\nRead more\nCLUSTER SLOTS\nDeprecated\nUse CLUSTER SHARDS instead\nReturns the mapping of cluster slots to nodes.\nLearn more â\nRead more\nCMS.INCRBY\nIncreases the count of one or more items by increment\nLearn more â\nRead more\nCMS.INFO\nReturns information about a sketch\nLearn more â\nRead more\nCMS.INITBYDIM\nInitializes a Count-Min Sketch to dimensions specified by user\nLearn more â\nRead more\nCMS.INITBYPROB\nInitializes a Count-Min Sketch to accommodate requested tolerances.\nLearn more â\nRead more\nCMS.MERGE\nMerges several sketches into one sketch\nLearn more â\nRead more\nCMS.QUERY\nReturns the count for one or more items in a sketch\nLearn more â\nRead more\nCOMMAND\nReturns detailed information about all commands.\nLearn more â\nRead more\nCOMMAND COUNT\nReturns a count of commands.\nLearn more â\nRead more\nCOMMAND DOCS\nReturns documentary information about one, multiple or all commands.\nLearn more â\nRead more\nCOMMAND GETKEYS\nExtracts the key names from an arbitrary command.\nLearn more â\nRead more\nCOMMAND GETKEYSANDFLAGS\nExtracts the key names and access flags for an arbitrary command.\nLearn more â\nRead more\nCOMMAND INFO\nReturns information about one, multiple or all commands.\nLearn more â\nRead more\nCOMMAND LIST\nReturns a list of command names.\nLearn more â\nRead more\nCommands\nLearn more â\nRead more\nCONFIG GET\nReturns the effective values of configuration parameters.\nLearn more â\nRead more\nCONFIG RESETSTAT\nResets the server's statistics.\nLearn more â\nRead more\nCONFIG REWRITE\nPersists the effective configuration to file.\nLearn more â\nRead more\nCONFIG SET\nSets configuration parameters in-flight.\nLearn more â\nRead more\nCOPY\nCopies the value of a key to a new key.\nLearn more â\nRead more\nDBSIZE\nReturns the number of keys in the database.\nLearn more â\nRead more\nDECR\nDecrements the integer value of a key by one. Uses 0 as initial value if the key doesn't exist.\nLearn more â\nRead more\nDECRBY\nDecrements a number from the integer value of a key. Uses 0 as initial value if the key doesn't exist.\nLearn more â\nRead more\nDEL\nDeletes one or more keys.\nLearn more â\nRead more\nDELEX\nConditionally removes the specified key based on value or hash digest comparison.\nLearn more â\nRead more\nDIGEST\nReturns the hash digest of a string value as a hexadecimal string.\nLearn more â\nRead more\nDISCARD\nDiscards a transaction.\nLearn more â\nRead more\nDUMP\nReturns a serialized representation of the value stored at a key.\nLearn more â\nRead more\nECHO\nReturns the given string.\nLearn more â\nRead more\nEVAL\nExecutes a server-side Lua script.\nLearn more â\nRead more\nEVAL_RO\nExecutes a read-only server-side Lua script.\nLearn more â\nRead more\nEVALSHA\nExecutes a server-side Lua script by SHA1 digest.\nLearn more â\nRead more\nEVALSHA_RO\nExecutes a read-only server-side Lua script by SHA1 digest.\nLearn more â\nRead more\nEXEC\nExecutes all commands in a transaction.\nLearn more â\nRead more\nEXISTS\nDetermines whether one or more keys exist.\nLearn more â\nRead more\nEXPIRE\nSets the expiration time of a key in seconds.\nLearn more â\nRead more\nEXPIREAT\nSets the expiration time of a key to a Unix timestamp.\nLearn more â\nRead more\nEXPIRETIME\nReturns the expiration time of a key as a Unix timestamp.\nLearn more â\nRead more\nFAILOVER\nStarts a coordinated failover from a server to one of its replicas.\nLearn more â\nRead more\nFCALL\nInvokes a function.\nLearn more â\nRead more\nFCALL_RO\nInvokes a read-only function.\nLearn more â\nRead more\nFLUSHALL\nRemoves all keys from all databases.\nLearn more â\nRead more\nFLUSHDB\nRemove all keys from the current database.\nLearn more â\nRead more\nFT._LIST\nReturns a list of all existing indexes\nLearn more â\nRead more\nFT.AGGREGATE\nRun a search query on an index and perform aggregate transformations on the results\nLearn more â\nRead more\nFT.ALIASADD\nAdds an alias to the index\nLearn more â\nRead more\nFT.ALIASDEL\nDeletes an alias from the index\nLearn more â\nRead more\nFT.ALIASUPDATE\nAdds or updates an alias to the index\nLearn more â\nRead more\nFT.ALTER\nAdds a new field to the index\nLearn more â\nRead more\nFT.CONFIG GET\nDeprecated\nUse CONFIG GET instead\nRetrieves runtime configuration options\nLearn more â\nRead more\nFT.CONFIG SET\nDeprecated\nUse CONFIG SET instead\nSets runtime configuration options\nLearn more â\nRead more\nFT.CREATE\nCreates an index with the given spec\nLearn more â\nRead more\nFT.CURSOR DEL\nDeletes a cursor\nLearn more â\nRead more\nFT.CURSOR READ\nReads from a cursor\nLearn more â\nRead more\nFT.DICTADD\nAdds terms to a dictionary\nLearn more â\nRead more\nFT.DICTDEL\nDeletes terms from a dictionary\nLearn more â\nRead more\nFT.DICTDUMP\nDumps all terms in the given dictionary\nLearn more â\nRead more\nFT.DROPINDEX\nDeletes the index\nLearn more â\nRead more\nFT.EXPLAIN\nReturns the execution plan for a complex query\nLearn more â\nRead more\nFT.EXPLAINCLI\nReturns the execution plan for a complex query\nLearn more â\nRead more\nFT.HYBRID\nPerforms hybrid search combining text search and vector similarity search\nLearn more â\nRead more\nFT.INFO\nReturns information and statistics on the index\nLearn more â\nRead more\nFT.PROFILE\nPerforms a `FT.SEARCH` or `FT.AGGREGATE` command and collects performance information\nLearn more â\nRead more\nFT.SEARCH\nSearches the index with a textual query, returning either documents or just ids\nLearn more â\nRead more\nFT.SPELLCHECK\nPerforms spelling correction on a query, returning suggestions for misspelled terms\nLearn more â\nRead more\nFT.SUGADD\nAdds a suggestion string to an auto-complete suggestion dictionary\nLearn more â\nRead more\nFT.SUGDEL\nDeletes a string from a suggestion index\nLearn more â\nRead more\nFT.SUGGET\nGets completion suggestions for a prefix\nLearn more â\nRead more\nFT.SUGLEN\nGets the size of an auto-complete suggestion dictionary\nLearn more â\nRead more\nFT.SYNDUMP\nDumps the contents of a synonym group\nLearn more â\nRead more\nFT.SYNUPDATE\nCreates or updates a synonym group with additional terms\nLearn more â\nRead more\nFT.TAGVALS\nDeprecated\nReturns the distinct tags indexed in a Tag field\nLearn more â\nRead more\nFUNCTION DELETE\nDeletes a library and its functions.\nLearn more â\nRead more\nFUNCTION DUMP\nDumps all libraries into a serialized binary payload.\nLearn more â\nRead more\nFUNCTION FLUSH\nDeletes all libraries and functions.\nLearn more â\nRead more\nFUNCTION KILL\nTerminates a function during execution.\nLearn more â\nRead more\nFUNCTION LIST\nReturns information about all libraries.\nLearn more â\nRead more\nFUNCTION LOAD\nCreates a library.\nLearn more â\nRead more\nFUNCTION RESTORE\nRestores all libraries from a payload.\nLearn more â\nRead more\nFUNCTION STATS\nReturns information about a function during execution.\nLearn more â\nRead more\nGEOADD\nAdds one or more members to a geospatial index. The key is created if it doesn't exist.\nLearn more â\nRead more\nGEODIST\nReturns the distance between two members of a geospatial index.\nLearn more â\nRead more\nGEOHASH\nReturns members from a geospatial index as geohash strings.\nLearn more â\nRead more\nGEOPOS\nReturns the longitude and latitude of members from a geospatial index.\nLearn more â\nRead more\nGEORADIUS\nDeprecated\nUse GEOSEARCH and GEOSEARCHSTORE with the BYRADIUS argument instead\nQueries a geospatial index for members within a distance from a coordinate, optionally stores the result.\nLearn more â\nRead more\nGEORADIUS_RO\nDeprecated\nUse GEOSEARCH with the BYRADIUS argument instead\nReturns members from a geospatial index that are within a distance from a coordinate.\nLearn more â\nRead more\nGEORADIUSBYMEMBER\nDeprecated\nUse GEOSEARCH and GEOSEARCHSTORE with the BYRADIUS and FROMMEMBER arguments instead\nQueries a geospatial index for members within a distance from a member, optionally stores the result.\nLearn more â\nRead more\nGEORADIUSBYMEMBER_RO\nDeprecated\nUse GEOSEARCH with the BYRADIUS and FROMMEMBER arguments instead\nReturns members from a geospatial index that are within a distance from a member.\nLearn more â\nRead more\nGEOSEARCH\nQueries a geospatial index for members inside an area of a box or a circle.\nLearn more â\nRead more\nGEOSEARCHSTORE\nQueries a geospatial index for members inside an area of a box or a circle, optionally stores the result.\nLearn more â\nRead more\nGET\nReturns the string value of a key.\nLearn more â\nRead more\nGETBIT\nReturns a bit value by offset.\nLearn more â\nRead more\nGETDEL\nReturns the string value of a key after deleting the key.\nLearn more â\nRead more\nGETEX\nReturns the string value of a key after setting its expiration time.\nLearn more â\nRead more\nGETRANGE\nReturns a substring of the string stored at a key.\nLearn more â\nRead more\nGETSET\nDeprecated\nUse SET with the GET argument instead\nReturns the previous string value of a key after setting it to a new value.\nLearn more â\nRead more\nHDEL\nDeletes one or more fields and their values from a hash. Deletes the hash if no fields remain.\nLearn more â\nRead more\nHELLO\nHandshakes with the Redis server.\nLearn more â\nRead more\nHEXISTS\nDetermines whether a field exists in a hash.\nLearn more â\nRead more\nHEXPIRE\nSet expiry for hash field using relative time to expire (seconds)\nLearn more â\nRead more\nHEXPIREAT\nSet expiry for hash field using an absolute Unix timestamp (seconds)\nLearn more â\nRead more\nHEXPIRETIME\nReturns the expiration time of a hash field as a Unix timestamp, in seconds.\nLearn more â\nRead more\nHGET\nReturns the value of a field in a hash.\nLearn more â\nRead more\nHGETALL\nReturns all fields and values in a hash.\nLearn more â\nRead more\nHGETDEL\nReturns the value of a field and deletes it from the hash.\nLearn more â\nRead more\nHGETEX\nGet the value of one or more fields of a given hash key, and optionally set their expiration.\nLearn more â\nRead more\nHINCRBY\nIncrements the integer value of a field in a hash by a number. Uses 0 as initial value if the field doesn't exist.\nLearn more â\nRead more\nHINCRBYFLOAT\nIncrements the floating point value of a field by a number. Uses 0 as initial value if the field doesn't exist.\nLearn more â\nRead more\nHKEYS\nReturns all fields in a hash.\nLearn more â\nRead more\nHLEN\nReturns the number of fields in a hash.\nLearn more â\nRead more\nHMGET\nReturns the values of all fields in a hash.\nLearn more â\nRead more\nHMSET\nDeprecated\nUse HSET with multiple field-value pairs instead\nSets the values of multiple fields.\nLearn more â\nRead more\nHPERSIST\nRemoves the expiration time for each specified field\nLearn more â\nRead more\nHPEXPIRE\nSet expiry for hash field using relative time to expire (milliseconds)\nLearn more â\nRead more\nHPEXPIREAT\nSet expiry for hash field using an absolute Unix timestamp (milliseconds)\nLearn more â\nRead more\nHPEXPIRETIME\nReturns the expiration time of a hash field as a Unix timestamp, in msec.\nLearn more â\nRead more\nHPTTL\nReturns the TTL in milliseconds of a hash field.\nLearn more â\nRead more\nHRANDFIELD\nReturns one or more random fields from a hash.\nLearn more â\nRead more\nHSCAN\nIterates over fields and values of a hash.\nLearn more â\nRead more\nHSET\nCreates or modifies the value of a field in a hash.\nLearn more â\nRead more\nHSETEX\nSet the value of one or more fields of a given hash key, and optionally set their expiration.\nLearn more â\nRead more\nHSETNX\nSets the value of a field in a hash only when the field doesn't exist.\nLearn more â\nRead more\nHSTRLEN\nReturns the length of the value of a field.\nLearn more â\nRead more\nHTTL\nReturns the TTL in seconds of a hash field.\nLearn more â\nRead more\nHVALS\nReturns all values in a hash.\nLearn more â\nRead more\nINCR\nIncrements the integer value of a key by one. Uses 0 as initial value if the key doesn't exist.\nLearn more â\nRead more\nINCRBY\nIncrements the integer value of a key by a number. Uses 0 as initial value if the key doesn't exist.\nLearn more â\nRead more\nINCRBYFLOAT\nIncrement the floating point value of a key by a number. Uses 0 as initial value if the key doesn't exist.\nLearn more â\nRead more\nINFO\nReturns information and statistics about the server.\nLearn more â\nRead more\nJSON.ARRAPPEND\nAppend one or more JSON values into the array at path after the last element in it.\nLearn more â\nRead more\nJSON.ARRINDEX\nReturns the index of the first occurrence of a JSON scalar value in the array at path\nLearn more â\nRead more\nJSON.ARRINSERT\nInserts the JSON scalar(s) value at the specified index in the array at path\nLearn more â\nRead more\nJSON.ARRLEN\nReturns the length of the array at path\nLearn more â\nRead more\nJSON.ARRPOP\nRemoves and returns the element at the specified index in the array at path\nLearn more â\nRead more\nJSON.ARRTRIM\nTrims the array at path to contain only the specified inclusive range of indices from start to stop\nLearn more â\nRead more\nJSON.CLEAR\nClears all values from an array or an object and sets numeric values to `0`\nLearn more â\nRead more\nJSON.DEBUG\nDebugging container command\nLearn more â\nRead more\nJSON.DEBUG MEMORY\nReports the size in bytes of a key\nLearn more â\nRead more\nJSON.DEL\nDeletes a value\nLearn more â\nRead more\nJSON.FORGET\nDeletes a value\nLearn more â\nRead more\nJSON.GET\nGets the value at one or more paths in JSON serialized form\nLearn more â\nRead more\nJSON.MERGE\nMerges a given JSON value into matching paths. Consequently, JSON values at matching paths are updated, deleted, or expanded with new children\nLearn more â\nRead more\nJSON.MGET\nReturns the values at a path from one or more keys\nLearn more â\nRead more\nJSON.MSET\nSets or updates the JSON value of one or more keys\nLearn more â\nRead more\nJSON.NUMINCRBY\nIncrements the numeric value at path by a value\nLearn more â\nRead more\nJSON.NUMMULTBY\nMultiplies the numeric value at path by a value\nLearn more â\nRead more\nJSON.OBJKEYS\nReturns the JSON keys of the object at path\nLearn more â\nRead more\nJSON.OBJLEN\nReturns the number of keys of the object at path\nLearn more â\nRead more\nJSON.RESP\nReturns the JSON value at path in Redis Serialization Protocol (RESP)\nLearn more â\nRead more\nJSON.SET\nSets or updates the JSON value at a path\nLearn more â\nRead more\nJSON.STRAPPEND\nAppends a string to a JSON string value at path\nLearn more â\nRead more\nJSON.STRLEN\nReturns the length of the JSON String at path in key\nLearn more â\nRead more\nJSON.TOGGLE\nToggles a boolean value\nLearn more â\nRead more\nJSON.TYPE\nReturns the type of the JSON value at path\nLearn more â\nRead more\nKEYS\nReturns all key names that match a pattern.\nLearn more â\nRead more\nLASTSAVE\nReturns the Unix timestamp of the last successful save to disk.\nLearn more â\nRead more\nLATENCY DOCTOR\nReturns a human-readable latency analysis report.\nLearn more â\nRead more\nLATENCY GRAPH\nReturns a latency graph for an event.\nLearn more â\nRead more\nLATENCY HISTOGRAM\nReturns the cumulative distribution of latencies of a subset or all commands.\nLearn more â\nRead more\nLATENCY HISTORY\nReturns timestamp-latency samples for an event.\nLearn more â\nRead more\nLATENCY LATEST\nReturns the latest latency samples for all events.\nLearn more â\nRead more\nLATENCY RESET\nResets the latency data for one or more events.\nLearn more â\nRead more\nLCS\nFinds the longest common substring.\nLearn more â\nRead more\nLINDEX\nReturns an element from a list by its index.\nLearn more â\nRead more\nLINSERT\nInserts an element before or after another element in a list.\nLearn more â\nRead more\nLLEN\nReturns the length of a list.\nLearn more â\nRead more\nLMOVE\nReturns an element after popping it from one list and pushing it to another. Deletes the list if the last element was moved.\nLearn more â\nRead more\nLMPOP\nReturns multiple elements from a list after removing them. Deletes the list if the last element was popped.\nLearn more â\nRead more\nLOLWUT\nDisplays computer art and the Redis version\nLearn more â\nRead more\nLPOP\nReturns the first elements in a list after removing it. Deletes the list if the last element was popped.\nLearn more â\nRead more\nLPOS\nReturns the index of matching elements in a list.\nLearn more â\nRead more\nLPUSH\nPrepends one or more elements to a list. Creates the key if it doesn't exist.\nLearn more â\nRead more\nLPUSHX\nPrepends one or more elements to a list only when the list exists.\nLearn more â\nRead more\nLRANGE\nReturns a range of elements from a list.\nLearn more â\nRead more\nLREM\nRemoves elements from a list. Deletes the list if the last element was removed.\nLearn more â\nRead more\nLSET\nSets the value of an element in a list by its index.\nLearn more â\nRead more\nLTRIM\nRemoves elements from both ends a list. Deletes the list if all elements were trimmed.\nLearn more â\nRead more\nMEMORY DOCTOR\nOutputs a memory problems report.\nLearn more â\nRead more\nMEMORY MALLOC-STATS\nReturns the allocator statistics.\nLearn more â\nRead more\nMEMORY PURGE\nAsks the allocator to release memory.\nLearn more â\nRead more\nMEMORY STATS\nReturns details about memory usage.\nLearn more â\nRead more\nMEMORY USAGE\nEstimates the memory usage of a key.\nLearn more â\nRead more\nMGET\nAtomically returns the string values of one or more keys.\nLearn more â\nRead more\nMIGRATE\nAtomically transfers a key from one Redis instance to another.\nLearn more â\nRead more\nMODULE LIST\nReturns all loaded modules.\nLearn more â\nRead more\nMODULE LOAD\nLoads a module.\nLearn more â\nRead more\nMODULE LOADEX\nLoads a module using extended parameters.\nLearn more â\nRead more\nMODULE UNLOAD\nUnloads a module.\nLearn more â\nRead more\nMONITOR\nListens for all requests received by the server in real-time.\nLearn more â\nRead more\nMOVE\nMoves a key to another database.\nLearn more â\nRead more\nMSET\nAtomically creates or modifies the string values of one or more keys.\nLearn more â\nRead more\nMSETEX\nAtomically sets multiple string keys with a shared expiration in a single operation.\nLearn more â\nRead more\nMSETNX\nAtomically modifies the string values of one or more keys only when all keys don't exist.\nLearn more â\nRead more\nMULTI\nStarts a transaction.\nLearn more â\nRead more\nOBJECT ENCODING\nReturns the internal encoding of a Redis object.\nLearn more â\nRead more\nOBJECT FREQ\nReturns the logarithmic access frequency counter of a Redis object.\nLearn more â\nRead more\nOBJECT IDLETIME\nReturns the time since the last access to a Redis object.\nLearn more â\nRead more\nOBJECT REFCOUNT\nReturns the reference count of a value of a key.\nLearn more â\nRead more\nPERSIST\nRemoves the expiration time of a key.\nLearn more â\nRead more\nPEXPIRE\nSets the expiration time of a key in milliseconds.\nLearn more â\nRead more\nPEXPIREAT\nSets the expiration time of a key to a Unix milliseconds timestamp.\nLearn more â\nRead more\nPEXPIRETIME\nReturns the expiration time of a key as a Unix milliseconds timestamp.\nLearn more â\nRead more\nPFADD\nAdds elements to a HyperLogLog key. Creates the key if it doesn't exist.\nLearn more â\nRead more\nPFCOUNT\nReturns the approximated cardinality of the set(s) observed by the HyperLogLog key(s).\nLearn more â\nRead more\nPFDEBUG\nInternal commands for debugging HyperLogLog values.\nLearn more â\nRead more\nPFMERGE\nMerges one or more HyperLogLog values into a single key.\nLearn more â\nRead more\nPFSELFTEST\nAn internal command for testing HyperLogLog values.\nLearn more â\nRead more\nPING\nReturns the server's liveliness response.\nLearn more â\nRead more\nPSETEX\nDeprecated\nUse SET with the PX argument instead\nSets both string value and expiration time in milliseconds of a key. The key is created if it doesn't exist.\nLearn more â\nRead more\nPSUBSCRIBE\nListens for messages published to channels that match one or more patterns.\nLearn more â\nRead more\nPSYNC\nAn internal command used in replication.\nLearn more â\nRead more\nPTTL\nReturns the expiration time in milliseconds of a key.\nLearn more â\nRead more\nPUBLISH\nPosts a message to a channel.\nLearn more â\nRead more\nPUBSUB CHANNELS\nReturns the active channels.\nLearn more â\nRead more\nPUBSUB NUMPAT\nReturns a count of unique pattern subscriptions.\nLearn more â\nRead more\nPUBSUB NUMSUB\nReturns a count of subscribers to channels.\nLearn more â\nRead more\nPUBSUB SHARDCHANNELS\nReturns the active shard channels.\nLearn more â\nRead more\nPUBSUB SHARDNUMSUB\nReturns the count of subscribers of shard channels.\nLearn more â\nRead more\nPUNSUBSCRIBE\nStops listening to messages published to channels that match one or more patterns.\nLearn more â\nRead more\nQUIT\nDeprecated\nUse just closing the connection instead\nCloses the connection.\nLearn more â\nRead more\nRANDOMKEY\nReturns a random key name from the database.\nLearn more â\nRead more\nREADONLY\nEnables read-only queries for a connection to a Redis Cluster replica node.\nLearn more â\nRead more\nREADWRITE\nEnables read-write queries for a connection to a Reids Cluster replica node.\nLearn more â\nRead more\nRENAME\nRenames a key and overwrites the destination.\nLearn more â\nRead more\nRENAMENX\nRenames a key only when the target key name doesn't exist.\nLearn more â\nRead more\nREPLCONF\nAn internal command for configuring the replication stream.\nLearn more â\nRead more\nREPLICAOF\nConfigures a server as replica of another, or promotes it to a master.\nLearn more â\nRead more\nRESET\nResets the connection.\nLearn more â\nRead more\nRESTORE\nCreates a key from the serialized representation of a value.\nLearn more â\nRead more\nRESTORE-ASKING\nAn internal command for migrating keys in a cluster.\nLearn more â\nRead more\nROLE\nReturns the replication role.\nLearn more â\nRead more\nRPOP\nReturns and removes the last elements of a list. Deletes the list if the last element was popped.\nLearn more â\nRead more\nRPOPLPUSH\nDeprecated\nUse LMOVE with the RIGHT and LEFT arguments instead\nReturns the last element of a list after removing and pushing it to another list. Deletes the list if the last element was popped.\nLearn more â\nRead more\nRPUSH\nAppends one or more elements to a list. Creates the key if it doesn't exist.\nLearn more â\nRead more\nRPUSHX\nAppends an element to a list only when the list exists.\nLearn more â\nRead more\nSADD\nAdds one or more members to a set. Creates the key if it doesn't exist.\nLearn more â\nRead more\nSAVE\nSynchronously saves the database(s) to disk.\nLearn more â\nRead more\nSCAN\nIterates over the key names in the database.\nLearn more â\nRead more\nSCARD\nReturns the number of members in a set.\nLearn more â\nRead more\nSCRIPT DEBUG\nSets the debug mode of server-side Lua scripts.\nLearn more â\nRead more\nSCRIPT EXISTS\nDetermines whether server-side Lua scripts exist in the script cache.\nLearn more â\nRead more\nSCRIPT FLUSH\nRemoves all server-side Lua scripts from the script cache.\nLearn more â\nRead more\nSCRIPT KILL\nTerminates a server-side Lua script during execution.\nLearn more â\nRead more\nSCRIPT LOAD\nLoads a server-side Lua script to the script cache.\nLearn more â\nRead more\nSDIFF\nReturns the difference of multiple sets.\nLearn more â\nRead more\nSDIFFSTORE\nStores the difference of multiple sets in a key.\nLearn more â\nRead more\nSELECT\nChanges the selected database.\nLearn more â\nRead more\nSET\nSets the string value of a key, ignoring its type. The key is created if it doesn't exist.\nLearn more â\nRead more\nSETBIT\nSets or clears the bit at offset of the string value. Creates the key if it doesn't exist.\nLearn more â\nRead more\nSETEX\nDeprecated\nUse SET with the EX argument instead\nSets the string value and expiration time of a key. Creates the key if it doesn't exist.\nLearn more â\nRead more\nSETNX\nDeprecated\nUse SET with the NX argument instead\nSet the string value of a key only when the key doesn't exist.\nLearn more â\nRead more\nSETRANGE\nOverwrites a part of a string value with another by an offset. Creates the key if it doesn't exist.\nLearn more â\nRead more\nSHUTDOWN\nSynchronously saves the database(s) to disk and shuts down the Redis server.\nLearn more â\nRead more\nSINTER\nReturns the intersect of multiple sets.\nLearn more â\nRead more\nSINTERCARD\nReturns the number of members of the intersect of multiple sets.\nLearn more â\nRead more\nSINTERSTORE\nStores the intersect of multiple sets in a key.\nLearn more â\nRead more\nSISMEMBER\nDetermines whether a member belongs to a set.\nLearn more â\nRead more\nSLAVEOF\nDeprecated\nUse REPLICAOF instead\nSets a Redis server as a replica of another, or promotes it to being a master.\nLearn more â\nRead more\nSLOWLOG GET\nReturns the slow log's entries.\nLearn more â\nRead more\nSLOWLOG LEN\nReturns the number of entries in the slow log.\nLearn more â\nRead more\nSLOWLOG RESET\nClears all entries from the slow log.\nLearn more â\nRead more\nSMEMBERS\nReturns all members of a set.\nLearn more â\nRead more\nSMISMEMBER\nDetermines whether multiple members belong to a set.\nLearn more â\nRead more\nSMOVE\nMoves a member from one set to another.\nLearn more â\nRead more\nSORT\nSorts the elements in a list, a set, or a sorted set, optionally storing the result.\nLearn more â\nRead more\nSORT_RO\nReturns the sorted elements of a list, a set, or a sorted set.\nLearn more â\nRead more\nSPOP\nReturns one or more random members from a set after removing them. Deletes the set if the last member was popped.\nLearn more â\nRead more\nSPUBLISH\nPost a message to a shard channel\nLearn more â\nRead more\nSRANDMEMBER\nGet one or multiple random members from a set\nLearn more â\nRead more\nSREM\nRemoves one or more members from a set. Deletes the set if the last member was removed.\nLearn more â\nRead more\nSSCAN\nIterates over members of a set.\nLearn more â\nRead more\nSSUBSCRIBE\nListens for messages published to shard channels.\nLearn more â\nRead more\nSTRLEN\nReturns the length of a string value.\nLearn more â\nRead more\nSUBSCRIBE\nListens for messages published to channels.\nLearn more â\nRead more\nSUBSTR\nDeprecated\nUse GETRANGE instead\nReturns a substring from a string value.\nLearn more â\nRead more\nSUNION\nReturns the union of multiple sets.\nLearn more â\nRead more\nSUNIONSTORE\nStores the union of multiple sets in a key.\nLearn more â\nRead more\nSUNSUBSCRIBE\nStops listening to messages posted to shard channels.\nLearn more â\nRead more\nSWAPDB\nSwaps two Redis databases.\nLearn more â\nRead more\nSYNC\nAn internal command used in replication.\nLearn more â\nRead more\nTDIGEST.ADD\nAdds one or more observations to a t-digest sketch\nLearn more â\nRead more\nTDIGEST.BYRANK\nReturns, for each input rank, a floating-point estimation of the value with that rank\nLearn more â\nRead more\nTDIGEST.BYREVRANK\nReturns, for each input reverse rank, an estimation of the floating-point value with that reverse rank\nLearn more â\nRead more\nTDIGEST.CDF\nReturns, for each input value, an estimation of the floating-point fraction of (observations smaller than the given value + half the observations equal to the given value)\nLearn more â\nRead more\nTDIGEST.CREATE\nAllocates memory and initializes a new t-digest sketch\nLearn more â\nRead more\nTDIGEST.INFO\nReturns information and statistics about a t-digest sketch\nLearn more â\nRead more\nTDIGEST.MAX\nReturns the maximum observation value from a t-digest sketch\nLearn more â\nRead more\nTDIGEST.MERGE\nMerges multiple t-digest sketches into a single sketch\nLearn more â\nRead more\nTDIGEST.MIN\nReturns the minimum observation value from a t-digest sketch\nLearn more â\nRead more\nTDIGEST.QUANTILE\nReturns, for each input fraction, a floating-point estimation of the value that is smaller than the given fraction of observations\nLearn more â\nRead more\nTDIGEST.RANK\nReturns, for each floating-point input value, the estimated rank of the value (the number of observations in the sketch that are smaller than the value + half the number of observations that are equal to the value)\nLearn more â\nRead more\nTDIGEST.RESET\nResets a t-digest sketch (empties the sketch and re-initializes it).\nLearn more â\nRead more\nTDIGEST.REVRANK\nReturns, for each floating-point input value, the estimated reverse rank of the value (the number of observations in the sketch that are larger than the value + half the number of observations that are equal to the value)\nLearn more â\nRead more\nTDIGEST.TRIMMED_MEAN\nReturns an estimation of the mean value from the sketch, excluding observation values outside the low and high cutoff quantiles\nLearn more â\nRead more\nTIME\nReturns the server time.\nLearn more â\nRead more\nTOPK.ADD\nAdds an item to a Top-k sketch. Multiple items can be added at the same time.\nLearn more â\nRead more\nTOPK.COUNT\nReturn the count for one or more items in a sketch\nLearn more â\nRead more\nTOPK.INCRBY\nIncreases the count of one or more items by increment\nLearn more â\nRead more\nTOPK.INFO\nReturns information about a sketch\nLearn more â\nRead more\nTOPK.LIST\nReturn the full list of items in the Top-K sketch\nLearn more â\nRead more\nTOPK.QUERY\nChecks whether one or more items are in a sketch\nLearn more â\nRead more\nTOPK.RESERVE\nInitializes a Top-K sketch with specified parameters\nLearn more â\nRead more\nTOUCH\nReturns the number of existing keys out of those specified after updating the time they were last accessed.\nLearn more â\nRead more\nTS.ADD\nAppend a sample to a time series\nLearn more â\nRead more\nTS.ALTER\nUpdate the retention, chunk size, duplicate policy, and labels of an existing time series\nLearn more â\nRead more\nTS.CREATE\nCreate a new time series\nLearn more â\nRead more\nTS.CREATERULE\nCreate a compaction rule\nLearn more â\nRead more\nTS.DECRBY\nDecrease the value of the sample with the maximum existing timestamp, or create a new sample with a value equal to the value of the sample with the maximum existing timestamp with a given decrement\nLearn more â\nRead more\nTS.DEL\nDelete all samples between two timestamps for a given time series\nLearn more â\nRead more\nTS.DELETERULE\nDelete a compaction rule\nLearn more â\nRead more\nTS.GET\nGet the sample with the highest timestamp from a given time series\nLearn more â\nRead more\nTS.INCRBY\nIncrease the value of the sample with the maximum existing timestamp, or create a new sample with a value equal to the value of the sample with the maximum existing timestamp with a given increment\nLearn more â\nRead more\nTS.INFO\nReturns information and statistics for a time series\nLearn more â\nRead more\nTS.MADD\nAppend new samples to one or more time series\nLearn more â\nRead more\nTS.MGET\nGet the sample with the highest timestamp from each time series matching a specific filter\nLearn more â\nRead more\nTS.MRANGE\nQuery a range across multiple time series by filters in forward direction\nLearn more â\nRead more\nTS.MREVRANGE\nQuery a range across multiple time-series by filters in reverse direction\nLearn more â\nRead more\nTS.QUERYINDEX\nGet all time series keys matching a filter list\nLearn more â\nRead more\nTS.RANGE\nQuery a range in forward direction\nLearn more â\nRead more\nTS.REVRANGE\nQuery a range in reverse direction\nLearn more â\nRead more\nTTL\nReturns the expiration time in seconds of a key.\nLearn more â\nRead more\nTYPE\nDetermines the type of value stored at a key.\nLearn more â\nRead more\nUNLINK\nAsynchronously deletes one or more keys.\nLearn more â\nRead more\nUNSUBSCRIBE\nStops listening to messages posted to channels.\nLearn more â\nRead more\nUNWATCH\nForgets about watched keys of a transaction.\nLearn more â\nRead more\nVADD\nAdd a new element to a vector set, or update its vector if it already exists.\nLearn more â\nRead more\nVCARD\nReturn the number of elements in a vector set.\nLearn more â\nRead more\nVDIM\nReturn the dimension of vectors in the vector set.\nLearn more â\nRead more\nVEMB\nReturn the vector associated with an element.\nLearn more â\nRead more\nVGETATTR\nRetrieve the JSON attributes of elements.\nLearn more â\nRead more\nVINFO\nReturn information about a vector set.\nLearn more â\nRead more\nVISMEMBER\nCheck if an element exists in a vector set.\nLearn more â\nRead more\nVLINKS\nReturn the neighbors of an element at each layer in the HNSW graph.\nLearn more â\nRead more\nVRANDMEMBER\nReturn one or multiple random members from a vector set.\nLearn more â\nRead more\nVRANGE\nReturn elements in a lexicographical range\nLearn more â\nRead more\nVREM\nRemove an element from a vector set.\nLearn more â\nRead more\nVSETATTR\nAssociate or remove the JSON attributes of elements.\nLearn more â\nRead more\nVSIM\nReturn elements by vector similarity.\nLearn more â\nRead more\nWAIT\nBlocks until the asynchronous replication of all preceding write commands sent by the connection is completed.\nLearn more â\nRead more\nWAITAOF\nBlocks until all of the preceding write commands sent by the connection are written to the append-only file of the master and/or replicas.\nLearn more â\nRead more\nWATCH\nMonitors changes to keys to determine the execution of a transaction.\nLearn more â\nRead more\nXACK\nReturns the number of messages that were successfully acknowledged by the consumer group member of a stream.\nLearn more â\nRead more\nXACKDEL\nAcknowledges and conditionally deletes one or multiple entries for a stream consumer group.\nLearn more â\nRead more\nXADD\nAppends a new message to a stream. Creates the key if it doesn't exist.\nLearn more â\nRead more\nXAUTOCLAIM\nChanges, or acquires, ownership of messages in a consumer group, as if the messages were delivered to as consumer group member.\nLearn more â\nRead more\nXCLAIM\nChanges, or acquires, ownership of a message in a consumer group, as if the message was delivered a consumer group member.\nLearn more â\nRead more\nXDEL\nReturns the number of messages after removing them from a stream.\nLearn more â\nRead more\nXDELEX\nDeletes one or multiple entries from the stream.\nLearn more â\nRead more\nXGROUP CREATE\nCreates a consumer group.\nLearn more â\nRead more\nXGROUP CREATECONSUMER\nCreates a consumer in a consumer group.\nLearn more â\nRead more\nXGROUP DELCONSUMER\nDeletes a consumer from a consumer group.\nLearn more â\nRead more\nXGROUP DESTROY\nDestroys a consumer group.\nLearn more â\nRead more\nXGROUP SETID\nSets the last-delivered ID of a consumer group.\nLearn more â\nRead more\nXINFO CONSUMERS\nReturns a list of the consumers in a consumer group.\nLearn more â\nRead more\nXINFO GROUPS\nReturns a list of the consumer groups of a stream.\nLearn more â\nRead more\nXINFO STREAM\nReturns information about a stream.\nLearn more â\nRead more\nXLEN\nReturn the number of messages in a stream.\nLearn more â\nRead more\nXPENDING\nReturns the information and entries from a stream consumer group's pending entries list.\nLearn more â\nRead more\nXRANGE\nReturns the messages from a stream within a range of IDs.\nLearn more â\nRead more\nXREAD\nReturns messages from multiple streams with IDs greater than the ones requested. Blocks until a message is available otherwise.\nLearn more â\nRead more\nXREADGROUP\nReturns new or historical messages from a stream for a consumer in a group. Blocks until a message is available otherwise.\nLearn more â\nRead more\nXREVRANGE\nReturns the messages from a stream within a range of IDs in reverse order.\nLearn more â\nRead more\nXSETID\nAn internal command for replicating stream values.\nLearn more â\nRead more\nXTRIM\nDeletes messages from the beginning of a stream.\nLearn more â\nRead more\nZADD\nAdds one or more members to a sorted set, or updates their scores. Creates the key if it doesn't exist.\nLearn more â\nRead more\nZCARD\nReturns the number of members in a sorted set.\nLearn more â\nRead more\nZCOUNT\nReturns the count of members in a sorted set that have scores within a range.\nLearn more â\nRead more\nZDIFF\nReturns the difference between multiple sorted sets.\nLearn more â\nRead more\nZDIFFSTORE\nStores the difference of multiple sorted sets in a key.\nLearn more â\nRead more\nZINCRBY\nIncrements the score of a member in a sorted set.\nLearn more â\nRead more\nZINTER\nReturns the intersect of multiple sorted sets.\nLearn more â\nRead more\nZINTERCARD\nReturns the number of members of the intersect of multiple sorted sets.\nLearn more â\nRead more\nZINTERSTORE\nStores the intersect of multiple sorted sets in a key.\nLearn more â\nRead more\nZLEXCOUNT\nReturns the number of members in a sorted set within a lexicographical range.\nLearn more â\nRead more\nZMPOP\nReturns the highest- or lowest-scoring members from one or more sorted sets after removing them. Deletes the sorted set if the last member was popped.\nLearn more â\nRead more\nZMSCORE\nReturns the score of one or more members in a sorted set.\nLearn more â\nRead more\nZPOPMAX\nReturns the highest-scoring members from a sorted set after removing them. Deletes the sorted set if the last member was popped.\nLearn more â\nRead more\nZPOPMIN\nReturns the lowest-scoring members from a sorted set after removing them. Deletes the sorted set if the last member was popped.\nLearn more â\nRead more\nZRANDMEMBER\nReturns one or more random members from a sorted set.\nLearn more â\nRead more\nZRANGE\nReturns members in a sorted set within a range of indexes.\nLearn more â\nRead more\nZRANGEBYLEX\nDeprecated\nUse ZRANGE with the BYLEX argument instead\nReturns members in a sorted set within a lexicographical range.\nLearn more â\nRead more\nZRANGEBYSCORE\nDeprecated\nUse ZRANGE with the BYSCORE argument instead\nReturns members in a sorted set within a range of scores.\nLearn more â\nRead more\nZRANGESTORE\nStores a range of members from sorted set in a key.\nLearn more â\nRead more\nZRANK\nReturns the index of a member in a sorted set ordered by ascending scores.\nLearn more â\nRead more\nZREM\nRemoves one or more members from a sorted set. Deletes the sorted set if all members were removed.\nLearn more â\nRead more\nZREMRANGEBYLEX\nRemoves members in a sorted set within a lexicographical range. Deletes the sorted set if all members were removed.\nLearn more â\nRead more\nZREMRANGEBYRANK\nRemoves members in a sorted set within a range of indexes. Deletes the sorted set if all members were removed.\nLearn more â\nRead more\nZREMRANGEBYSCORE\nRemoves members in a sorted set within a range of scores. Deletes the sorted set if all members were removed.\nLearn more â\nRead more\nZREVRANGE\nDeprecated\nUse ZRANGE with the REV argument instead\nReturns members in a sorted set within a range of indexes in reverse order.\nLearn more â\nRead more\nZREVRANGEBYLEX\nDeprecated\nUse ZRANGE with the REV and BYLEX arguments instead\nReturns members in a sorted set within a lexicographical range in reverse order.\nLearn more â\nRead more\nZREVRANGEBYSCORE\nDeprecated\nUse ZRANGE with the REV and BYSCORE arguments instead\nReturns members in a sorted set within a range of scores in reverse order.\nLearn more â\nRead more\nZREVRANK\nReturns the index of a member in a sorted set ordered by descending scores.\nLearn more â\nRead more\nZSCAN\nIterates over members and scores of a sorted set.\nLearn more â\nRead more\nZSCORE\nReturns the score of a member in a sorted set.\nLearn more â\nRead more\nZUNION\nReturns the union of multiple sorted sets.\nLearn more â\nRead more\nZUNIONSTORE\nStores the union of multiple sorted sets in a key.\nLearn more â\nRead more\n#\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nO\nP\nQ\nR\nS\nT\nU\nV\nW\nX\nZ\nAll products\nRedis Enterprise\nRedis Cloud\nRedis Open Source\nRedis Insight\nRedis Enterprise for K8s\nRedis Data Integration\nClient Libraries\nESC", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://redis.io/docs/latest/commands/"}}
{"text": "Command Line Shell For SQLite\nSmall. Fast. Reliable.\nChoose any three.\nHome\nMenu\nAbout\nDocumentation\nDownload\nLicense\nSupport\nPurchase\nSearch\nAbout\nDocumentation\nDownload\nSupport\nPurchase\nSearch Documentation\nSearch Changelog\nCommand Line Shell For SQLite\nTable Of Contents\n1. Getting Started\n1.1. SQLite command-line program versus the SQLite library\n1.2. GUI Alternatives To The CLI\n1.3. Starting the CLI\n1.4. Double-click Startup On Windows\n2. Special commands to sqlite3 (dot-commands)\n3. Rules for \"dot-commands\", SQL and More\n3.1. Line Structure\n3.2. Dot-command arguments\n3.3. Dot-command execution\n4. Changing Output Formats\n4.1. Control of line endings\n4.2. Control characters in output\n5. Querying the database schema\n6. Opening Database Files\n7. Redirecting I/O\n7.1. Writing results to a file\n7.2. Reading SQL from a file\n7.3. File I/O Functions\n7.4. The edit() SQL function\n7.5. Importing files as CSV or other formats\n7.6. Export to CSV\n7.6.1.  Export to Excel\n7.6.2.  Export to TSV (tab separated values)\n8. Accessing ZIP Archives As Database Files\n8.1. How ZIP archive access is implemented\n9. Converting An Entire Database To A Text File\n10. Recover Data From a Corrupted Database\n11. Loading Extensions\n12. Cryptographic Hashes Of Database Content\n13. Database Content Self-Tests\n14. SQLite Archive Support\n14.1.  SQLite Archive Create Command\n14.2.  SQLite Archive Extract Command\n14.3.  SQLite Archive List Command\n14.4.  SQLite Archive Insert And Update Commands\n14.5.  SQLite Archive Remove Command\n14.6.  Operations On ZIP Archives\n14.7.  SQL Used To Implement SQLite Archive Operations\n15. SQL Parameters\n16. Index Recommendations (SQLite Expert)\n17. Working With Multiple Database Connections\n18. Miscellaneous Extension Features\n19. Other Dot Commands\n20. Using sqlite3 in a shell script\n21. Marking The End Of An SQL Statement\n22. More Details On How To Start The CLI\n22.1. Extra command-line arguments\n22.2. Command-line Options\n22.3. The --safe command-line option\n22.3.1. Bypassing --safe restrictions for specific commands\n22.4. The --unsafe-testing command-line option\n22.5. The --no-utf8 and --utf8 command-line options\n23. Compiling the sqlite3 program from sources\n23.1.  Do-It-Yourself Builds\n1.\nGetting Started\nThe SQLite project provides a simple command-line program named\nsqlite3\n(or\nsqlite3.exe\non Windows)\nthat allows the user to manually enter and execute SQL\nstatements against an SQLite database or against a\nZIP archive\n.  This document provides a brief\nintroduction on how to use the\nsqlite3\nprogram.\n1.1.\nSQLite command-line program versus the SQLite library\nThe SQLite library is code that implements an SQL database engine.\nThe \"sqlite3\" command-line program or \"CLI\" is an application that\naccepts user input and passes it down into the SQLite library for\nevaluation.  Understand that these are two different things.  When\nsomebody says \"SQLite\" or \"sqlite3\" they might be referring to either\nthe SQLite library itself, or the CLI that provides a human interface\nto the library.  You will often need to use context to figure out exactly\nwhich of these two things the speaker is referring to.\nThis document is about the CLI, not the underlying SQLite library.\n1.2.\nGUI Alternatives To The CLI\nThe\nsqlite3\nprogram is written by and for the core SQLite\ndevelopers and is the officially supported way to accessing\nSQLite database files interactively.\nHowever, some users might prefer a Graphical User Interface (GUI).\nSeveral such programs are available from third-parties.\nOne of those is\nVisual DB\n,\na sponsor of the SQLite project:\nThanks to Visual DB for helping us make SQLite better for everyone!\n1.3.\nStarting the CLI\nStart the\nsqlite3\nprogram by typing \"sqlite3\" at the\ncommand prompt, optionally followed\nby the name of the file that holds the SQLite database\n(or\nZIP archive\n).  If the named\nfile does not exist, a new database file with the given name will be\ncreated automatically.  If no database file is specified on the\ncommand-line, a transient in-memory database is used.  This in-memory\ndatabase is deleted when the program exits.\nOn startup, the\nsqlite3\nprogram will show a brief banner\nmessage then prompt you to enter SQL.  Type in SQL statements (terminated\nby a semicolon), press \"Enter\" and the SQL will be executed.\nFor example, to create a new SQLite database named \"ex1\"\nwith a single table named \"tbl1\", you might do this:\n$\nsqlite3 ex1\nSQLite version 3.36.0 2021-06-18 18:36:39\nEnter \".help\" for usage hints.\nsqlite>\ncreate table tbl1(one text, two int);\nsqlite>\ninsert into tbl1 values('hello!',10);\nsqlite>\ninsert into tbl1 values('goodbye', 20);\nsqlite>\nselect * from tbl1;\nhello!|10\ngoodbye|20\nsqlite>\nTerminate the sqlite3 program by typing your system\nEnd-Of-File character (usually a Control-D).  Use the interrupt\ncharacter (usually a Control-C) to stop a long-running SQL statement.\nMake sure you type a semicolon at the end of each SQL command!\nThe sqlite3 program looks for a semicolon to know when your SQL command is\ncomplete.  If you omit the semicolon, sqlite3 will give you a\ncontinuation prompt and wait for you to enter more text to\ncomplete the SQL command.  This feature allows you to\nenter SQL commands that span multiple lines.  For example:\nsqlite>\nCREATE TABLE tbl2 (\n...>\nf1 varchar(30) primary key,\n...>\nf2 text,\n...>\nf3 real\n...>\n);\nsqlite>\n1.4.\nDouble-click Startup On Windows\nWindows users can double-click on the\nsqlite3.exe\nicon to cause\nthe command-line shell to pop-up a terminal window running SQLite.  However,\nbecause double-clicking starts the sqlite3.exe without command-line arguments,\nno database file will have been specified, so SQLite will use a transient\nin-memory database that is deleted when the session exits.\nTo use a persistent disk file as the database, enter the \".open\" command\nimmediately after the terminal window starts up:\nSQLite version 3.36.0 2021-06-18 18:36:39\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite>\n.open ex1.db\nsqlite>\nThe example above causes the database file named \"ex1.db\" to be opened\nand used.  The \"ex1.db\" file is created if it does not previously exist.\nYou might want to\nuse a full pathname to ensure that the file is in the directory that you\nthink it is in.  Use forward-slashes as the directory separator character.\nIn other words use \"c:/work/ex1.db\", not \"c:\\work\\ex1.db\".\nAlternatively, you can create a new database using the default temporary\nstorage, then save that database into a disk file using the \".save\" command:\nSQLite version 3.36.0 2021-06-18 18:36:39\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite>\n... many SQL commands omitted ...\nsqlite>\n.save ex1.db\nsqlite>\nBe careful when using the \".save\" command as it will overwrite any\npreexisting database files having the same name without prompting for\nconfirmation.  As with the \".open\" command, you might want to use a\nfull pathname with forward-slash directory separators to avoid ambiguity.\n2.\nSpecial commands to sqlite3 (dot-commands)\nMost of the time, sqlite3 just reads lines of input and passes them\non to the SQLite library for execution.\nBut input lines that begin with a dot (\".\")\nare intercepted and interpreted by the sqlite3 program itself.\nThese \"dot commands\" are typically used to change the output format\nof queries, or to execute certain prepackaged query statements.\nThere were originally just a few dot commands, but over the years\nmany new features have accumulated so that today there are over 60.\nFor a listing of the available dot commands, you can enter \".help\" with\nno arguments.  Or enter \".help TOPIC\" for detailed information about TOPIC.\nThe list of available dot-commands follows:\nsqlite>\n.help\n.archive ...             Manage SQL archives\n.auth ON|OFF             Show authorizer callbacks\n.backup ?DB? FILE        Backup DB (default \"main\") to FILE\n.bail on|off             Stop after hitting an error.  Default OFF\n.cd DIRECTORY            Change the working directory to DIRECTORY\n.changes on|off          Show number of rows changed by SQL\n.check GLOB              Fail if output since .testcase does not match\n.clone NEWDB             Clone data into NEWDB from the existing database\n.connection [close] [#]  Open or close an auxiliary database connection\n.crlf ?on|off?           Whether or not to use \\r\\n line endings\n.databases               List names and files of attached databases\n.dbconfig ?op? ?val?     List or change sqlite3_db_config() options\n.dbinfo ?DB?             Show status information about the database\n.dbtotxt                 Hex dump of the database file\n.dump ?OBJECTS?          Render database content as SQL\n.echo on|off             Turn command echo on or off\n.eqp on|off|full|...     Enable or disable automatic EXPLAIN QUERY PLAN\n.excel                   Display the output of next command in spreadsheet\n.exit ?CODE?             Exit this program with return-code CODE\n.expert                  EXPERIMENTAL. Suggest indexes for queries\n.explain ?on|off|auto?   Change the EXPLAIN formatting mode.  Default: auto\n.filectrl CMD ...        Run various sqlite3_file_control() operations\n.fullschema ?--indent?   Show schema and the content of sqlite_stat tables\n.headers on|off          Turn display of headers on or off\n.help ?-all? ?PATTERN?   Show help text for PATTERN\n.import FILE TABLE       Import data from FILE into TABLE\n.imposter INDEX TABLE    Create imposter table TABLE on index INDEX\n.indexes ?TABLE?         Show names of indexes\n.intck ?STEPS_PER_UNLOCK?  Run an incremental integrity check on the db\n.limit ?LIMIT? ?VAL?     Display or change the value of an SQLITE_LIMIT\n.lint OPTIONS            Report potential schema issues.\n.load FILE ?ENTRY?       Load an extension library\n.log FILE|on|off         Turn logging on or off.  FILE can be stderr/stdout\n.mode ?MODE? ?OPTIONS?   Set output mode\n.nonce STRING            Suspend safe mode for one command if nonce matches\n.nullvalue STRING        Use STRING in place of NULL values\n.once ?OPTIONS? ?FILE?   Output for the next SQL command only to FILE\n.open ?OPTIONS? ?FILE?   Close existing database and reopen FILE\n.output ?FILE?           Send output to FILE or stdout if FILE is omitted\n.parameter CMD ...       Manage SQL parameter bindings\n.print STRING...         Print literal STRING\n.progress N              Invoke progress handler after every N opcodes\n.prompt MAIN CONTINUE    Replace the standard prompts\n.quit                    Stop interpreting input stream, exit if primary.\n.read FILE               Read input from FILE or command output\n.recover                 Recover as much data as possible from corrupt db.\n.restore ?DB? FILE       Restore content of DB (default \"main\") from FILE\n.save ?OPTIONS? FILE     Write database to FILE (an alias for .backup ...)\n.scanstats on|off|est    Turn sqlite3_stmt_scanstatus() metrics on or off\n.schema ?PATTERN?        Show the CREATE statements matching PATTERN\n.separator COL ?ROW?     Change the column and row separators\n.session ?NAME? CMD ...  Create or control sessions\n.sha3sum ...             Compute a SHA3 hash of database content\n.shell CMD ARGS...       Run CMD ARGS... in a system shell\n.show                    Show the current values for various settings\n.stats ?ARG?             Show stats or turn stats on or off\n.system CMD ARGS...      Run CMD ARGS... in a system shell\n.tables ?TABLE?          List names of tables matching LIKE pattern TABLE\n.timeout MS              Try opening locked tables for MS milliseconds\n.timer on|off            Turn SQL timer on or off\n.trace ?OPTIONS?         Output each SQL statement as it is run\n.unmodule NAME ...       Unregister virtual table modules\n.version                 Show source, library and compiler versions\n.vfsinfo ?AUX?           Information about the top-level VFS\n.vfslist                 List all available VFSes\n.vfsname ?AUX?           Print the name of the VFS stack\n.width NUM1 NUM2 ...     Set minimum column widths for columnar output\n.www                     Display output of the next command in web browser\nsqlite>\n3.\nRules for \"dot-commands\", SQL and More\n3.1.\nLine Structure\nThe CLI's input is parsed into a sequence consisting of:\nSQL statements;\ndot-commands; or\nCLI comments\nSQL statements are free-form, and can be spread across multiple lines,\nwith whitespace or SQL comments embedded anywhere.\nThey are terminated by either a ';' character at the end of an input line,\nor a '/' character or the word \"go\" on a line by itself.\nWhen not at the end of an input line, the ';' character\nacts to separate SQL statements.\nTrailing whitespace is ignored for purposes of termination.\nA dot-command has a more restrictive structure:\nIt must begin with its \".\" at the left margin\nwith no preceding whitespace.\nIt must be entirely contained on a single input line.\nIt cannot occur in the middle of an ordinary SQL\nstatement.  In other words, it cannot occur at a\ncontinuation prompt.\nThere is no comment syntax for dot-commands.\nThe CLI also accepts whole-line comments that\nbegin with a '#' character and extend to the end of the line.\nThere can be no whitespace prior to the '#'.\n3.2.\nDot-command arguments\nThe arguments passed to dot-commands are parsed from the command tail,\nper these rules:\nThe trailing newline and any other trailing whitespace is discarded;\nWhitespace immediately following the dot-command name, or any argument\ninput end bound is discarded;\nAn argument input begins with any non-whitespace character;\nAn argument input ends with a character which\ndepends upon its leading character thusly:\nfor a leading single-quote ('), a single-quote acts\nas the end delimiter;\nfor a leading double-quote (\"), an unescaped double-quote\nacts as the end delimiter;\nfor any other leading character, the end delimiter is\nany whitespace; and\nthe command tail end acts as the end delimiter for any argument;\nWithin a double-quoted argument input, a backslash-escaped double-quote\nis part of the argument rather than its terminating quote;\nWithin a double-quoted argument, traditional C-string literal, backslash\nescape sequence translation is done; and\nArgument input delimiters (the bounding quotes or whitespace)\nare discarded to yield the passed argument.\n3.3.\nDot-command execution\nThe dot-commands\nare interpreted by the sqlite3.exe command-line program, not by\nSQLite itself.  So none of the dot-commands will work as an argument\nto SQLite interfaces such as\nsqlite3_prepare()\nor\nsqlite3_exec()\n.\n4.\nChanging Output Formats\nThe sqlite3 program is able to show the results of a query\nin 14 different output formats:\nascii\nbox\ncsv\ncolumn\nhtml\ninsert\njson\nline\nlist\nmarkdown\nquote\ntable\ntabs\ntcl\nYou can use the \".mode\" dot command to switch between these output\nformats.\nThe default output mode is \"list\".  In\nlist mode, each row of a query result is written on one line of\noutput and each column within that row is separated by a specific\nseparator string.  The default separator is a pipe symbol (\"|\").\nList mode is especially useful when you are going to send the output\nof a query to another program (such as AWK) for additional processing.\nsqlite>\n.mode list\nsqlite>\nselect * from tbl1;\nhello!|10\ngoodbye|20\nsqlite>\nType \".mode\" with no arguments to show the current mode:\nsqlite>\n.mode\ncurrent output mode: list\nsqlite>\nUse the \".separator\" dot command to change the separator.\nFor example, to change the separator to a comma and\na space, you could do this:\nsqlite>\n.separator \", \"\nsqlite>\nselect * from tbl1;\nhello!, 10\ngoodbye, 20\nsqlite>\nThe next \".mode\" command might reset the \".separator\" back to some\ndefault value (depending on its arguments).\nSo you will likely need to repeat the \".separator\" command whenever you\nchange modes if you want to continue using a non-standard separator.\nIn \"quote\" mode, the output is formatted as SQL literals.  Strings are\nenclosed in single-quotes and internal single-quotes are escaped by doubling.\nBlobs are displayed in hexadecimal blob literal notation (Ex: x'abcd').\nNumbers are displayed as ASCII text and NULL values are shown as \"NULL\".\nAll columns are separated from each other by a comma (or whatever alternative\ncharacter is selected using \".separator\").\nsqlite>\n.mode quote\nsqlite>\nselect * from tbl1;\n'hello!',10\n'goodbye',20\nsqlite>\nIn \"line\" mode, each column in a row of the database\nis shown on a line by itself.  Each line consists of the column\nname, an equal sign and the column data.  Successive records are\nseparated by a blank line.  Here is an example of line mode\noutput:\nsqlite>\n.mode line\nsqlite>\nselect * from tbl1;\none = hello!\ntwo = 10\none = goodbye\ntwo = 20\nsqlite>\nIn column mode, each record is shown on a separate line with the\ndata aligned in columns.  For example:\nsqlite>\n.mode column\nsqlite>\nselect * from tbl1;\none       two\n--------  ---\nhello!    10\ngoodbye   20\nsqlite>\nIn \"column\" mode (and also in \"box\", \"table\", and \"markdown\" modes)\nthe width of columns adjusts automatically.  But you can override this,\nproviding a specified width for each column using the \".width\" command.\nThe arguments to \".width\" are integers which are the number of\ncharacters to devote to each column.  Negative numbers mean right-justify.\nThus:\nsqlite>\n.width 12 -6\nsqlite>\nselect * from tbl1;\none              two\n------------  ------\nhello!            10\ngoodbye           20\nsqlite>\nA width of 0 means the column width is chosen automatically.\nUnspecified column widths become zero.  Hence, the command\n\".width\" with no arguments resets all column widths to zero and\nhence causes all column widths to be determined automatically.\nThe \"column\" mode is a tabular output format.  Other\ntabular output formats are \"box\", \"markdown\", and \"table\":\nsqlite>\n.width\nsqlite>\n.mode markdown\nsqlite>\nselect * from tbl1;\n|   one   | two |\n|---------|-----|\n| hello!  | 10  |\n| goodbye | 20  |\nsqlite>\n.mode table\nsqlite>\nselect * from tbl1;\n+---------+-----+\n|   one   | two |\n+---------+-----+\n| hello!  | 10  |\n| goodbye | 20  |\n+---------+-----+\nsqlite>\n.mode box\nsqlite>\nselect * from tbl1;\n┌─────────┬─────┐\n│   one   │ two │\n├─────────┼─────┤\n│ hello!  │ 10  │\n│ goodbye │ 20  │\n└─────────┴─────┘\nsqlite>\nThe columnar modes accept some additional options to control formatting.\nThe \"--wrap\nN\n\" option (where\nN\nis an integer) causes columns\nto wrap text that is longer than N characters.  Wrapping is disabled if\nN is zero.\nsqlite>\ninsert into tbl1 values('The quick fox jumps over a lazy brown dog.',90);\nsqlite>\n.mode box --wrap 30\nsqlite>\nselect * from tbl1 where two>50;\n┌────────────────────────────────┬─────┐\n│              one               │ two │\n├────────────────────────────────┼─────┤\n│ The quick fox jumps over a laz │ 90  │\n│ y brown dog.                   │     │\n└────────────────────────────────┴─────┘\nsqlite>\nWrapping happens after exactly\nN\ncharacters,\nwhich might be in the middle of a word.\nTo wrap at a word boundary, add the \"--wordwrap on\" option\n(or just \"-ww\" for short):\nsqlite>\n.mode box --wrap 30 -ww\nsqlite>\nselect * from tbl1 where two>50;\n┌─────────────────────────────┬─────┐\n│             one             │ two │\n├─────────────────────────────┼─────┤\n│ The quick fox jumps over a  │ 90  │\n│ lazy brown dog.             │     │\n└─────────────────────────────┴─────┘\nsqlite>\nThe \"--quote\" option causes the results in each column to be\nquoted like an SQL literal, as in the \"quote\" mode.  See the on-line\nhelp for additional options.\nThe command \".mode box --wrap 60 --quote\" is so useful for general-purpose\ndatabase queries that it is given its own alias.  Instead of typing out\nthat whole 27-character command, you can just say \".mode qbox\".\nAnother useful output mode is \"insert\".  In insert mode, the output\nis formatted to look like SQL INSERT statements.  Use insert\nmode to generate text that can later be used to input data into a\ndifferent database.\nWhen specifying insert mode, you have to give an extra argument\nwhich is the name of the table to be inserted into.  For example:\nsqlite>\n.mode insert new_table\nsqlite>\nselect * from tbl1 where two<50;\nINSERT INTO \"new_table\" VALUES('hello',10);\nINSERT INTO \"new_table\" VALUES('goodbye',20);\nsqlite>\nIf\n.headers on\nis active, the INSERT output will\ninclude that list of column names:\nsqlite>\n.mode insert mytable\nsqlite>\n.headers on\nsqlite>\nselect 1 a, 2 b, 3 c;\nINSERT INTO mytable(a,b,c) VALUES(1,2,3);\nsqlite>\nOther output modes include \"csv\", \"json\", and \"tcl\".  Try these\nyourself to see what they do.\n4.1.\nControl of line endings\nThe default line ending on Windows can be either \"\\r\\n\" (CRLF)\nor \"\\n\" NL.  The line ending is controlled by the \".crlf\" dot-command.\nUse \".crlf on\" to set the CRLF line ending and \".crlf off\" for NL.\nAs is traditional for Windows, CRLF is the default.  However, this\ncauses some outputs to be different than on non-Windows platforms due\nto the added \"\\r\" characters.  To cause the CLI to output results on\nWindows that are identical to the results on all other systems,\nrun \".crlf off\".\nOn non-Windows platforms, the \".crlf\" command is a no-op and the\ncrlf mode is always \"off\".  For\nCSV output\n, the line ending is always\n\"\\r\\n\" regardless of the .crlf setting, due to requirements of\nRFC-4180.\n4.2.\nControl characters in output\nBy default (since version 3.50.0), the CLI avoids\ndisplaying most control characters in the range of U+0001 through U+001f\neven when such characters are within content strings that the CLI is\ntrying to output.  This is done to avoid problems when the output\nis viewed on a device that interprets\nANSI escape codes\n.\nThe CLI avoids showing\nmost\ncontrol characters, but makes\nthe following exceptions: TAB (0x09), LF (0x0a) and CRLF (0x0d,0x0a).\nThe exceptions are passed through into the output unchanged.\nThe default behavior is for the CLI to display most control characters\nthe same way the \"cat -A\" command does in Linux:  For control character X,\ndisplay two characters \"^Y\" where Y is X+0x40.  For example,\nthe \"ESC\" character (0x1b) is rendered as \"^[\" and\nthe backspace character (0x08) is rendered as \"^H\".\nThe rendering of control characters is governed by the \"--escape T\"\ncommand-line option to the CLI, or to the \".mode\" dot-command, where T is\nthe control-character handling algorithm.  The default\nT is \"ascii\".  If you change it to \"--escape symbol\" then control\ncharacters are mapped into printable unicode values in the\nrange of U+2401 through U+241f.  For example, ESC is rendered as \"␛\"\nand backspace becomes \"␈\".  Setting \"--escape off\" turns off all\ncontrol character mapping so that the characters output by the CLI are\nexactly what are in the database.\n5.\nQuerying the database schema\nThe sqlite3 program provides several convenience commands that\nare useful for looking at the schema of the database.  There is\nnothing that these commands do that cannot be done by some other\nmeans.  These commands are provided purely as a shortcut.\nFor example, to see a list of the tables in the database, you\ncan enter \".tables\".\nsqlite>\n.tables\ntbl1 tbl2\nsqlite>\nThe \".tables\" command is similar to setting list mode then\nexecuting the following query:\nSELECT name FROM sqlite_schema\nWHERE type IN ('table','view') AND name NOT LIKE 'sqlite_%'\nORDER BY 1\nBut the \".tables\" command does more.  It queries the\nsqlite_schema\ntable\nfor all\nattached\ndatabases, not just the primary database.  And it arranges\nits output into neat columns.\nThe \".indexes\" command works in a similar way to list all of\nthe indexes. If the \".indexes\" command is given an argument which is\nthe name of a table, then it shows just indexes on that table.\nThe \".schema\" command shows the complete schema for the database,\nor for a single table if an optional tablename argument is provided:\nsqlite>\n.schema\ncreate table tbl1(one varchar(10), two smallint)\nCREATE TABLE tbl2 (\nf1 varchar(30) primary key,\nf2 text,\nf3 real\n);\nsqlite>\n.schema tbl2\nCREATE TABLE tbl2 (\nf1 varchar(30) primary key,\nf2 text,\nf3 real\n);\nsqlite>\nThe \".schema\" command is roughly the same as setting\nlist mode, then entering the following query:\nSELECT sql FROM sqlite_schema\nORDER BY tbl_name, type DESC, name\nAs with \".tables\", the \".schema\" command shows the schema for\nall\nattached\ndatabases.  If you only want to see the schema for\na single database (perhaps \"main\") then you can add an argument\nto \".schema\" to restrict its output:\nsqlite>\n.schema main.*\nThe \".schema\" command can be augmented with the \"--indent\" option,\nin which case it tries to reformat the various CREATE statements of\nthe schema so that they are more easily readable by humans.\nThe \".databases\" command shows a list of all databases open in\nthe current connection.  There will always be at least 2.  The first\none is \"main\", the original database opened.  The second is \"temp\",\nthe database used for temporary tables. There may be additional\ndatabases listed for databases attached using the ATTACH statement.\nThe first output column is the name the database is attached with,\nand the second result column is the filename of the external file.\nThere may be a third result column which will be either \"'r/o'\" or\n\"'r/w'\" depending on whether the database file is read-only or read-write.\nAnd there might be a fourth result column showing the result of\nsqlite3_txn_state()\nfor that database file.\nsqlite>\n.databases\nThe \".fullschema\" dot-command works like the \".schema\" command in\nthat it displays the entire database schema.  But \".fullschema\" also\nincludes dumps of the statistics tables \"sqlite_stat1\", \"sqlite_stat3\",\nand \"sqlite_stat4\", if they exist.  The \".fullschema\" command normally\nprovides all of the information needed to exactly recreate a query\nplan for a specific query.  When reporting suspected problems with\nthe SQLite query planner to the SQLite development team, developers\nare requested to provide the complete \".fullschema\" output as part\nof the trouble report.  Note that the sqlite_stat3 and sqlite_stat4\ntables contain samples of index entries and so might contain sensitive\ndata, so do not send the \".fullschema\" output of a proprietary database\nover a public channel.\n6.\nOpening Database Files\nThe \".open\" command opens a new database connection, after first closing the\npreviously opened database command.  In its simplest form, the \".open\" command merely\ninvokes\nsqlite3_open()\non the file named as its argument.  Use the name \":memory:\"\nto open a new in-memory database that disappears when the CLI exits or when the\n\".open\" command is run again.\nOr use no name to open a private, temporary on-disk database which\nwill also disappear upon exit or use of \".open\".\nIf the --new option is included with \".open\", then the database is reset prior\nto being opened.  Any prior data is destroyed.  This is a destructive overwrite of\nprior data and no confirmation is requested, so use this option carefully.\nIf the --ifexists option is included, the \".open\" command only works if the\ndatabase file already exists.  In other words, --ifexists prevents a new, empty\ndatabase from being created.\nThe --readonly option opens the database in read-only mode.  Write will be\nprohibited.\nThe --deserialize option causes the entire content of the on-disk file to be\nread into memory and then opened as an in-memory database using the\nsqlite3_deserialize()\ninterface.  This will, of course, require a lot of memory\nif you have a large database.  Also, any changes you make to the database will not\nbe saved back to disk unless you explicitly save them using the \".save\" or \".backup\"\ncommands.\nThe --append option causes the SQLite database to be appended to an existing\nfile rather than working as a stand-alone file.  See the\nappendvfs extension\nfor\nmore information.\nThe --zip option causes the specified input file to be interpreted as a ZIP archive\ninstead of as an SQLite database file.\nThe --hexdb option causes the database content to be read from subsequent\nlines of input in a hex format, rather than from a separate file on disk.\nThe \".dbtotxt\" dot-command and/or the dbtotxt command-line tool can be used to generate\nthe appropriate text for a database.  The --hexdb option is intended for use by the\nSQLite developers for testing purposes.  We do not know of any use cases for this\noption outside of internal SQLite testing and development.\n7.\nRedirecting I/O\n7.1.\nWriting results to a file\nBy default, sqlite3 sends query results to standard output.  You\ncan change this using the \".output\" and \".once\" commands.  Just put\nthe name of an output file as an argument to .output and all subsequent\nquery results will be written to that file.  Or use the .once command\ninstead of .output and output will only be redirected for the single next\ncommand before reverting to the console.  Use .output with no arguments to\nbegin writing to standard output again.  For example:\nsqlite>\n.mode list\nsqlite>\n.separator |\nsqlite>\n.output test_file_1.txt\nsqlite>\nselect * from tbl1;\nsqlite>\n.exit\n$\ncat test_file_1.txt\nhello|10\ngoodbye|20\n$\nIf the first character of the \".output\" or \".once\" filename is a pipe\nsymbol (\"|\") then the remaining characters are treated as a command and the\noutput is sent to that command.  This makes it easy to pipe the results\nof a query into some other process.  For example, the\n\"open -f\" command on a Mac opens a text editor to display the content that\nit reads from standard input.  So to see the results of a query\nin a text editor, one could type:\nsqlite>\n.once | open -f\nsqlite>\nSELECT * FROM bigTable;\nIf the \".output\" or \".once\" commands have an argument of \"-e\" then\noutput is collected into a temporary file and the system text editor is\ninvoked on that text file.  Thus, the command \".once -e\" achieves the\nsame result as \".once '|open -f'\" but with the benefit of being portable\nacross all systems.\nIf the \".output\" or \".once\" commands have a \"-x\" argument, that causes\nthem to accumulate output as Comma-Separated-Values (CSV) in a temporary\nfile, then invoke the default system utility for viewing CSV files\n(usually a spreadsheet program) on the result.  This is a quick way of\nsending the result of a query to a spreadsheet for easy viewing:\nsqlite>\n.once -x\nsqlite>\nSELECT * FROM bigTable;\nThe \".excel\" command is an alias for \".once -x\".  It does exactly the same\nthing.\nThe \"-w\" option to \".output\" or \".once\" cause the output to be displayed\nin your web-browser.  The \".www\" command is an alias for \".once -w\".  Normally\nthe data shown in the web-browser is in the form of an HTML table, but you\ncan instead show it as plain text by adding the \"--plain\" argument.\nsqlite>\n.www\nsqlite>\nSELECT * FROM users WHERE email LIKE '%@aol.com';\n7.2.\nReading SQL from a file\nIn interactive mode, sqlite3 reads input text (either SQL statements\nor\ndot-commands\n) from the keyboard.  You can also redirect input from\na file when you launch sqlite3, of course, but then you do not have the\nability to interact with the program.  Sometimes it is useful to run an\nSQL script contained in a file entering other commands from the command-line.\nFor this, the \".read\" dot-command is provided.\nThe \".read\" command takes a single argument which is (usually) the name\nof a file from which to read input text.\nsqlite>\n.read myscript.sql\nThe \".read\" command temporarily stops reading from the keyboard and instead\ntakes its input from the file named.  Upon reaching the end of the file,\ninput reverts back to the keyboard.  The script file may contain dot-commands,\njust like ordinary interactive input.\nIf the argument to \".read\" begins with the \"|\" character, then instead of\nopening the argument as a file, it runs the argument (without the leading \"|\")\nas a command, then uses the output of that command as its input.  Thus, if you\nhave a script that generates SQL, you can execute that SQL directly using\na command similar to the following:\nsqlite>\n.read |myscript.bat\n7.3.\nFile I/O Functions\nThe command-line shell adds two\napplication-defined SQL functions\nthat\nfacilitate reading content from a file into a table column, and writing the\ncontent of a column into a file, respectively.\nThe readfile(X) SQL function reads the entire content of the file named\nX and returns that content as a BLOB.  This can be used to load content into\na table.  For example:\nsqlite>\nCREATE TABLE images(name TEXT, type TEXT, img BLOB);\nsqlite>\nINSERT INTO images(name,type,img\n)\n...>\nVALUES('icon','jpeg',readfile('icon.jpg'));\nThe writefile(X,Y) SQL function write the blob Y into the file named X\nand returns the number of bytes written.  Use this function to extract\nthe content of a single table column into a file.  For example:\nsqlite>\nSELECT writefile('icon.jpg',img) FROM images WHERE name='icon';\nNote that the readfile(X) and writefile(X,Y) functions are extension\nfunctions and are not built into the core SQLite library.  These routines\nare available as a\nloadable extension\nin the\next/misc/fileio.c\nsource file in the\nSQLite source code repositories\n.\n7.4.\nThe edit() SQL function\nThe CLI has another built-in SQL function named edit().  Edit() takes\none or two arguments.  The first argument is a value - often a large\nmulti-line string to be edited.  The second argument is the invocation\nfor a text editor. (It may include options to affect the editor's\nbehavior.) If the second argument is omitted, the VISUAL environment\nvariable is used.  The edit() function writes its first argument into a\ntemporary file, invokes the editor on the temporary file, rereads the file\nback into memory after the editor is done, then returns the edited text.\nThe edit() function can be used to make changes to large text\nvalues.  For example:\nsqlite>\nUPDATE docs SET body=edit(body) WHERE name='report-15';\nIn this example, the content of the docs.body field for the entry where\ndocs.name is \"report-15\" will be sent to the editor.  After the editor returns,\nthe result will be written back into the docs.body field.\nThe default operation of edit() is to invoke a text editor.  But by using\nan alternative edit program in the second argument, you can also get it to edit\nimages or other non-text resources.  For example, if you want to modify a JPEG\nimage that happens to be stored in a field of a table, you could run:\nsqlite>\nUPDATE pics SET img=edit(img,'gimp') WHERE id='pic-1542';\nThe edit program can also be used as a viewer, by simply ignoring the\nreturn value.  For example, to merely look at the image above, you might run:\nsqlite>\nSELECT length(edit(img,'gimp')) WHERE id='pic-1542';\n7.5.\nImporting files as CSV or other formats\nUse the \".import\" command to import CSV (comma separated value)\nor similarly delimited data into an SQLite table.\nThe \".import\" command takes two arguments which are the\nsource from which data is to be read and the name of the\nSQLite table into which the data is to be inserted. The source argument\nis the name of a file to be read or, if it begins with a \"|\" character,\nit specifies a command which will be run to produce the input data.\nNote that it may be important to set the \"mode\" before running the\n\".import\" command.  This is prudent to prevent the command-line shell\nfrom trying to interpret the input file text as some format other than\nhow the file is structured. If the --csv or --ascii options are used,\nthey control import input delimiters. Otherwise, the delimiters are\nthose in effect for the current output mode.\nTo import into a table not in the \"main\" schema, the --schema option\nmay be used to specify that the table is in some other schema. This can\nbe useful for ATTACH'ed databases or to import into a TEMP table.\nWhen .import is run, its treatment of the first input row depends\nupon whether the target table already exists. If it does not exist,\nthe table is automatically created and the content of the first input\nrow is used to set the name of all the columns in the table. In this\ncase, the table data content is taken from the second and subsequent\ninput rows. If the target table already exists, every row of the\ninput, including the first, is taken to be actual data content.  If\nthe input file contains an initial row of column labels, you can make\nthe .import command skip that initial row using the \"--skip 1\" option.\nHere is an example usage, loading a pre-existing temporary table\nfrom a CSV file which has column names in its first row:\nsqlite>\n.import --csv --skip 1 --schema temp C:/work/somedata.csv tab1\nWhile reading input data in modes other than 'ascii', \".import\"\ninterprets input as records composed of fields according to the RFC 4180\nspecification with this exception: The input record and field separators\nare as set by the mode or by use of the .separator command. Fields are\nalways subject to quote removal to reverse quoting done per RFC 4180,\nexcept in ascii mode.\nTo import data with arbitrary delimiters and no quoting,\nfirst set ascii mode (\".mode ascii\"), then set the field\nand record delimiters using the \".separator\" command. This\nwill suppress dequoting. Upon \".import\", the data will be split\ninto fields and records according to the delimiters so specified.\n7.6.\nExport to CSV\nTo export an SQLite table (or part of a table) as CSV, simply set\nthe \"mode\" to \"csv\" and then run a query to extract the desired rows\nof the table. The output will formatted as CSV per RFC 4180.\nsqlite>\n.headers on\nsqlite>\n.mode csv\nsqlite>\n.once c:/work/dataout.csv\nsqlite>\nSELECT * FROM tab1;\nsqlite>\n.system c:/work/dataout.csv\nIn the example above, the \".headers on\" line causes column labels to\nbe printed as the first row of output.  This means that the first row of\nthe resulting CSV file will contain column labels.  If column labels are\nnot desired, set \".headers off\" instead. (The \".headers off\" setting is\nthe default and can be omitted if the headers have not been previously\nturned on.)\nThe line \".once\nFILENAME\n\" causes all query output to go into\nthe named file instead of being printed on the console.  In the example\nabove, that line causes the CSV content to be written into a file named\n\"C:/work/dataout.csv\".\nThe final line of the example (the \".system c:/work/dataout.csv\")\nhas the same effect as double-clicking on the c:/work/dataout.csv file\nin windows.  This will typically bring up a spreadsheet program to display\nthe CSV file.\nThat command only works as written on Windows.\nThe equivalent line on a Mac would be:\nsqlite>\n.system open dataout.csv\nOn Linux and other unix systems you will need to enter something like:\nsqlite>\n.system xdg-open dataout.csv\n7.6.1.\nExport to Excel\nTo simplify export to a spreadsheet, the CLI provides the\n\".excel\" command which captures the output of a single query and sends\nthat output to the default spreadsheet program on the host computer.\nUse it like this:\nsqlite>\n.excel\nsqlite>\nSELECT * FROM tab;\nThe command above writes the output of the query as CSV into a temporary\nfile, invokes the default handler for CSV files (usually the preferred\nspreadsheet program such as Excel or LibreOffice), then deletes the\ntemporary file.  This is essentially a short-hand method of doing\nthe sequence of \".csv\", \".once\", and \".system\" commands described above.\nThe \".excel\" command is really an alias for \".once -x\".  The -x option\nto .once causes it to writes results as CSV into a temporary file that\nis named with a \".csv\" suffix, then invoke the systems default handler\nfor CSV files.\nThere is also a \".once -e\" command which works similarly, except that\nit names the temporary file with a \".txt\" suffix so that the default\ntext editor for the system will be invoked, instead of the default\nspreadsheet.\n7.6.2.\nExport to TSV (tab separated values)\nExporting to pure TSV, without any field quoting, can be done by\nentering \".mode tabs\" before running a query. However, the output\nwill not be read correctly in tabs mode by the \".import\" command\nif it contains doublequote characters. To get TSV quoted per\nRFC 4180 so that it can be input in tabs mode with \".import\",\nfirst enter \".mode csv\", then enter '.separator \"\\t\"'\nbefore running a query.\n8.\nAccessing ZIP Archives As Database Files\nIn addition to reading and writing SQLite database files,\nthe\nsqlite3\nprogram will also read and write ZIP archives.\nSimply specify a ZIP archive filename in place of an SQLite database\nfilename on the initial command line, or in the \".open\" command,\nand\nsqlite3\nwill automatically detect that the file is a\nZIP archive instead of an SQLite database and will open it as such.\nThis works regardless of file suffix.  So you can open JAR, DOCX,\nand ODP files and any other file format that is really a ZIP\narchive and SQLite will read it for you.\nA ZIP archive appears to be a database containing a single table\nwith the following schema:\nCREATE TABLE zip(\nname,     -- Name of the file\nmode,     -- Unix-style file permissions\nmtime,    -- Timestamp, seconds since 1970\nsz,       -- File size after decompression\nrawdata,  -- Raw compressed file data\ndata,     -- Uncompressed file content\nmethod    -- ZIP compression method code\n);\nSo, for example, if you wanted to see the compression efficiency\n(expressed as the size of the compressed content relative to the\noriginal uncompressed file size) for all files in the ZIP archive,\nsorted from most compressed to least compressed, you could run a\nquery like this:\nsqlite> SELECT name, (100.0*length(rawdata))/sz FROM zip ORDER BY 2;\nOr using\nfile I/O functions\n, you can extract elements of the\nZIP archive:\nsqlite> SELECT writefile(name,content) FROM zip\n...> WHERE name LIKE 'docProps/%';\n8.1.\nHow ZIP archive access is implemented\nThe command-line shell uses the\nZipfile virtual table\nto\naccess ZIP archives.  You can see this by running the \".schema\"\ncommand when a ZIP archive is open:\nsqlite> .schema\nCREATE VIRTUAL TABLE zip USING zipfile('document.docx')\n/* zip(name,mode,mtime,sz,rawdata,data,method) */;\nWhen opening a file, if the command-line client discovers that the\nfile is a ZIP archive instead of an SQLite database, it actually opens\nan\nin-memory database\nand then in that in-memory database it creates\nan instance of the\nZipfile virtual table\nthat is attached to the\nZIP archive.\nThe special processing for opening ZIP archives is a trick of the\ncommand-line shell, not the core SQLite library.  So if you want to\nopen a ZIP archive as a database in your application, you will need to\nactivate the\nZipfile virtual table\nmodule then run an appropriate\nCREATE VIRTUAL TABLE\nstatement.\n9.\nConverting An Entire Database To A Text File\nUse the \".dump\" command to convert the entire contents of a\ndatabase into a single UTF-8 text file.  This file can be converted\nback into a database by piping it back into\nsqlite3\n.\nA good way to make an archival copy of a database is this:\n$\nsqlite3 ex1 .dump | gzip -c >ex1.dump.gz\nThis generates a file named\nex1.dump.gz\nthat contains everything\nyou need to reconstruct the database at a later time, or on another\nmachine.  To reconstruct the database, just type:\n$\nzcat ex1.dump.gz | sqlite3 ex2\nThe text format is pure SQL so you\ncan also use the .dump command to export an SQLite database\ninto other popular SQL database engines.  Like this:\n$\ncreatedb ex2\n$\nsqlite3 ex1 .dump | psql ex2\n10.\nRecover Data From a Corrupted Database\nLike the \".dump\" command, \".recover\" attempts to convert the entire\ncontents of a database file to text. The difference is that instead of\nreading data using the normal SQL database interface, \".recover\"\nattempts to reassemble the database based on data extracted directly from\nas many database pages as possible. If the database is corrupt, \".recover\"\nis usually able to recover data from all uncorrupted parts of the database,\nwhereas \".dump\" stops when the first sign of corruption is encountered.\nIf the \".recover\" command recovers one or more rows that it cannot\nattribute to any database table, the output script creates a \"lost_and_found\"\ntable to store the orphaned rows. The schema of the lost_and_found\ntable is as follows:\nCREATE TABLE lost_and_found(\nrootpgno INTEGER,             -- root page of tree pgno is a part of\npgno INTEGER,                 -- page number row was found on\nnfield INTEGER,               -- number of fields in row\nid INTEGER,                   -- value of rowid field, or NULL\nc0, c1, c2, c3...             -- columns for fields of row\n);\nThe \"lost_and_found\" table contains one row for each orphaned row recovered\nfrom the database. Additionally, there is one row for each recovered index\nentry that cannot be attributed to any SQL index. This is because, in an\nSQLite database, the same format is used to store SQL index entries and\nWITHOUT ROWID table entries.\nColumn\nContents\nrootpgno\nEven though it may not be possible to attribute the\nrow to a specific database table, it may be part of a tree structure\nwithin the database file. In this case, the root page number of that\ntree structure is stored in this column. Or, if the page the row was\nfound on is not part of a tree structure, this column stores a copy of\nthe value in column \"pgno\" - the page number of the page the row was\nfound on. In many, although not all, cases, all rows in the\nlost_and_found table with the same value in this column belong to the\nsame table.\npgno\nThe page number of the page on which this row was found.\nnfield\nThe number of fields in this row.\nid\nIf the row comes from a WITHOUT ROWID table, this column\ncontains NULL. Otherwise, it contains the 64-bit integer rowid value for\nthe row.\nc0, c1, c2...\nThe values for each column of the row\nare stored in these columns. The \".recover\" command creates the\nlost_and_found table with as many columns as required by the longest\norphaned row.\nIf the recovered database schema already contains a table named\n\"lost_and_found\", the \".recover\" command uses the name \"lost_and_found0\". If\nthe name \"lost_and_found0\" is also already taken, \"lost_and_found1\", and so\non. The default name \"lost_and_found\" may be overridden by invoking \".recover\"\nwith the --lost-and-found switch. For example, to have the output script call\nthe table \"orphaned_rows\":\nsqlite> .recover --lost-and-found orphaned_rows\n11.\nLoading Extensions\nYou can add new custom\napplication-defined SQL functions\n,\ncollating sequences\n,\nvirtual tables\n, and\nVFSes\nto the command-line\nshell at run-time using the \".load\" command.  First, build the\nextension as a DLL or shared library (as described in the\nRun-Time Loadable Extensions\ndocument) then type:\nsqlite> .load /path/to/my_extension\nNote that SQLite automatically adds the appropriate extension suffix\n(\".dll\" on windows, \".dylib\" on Mac, \".so\" on most other unixes) to the\nextension filename.  It is generally a good idea to specify the full\npathname of the extension.\nSQLite computes the entry point for the extension based on the extension\nfilename.  To override this choice, simply add the name of the extension\nas a second argument to the \".load\" command.\nSource code for several useful extensions can be found in the\next/misc\nsubdirectory of the SQLite source tree.  You can use these extensions\nas-is, or as a basis for creating your own custom extensions to address\nyour own particular needs.\n12.\nCryptographic Hashes Of Database Content\nThe \".sha3sum\" dot-command computes a\nSHA3\nhash of the\ncontent\nof the database.  To be clear, the hash is computed over the database content,\nnot its representation on disk.  This means, for example, that a\nVACUUM\nor similar data-preserving transformation does not change the hash.\nThe \".sha3sum\" command supports options \"--sha3-224\", \"--sha3-256\",\n\"--sha3-384\", and \"--sha3-512\" to define which variety of SHA3 to use\nfor the hash.  The default is SHA3-256.\nThe database schema (in the\nsqlite_schema\ntable) is not normally\nincluded in the hash, but can be added by the \"--schema\" option.\nThe \".sha3sum\" command takes a single optional argument which is a\nLIKE\npattern.  If this option is present, only tables whose names match\nthe\nLIKE\npattern will be hashed.\nThe \".sha3sum\" command is implemented with the help of the\nextension function \"sha3_query()\"\nthat is included with the command-line shell.\n13.\nDatabase Content Self-Tests\nThe \".selftest\" command attempts to verify that a database is\nintact and is not corrupt.\nThe .selftest command looks for a table in schema named \"selftest\"\nand defined as follows:\nCREATE TABLE selftest(\ntno INTEGER PRIMARY KEY,  -- Test number\nop TEXT,                  -- 'run' or 'memo'\ncmd TEXT,                 -- SQL command to run, or text of \"memo\"\nans TEXT                  -- Expected result of the SQL command\n);\nThe .selftest command reads the rows of the selftest table in\nselftest.tno order.\nFor each 'memo' row, it writes the text in 'cmd' to the output.  For\neach 'run' row, it runs the 'cmd' text as SQL and compares the result\nto the value in 'ans', and shows an error message if the results differ.\nIf there is no selftest table, the \".selftest\" command runs\nPRAGMA integrity_check\n.\nThe \".selftest --init\" command creates the selftest table if it\ndoes not already exist, then appends entries that check the SHA3\nhash of the content of all tables.  Subsequent runs of \".selftest\"\nwill verify that the database has not been changed in any way.  To\ngenerate tests to verify that a subset of the tables is unchanged,\nsimply run \".selftest --init\" then\nDELETE\nthe selftest rows that\nrefer to tables that are not constant.\n14.\nSQLite Archive Support\nThe \".archive\" dot-command and the \"-A\" command-line option\nprovide built-in support for the\nSQLite Archive format\n. The interface is similar to\nthat of the \"tar\" command on unix systems. Each invocation of the \".ar\"\ncommand must specify a single command option. The following commands\nare available for \".archive\":\nOption\nLong Option\nPurpose\n-c\n--create\nCreate a new archive containing specified files.\n-x\n--extract\nExtract specified files from archive.\n-i\n--insert\nAdd files to existing archive.\n-r\n--remove\nRemove files from the archive.\n-t\n--list\nList the files in the archive.\n-u\n--update\nAdd files to existing archive\nif\nthey have changed.\nAs well as the command option, each invocation of \".ar\" may specify\none or more modifier options. Some modifier options require an argument,\nsome do not. The following modifier options are available:\nOption\nLong Option\nPurpose\n-v\n--verbose\nList each file as it is processed.\n-f FILE\n--file FILE\nIf specified, use file FILE as the\narchive. Otherwise, assume that the current \"main\" database is the\narchive to be operated on.\n-a FILE\n--append FILE\nLike --file, use file FILE as the\narchive, but open the file using the\napndvfs VFS\nso that\nthe archive will be appended to the end of FILE if FILE already exists.\n-C DIR\n--directory DIR\nIf specified, interpret all relative\npaths as relative to DIR, instead of the current working directory.\n-g\n--glob\nUse\nglob(\nY\n,\nX\n)\nto match arguments\nagainst names in the archive.\n-n\n--dryrun\nShow the SQL that would be run to carry out the\narchive operation, but do not actually change anything.\n--\n--\nAll subsequent command line words are command arguments,\nnot options.\nFor command-line usage, add the short style command-line options immediately\nfollowing the \"-A\", without an intervening space.  All subsequent arguments\nare considered to be part of the .archive command.  For example, the following\ncommands are equivalent:\nsqlite3 new_archive.db -Acv file1 file2 file3\nsqlite3 new_archive.db \".ar -cv file1 file2 file3\"\nLong and short style options may be mixed. For example, the following are\nequivalent:\n-- Two ways to create a new archive named \"new_archive.db\" containing\n-- files \"file1\", \"file2\" and \"file3\".\n.ar -c --file new_archive.db file1 file2 file3\n.ar -f new_archive.db --create file1 file2 file3\nAlternatively, the first argument following to \".ar\" may be the concatenation\nof the short form of all required options (without the \"-\" characters). In\nthis case arguments for options requiring them are read from the command line\nnext, and any remaining words are considered command arguments. For example:\n-- Create a new archive \"new_archive.db\" containing files \"file1\" and\n-- \"file2\" from directory \"dir1\".\n.ar cCf dir1 new_archive.db file1 file2 file3\n14.1.\nSQLite Archive Create Command\nCreate a new archive, overwriting any existing archive (either in the current\n\"main\" db or in the file specified by a --file option). Each argument following\nthe options is a file to add to the archive. Directories are imported\nrecursively. See above for examples.\n14.2.\nSQLite Archive Extract Command\nExtract files from the archive (either to the current working directory or\nto the directory specified by a --directory option).\nFiles or directories whose names match the arguments,\nas affected by the --glob option, are extracted.\nOr, if no arguments follow the options, all files and directories are extracted.\nAny specified directories are extracted recursively. It is an error if any\nspecified names or match patterns cannot be found in the archive.\n-- Extract all files from the archive in the current \"main\" db to the\n-- current working directory. List files as they are extracted.\n.ar --extract --verbose\n-- Extract file \"file1\" from archive \"ar.db\" to directory \"dir1\".\n.ar fCx ar.db dir1 file1\n-- Extract files with \".h\" extension to directory \"headers\".\n.ar -gCx headers *.h\n14.3.\nSQLite Archive List Command\nList the contents of the archive. If no arguments are specified, then all\nfiles are listed. Otherwise, only those which match the arguments,\nas affected by the --glob option, are listed. Currently,\nthe --verbose option does not change the behaviour of this command. That may\nchange in the future.\n-- List contents of archive in current \"main\" db.\n.\n.ar --list\n14.4.\nSQLite Archive Insert And Update Commands\nThe --update and --insert commands work like --create command, except that\nthey do not delete the current archive before commencing. New versions of\nfiles silently replace existing files with the same names, but otherwise\nthe initial contents of the archive (if any) remain intact.\nFor the --insert command, all files listed are inserted into the archive.\nFor the --update command, files are only inserted if they do not previously\nexist in the archive, or if their \"mtime\" or \"mode\" is different from what\nis currently in the archive.\nCompatibility node:  Prior to SQLite version 3.28.0 (2019-04-16) only\nthe --update option was supported but that option worked like --insert in that\nit always reinserted every file regardless of whether or not it had changed.\n14.5.\nSQLite Archive Remove Command\nThe --remove command deletes files and directories which match the\nprovided arguments (if any) as affected by the --glob option.\nIt is an error to provide arguments which match nothing in the archive.\n14.6.\nOperations On ZIP Archives\nIf FILE is a ZIP archive rather than an SQLite Archive, the \".archive\"\ncommand and the \"-A\" command-line option still work.  This is accomplished\nusing the\nzipfile\nextension.\nHence, the following commands are roughly equivalent,\ndiffering only in output formatting:\nTraditional Command\nEquivalent sqlite3.exe Command\nunzip archive.zip\nsqlite3 -Axf archive.zip\nunzip -l archive.zip\nsqlite3 -Atvf archive.zip\nzip -r archive2.zip dir\nsqlite3 -Acf archive2.zip dir\n14.7.\nSQL Used To Implement SQLite Archive Operations\nThe various SQLite Archive Archive commands are implemented using SQL statements.\nApplication developers can easily add SQLite Archive Archive reading and writing\nsupport to their own projects by running the appropriate SQL.\nTo see what SQL statements are used to implement an SQLite Archive\noperation, add the --dryrun or -n option.  This causes the SQL to be\ndisplayed but inhibits the execution of the SQL.\nThe SQL statements used to implement SQLite Archive operations make use of\nvarious\nloadable extensions\n.  These extensions are all available in\nthe\nSQLite source tree\nin the\next/misc/ subfolder\n.\nThe extensions needed for full SQLite Archive support include:\nfileio.c\n—\nThis extension adds SQL functions readfile() and writefile() for\nreading and writing content from files on disk.  The fileio.c\nextension also includes the fsdir() table-valued function for listing\nthe contents of a directory and the lsmode() function for converting\nnumeric st_mode integers from the stat() system call into human-readable\nstrings after the fashion of the \"ls -l\" command.\nsqlar.c\n—\nThis extension adds the sqlar_compress() and sqlar_uncompress()\nfunctions that are needed to compress and uncompress file content\nas it is inserted and extracted from an SQLite Archive.\nzipfile.c\n—\nThis extension implements the \"zipfile(FILE)\" table-valued function\nwhich is used to read ZIP archives.  This extension is only needed\nwhen reading ZIP archives instead of SQLite archives.\nappendvfs.c\n—\nThis extension implements a new\nVFS\nthat allows an SQLite database\nto be appended to some other file, such as an executable.  This\nextension is only needed if the --append option to the .archive\ncommand is used.\n15.\nSQL Parameters\nSQLite allows\nbound parameters\nto appear in an SQL statement anywhere\nthat a literal value is allowed.  The values for these parameters are set\nusing the\nsqlite3_bind_...()\nfamily of APIs.\nParameters can be either named or unnamed.  An unnamed parameter is a single\nquestion mark (\"?\").  Named parameters are a \"?\" followed immediately by a number\n(ex: \"?15\" or \"?123\") or one of the characters \"$\", \":\", or \"@\" followed by an\nalphanumeric name (ex: \"$var1\", \":xyz\", \"@bingo\").\nThis command-line shell leaves unnamed parameters unbound, meaning that they\nwill have a value of an SQL NULL, but named parameters might be assigned values.\nIf there exists a TEMP table named \"sqlite_parameters\" with a schema like this:\nCREATE TEMP TABLE sqlite_parameters(\nkey TEXT PRIMARY KEY,\nvalue\n) WITHOUT ROWID;\nAnd if there is an entry in that table where the key column exactly matches\nthe name of parameter (including the initial \"?\", \"$\", \":\", or \"@\" character)\nthen the parameter is assigned the value of the value column.  If no entry exists,\nthe parameter defaults to NULL.\nThe \".parameter\" command exists to simplify managing this table.  The\n\".parameter init\" command (often abbreviated as just \".param init\") creates\nthe temp.sqlite_parameters table if it does not already exist.  The \".param list\"\ncommand shows all entries in the temp.sqlite_parameters table.  The \".param clear\"\ncommand drops the temp.sqlite_parameters table.  The \".param set KEY VALUE\" and\n\".param unset KEY\" commands create or delete entries from the\ntemp.sqlite_parameters table.\nThe VALUE passed to \".param set KEY VALUE\" can be either a SQL literal\nor any other SQL expression or query which can be evaluated to yield a value.\nThis allows values of differing types to be set.\nIf such evaluation fails, the provided VALUE is instead quoted and inserted\nas text.\nBecause such initial evaluation may or may not fail depending upon\nthe VALUE content, the reliable way to get a text value is to enclose it\nwith single-quotes protected from the above-described command-tail parsing.\nFor example, (unless one intends a value of -1365):\n.parameter init\n.parameter set @phoneNumber \"'202-456-1111'\"\nNote that the double-quotes serve to protect the single-quotes\nand ensure that the quoted text is parsed as one argument.\nThe temp.sqlite_parameters table only provides values for parameters in the\ncommand-line shell.  The temp.sqlite_parameter table has no effect on queries\nthat are run directly using the SQLite C-language API.  Individual applications\nare expected to implement their own parameter binding.  You can search for\n\"sqlite_parameters\" in the\ncommand-line shell source code\nto see how the command-line shell does parameter binding, and use that as\na hint for how to implement it yourself.\n16.\nIndex Recommendations (SQLite Expert)\nNote: This command is experimental. It may be removed or the\ninterface modified in incompatible ways at some point in the future.\nFor most non-trivial SQL databases, the key to performance is creating\nthe right SQL indexes. In this context \"the right SQL indexes\" means those\nthat cause the queries that an application needs to optimize run fast. The\n\".expert\" command can assist with this by proposing indexes that might\nassist with specific queries, were they present in the database.\nThe \".expert\" command is issued first, followed by the SQL query\non a separate line. For example, consider the following session:\nsqlite> CREATE TABLE x1(a, b, c);\n-- Create table in database\nsqlite> .expert\nsqlite> SELECT * FROM x1 WHERE a=? AND b>?;\n-- Analyze this SELECT\nCREATE INDEX x1_idx_000123a7 ON x1(a, b);\n0|0|0|SEARCH TABLE x1 USING INDEX x1_idx_000123a7 (a=? AND b>?)\nsqlite> CREATE INDEX x1ab ON x1(a, b);\n-- Create the recommended index\nsqlite> .expert\nsqlite> SELECT * FROM x1 WHERE a=? AND b>?;\n-- Re-analyze the same SELECT\n(no new indexes)\n0|0|0|SEARCH TABLE x1 USING INDEX x1ab (a=? AND b>?)\nIn the above, the user creates the database schema (a single table - \"x1\"),\nand then uses the \".expert\" command to analyze a query, in this case\n\"SELECT * FROM x1 WHERE a=? AND b>?\". The shell tool recommends that the\nuser create a new index (index \"x1_idx_000123a7\") and outputs the plan\nthat the query would use in\nEXPLAIN QUERY PLAN\nformat. The user then creates\nan index with an equivalent schema and runs the analysis on the same query\nagain. This time the shell tool does not recommend any new indexes, and\noutputs the plan that SQLite will use for the query given the existing\nindexes.\nThe \".expert\" command accepts the following options:\nOption\nPurpose\n‑‑verbose\nIf present, output a more verbose report for each query analyzed.\n‑‑sample PERCENT\nThis parameter defaults to 0, causing the \".expert\" command to\nrecommend indexes based on the query and database schema alone.\nThis is similar to the way the\nSQLite query planner\nselects\nindexes for queries if the user has not run the\nANALYZE\ncommand\non the database to generate data distribution statistics.\nIf this option is passed a non-zero argument, the \".expert\" command\ngenerates similar data distribution statistics for all indexes\nconsidered based on PERCENT percent of the rows currently stored in\neach database table. For databases with unusual data distributions,\nthis may lead to better index recommendations, particularly if the\napplication intends to run ANALYZE.\nFor small databases and modern CPUs, there is usually no reason not\nto pass \"--sample 100\". However, gathering data distribution\nstatistics can be expensive for large database tables. If the\noperation is too slow, try passing a smaller value for the --sample\noption.\nThe functionality described in this section may be integrated into other\napplications or tools using the\nSQLite expert extension\ncode.\nA database schema which incorporates SQL custom functions made available\nvia the extension load mechanism may need special provision to work with\nthe .expert feature. Because the feature uses additional connections to\nimplement its functionality, those custom functions must be made available\nto those additional connections. This can be done by means of the extension\nload/usage options described at\nAutomatically Load Statically Linked Extensions\nand\nPersistent Loadable Extensions\n.\n17.\nWorking With Multiple Database Connections\nBeginning with version 3.37.0 (2021-11-27), the CLI has the ability to\nhold multiple\ndatabase connections\nopen at once.  Only one database connection\nis active at a time.  The inactive connections are still open but are idle.\nUse the \".connection\" dot-command (often abbreviated as just \".conn\") to see a\nlist of database connections and an indication of which one is currently active.\nEach database connection is identified by an integer between 0 and 9.  (There\ncan be at most 10 simultaneously open connections.)  Change to another database\nconnection, creating it if it does not already exist, by typing the \".conn\"\ncommand followed by its number.  Close a database connection by typing\n\".conn close N\" where N is the connection number.\nThough the underlying SQLite database connections are completely independent\nof one another, many of the CLI settings, such as the output format, are\nshared across all database connections.  Thus, changing the\noutput mode\nin\none connection will change it in them all.  On the other hand, some\ndot-commands\nsuch as\n.open\nonly affect the current connection.\n18.\nMiscellaneous Extension Features\nThe CLI is built with several SQLite extensions that are not\nincluded with the SQLite library. A few add features\nnot described in the preceding sections, namely:\nthe\nUINT collating sequence\nwhich treats\nunsigned integers embedded in text according to\ntheir value, along with other text, for ordering;\ndecimal arithmetic as provided by the\ndecimal extension\n;\nthe\ngenerate_series\n() table-valued function;\nthe\nbase64()\nand\nbase85()\nfunctions which encode a\nblob to base64 or base85 text or decode the same to a blob; and\nsupport for POSIX extended regular expressions\nbound to the\nREGEXP\noperator.\n19.\nOther Dot Commands\nThere are many other dot-commands available in the command-line\nshell.  See the \".help\" command for a complete list for any particular\nversion and build of SQLite.\n20.\nUsing sqlite3 in a shell script\nOne way to use sqlite3 in a shell script is to use \"echo\" or\n\"cat\" to generate a sequence of commands in a file, then invoke sqlite3\nwhile redirecting input from the generated command file.  This\nworks fine and is appropriate in many circumstances.  But as\nan added convenience, sqlite3 allows a single SQL command to be\nentered on the command line as a second argument after the\ndatabase name.  When the sqlite3 program is launched with two\narguments, the second argument is passed to the SQLite library\nfor processing, the query results are printed on standard output\nin list mode, and the program exits.  This mechanism is designed\nto make sqlite3 easy to use in conjunction with programs like\n\"awk\".  For example:\n$\nsqlite3 ex1 'select * from tbl1' \\\n>\n| awk '{printf \"<tr><td>%s<td>%s\\n\",$1,$2 }'\n<tr><td>hello<td>10\n<tr><td>goodbye<td>20\n$\n21.\nMarking The End Of An SQL Statement\nSQLite commands are normally terminated by a semicolon.  In the CLI\nyou can also use the word \"GO\" (case-insensitive) or a slash character\n\"/\" on a line by itself to end a command.  These are used by SQL Server\nand Oracle, respectively, and are supported by the SQLite CLI for\ncompatibility.  These won't work in\nsqlite3_exec()\n,\nbecause the CLI translates these inputs into a semicolon before passing\nthem down into the SQLite core.\n22.\nMore Details On How To Start The CLI\nAs stated\npreviously\n, the usual way to start\nup the CLI is to type \"sqlite3\" followed by the name of the database file.\nBut the \"sqlite3\" program accepts many other arguments other than just\nthe database filename.\n22.1.\nExtra command-line arguments\nAdditional command-line arguments that occur after the database filename\nare treated as if they were lines of input text.  Each additional argument\ncan be either an SQL statement or a\ndot-command\n.  They are evaluated in\norder from left to right.\nSince both SQLite statements and dot-commands often contain spaces, you will\nprobably need to put each SQL statement or dot-command inside\nsingle- or double-quotes (depending on your OS).  For example:\n$\nsqlite3 test.db   \".mode box\"   \"SELECT * FROM users;\"\nWhen extra arguments are provided this way, standard input is not read\nand the CLI exits after it has processed all the extra arguments.\n22.2.\nCommand-line Options\nExtra arguments that start with the \"-\" character are command-line options.\nThere are many command-line options available.  Use the --help\ncommand-line option to see a list:\n$\nsqlite3 --help\nFILENAME is the name of an SQLite database. A new database is created\nif the file does not previously exist. Defaults to :memory:.\nOPTIONS include:\n--                   treat no subsequent arguments as options\n-A ARGS...           run \".archive ARGS\" and exit\n-append              append the database to the end of the file\n-ascii               set output mode to 'ascii'\n-bail                stop after hitting an error\n-batch               force batch I/O\n-box                 set output mode to 'box'\n-column              set output mode to 'column'\n-cmd COMMAND         run \"COMMAND\" before reading stdin\n-csv                 set output mode to 'csv'\n-deserialize         open the database using sqlite3_deserialize()\n-echo                print inputs before execution\n-escape T            ctrl-char escape; T is one of: symbol, ascii, off\n-init FILENAME       read/process named file\n-[no]header          turn headers on or off\n-heap SIZE           Size of heap for memsys3 or memsys5\n-help                show this message\n-html                set output mode to HTML\n-ifexists            only open if database already exists\n-interactive         force interactive I/O\n-json                set output mode to 'json'\n-line                set output mode to 'line'\n-list                set output mode to 'list'\n-lookaside SIZE N    use N entries of SZ bytes for lookaside memory\n-markdown            set output mode to 'markdown'\n-maxsize N           maximum size for a --deserialize database\n-memtrace            trace all memory allocations and deallocations\n-mmap N              default mmap size set to N\n-newline SEP         set output row separator. Default: '\\n'\n-nofollow            refuse to open symbolic links to database files\n-nonce STRING        set the safe-mode escape nonce\n-no-rowid-in-view    Disable rowid-in-view using sqlite3_config()\n-nullvalue TEXT      set text string for NULL values. Default ''\n-pagecache SIZE N    use N slots of SZ bytes each for page cache memory\n-pcachetrace         trace all page cache operations\n-quote               set output mode to 'quote'\n-readonly            open the database read-only\n-safe                enable safe-mode\n-separator SEP       set output column separator. Default: '|'\n-stats               print memory stats before each finalize\n-table               set output mode to 'table'\n-tabs                set output mode to 'tabs'\n-unsafe-testing      allow unsafe commands and modes for testing\n-version             show SQLite version\n-vfs NAME            use NAME as the default VFS\n-vfstrace            enable tracing of all VFS calls\n-zip                 open the file as a ZIP Archive\nThe CLI is flexible regarding command-line option formatting.\nEither one or two leading \"-\" characters are permitted.\nThus \"-box\" and \"--box\" mean the same thing.\nCommand-line options are processed from left to right.\nHence a \"--box\" option will override a prior \"--quote\" option.\nMost of the command-line options are self-explanatory, but a few merit additional\ndiscussion below.\n22.3.\nThe --safe command-line option\nThe --safe command-line option attempts to disable all features of the CLI that\nmight cause any changes to the host computer other than changes to the specific database\nfile named on the command-line.  The idea is that if you receive a large SQL script\nfrom an unknown or untrusted source, you can run that script to see what it does without\nrisking an exploit by using the --safe option.  The --safe option disables (among other\nthings):\nThe\n.open command\n, unless the --hexdb option is used or the filename is \":memory:\".\nThis prevents the script from reading or writing any database files not named on\nthe original command-line.\nThe\nATTACH\nSQL command.\nSQL functions that have potentially harmful side-effects, such as\nedit(), fts3_tokenizer(), load_extension(), readfile() and writefile().\nThe\n.archive command\n.\nThe .backup and .save commands.\nThe\n.import command\n.\nThe\n.load command\n.\nThe .log command.\nThe .shell and .system commands.\nThe .excel, .once and .output commands.\nOther commands that can have deleterious side effects.\nBasically, any feature of the CLI that reads or writes from a file on disk other\nthan the main database file is disabled.\n22.3.1.\nBypassing --safe restrictions for specific commands\nIf the \"--nonce NONCE\" option is also included on the command-line, for some\nlarge and arbitrary NONCE string, then the \".nonce NONCE\" command (with the\nsame large nonce string) will permit the next SQL statement or dot-command\nto bypass the --safe restrictions.\nSuppose you want to run a suspicious script and the script requires one or\ntwo of the features that --safe normally disables.  For example, suppose it\nneeds to ATTACH one additional database.  Or suppose the script needs to load\na specific extension. This can be accomplished by preceding the (carefully\naudited) ATTACH statement or the \".load\" command with an appropriate \".nonce\"\ncommand and supplying the same nonce value using the \"--nonce\" command-line\noption.  Those specific commands will then be allowed to execute normally,\nbut all other unsafe commands will still be restricted.\nThe use of \".nonce\" is dangerous in the sense that a mistake can allow a\nhostile script to damage your system.  Therefore, use \".nonce\" carefully,\nsparingly, and as a last resort when there are no other ways to get a\nscript to run under --safe mode.\n22.4.\nThe --unsafe-testing command-line option\nThe --unsafe-testing command-line option enables features of the CLI\nthat are intended for internal testing only.  The --unsafe-testing option\ndisables defenses that are built into SQLite, for example\nSQLITE_DBCONFIG_DEFENSIVE\nand\nSQLITE_DBCONFIG_TRUSTED_SCHEMA\n.\nThe --unsafe-testing option also enables features that, if misused, might\ncause database corruption, memory errors, or\nsimilar problems in the CLI itself or in the SQLite library.\nAn example of features that --unsafe-testing enables is the\n\".testctrl assert false\" command which deliberately triggers an\nassertion fault, in order to verify that the assertion fault\nmechanism is working.\nMisbehavior which requires use of the --unsafe-testing option\nwill generally not be considered a bug.\n22.5.\nThe --no-utf8 and --utf8 command-line options\nOn the Windows platform, when the console is used for input or output,\ntranslation is required between character encoding available from or sent to\nthe console and the CLI's internal, UTF-8 text representation. Past versions\nof the CLI accepted these options to enable or disable use of a translation\nthat relied upon a Windows console feature whereby it could be made to\nproduce or accept UTF-8 on modern versions of the OS.\nPresent CLI versions (3.44.1 or later) do console I/O by reading or writing\nUTF-16 from/to the Windows console APIs. Because this operates correctly even\non Windows versions going back to Window 2000, there is no longer any need\nfor these options. They are still accepted, but without effect.\nIn all cases, non-console text I/O is UTF-8 encoded.\nOn non-Windows platforms, these options are also ignored.\n23.\nCompiling the sqlite3 program from sources\nTo compile the command-line shell on unix systems and on Windows with MinGW,\nthe usual configure-make command works:\nsh configure; make\nThe configure-make works whether you are building from the canonical sources\nfrom the source tree, or from an amalgamated bundle.  There are few\ndependencies.  When building from canonical sources, a working\ntclsh\nis required.\nIf using an amalgamation bundle, all the preprocessing work normally\ndone by tclsh will have already been carried out and only normal build\ntools are required.\nA working\nzlib compression library\nis\nneeded in order for the\n.archive command\nto operate.\nOn Windows with MSVC, use nmake with the Makefile.msc:\nnmake /f Makefile.msc\nFor correct operation of the\n.archive command\n, make a copy of the\nzlib source code\ninto the compat/zlib subdirectory\nof the source tree and compile this way:\nnmake /f Makefile.msc USE_ZLIB=1\n23.1.\nDo-It-Yourself Builds\nThe source code to the sqlite3 command line interface is in a single\nfile named \"shell.c\".  The shell.c source file is generated from other\nsources, but most of the code for shell.c can be found in\nsrc/shell.c.in\n.\n(Regenerate shell.c by typing \"make shell.c\" from the canonical source tree.)\nCompile\nthe shell.c file (together\nwith the\nsqlite3 library source code\n) to generate\nthe executable.  For example:\ngcc -o sqlite3 shell.c sqlite3.c -ldl -lpthread -lz -lm\nThe following additional compile-time options are recommended in order to\nprovide a full-featured command-line shell:\n-DSQLITE_THREADSAFE=0\n-DSQLITE_ENABLE_EXPLAIN_COMMENTS\n-DSQLITE_HAVE_ZLIB\n-DSQLITE_INTROSPECTION_PRAGMAS\n-DSQLITE_ENABLE_UNKNOWN_SQL_FUNCTION\n-DSQLITE_ENABLE_STMTVTAB\n-DSQLITE_ENABLE_DBPAGE_VTAB\n-DSQLITE_ENABLE_DBSTAT_VTAB\n-DSQLITE_ENABLE_OFFSET_SQL_FUNC\n-DSQLITE_ENABLE_JSON1\n-DSQLITE_ENABLE_RTREE\n-DSQLITE_ENABLE_FTS4\n-DSQLITE_ENABLE_FTS5\nThis page was last updated on 2025-11-24 21:55:24Z", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.sqlite.org/cli.html"}}
{"text": "Query Language Understood by SQLite\nSmall. Fast. Reliable.\nChoose any three.\nHome\nMenu\nAbout\nDocumentation\nDownload\nLicense\nSupport\nPurchase\nSearch\nAbout\nDocumentation\nDownload\nSupport\nPurchase\nSearch Documentation\nSearch Changelog\nSQL As Understood By SQLite\nSQLite understands most of the standard SQL\nlanguage.  But it does\nomit some features\nwhile at the same time\nadding a few features of its own.  This document attempts to\ndescribe precisely what parts of the SQL language SQLite does\nand does not support.  A list of\nSQL keywords\nis\nalso provided.  The SQL language syntax is described by\nsyntax diagrams\n.\nThe following syntax documentation topics are available:\naggregate functions\nALTER TABLE\nANALYZE\nATTACH DATABASE\nBEGIN TRANSACTION\ncomment\nCOMMIT TRANSACTION\ncore functions\nCREATE INDEX\nCREATE TABLE\nCREATE TRIGGER\nCREATE VIEW\nCREATE VIRTUAL TABLE\ndate and time functions\nDELETE\nDETACH DATABASE\nDROP INDEX\nDROP TABLE\nDROP TRIGGER\nDROP VIEW\nEND TRANSACTION\nEXPLAIN\nexpression\nINDEXED BY\nINSERT\nJSON functions\nkeywords\nmath functions\nON CONFLICT clause\nPRAGMA\nREINDEX\nRELEASE SAVEPOINT\nREPLACE\nRETURNING clause\nROLLBACK TRANSACTION\nSAVEPOINT\nSELECT\nUPDATE\nUPSERT\nVACUUM\nwindow functions\nWITH clause\nThe routines\nsqlite3_prepare_v2()\n,\nsqlite3_prepare()\n,\nsqlite3_prepare16()\n,\nsqlite3_prepare16_v2()\n,\nsqlite3_exec()\n, and\nsqlite3_get_table()\naccept\nan SQL statement list (sql-stmt-list) which is a semicolon-separated\nlist of statements.\nsql-stmt-list:\nsql-stmt\n;\nEach SQL statement in the statement list is an instance of the\nfollowing:\nsql-stmt:\nEXPLAIN\nQUERY\nPLAN\nalter-table-stmt\nanalyze-stmt\nattach-stmt\nbegin-stmt\ncommit-stmt\ncreate-index-stmt\ncreate-table-stmt\ncreate-trigger-stmt\ncreate-view-stmt\ncreate-virtual-table-stmt\ndelete-stmt\ndelete-stmt-limited\ndetach-stmt\ndrop-index-stmt\ndrop-table-stmt\ndrop-trigger-stmt\ndrop-view-stmt\ninsert-stmt\npragma-stmt\nreindex-stmt\nrelease-stmt\nrollback-stmt\nsavepoint-stmt\nselect-stmt\nupdate-stmt\nupdate-stmt-limited\nvacuum-stmt\nThis page was last updated on 2024-04-01 12:41:31Z", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.sqlite.org/lang.html"}}
