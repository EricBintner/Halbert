{"text": "docker | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\ndocker\nDescription\nThe base command for the Docker CLI.\nDescription\nDepending on your Docker system configuration, you may be required to preface\neach\ndocker\ncommand with\nsudo\n. To avoid having to use\nsudo\nwith the\ndocker\ncommand, your system administrator can create a Unix group called\ndocker\nand add users to it.\nFor more information about installing Docker or\nsudo\nconfiguration, refer to\nthe\ninstallation\ninstructions for your operating system.\nDisplay help text\nTo list the help on any command just execute the command, followed by the\n--help\noption.\n$\ndocker run --help\nUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\nCreate and run a new container from an image\nOptions:\n--add-host value             Add a custom host-to-IP mapping (host:ip) (default [])\n-a, --attach value               Attach to STDIN, STDOUT or STDERR (default [])\n<...>\nEnvironment variables\nThe following list of environment variables are supported by the\ndocker\ncommand\nline:\nVariable\nDescription\nDOCKER_API_VERSION\nOverride the negotiated API version to use for debugging (e.g.\n1.19\n)\nDOCKER_CERT_PATH\nLocation of your authentication keys. This variable is used both by the\ndocker\nCLI and the\ndockerd\ndaemon\nDOCKER_CONFIG\nThe location of your client configuration files.\nDOCKER_CONTENT_TRUST_SERVER\nThe URL of the Notary server to use. Defaults to the same URL as the registry.\nDOCKER_CONTENT_TRUST\nWhen set Docker uses notary to sign and verify images. Equates to\n--disable-content-trust=false\nfor build, create, pull, push, run.\nDOCKER_CONTEXT\nName of the\ndocker context\nto use (overrides\nDOCKER_HOST\nenv var and default context set with\ndocker context use\n)\nDOCKER_CUSTOM_HEADERS\n(Experimental) Configure\ncustom HTTP headers\nto be sent by the client. Headers must be provided as a comma-separated list of\nname=value\npairs. This is the equivalent to the\nHttpHeaders\nfield in the configuration file.\nDOCKER_DEFAULT_PLATFORM\nDefault platform for commands that take the\n--platform\nflag.\nDOCKER_HIDE_LEGACY_COMMANDS\nWhen set, Docker hides \"legacy\" top-level commands (such as\ndocker rm\n, and\ndocker pull\n) in\ndocker help\noutput, and only\nManagement commands\nper object-type (e.g.,\ndocker container\n) are printed. This may become the default in a future release.\nDOCKER_HOST\nDaemon socket to connect to.\nDOCKER_TLS\nEnable TLS for connections made by the\ndocker\nCLI (equivalent of the\n--tls\ncommand-line option). Set to a non-empty value to enable TLS. Note that TLS is enabled automatically if any of the other TLS options are set.\nDOCKER_TLS_VERIFY\nWhen set Docker uses TLS and verifies the remote. This variable is used both by the\ndocker\nCLI and the\ndockerd\ndaemon\nBUILDKIT_PROGRESS\nSet type of progress output (\nauto\n,\nplain\n,\ntty\n,\nrawjson\n) when\nbuilding\nwith\nBuildKit backend\n. Use plain to show container output (default\nauto\n).\nBecause Docker is developed using Go, you can also use any environment\nvariables used by the Go runtime. In particular, you may find these useful:\nVariable\nDescription\nHTTP_PROXY\nProxy URL for HTTP requests unless overridden by NoProxy.\nHTTPS_PROXY\nProxy URL for HTTPS requests unless overridden by NoProxy.\nNO_PROXY\nComma-separated values specifying hosts that should be excluded from proxying.\nSee the\nGo specification\nfor details on these variables.\nOption types\nSingle character command line options can be combined, so rather than\ntyping\ndocker run -i -t --name test busybox sh\n,\nyou can write\ndocker run -it --name test busybox sh\n.\nBoolean\nBoolean options take the form\n-d=false\n. The value you see in the help text is\nthe default value which is set if you do\nnot\nspecify that flag. If you\nspecify a Boolean flag without a value, this will set the flag to\ntrue\n,\nirrespective of the default value.\nFor example, running\ndocker run -d\nwill set the value to\ntrue\n, so your\ncontainer\nwill\nrun in \"detached\" mode, in the background.\nOptions which default to\ntrue\n(e.g.,\ndocker build --rm=true\n) can only be\nset to the non-default value by explicitly setting them to\nfalse\n:\n$\ndocker build --rm\n=\nfalse\n.\nMulti\nYou can specify options like\n-a=[]\nmultiple times in a single command line,\nfor example in these commands:\n$\ndocker run -a stdin -a stdout -i -t ubuntu /bin/bash\n$\ndocker run -a stdin -a stdout -a stderr ubuntu /bin/ls\nSometimes, multiple options can call for a more complex value string as for\n-v\n:\n$\ndocker run -v /host:/container example/mysql\nNote\nDo not use the\n-t\nand\n-a stderr\noptions together due to\nlimitations in the\npty\nimplementation. All\nstderr\nin\npty\nmode\nsimply goes to\nstdout\n.\nStrings and Integers\nOptions like\n--name=\"\"\nexpect a string, and they\ncan only be specified once. Options like\n-c=0\nexpect an integer, and they can only be specified once.\nConfiguration files\nBy default, the Docker command line stores its configuration files in a\ndirectory called\n.docker\nwithin your\n$HOME\ndirectory.\nDocker manages most of the files in the configuration directory\nand you shouldn't modify them. However, you can modify the\nconfig.json\nfile to control certain aspects of how the\ndocker\ncommand behaves.\nYou can modify the\ndocker\ncommand behavior using environment\nvariables or command-line options. You can also use options within\nconfig.json\nto modify some of the same behavior. If an environment variable\nand the\n--config\nflag are set, the flag takes precedent over the environment\nvariable. Command line options override environment variables and environment\nvariables override properties you specify in a\nconfig.json\nfile.\nChange the\n.docker\ndirectory\nTo specify a different directory, use the\nDOCKER_CONFIG\nenvironment variable or the\n--config\ncommand line option. If both are\nspecified, then the\n--config\noption overrides the\nDOCKER_CONFIG\nenvironment\nvariable. The example below overrides the\ndocker ps\ncommand using a\nconfig.json\nfile located in the\n~/testconfigs/\ndirectory.\n$\ndocker --config ~/testconfigs/ ps\nThis flag only applies to whatever command is being ran. For persistent\nconfiguration, you can set the\nDOCKER_CONFIG\nenvironment variable in your\nshell (e.g.\n~/.profile\nor\n~/.bashrc\n). The example below sets the new\ndirectory to be\nHOME/newdir/.docker\n.\n$\necho\nexport\nDOCKER_CONFIG\n=\n$HOME\n/newdir/.docker > ~/.profile\nDocker CLI configuration file (\nconfig.json\n) properties\nUse the Docker CLI configuration to customize settings for the\ndocker\nCLI. The\nconfiguration file uses JSON formatting, and properties:\nBy default, configuration file is stored in\n~/.docker/config.json\n. Refer to the\nchange the\n.docker\ndirectory\nsection to use a\ndifferent location.\nWarning\nThe configuration file and other files inside the\n~/.docker\nconfiguration\ndirectory may contain sensitive information, such as authentication information\nfor proxies or, depending on your credential store, credentials for your image\nregistries. Review your configuration file's content before sharing with others,\nand prevent committing the file to version control.\nCustomize the default output format for commands\nThese fields lets you customize the default output format for some commands\nif no\n--format\nflag is provided.\nProperty\nDescription\nconfigFormat\nCustom default format for\ndocker config ls\noutput. See\ndocker config ls\nfor a list of supported formatting directives.\nimagesFormat\nCustom default format for\ndocker images\n/\ndocker image ls\noutput. See\ndocker images\nfor a list of supported formatting directives.\nnetworksFormat\nCustom default format for\ndocker network ls\noutput. See\ndocker network ls\nfor a list of supported formatting directives.\nnodesFormat\nCustom default format for\ndocker node ls\noutput. See\ndocker node ls\nfor a list of supported formatting directives.\npluginsFormat\nCustom default format for\ndocker plugin ls\noutput. See\ndocker plugin ls\nfor a list of supported formatting directives.\npsFormat\nCustom default format for\ndocker ps\n/\ndocker container ps\noutput. See\ndocker ps\nfor a list of supported formatting directives.\nsecretFormat\nCustom default format for\ndocker secret ls\noutput. See\ndocker secret ls\nfor a list of supported formatting directives.\nserviceInspectFormat\nCustom default format for\ndocker service inspect\noutput. See\ndocker service inspect\nfor a list of supported formatting directives.\nservicesFormat\nCustom default format for\ndocker service ls\noutput. See\ndocker service ls\nfor a list of supported formatting directives.\nstatsFormat\nCustom default format for\ndocker stats\noutput. See\ndocker stats\nfor a list of supported formatting directives.\ntasksFormat\nCustom default format for\ndocker stack ps\noutput. See\ndocker stack ps\nfor a list of supported formatting directives.\nvolumesFormat\nCustom default format for\ndocker volume ls\noutput. See\ndocker volume ls\nfor a list of supported formatting directives.\nCustom HTTP headers\nThe property\nHttpHeaders\nspecifies a set of headers to include in all messages\nsent from the Docker client to the daemon. Docker doesn't try to interpret or\nunderstand these headers; it simply puts them into the messages. Docker does\nnot allow these headers to change any headers it sets for itself.\nAlternatively, use the\nDOCKER_CUSTOM_HEADERS\nenvironment variable\n,\nwhich is available in v27.1 and higher. This environment-variable is experimental,\nand its exact behavior may change.\nCredential store options\nThe property\ncredsStore\nspecifies an external binary to serve as the default\ncredential store. When this property is set,\ndocker login\nwill attempt to\nstore credentials in the binary specified by\ndocker-credential-<value>\nwhich\nis visible on\n$PATH\n. If this property isn't set, credentials are stored\nin the\nauths\nproperty of the CLI configuration file. For more information,\nsee the\nCredential stores\nsection in the\ndocker login\ndocumentation\nThe property\ncredHelpers\nspecifies a set of credential helpers to use\npreferentially over\ncredsStore\nor\nauths\nwhen storing and retrieving\ncredentials for specific registries. If this property is set, the binary\ndocker-credential-<value>\nwill be used when storing or retrieving credentials\nfor a specific registry. For more information, see the\nCredential helpers\nsection in the\ndocker login\ndocumentation\nAutomatic proxy configuration for containers\nThe property\nproxies\nspecifies proxy environment variables to be automatically\nset on containers, and set as\n--build-arg\non containers used during\ndocker build\n.\nA\n\"default\"\nset of proxies can be configured, and will be used for any Docker\ndaemon that the client connects to, or a configuration per host (Docker daemon),\nfor example,\nhttps://docker-daemon1.example.com\n. The following properties can\nbe set for each environment:\nProperty\nDescription\nhttpProxy\nDefault value of\nHTTP_PROXY\nand\nhttp_proxy\nfor containers, and as\n--build-arg\non\ndocker build\nhttpsProxy\nDefault value of\nHTTPS_PROXY\nand\nhttps_proxy\nfor containers, and as\n--build-arg\non\ndocker build\nftpProxy\nDefault value of\nFTP_PROXY\nand\nftp_proxy\nfor containers, and as\n--build-arg\non\ndocker build\nnoProxy\nDefault value of\nNO_PROXY\nand\nno_proxy\nfor containers, and as\n--build-arg\non\ndocker build\nallProxy\nDefault value of\nALL_PROXY\nand\nall_proxy\nfor containers, and as\n--build-arg\non\ndocker build\nThese settings are used to configure proxy settings for containers only, and not\nused as proxy settings for the\ndocker\nCLI or the\ndockerd\ndaemon. Refer to the\nenvironment variables\nand\nHTTP/HTTPS proxy\nsections for configuring proxy settings for the CLI and daemon.\nWarning\nProxy settings may contain sensitive information (for example, if the proxy\nrequires authentication). Environment variables are stored as plain text in\nthe container's configuration, and as such can be inspected through the remote\nAPI or committed to an image when using\ndocker commit\n.\nDefault key-sequence to detach from containers\nOnce attached to a container, users detach from it and leave it running using\nthe using\nCTRL-p CTRL-q\nkey sequence. This detach key sequence is customizable\nusing the\ndetachKeys\nproperty. Specify a\n<sequence>\nvalue for the\nproperty. The format of the\n<sequence>\nis a comma-separated list of either\na letter [a-Z], or the\nctrl-\ncombined with any of the following:\na-z\n(a single lowercase alpha character )\n@\n(at sign)\n[\n(left bracket)\n\\\\\n(two backward slashes)\n_\n(underscore)\n^\n(caret)\nYour customization applies to all containers started in with your Docker client.\nUsers can override your custom or the default key sequence on a per-container\nbasis. To do this, the user specifies the\n--detach-keys\nflag with the\ndocker attach\n,\ndocker exec\n,\ndocker run\nor\ndocker start\ncommand.\nCLI plugin options\nThe property\nplugins\ncontains settings specific to CLI plugins. The\nkey is the plugin name, while the value is a further map of options,\nwhich are specific to that plugin.\nSample configuration file\nFollowing is a sample\nconfig.json\nfile to illustrate the format used for\nvarious fields:\n{\n\"HttpHeaders\"\n:\n{\n\"MyHeader\"\n:\n\"MyValue\"\n},\n\"psFormat\"\n:\n\"table {{.ID}}\\\\t{{.Image}}\\\\t{{.Command}}\\\\t{{.Labels}}\"\n,\n\"imagesFormat\"\n:\n\"table {{.ID}}\\\\t{{.Repository}}\\\\t{{.Tag}}\\\\t{{.CreatedAt}}\"\n,\n\"pluginsFormat\"\n:\n\"table {{.ID}}\\t{{.Name}}\\t{{.Enabled}}\"\n,\n\"statsFormat\"\n:\n\"table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}\"\n,\n\"servicesFormat\"\n:\n\"table {{.ID}}\\t{{.Name}}\\t{{.Mode}}\"\n,\n\"secretFormat\"\n:\n\"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\\t{{.UpdatedAt}}\"\n,\n\"configFormat\"\n:\n\"table {{.ID}}\\t{{.Name}}\\t{{.CreatedAt}}\\t{{.UpdatedAt}}\"\n,\n\"serviceInspectFormat\"\n:\n\"pretty\"\n,\n\"nodesFormat\"\n:\n\"table {{.ID}}\\t{{.Hostname}}\\t{{.Availability}}\"\n,\n\"detachKeys\"\n:\n\"ctrl-e,e\"\n,\n\"credsStore\"\n:\n\"secretservice\"\n,\n\"credHelpers\"\n:\n{\n\"awesomereg.example.org\"\n:\n\"hip-star\"\n,\n\"unicorn.example.com\"\n:\n\"vcbait\"\n},\n\"plugins\"\n:\n{\n\"plugin1\"\n:\n{\n\"option\"\n:\n\"value\"\n},\n\"plugin2\"\n:\n{\n\"anotheroption\"\n:\n\"anothervalue\"\n,\n\"athirdoption\"\n:\n\"athirdvalue\"\n}\n},\n\"proxies\"\n:\n{\n\"default\"\n:\n{\n\"httpProxy\"\n:\n\"http://user:pass@example.com:3128\"\n,\n\"httpsProxy\"\n:\n\"https://my-proxy.example.com:3129\"\n,\n\"noProxy\"\n:\n\"intra.mycorp.example.com\"\n,\n\"ftpProxy\"\n:\n\"http://user:pass@example.com:3128\"\n,\n\"allProxy\"\n:\n\"socks://example.com:1234\"\n},\n\"https://manager1.mycorp.example.com:2377\"\n:\n{\n\"httpProxy\"\n:\n\"http://user:pass@example.com:3128\"\n,\n\"httpsProxy\"\n:\n\"https://my-proxy.example.com:3129\"\n}\n}\n}\nExperimental features\nExperimental features provide early access to future product functionality.\nThese features are intended for testing and feedback, and they may change\nbetween releases without warning or can be removed from a future release.\nStarting with Docker 20.10, experimental CLI features are enabled by default,\nand require no configuration to enable them.\nNotary\nIf using your own notary server and a self-signed certificate or an internal\nCertificate Authority, you need to place the certificate at\ntls/<registry_url>/ca.crt\nin your Docker config directory.\nAlternatively you can trust the certificate globally by adding it to your system's\nlist of root Certificate Authorities.\nOptions\nOption\nDefault\nDescription\n--config\n/root/.docker\nLocation of client config files\n-c, --context\nName of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with\ndocker context use\n)\n-D, --debug\nEnable debug mode\n-H, --host\nDaemon socket to connect to\n-l, --log-level\ninfo\nSet the logging level (\ndebug\n,\ninfo\n,\nwarn\n,\nerror\n,\nfatal\n)\n--tls\nUse TLS; implied by --tlsverify\n--tlscacert\n/root/.docker/ca.pem\nTrust certs signed only by this CA\n--tlscert\n/root/.docker/cert.pem\nPath to TLS certificate file\n--tlskey\n/root/.docker/key.pem\nPath to TLS key file\n--tlsverify\nUse TLS and verify the remote\nExamples\nSpecify daemon host (-H, --host)\nYou can use the\n-H\n,\n--host\nflag to specify a socket to use when you invoke\na\ndocker\ncommand. You can use the following protocols:\nScheme\nDescription\nExample\nunix://[<path>]\nUnix socket (Linux only)\nunix:///var/run/docker.sock\ntcp://[<IP or host>[:port]]\nTCP connection\ntcp://174.17.0.1:2376\nssh://[username@]<IP or host>[:port]\nSSH connection\nssh://user@192.168.64.5\nnpipe://[<name>]\nNamed pipe (Windows only)\nnpipe:////./pipe/docker_engine\nIf you don't specify the\n-H\nflag, and you're not using a custom\ncontext\n,\ncommands use the following default sockets:\nunix:///var/run/docker.sock\non macOS and Linux\nnpipe:////./pipe/docker_engine\non Windows\nTo achieve a similar effect without having to specify the\n-H\nflag for every\ncommand, you could also\ncreate a context\n,\nor alternatively, use the\nDOCKER_HOST\nenvironment variable\n.\nFor more information about the\n-H\nflag, see\nDaemon socket option\n.\nUsing TCP sockets\nThe following example shows how to invoke\ndocker ps\nover TCP, to a remote\ndaemon with IP address\n174.17.0.1\n, listening on port\n2376\n:\n$\ndocker -H tcp://174.17.0.1:2376 ps\nNote\nBy convention, the Docker daemon uses port\n2376\nfor secure TLS connections,\nand port\n2375\nfor insecure, non-TLS connections.\nUsing SSH sockets\nWhen you use SSH invoke a command on a remote daemon, the request gets forwarded\nto the\n/var/run/docker.sock\nUnix socket on the SSH host.\n$\ndocker -H ssh://user@192.168.64.5 ps\nYou can optionally specify the location of the socket by appending a path\ncomponent to the end of the SSH address.\n$\ndocker -H ssh://user@192.168.64.5/var/run/docker.sock ps\nSubcommands\nCommand\nDescription\ndocker build (legacy builder)\nBuild an image from a Dockerfile\ndocker builder\nManage builds\ndocker buildx\nDocker Buildx\ndocker checkpoint\nManage checkpoints\ndocker compose\nDocker Compose\ndocker config\nManage Swarm configs\ndocker container\nManage containers\ndocker context\nManage contexts\ndocker debug\nGet a shell into any container or image. An alternative to debugging with `docker exec`.\ndocker desktop (Beta)\nDocker Desktop\ndocker image\nManage images\ndocker init\nCreates Docker-related starter files for your project\ndocker inspect\nReturn low-level information on Docker objects\ndocker login\nAuthenticate to a registry\ndocker logout\nLog out from a registry\ndocker manifest\nManage Docker image manifests and manifest lists\ndocker mcp\ndocker model\nDocker Model Runner\ndocker network\nManage networks\ndocker node\nManage Swarm nodes\ndocker offload\nControl Docker Offload from the CLI\ndocker plugin\nManage plugins\ndocker sandbox\nDocker Sandbox\ndocker scout\nCommand line tool for Docker Scout\ndocker search\nSearch Docker Hub for images\ndocker secret\nManage Swarm secrets\ndocker service\nManage Swarm services\ndocker stack\nManage Swarm stacks\ndocker swarm\nManage Swarm\ndocker system\nManage Docker\ndocker trust\nManage trust on Docker images\ndocker version\nShow the Docker version information\ndocker volume\nManage volumes\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/reference/cli/docker/"}}
{"text": "docker container | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\ndocker container\nDescription\nManage containers\nUsage\ndocker container\nDescription\nManage containers.\nSubcommands\nCommand\nDescription\ndocker container attach\nAttach local standard input, output, and error streams to a running container\ndocker container commit\nCreate a new image from a container's changes\ndocker container cp\nCopy files/folders between a container and the local filesystem\ndocker container create\nCreate a new container\ndocker container diff\nInspect changes to files or directories on a container's filesystem\ndocker container exec\nExecute a command in a running container\ndocker container export\nExport a container's filesystem as a tar archive\ndocker container inspect\nDisplay detailed information on one or more containers\ndocker container kill\nKill one or more running containers\ndocker container logs\nFetch the logs of a container\ndocker container ls\nList containers\ndocker container pause\nPause all processes within one or more containers\ndocker container port\nList port mappings or a specific mapping for the container\ndocker container prune\nRemove all stopped containers\ndocker container rename\nRename a container\ndocker container restart\nRestart one or more containers\ndocker container rm\nRemove one or more containers\ndocker container run\nCreate and run a new container from an image\ndocker container start\nStart one or more stopped containers\ndocker container stats\nDisplay a live stream of container(s) resource usage statistics\ndocker container stop\nStop one or more running containers\ndocker container top\nDisplay the running processes of a container\ndocker container unpause\nUnpause all processes within one or more containers\ndocker container update\nUpdate configuration of one or more containers\ndocker container wait\nBlock until one or more containers stop, then print their exit codes\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/reference/cli/docker/container/"}}
{"text": "docker image | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\ndocker image\nDescription\nManage images\nUsage\ndocker image\nDescription\nManage images.\nSubcommands\nCommand\nDescription\ndocker image history\nShow the history of an image\ndocker image import\nImport the contents from a tarball to create a filesystem image\ndocker image inspect\nDisplay detailed information on one or more images\ndocker image load\nLoad an image from a tar archive or STDIN\ndocker image ls\nList images\ndocker image prune\nRemove unused images\ndocker image pull\nDownload an image from a registry\ndocker image push\nUpload an image to a registry\ndocker image rm\nRemove one or more images\ndocker image save\nSave one or more images to a tar archive (streamed to STDOUT by default)\ndocker image tag\nCreate a tag TARGET_IMAGE that refers to SOURCE_IMAGE\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/reference/cli/docker/image/"}}
{"text": "docker network | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\ndocker network\nDescription\nManage networks\nUsage\ndocker network\nDescription\nManage networks. You can use subcommands to create, inspect, list, remove,\nprune, connect, and disconnect networks.\nSubcommands\nCommand\nDescription\ndocker network connect\nConnect a container to a network\ndocker network create\nCreate a network\ndocker network disconnect\nDisconnect a container from a network\ndocker network inspect\nDisplay detailed information on one or more networks\ndocker network ls\nList networks\ndocker network prune\nRemove all unused networks\ndocker network rm\nRemove one or more networks\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/reference/cli/docker/network/"}}
{"text": "docker volume | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\ndocker volume\nDescription\nManage volumes\nUsage\ndocker volume COMMAND\nDescription\nManage volumes. You can use subcommands to create, inspect, list, remove, or\nprune volumes.\nSubcommands\nCommand\nDescription\ndocker volume create\nCreate a volume\ndocker volume inspect\nDisplay detailed information on one or more volumes\ndocker volume ls\nList volumes\ndocker volume prune\nRemove unused local volumes\ndocker volume rm\nRemove one or more volumes\ndocker volume update\nUpdate a volume (cluster volumes only)\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/reference/cli/docker/volume/"}}
{"text": "Docker Compose | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nManuals\nGet started\nGuides\nReference\nDocker Compose\nPage options\nCopy page as Markdown for LLMs\nView page as plain text\nAsk questions with Docs AI\nClaude\nOpen in Claude\nDocker Compose is a tool for defining and running multi-container applications.\nIt is the key to unlocking a streamlined and efficient development and deployment experience.\nCompose simplifies the control of your entire application stack, making it easy to manage services, networks, and volumes in a single YAML configuration file. Then, with a single command, you create and start all the services\nfrom your configuration file.\nCompose works in all environments - production, staging, development, testing, as\nwell as CI workflows. It also has commands for managing the whole lifecycle of your application:\nStart, stop, and rebuild services\nView the status of running services\nStream the log output of running services\nRun a one-off command on a service\nWhy use Compose?\nUnderstand Docker Compose's key benefits\nHow Compose works\nUnderstand how Compose works\nInstall Compose\nFollow the instructions on how to install Docker Compose.\nQuickstart\nLearn the key concepts of Docker Compose whilst building a simple Python web application.\nView the release notes\nFind out about the latest enhancements and bug fixes.\nExplore the Compose file reference\nFind information on defining services, networks, and volumes for a Docker application.\nUse Compose Bridge\nTransform your Compose configuration file into configuration files for different platforms, such as Kubernetes.\nBrowse common FAQs\nExplore general FAQs and find out how to give feedback.\nMigrate to Compose v2\nLearn how to migrate from Compose v1 to v2\nEdit this page\nRequest changes", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/compose/"}}
{"text": "Compose file reference | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nReference\nGet started\nGuides\nManuals\nCompose file reference\nPage options\nCopy page as Markdown for LLMs\nView page as plain text\nAsk questions with Docs AI\nClaude\nOpen in Claude\nNew to Docker Compose?\nFind more information about the\nkey features and use cases of Docker Compose\nor\ntry the quickstart guide\n.\nThe Compose Specification is the latest and recommended version of the Compose file format. It helps you define a\nCompose file\nwhich is used to configure your Docker applicationâs services, networks, volumes, and more.\nLegacy versions 2.x and 3.x of the Compose file format were merged into the Compose Specification. It is implemented in versions 1.27.0 and above (also known as Compose v2) of the Docker Compose CLI.\nThe Compose Specification on Docker Docs is the Docker Compose implementation. If you wish to implement your own version of the Compose Specification, see the\nCompose Specification repository\n.\nUse the following links to navigate key sections of the Compose Specification.\nTip\nWant a better editing experience for Compose files in VS Code?\nCheck out the\nDocker VS Code Extension (Beta)\nfor linting, code navigation, and vulnerability scanning.\nVersion and name top-level element\nUnderstand version and name attributes for Compose.\nServices top-level element\nExplore all services attributes for Compose.\nNetworks top-level element\nFind all networks attributes for Compose.\nVolumes top-level element\nExplore all volumes attributes for Compose.\nConfigs top-level element\nFind out about configs in Compose.\nSecrets top-level element\nLearn about secrets in Compose.\nEdit this page\nRequest changes", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/compose/compose-file/"}}
{"text": "Get started | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nGet started\nGuides\nManuals\nReference\nGet started\nIf you're new to Docker, this section guides you through the essential resources to get started.\nFollow the guides to help you get started and learn how Docker can optimize your development workflows.\nFor more advanced concepts and scenarios in Docker, see\nGuides\n.\nFoundations of Docker\nInstall Docker and jump into discovering what Docker is.\nGet Docker\nChoose the best installation path for your setup.\nWhat is Docker?\nLearn about the Docker platform.\nLearn the foundational concepts and workflows of Docker.\nIntroduction\nGet started with the basics and the benefits of containerizing your applications.\nDocker concepts\nGain a better understanding of foundational Docker concepts.\nDocker workshop\nGet guided through a 45-minute workshop to learn about Docker.", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/get-started/"}}
{"text": "Best practices | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nManuals\nGet started\nGuides\nReference\nBuilding best practices\nPage options\nCopy page as Markdown for LLMs\nView page as plain text\nAsk questions with Docs AI\nClaude\nOpen in Claude\nTable of contents\nUse multi-stage builds\nMulti-stage builds let you reduce the size of your final image, by creating a\ncleaner separation between the building of your image and the final output.\nSplit your Dockerfile instructions into distinct stages to make sure that the\nresulting output only contains the files that are needed to run the application.\nUsing multiple stages can also let you build more efficiently by executing\nbuild steps in parallel.\nSee\nMulti-stage builds\nfor more\ninformation.\nCreate reusable stages\nIf you have multiple images with a lot in common, consider creating a reusable\nstage that includes the shared components, and basing your unique stages on\nthat. Docker only needs to build the common stage once. This means that your derivative images use memory\non the Docker host more efficiently and load more quickly.\nIt's also easier to maintain a common base stage (\"Don't repeat yourself\"),\nthan it is to have multiple different stages doing similar things.\nChoose the right base image\nThe first step towards achieving a secure image is to choose the right base\nimage. When choosing an image, ensure it's built from a trusted source and keep\nit small.\nDocker Official Images\nare a curated collection that have clear documentation, promote best\npractices, and are regularly updated. They provide a trusted starting point\nfor many applications.\nVerified Publisher\nimages\nare high-quality images published and maintained by the organizations\npartnering with Docker, with Docker verifying the authenticity of the content\nin their repositories.\nDocker-Sponsored Open Source\nare published and maintained by open source projects sponsored by Docker\nthrough an\nopen source program\n.\nWhen you pick your base image, look out for the badges indicating that the\nimage is part of these programs.\nWhen building your own image from a Dockerfile, ensure you choose a minimal base\nimage that matches your requirements. A smaller base image not only offers\nportability and fast downloads, but also shrinks the size of your image and\nminimizes the number of vulnerabilities introduced through the dependencies.\nYou should also consider using two types of base image: one for building and\nunit testing, and another (typically slimmer) image for production. In the\nlater stages of development, your image may not require build tools such as\ncompilers, build systems, and debugging tools. A small image with minimal\ndependencies can considerably lower the attack surface.\nRebuild your images often\nDocker images are immutable. Building an image is taking a snapshot of that\nimage at that moment. That includes any base images, libraries, or other\nsoftware you use in your build. To keep your images up-to-date and secure, make\nsure to rebuild your image often, with updated dependencies.\nTo ensure that you're getting the latest versions of dependencies in your build,\nyou can use the\n--no-cache\noption to avoid cache hits.\n$\ndocker build --no-cache -t my-image:my-tag .\nThe following Dockerfile uses the\n24.04\ntag of the\nubuntu\nimage. Over time,\nthat tag may resolve to a different underlying version of the\nubuntu\nimage,\nas the publisher rebuilds the image with new security patches and updated\nlibraries. Using the\n--no-cache\n, you can avoid cache hits and ensure a fresh\ndownload of base images and dependencies.\n# syntax=docker/dockerfile:1\nFROM\nubuntu:24.04\nRUN\napt-get -y update\n&&\napt-get install -y --no-install-recommends python3\nAlso consider\npinning base image versions\n.\nExclude with .dockerignore\nTo exclude files not relevant to the build, without restructuring your source\nrepository, use a\n.dockerignore\nfile. This file supports exclusion patterns\nsimilar to\n.gitignore\nfiles.\nFor example, to exclude all files with the\n.md\nextension:\n*.md\nFor information on creating one, see\nDockerignore file\n.\nCreate ephemeral containers\nThe image defined by your Dockerfile should generate containers that are as\nephemeral as possible. Ephemeral means that the container can be stopped\nand destroyed, then rebuilt and replaced with an absolute minimum set up and\nconfiguration.\nRefer to\nProcesses\nunder\nThe Twelve-factor App\nmethodology to get a feel for the motivations of running containers in such a\nstateless fashion.\nDon't install unnecessary packages\nAvoid installing extra or unnecessary packages just because they might be nice to have. For example, you donât need to include a text editor in a database image.\nWhen you avoid installing extra or unnecessary packages, your images have reduced complexity, reduced dependencies, reduced file sizes, and reduced build times.\nDecouple applications\nEach container should have only one concern. Decoupling applications into\nmultiple containers makes it easier to scale horizontally and reuse containers.\nFor instance, a web application stack might consist of three separate\ncontainers, each with its own unique image, to manage the web application,\ndatabase, and an in-memory cache in a decoupled manner.\nLimiting each container to one process is a good rule of thumb, but it's not a\nhard and fast rule. For example, not only can containers be\nspawned with an init process\n,\nsome programs might spawn additional processes of their own accord. For\ninstance,\nCelery\ncan spawn multiple worker\nprocesses, and\nApache\ncan create one process per\nrequest.\nUse your best judgment to keep containers as clean and modular as possible. If\ncontainers depend on each other, you can use\nDocker container networks\nto ensure that these containers can communicate.\nSort multi-line arguments\nWhenever possible, sort multi-line arguments alphanumerically to make maintenance easier.\nThis helps to avoid duplication of packages and make the\nlist much easier to update. This also makes PRs a lot easier to read and\nreview. Adding a space before a backslash (\n\\\n) helps as well.\nHereâs an example from the\nbuildpack-deps image\n:\nRUN\napt-get update\n&&\napt-get install -y --no-install-recommends\n\\\nbzr\n\\\ncvs\n\\\ngit\n\\\nmercurial\n\\\nsubversion\n\\\n&&\nrm -rf /var/lib/apt/lists/*\nLeverage build cache\nWhen building an image, Docker steps through the instructions in your\nDockerfile, executing each in the order specified. For each instruction, Docker\nchecks whether it can reuse the instruction from the build cache.\nUnderstanding how the build cache works, and how cache invalidation occurs,\nis critical for ensuring faster builds.\nFor more information about the Docker build cache and how to optimize your builds,\nsee\nDocker build cache\n.\nPin base image versions\nImage tags are mutable, meaning a publisher can update a tag to point to a new\nimage. This is useful because it lets publishers update tags to point to\nnewer versions of an image. And as an image consumer, it means you\nautomatically get the new version when you re-build your image.\nFor example, if you specify\nFROM alpine:3.21\nin your Dockerfile,\n3.21\nresolves to the latest patch version for\n3.21\n.\n# syntax=docker/dockerfile:1\nFROM\nalpine:3.21\nAt one point in time, the\n3.21\ntag might point to version 3.21.1 of the\nimage. If you rebuild the image 3 months later, the same tag might point to a\ndifferent version, such as 3.21.4. This publishing workflow is best practice,\nand most publishers use this tagging strategy, but it isn't enforced.\nThe downside with this is that you're not guaranteed to get the same for every\nbuild. This could result in breaking changes, and it means you also don't have\nan audit trail of the exact image versions that you're using.\nTo fully secure your supply chain integrity, you can pin the image version to a\nspecific digest. By pinning your images to a digest, you're guaranteed to\nalways use the same image version, even if a publisher replaces the tag with a\nnew image. For example, the following Dockerfile pins the Alpine image to the\nsame tag as earlier,\n3.21\n, but this time with a digest reference as well.\n# syntax=docker/dockerfile:1\nFROM\nalpine:3.21@sha256:a8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c\nWith this Dockerfile, even if the publisher updates the\n3.21\ntag, your builds\nwould still use the pinned image version:\na8560b36e8b8210634f77d9f7f9efd7ffa463e380b75e2e74aff4511df3ef88c\n.\nWhile this helps you avoid unexpected changes, it's also more tedious to have\nto look up and include the image digest for base image versions manually each\ntime you want to update it. And you're opting out of automated security fixes,\nwhich is likely something you want to get.\nDocker Scout's default\nUp-to-Date Base Images\npolicy\nchecks whether the\nbase image version you're using is in fact the latest version. This policy also\nchecks if pinned digests in your Dockerfile correspond to the correct version.\nIf a publisher updates an image that you've pinned, the policy evaluation\nreturns a non-compliant status, indicating that you should update your image.\nDocker Scout also supports an automated remediation workflow for keeping your\nbase images up-to-date. When a new image digest is available, Docker Scout can\nautomatically raise a pull request on your repository to update your\nDockerfiles to use the latest version. This is better than using a tag that\nchanges the version automatically, because you're in control and you have an\naudit trail of when and how the change occurred.\nFor more information about automatically updating your base images with Docker\nScout, see\nRemediation\n.\nBuild and test your images in CI\nWhen you check in a change to source control or create a pull request, use\nGitHub Actions\nor another CI/CD pipeline to\nautomatically build and tag a Docker image and test it.\nDockerfile instructions\nFollow these recommendations on how to properly use the\nDockerfile instructions\nto create an efficient and maintainable Dockerfile.\nTip\nTo improve linting, code navigation, and vulnerability scanning of your Dockerfiles in Visual Studio Code\nsee\nDocker VS Code Extension\n.\nFROM\nWhenever possible, use current official images as the basis for your\nimages. Docker recommends the\nAlpine image\nas it\nis tightly controlled and small in size (currently under 6 MB), while still\nbeing a full Linux distribution.\nFor more information about the\nFROM\ninstruction, see\nDockerfile reference for the FROM instruction\n.\nLABEL\nYou can add labels to your image to help organize images by project, record\nlicensing information, to aid in automation, or for other reasons. For each\nlabel, add a line beginning with\nLABEL\nwith one or more key-value pairs.\nThe following examples show the different acceptable formats. Explanatory comments are included inline.\nStrings with spaces must be quoted or the spaces must be escaped. Inner\nquote characters (\n\"\n), must also be escaped. For example:\n# Set one or more individual labels\nLABEL\ncom.example.version\n=\n\"0.0.1-beta\"\nLABEL\nvendor1\n=\n\"ACME Incorporated\"\nLABEL\nvendor2\n=\nZENITH\n\\\nIncorporated\nLABEL\ncom.example.release-date\n=\n\"2015-02-12\"\nLABEL\ncom.example.version.is-production\n=\n\"\"\nAn image can have more than one label. Prior to Docker 1.10, it was recommended\nto combine all labels into a single\nLABEL\ninstruction, to prevent extra layers\nfrom being created. This is no longer necessary, but combining labels is still\nsupported. For example:\n# Set multiple labels on one line\nLABEL\ncom.example.version\n=\n\"0.0.1-beta\"\ncom.example.release-date\n=\n\"2015-02-12\"\nThe above example can also be written as:\n# Set multiple labels at once, using line-continuation characters to break long lines\nLABEL\nvendor\n=\nACME\n\\\nIncorporated\n\\\ncom.example.is-beta\n=\n\\\ncom.example.is-production\n=\n\"\"\n\\\ncom.example.version\n=\n\"0.0.1-beta\"\n\\\ncom.example.release-date\n=\n\"2015-02-12\"\nSee\nUnderstanding object labels\nfor guidelines about acceptable label keys and values. For information about\nquerying labels, refer to the items related to filtering in\nManaging labels on objects\n.\nSee also\nLABEL\nin the Dockerfile reference.\nRUN\nSplit long or complex\nRUN\nstatements on multiple lines separated with\nbackslashes to make your Dockerfile more readable, understandable, and\nmaintainable.\nFor example, you can chain commands with the\n&&\noperator, and use\nescape characters to break long commands into multiple lines.\nRUN\napt-get update\n&&\napt-get install -y --no-install-recommends\n\\\npackage-bar\n\\\npackage-baz\n\\\npackage-foo\nBy default, backslash escapes a newline character, but you can change it with\nthe\nescape\ndirective\n.\nYou can also use here documents to run multiple commands without chaining them\nwith a pipeline operator:\nRUN\n<<EOF\napt-get update\napt-get install -y --no-install-recommends\n\\\npackage-bar\n\\\npackage-baz\n\\\npackage-foo\nEOF\nFor more information about\nRUN\n, see\nDockerfile reference for the RUN instruction\n.\napt-get\nOne common use case for\nRUN\ninstructions in Debian-based images is to install\nsoftware using\napt-get\n. Because\napt-get\ninstalls packages, the\nRUN apt-get\ncommand has several counter-intuitive behaviors to look out for.\nAlways combine\nRUN apt-get update\nwith\napt-get install\nin the same\nRUN\nstatement. For example:\nRUN\napt-get update\n&&\napt-get install -y --no-install-recommends\n\\\npackage-bar\n\\\npackage-baz\n\\\npackage-foo\nUsing\napt-get update\nalone in a\nRUN\nstatement causes caching issues and\nsubsequent\napt-get install\ninstructions to fail. For example, this issue will occur in the following Dockerfile:\n# syntax=docker/dockerfile:1\nFROM\nubuntu:22.04\nRUN\napt-get update\nRUN\napt-get install -y --no-install-recommends curl\nAfter building the image, all layers are in the Docker cache. Suppose you later\nmodify\napt-get install\nby adding an extra package as shown in the following Dockerfile:\n# syntax=docker/dockerfile:1\nFROM\nubuntu:22.04\nRUN\napt-get update\nRUN\napt-get install -y --no-install-recommends curl nginx\nDocker sees the initial and modified instructions as identical and reuses the\ncache from previous steps. As a result the\napt-get update\nisn't executed\nbecause the build uses the cached version. Because the\napt-get update\nisn't\nrun, your build can potentially get an outdated version of the\ncurl\nand\nnginx\npackages.\nUsing\nRUN apt-get update && apt-get install -y --no-install-recommends\nensures your Dockerfile\ninstalls the latest package versions with no further coding or manual\nintervention. This technique is known as cache busting. You can also achieve\ncache busting by specifying a package version. This is known as version pinning.\nFor example:\nRUN\napt-get update\n&&\napt-get install -y --no-install-recommends\n\\\npackage-bar\n\\\npackage-baz\n\\\npackage-foo\n=\n1.3.*\nVersion pinning forces the build to retrieve a particular version regardless of\nwhatâs in the cache. This technique can also reduce failures due to unanticipated changes\nin required packages.\nBelow is a well-formed\nRUN\ninstruction that demonstrates all the\napt-get\nrecommendations.\nRUN\napt-get update\n&&\napt-get install -y --no-install-recommends\n\\\naufs-tools\n\\\nautomake\n\\\nbuild-essential\n\\\ncurl\n\\\ndpkg-sig\n\\\nlibcap-dev\n\\\nlibsqlite3-dev\n\\\nmercurial\n\\\nreprepro\n\\\nruby1.9.1\n\\\nruby1.9.1-dev\n\\\ns3cmd\n=\n1.1.*\n\\\n&&\nrm -rf /var/lib/apt/lists/*\nThe\ns3cmd\nargument specifies a version\n1.1.*\n. If the image previously\nused an older version, specifying the new one causes a cache bust of\napt-get update\nand ensures the installation of the new version. Listing packages on\neach line can also prevent mistakes in package duplication.\nIn addition, when you clean up the apt cache by removing\n/var/lib/apt/lists\nit\nreduces the image size, since the apt cache isn't stored in a layer. Since the\nRUN\nstatement starts with\napt-get update\n, the package cache is always\nrefreshed prior to\napt-get install\n.\nOfficial Debian and Ubuntu images\nautomatically run\napt-get clean\n, so explicit invocation is not required.\nUsing pipes\nSome\nRUN\ncommands depend on the ability to pipe the output of one command into another, using the pipe character (\n|\n), as in the following example:\nRUN\nwget -O - https://some.site\n|\nwc -l > /number\nDocker executes these commands using the\n/bin/sh -c\ninterpreter, which only\nevaluates the exit code of the last operation in the pipe to determine success.\nIn the example above, this build step succeeds and produces a new image so long\nas the\nwc -l\ncommand succeeds, even if the\nwget\ncommand fails.\nIf you want the command to fail due to an error at any stage in the pipe,\nprepend\nset -o pipefail &&\nto ensure that an unexpected error prevents the\nbuild from inadvertently succeeding. For example:\nRUN\nset\n-o pipefail\n&&\nwget -O - https://some.site\n|\nwc -l > /number\nNote\nNot all shells support the\n-o pipefail\noption.\nIn cases such as the\ndash\nshell on\nDebian-based images, consider using the\nexec\nform of\nRUN\nto explicitly\nchoose a shell that does support the\npipefail\noption. For example:\nRUN\n[\n\"/bin/bash\"\n,\n\"-c\"\n,\n\"set -o pipefail && wget -O - https://some.site | wc -l > /number\"\n]\nCMD\nThe\nCMD\ninstruction should be used to run the software contained in your\nimage, along with any arguments.\nCMD\nshould almost always be used in the form\nof\nCMD [\"executable\", \"param1\", \"param2\"]\n. Thus, if the image is for a\nservice, such as Apache and Rails, you would run something like\nCMD [\"apache2\",\"-DFOREGROUND\"]\n. Indeed, this form of the instruction is recommended\nfor any service-based image.\nIn most other cases,\nCMD\nshould be given an interactive shell, such as bash,\nPython and perl. For example,\nCMD [\"perl\", \"-de0\"]\n,\nCMD [\"python\"]\n, or\nCMD [\"php\", \"-a\"]\n. Using this form means that when you execute something like\ndocker run -it python\n, youâll get dropped into a usable shell, ready to go.\nCMD\nshould rarely be used in the manner of\nCMD [\"param\", \"param\"]\nin\nconjunction with\nENTRYPOINT\n, unless\nyou and your expected users are already quite familiar with how\nENTRYPOINT\nworks.\nFor more information about\nCMD\n, see\nDockerfile reference for the CMD instruction\n.\nEXPOSE\nThe\nEXPOSE\ninstruction indicates the ports on which a container listens\nfor connections. Consequently, you should use the common, traditional port for\nyour application. For example, an image containing the Apache web server would\nuse\nEXPOSE 80\n, while an image containing MongoDB would use\nEXPOSE 27017\nand\nso on.\nFor external access, your users can execute\ndocker run\nwith a flag indicating\nhow to map the specified port to the port of their choice.\nFor container linking, Docker provides environment variables for the path from\nthe recipient container back to the source (for example,\nMYSQL_PORT_3306_TCP\n).\nFor more information about\nEXPOSE\n, see\nDockerfile reference for the EXPOSE instruction\n.\nENV\nTo make new software easier to run, you can use\nENV\nto update the\nPATH\nenvironment variable for the software your container installs. For\nexample,\nENV PATH=/usr/local/nginx/bin:$PATH\nensures that\nCMD [\"nginx\"]\njust works.\nThe\nENV\ninstruction is also useful for providing the required environment\nvariables specific to services you want to containerize, such as Postgresâs\nPGDATA\n.\nLastly,\nENV\ncan also be used to set commonly used version numbers so that\nversion bumps are easier to maintain, as seen in the following example:\nENV\nPG_MAJOR\n=\n9\n.3\nENV\nPG_VERSION\n=\n9\n.3.4\nRUN\ncurl -SL https://example.com/postgres-\n$PG_VERSION\n.tar.xz\n|\ntar -xJC /usr/src/postgres\n&&\nâ¦\nENV\nPATH\n=\n/usr/local/postgres-\n$PG_MAJOR\n/bin:\n$PATH\nSimilar to having constant variables in a program, as opposed to hard-coding\nvalues, this approach lets you change a single\nENV\ninstruction to\nautomatically bump the version of the software in your container.\nEach\nENV\nline creates a new intermediate layer, just like\nRUN\ncommands. This\nmeans that even if you unset the environment variable in a future layer, it\nstill persists in this layer and its value can be dumped. You can test this by\ncreating a Dockerfile like the following, and then building it.\n# syntax=docker/dockerfile:1\nFROM\nalpine\nENV\nADMIN_USER\n=\n\"mark\"\nRUN\necho\n$ADMIN_USER\n> ./mark\nRUN\nunset\nADMIN_USER\n$\ndocker run --rm\ntest\nsh -c\n'echo $ADMIN_USER'\nmark\nTo prevent this and unset the environment variable, use a\nRUN\ncommand\nwith shell commands, to set, use, and unset the variable all in a single layer.\nYou can separate your commands with\n;\nor\n&&\n. If you use the second method,\nand one of the commands fails, the\ndocker build\nalso fails. This is usually a\ngood idea. Using\n\\\nas a line continuation character for Linux Dockerfiles\nimproves readability. You could also put all of the commands into a shell script\nand have the\nRUN\ncommand just run that shell script.\n# syntax=docker/dockerfile:1\nFROM\nalpine\nRUN\nexport\nADMIN_USER\n=\n\"mark\"\n\\\n&&\necho\n$ADMIN_USER\n> ./mark\n\\\n&&\nunset\nADMIN_USER\nCMD\nsh\n$\ndocker run --rm\ntest\nsh -c\n'echo $ADMIN_USER'\nFor more information about\nENV\n, see\nDockerfile reference for the ENV instruction\n.\nADD or COPY\nADD\nand\nCOPY\nare functionally similar.\nCOPY\nsupports basic copying of\nfiles into the container, from the\nbuild context\nor from a stage in a\nmulti-stage build\n.\nADD\nsupports features for fetching files from remote HTTPS and Git URLs, and\nextracting tar files automatically when adding files from the build context.\nYou'll mostly want to use\nCOPY\nfor copying files from one stage to another in\na multi-stage build. If you need to add files from the build context to the\ncontainer temporarily to execute a\nRUN\ninstruction, you can often substitute\nthe\nCOPY\ninstruction with a bind mount instead. For example, to temporarily\nadd a\nrequirements.txt\nfile for a\nRUN pip install\ninstruction:\nRUN\n--mount\n=\ntype\n=\nbind,source\n=\nrequirements.txt,target\n=\n/tmp/requirements.txt\n\\\npip install --requirement /tmp/requirements.txt\nBind mounts are more efficient than\nCOPY\nfor including files from the build\ncontext in the container. Note that bind-mounted files are only added\ntemporarily for a single\nRUN\ninstruction, and don't persist in the final\nimage. If you need to include files from the build context in the final image,\nuse\nCOPY\n.\nThe\nADD\ninstruction is best for when you need to download a remote artifact\nas part of your build.\nADD\nis better than manually adding files using\nsomething like\nwget\nand\ntar\n, because it ensures a more precise build cache.\nADD\nalso has built-in support for checksum validation of the remote\nresources, and a protocol for parsing branches, tags, and subdirectories from\nGit URLs\n.\nThe following example uses\nADD\nto download a .NET installer. Combined with\nmulti-stage builds, only the .NET runtime remains in the final stage, no\nintermediate files.\n# syntax=docker/dockerfile:1\nFROM\nscratch AS src\nARG\nDOTNET_VERSION\n=\n8\n.0.0-preview.6.23329.7\nADD\n--checksum\n=\nsha256:270d731bd08040c6a3228115de1f74b91cf441c584139ff8f8f6503447cebdbb\n\\\nhttps://dotnetcli.azureedge.net/dotnet/Runtime/\n$DOTNET_VERSION\n/dotnet-runtime-\n$DOTNET_VERSION\n-linux-arm64.tar.gz /dotnet.tar.gz\nFROM\nmcr.microsoft.com/dotnet/runtime-deps:8.0.0-preview.6-bookworm-slim-arm64v8 AS installer\n# Retrieve .NET Runtime\nRUN\n--mount\n=\nfrom\n=\nsrc,target\n=\n/src <<EOF\nmkdir -p /dotnet\ntar -oxzf /src/dotnet.tar.gz -C /dotnet\nEOF\nFROM\nmcr.microsoft.com/dotnet/runtime-deps:8.0.0-preview.6-bookworm-slim-arm64v8\nCOPY\n--from\n=\ninstaller /dotnet /usr/share/dotnet\nRUN\nln -s /usr/share/dotnet/dotnet /usr/bin/dotnet\nFor more information about\nADD\nor\nCOPY\n, see the following:\nDockerfile reference for the ADD instruction\nDockerfile reference for the COPY instruction\nENTRYPOINT\nThe best use for\nENTRYPOINT\nis to set the image's main command, allowing that\nimage to be run as though it was that command, and then use\nCMD\nas the\ndefault flags.\nThe following is an example of an image for the command line tool\ns3cmd\n:\nENTRYPOINT\n[\n\"s3cmd\"\n]\nCMD\n[\n\"--help\"\n]\nYou can use the following command to run the image and show the command's help:\n$\ndocker run s3cmd\nOr, you can use the right parameters to execute a command, like in the following example:\n$\ndocker run s3cmd ls s3://mybucket\nThis is useful because the image name can double as a reference to the binary as\nshown in the command above.\nThe\nENTRYPOINT\ninstruction can also be used in combination with a helper\nscript, allowing it to function in a similar way to the command above, even\nwhen starting the tool may require more than one step.\nFor example, the\nPostgres Official Image\nuses the following script as its\nENTRYPOINT\n:\n#!/bin/bash\nset\n-e\nif\n[\n\"\n$1\n\"\n=\n'postgres'\n]\n;\nthen\nchown -R postgres\n\"\n$PGDATA\n\"\nif\n[\n-z\n\"\n$(\nls -A\n\"\n$PGDATA\n\"\n)\n\"\n]\n;\nthen\ngosu postgres initdb\nfi\nexec\ngosu postgres\n\"\n$@\n\"\nfi\nexec\n\"\n$@\n\"\nThis script uses\nthe\nexec\nBash command\nso that the final running application becomes the container's PID 1. This allows the application to receive any Unix signals sent to the container. For more information, see the\nENTRYPOINT\nreference\n.\nIn the following example, a helper script is copied into the container and run via\nENTRYPOINT\non\ncontainer start:\nCOPY\n./docker-entrypoint.sh /\nENTRYPOINT\n[\n\"/docker-entrypoint.sh\"\n]\nCMD\n[\n\"postgres\"\n]\nThis script lets you interact with Postgres in several ways.\nIt can simply start Postgres:\n$\ndocker run postgres\nOr, you can use it to run Postgres and pass parameters to the server:\n$\ndocker run postgres postgres --help\nLastly, you can use it to start a totally different tool, such as Bash:\n$\ndocker run --rm -it postgres bash\nFor more information about\nENTRYPOINT\n, see\nDockerfile reference for the ENTRYPOINT instruction\n.\nVOLUME\nYou should use the\nVOLUME\ninstruction to expose any database storage area,\nconfiguration storage, or files and folders created by your Docker container. You\nare strongly encouraged to use\nVOLUME\nfor any combination of mutable or user-serviceable\nparts of your image.\nFor more information about\nVOLUME\n, see\nDockerfile reference for the VOLUME instruction\n.\nUSER\nIf a service can run without privileges, use\nUSER\nto change to a non-root\nuser. Start by creating the user and group in the Dockerfile with something\nlike the following example:\nRUN\ngroupadd -r postgres\n&&\nuseradd --no-log-init -r -g postgres postgres\nNote\nConsider an explicit UID/GID.\nUsers and groups in an image are assigned a non-deterministic UID/GID in that\nthe \"next\" UID/GID is assigned regardless of image rebuilds. So, if itâs\ncritical, you should assign an explicit UID/GID.\nNote\nDue to an\nunresolved bug\nin the\nGo archive/tar package's handling of sparse files, attempting to create a user\nwith a significantly large UID inside a Docker container can lead to disk\nexhaustion because\n/var/log/faillog\nin the container layer is filled with\nNULL (\\0) characters. A workaround is to pass the\n--no-log-init\nflag to\nuseradd\n. The Debian/Ubuntu\nadduser\nwrapper does not support this flag.\nAvoid installing or using\nsudo\nas it has unpredictable TTY and\nsignal-forwarding behavior that can cause problems. If you absolutely need\nfunctionality similar to\nsudo\n, such as initializing the daemon as\nroot\nbut\nrunning it as non-\nroot\n, consider using\nâgosuâ\n.\nLastly, to reduce layers and complexity, avoid switching\nUSER\nback and forth\nfrequently.\nFor more information about\nUSER\n, see\nDockerfile reference for the USER instruction\n.\nWORKDIR\nFor clarity and reliability, you should always use absolute paths for your\nWORKDIR\n. Also, you should use\nWORKDIR\ninstead of proliferating instructions\nlike\nRUN cd â¦ && do-something\n, which are hard to read, troubleshoot, and\nmaintain.\nFor more information about\nWORKDIR\n, see\nDockerfile reference for the\nWORKDIR\ninstruction\n.\nONBUILD\nAn\nONBUILD\ncommand executes after the current Dockerfile build completes.\nONBUILD\nexecutes in any child image derived\nFROM\nthe current image. Think\nof the\nONBUILD\ncommand as an instruction that the parent Dockerfile gives\nto the child Dockerfile.\nA Docker build executes\nONBUILD\ncommands before any command in a child\nDockerfile.\nONBUILD\nis useful for images that are going to be built\nFROM\na given\nimage. For example, you would use\nONBUILD\nfor a language stack image that\nbuilds arbitrary user software written in that language within the\nDockerfile, as you can see in\nRubyâs\nONBUILD\nvariants\n.\nImages built with\nONBUILD\nshould get a separate tag. For example,\nruby:1.9-onbuild\nor\nruby:2.0-onbuild\n.\nBe careful when putting\nADD\nor\nCOPY\nin\nONBUILD\n. The image\nfails catastrophically if the new build's context is missing the resource being\nadded. Adding a separate tag, as recommended above, helps mitigate this by\nallowing the Dockerfile author to make a choice.\nFor more information about\nONBUILD\n, see\nDockerfile reference for the ONBUILD instruction\n.\nEdit this page\nRequest changes\nTable of contents\nBest practices", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/build/building/best-practices/"}}
{"text": "Logs and metrics | Docker Docs\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nBack\nAsk AI\nStart typing to search or try\nAsk AI\n.\nContact support\nManuals\nGet started\nGuides\nReference\nView container logs\nPage options\nCopy page as Markdown for LLMs\nView page as plain text\nAsk questions with Docs AI\nClaude\nOpen in Claude\nTable of contents\nThe\ndocker logs\ncommand shows information logged by a running container. The\ndocker service logs\ncommand shows information logged by all containers\nparticipating in a service. The information that's logged and the format of the\nlog depends almost entirely on the container's endpoint command.\nBy default,\ndocker logs\nor\ndocker service logs\nshows the command's output\njust as it would appear if you ran the command interactively in a terminal. Unix\nand Linux commands typically open three I/O streams when they run, called\nSTDIN\n,\nSTDOUT\n, and\nSTDERR\n.\nSTDIN\nis the command's input stream, which\nmay include input from the keyboard or input from another command.\nSTDOUT\nis\nusually a command's normal output, and\nSTDERR\nis typically used to output\nerror messages. By default,\ndocker logs\nshows the command's\nSTDOUT\nand\nSTDERR\n. To read more about I/O and Linux, see the\nLinux Documentation Project article on I/O redirection\n.\nIn some cases,\ndocker logs\nmay not show useful information unless you take\nadditional steps.\nIf you use a\nlogging driver\nwhich sends logs to a file, an\nexternal host, a database, or another logging back-end, and have\n\"dual logging\"\ndisabled,\ndocker logs\nmay not show useful information.\nIf your image runs a non-interactive process such as a web server or a\ndatabase, that application may send its output to log files instead of\nSTDOUT\nand\nSTDERR\n.\nIn the first case, your logs are processed in other ways and you may choose not\nto use\ndocker logs\n. In the second case, the official\nnginx\nimage shows one\nworkaround, and the official Apache\nhttpd\nimage shows another.\nThe official\nnginx\nimage creates a symbolic link from\n/var/log/nginx/access.log\nto\n/dev/stdout\n, and creates another symbolic link\nfrom\n/var/log/nginx/error.log\nto\n/dev/stderr\n, overwriting the log files and\ncausing logs to be sent to the relevant special device instead. See the\nDockerfile\n.\nThe official\nhttpd\ndriver changes the\nhttpd\napplication's configuration to\nwrite its normal output directly to\n/proc/self/fd/1\n(which is\nSTDOUT\n) and\nits errors to\n/proc/self/fd/2\n(which is\nSTDERR\n). See the\nDockerfile\n.\nNext steps\nConfigure\nlogging drivers\n.\nWrite a\nDockerfile\n.\nEdit this page\nRequest changes\nTable of contents", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.docker.com/config/containers/logging/"}}
