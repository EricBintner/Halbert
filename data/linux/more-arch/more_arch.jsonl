{"text": "Users and groups - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nUsers and groups\n9 languages\nالعربية\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nDeveloperWiki:UID / GID Database\nSudo\nPolkit\nFile permissions and attributes\nsystemd-homed\nReset lost root password\nIdentity management\nUsers and groups are used on GNU/Linux for\naccess control\n—that is, to control access to the system's files, directories, and peripherals. Linux offers relatively simple/coarse access control mechanisms by default. For more advanced options, see\nACL\n,\nCapabilities\nand\nPAM#Configuration How-Tos\n.\nOverview\nA\nuser\nis anyone who uses a computer. In this case, we are describing the names which represent those users. It may be Mary or Bill, and they may use the names Dragonlady or Pirate in place of their real name. All that matters is that the computer has a name for each account it creates, and it is this name by which a person gains access to use the computer. Some system services also run using restricted or privileged user accounts.\nManaging users is done for the purpose of security by limiting access in certain specific ways. The\nsuperuser\n(root) has complete access to the operating system and its configuration; it is intended for administrative use only. Unprivileged users can use several programs for controlled\nprivilege elevation\n.\nAny individual may have more than one account as long as they use a different name for each account they create. Further, there are some reserved names which may not be used such as \"root\".\nUsers may be grouped together into a \"group\", and users may be added to an existing group to utilize the privileged access it grants.\nNote\nThe beginner should use these tools carefully and stay away from having anything to do with any other\nexisting\nuser account, other than their own.\nPermissions and ownership\nFrom\nIn UNIX Everything is a File\n:\nThe UNIX operating system crystallizes a couple of unifying ideas and concepts that shaped its design, user interface, culture and evolution. One of the most important of these is probably the mantra: \"everything is a file,\" widely regarded as one of the defining points of UNIX.\nThis key design principle consists of providing a unified paradigm for accessing a wide range of input/output resources: documents, directories, hard-drives, CD-ROMs, modems, keyboards, printers, monitors, terminals and even some inter-process and network communications. The trick is to provide a common abstraction for all of these resources, each of which the UNIX fathers called a \"file.\" Since every \"file\" is exposed through the same API, you can use the same set of basic commands to read/write to a disk, keyboard, document or network device.\nFrom\nExtending UNIX File Abstraction for General-Purpose Networking\n:\nA fundamental and very powerful, consistent abstraction provided in UNIX and compatible operating systems is the file abstraction. Many OS services and device interfaces are implemented to provide a file or file system metaphor to applications. This enables new uses for, and greatly increases the power of, existing applications — simple tools designed with specific uses in mind can, with UNIX file abstractions, be used in novel ways. A simple tool, such as cat, designed to read one or more files and output the contents to standard output, can be used to read from I/O devices through special device files, typically found under the\n/dev\ndirectory. On many systems, audio recording and playback can be done simply with the commands, \"\ncat /dev/audio > myfile\n\" and \"\ncat myfile > /dev/audio\n,\" respectively.\nEvery file on a GNU/Linux system is owned by a user and a group. In addition, there are three types of access permissions: read, write, and execute. Different access permissions can be applied to a file's owning user, owning group, and others (those without ownership). One can determine a file's owners and permissions by viewing the long listing format of the\nls\ncommand:\n$ ls -l /boot/\ntotal 13740\ndrwxr-xr-x 2 root root    4096 Jan 12 00:33 grub\n-rw-r--r-- 1 root root 8570335 Jan 12 00:33 initramfs-linux-fallback.img\n-rw-r--r-- 1 root root 1821573 Jan 12 00:31 initramfs-linux.img\n-rw-r--r-- 1 root root 1457315 Jan  8 08:19 System.map26\n-rw-r--r-- 1 root root 2209920 Jan  8 08:19 vmlinuz-linux\nThe first column displays the file's permissions (for example, the file\ninitramfs-linux.img\nhas permissions\n-rw-r--r--\n). The third and fourth columns display the file's owning user and group, respectively. In this example, all files are owned by the\nroot\nuser and the\nroot\ngroup.\n$ ls -l /media/\ntotal 16\ndrwxrwx--- 1 root vboxsf 16384 Jan 29 11:02 sf_Shared\nIn this example, the\nsf_Shared\ndirectory is owned by the\nroot\nuser and the\nvboxsf\ngroup. It is also possible to determine a file's owners and permissions using the stat command:\nOwning user:\n$ stat -c %U /media/sf_Shared/\nroot\nOwning group:\n$ stat -c %G /media/sf_Shared/\nvboxsf\nAccess rights:\n$ stat -c %A /media/sf_Shared/\ndrwxrwx---\nAccess permissions are displayed in three groups of characters, representing the permissions of the owning user, owning group, and others, respectively. For example, the characters\n-rw-r--r--\nindicate that the file's owner has read and write permission, but not execute (\nrw-\n), whilst users belonging to the owning group and other users have only read permission (\nr--\nand\nr--\n). Meanwhile, the characters\ndrwxrwx---\nindicate that the file's owner and users belonging to the owning group all have read, write, and execute permissions (\nrwx\nand\nrwx\n), whilst other users are denied access (\n---\n). The first character represents the file's type.\nList files owned by a user or group with the\nfind\nutility:\n# find / -group\ngroupname\n# find / -group\ngroupnumber\n# find / -user\nuser\nA file's owning user and group can be changed with the\nchown\n(change owner) command. A file's access permissions can be changed with the\nchmod\n(change mode) command.\nSee\nchown(1)\n,\nchmod(1)\n, and\nLinux file permissions\nfor additional detail.\nShadow\nThe user, group and password management tools on Arch Linux come from the\nshadow\npackage, which is a dependency of the\nbase\nmeta package\n.\nFile list\nWarning\nDo not edit these files by hand. There are utilities that properly handle locking and avoid invalidating the format of the database. See\n#User management\nand\n#Group management\nfor an overview.\nFile\nPurpose\n/etc/shadow\nSecure user account information\n/etc/passwd\nUser account information\n/etc/gshadow\nContains the shadowed information for group accounts\n/etc/group\nDefines the groups to which users belong\nUser management\nTo list users currently logged on the system, the\nwho\ncommand can be used. To list all existing user accounts including their properties stored in the\nuser database\n, run\npasswd -Sa\nas root. See\npasswd(1)\nfor the description of the output format.\nTo add a new user, use the\nuseradd\ncommand:\n# useradd -m -G\nadditional_groups\n-s\nlogin_shell\nusername\n-m\n/\n--create-home\nthe user's home directory is created as\n/home/\nusername\n. The directory is populated by the files in the skeleton directory. The created files are owned by the new user.\n-G\n/\n--groups\na comma separated list of supplementary groups which the user is also a member of. The default is for the user to belong only to the initial group.\n-s\n/\n--shell\na path to the user's login shell. Ensure the chosen shell is installed if choosing something other than\nBash\n. The default shell for newly created user can be set in\n/etc/default/useradd\n.\nWarning\nIn order to be able to log in, the login shell must be one of those listed in\n/etc/shells\n, otherwise the\nPAM\nmodule\npam_shells(8)\nwill deny the login request.\nNote\nThe password for the newly created user must then be defined, using\npasswd\nas shown in\n#Example adding a user\n.\nIf an initial login group is specified by name or number, it must refer to an already existing group. If not specified, the behaviour of\nuseradd\nwill depend on the\nUSERGROUPS_ENAB\nvariable contained in\n/etc/login.defs\n. The default behaviour (\nUSERGROUPS_ENAB yes\n) is to create a group with the same name as the username.\nWhen the login shell is intended to be non-functional, for example when the user account is created for a specific service,\n/usr/bin/nologin\nmay be specified in place of a regular shell to politely refuse a login (see\nnologin(8)\n).\nSee\nuseradd(8)\nfor other supported options.\nExample adding a user\nTo add a new user named\narchie\n, creating its home directory and otherwise using all the defaults in terms of groups, directory names, shell used and various other parameters:\n# useradd -m archie\nAlthough it is not required to protect the newly created user\narchie\nwith a password, it is highly recommended to do so:\n# passwd archie\nThe above\nuseradd\ncommand will also automatically create a group called\narchie\nand makes this the default group for the user\narchie\n. Making each user have their own group (with the group name same as the user name) is the preferred way to add users.\nYou could also make the default group something else using the\n-g\noption, but note that, in multi-user systems, using a single default group (e.g.\nusers\n) for every user is not recommended. The reason is that typically, the method for facilitating shared write access for specific groups of users is setting user\numask\nvalue to\n002\n, which means that the default group will by default always have write access to any file you create. See also\nUser Private Groups\n. If a user must be a member of a specific group specify that group as a supplementary group when creating the user.\nIn the recommended scenario, where the default group has the same name as the user name, all files are by default writeable only for the user who created them. To allow write access to a specific group, shared files/directories can be made writeable by default for everyone in this group and the owning group can be automatically fixed to the group which owns the parent directory by setting the\nsetgid\nbit on this directory:\n# chmod g+s\nour_shared_directory\nOtherwise the file creator's default group (usually the same as the user name) is used.\nIf a GID change is required temporarily you can also use the\nnewgrp\ncommand to change the user's default GID to another GID at runtime. For example, after executing\nnewgrp\ngroupname\nfiles created by the user will be associated with the\ngroupname\nGID, without requiring a re-login. To change back to the default GID, execute\nnewgrp\nwithout a groupname.\nChanging user defaults\nThe default values used for creating new accounts are set in\n/etc/default/useradd\nand can be displayed using\nuseradd --defaults\n. For example, to change the default shell globally, set\nSHELL=/usr/bin/\nshell\n. A different shell can also be specified individually with the\n-s\n/\n--shell\noption. Use\nchsh -l\nto list valid login shells.\nFiles can also be specified to be added to newly created user home directories in\n/etc/skel\n. This is useful for minimalist window managers where config files need manual configuration to reach DE-familiar behavior. For example, to set up default shortcuts for all newly created users:\n# mkdir /etc/skel/.config\n# cp ~archie/.config/sxhkd /etc/skel/.config\nSee also:\nDisplay manager#Run ~/.xinitrc as a session\nto add xinitrc as an option to all users on the display manager.\nExample adding a system user\nSystem users can be used to run processes/daemons under a different user,  protecting (e.g. with\nchown\n) files and/or directories and more examples of computer hardening.\nWith the following command a system user without shell access and without a\nhome\ndirectory is created (optionally append the\n-U\nparameter to create a group with the same name as the user, and add the user to this group):\n# useradd --system -s /usr/bin/nologin\nusername\nIf the system user requires a specific user and group ID, specify them with the\n-u\n/\n--uid\nand\n-g\n/\n--gid\noptions when creating the user:\n# useradd --system -u 850 -g 850 -s /usr/bin/nologin\nusername\nChange a user's login name or home directory\nTo change a user's home directory:\n# usermod -d\n/my/new/home\n-m\nusername\nThe\n-m\noption also automatically creates the new directory and moves the content there.\nTip\nYou can create a link from the user's former home directory to the new one. Doing this will allow programs to find files that have hardcoded paths.\n# ln -s /my/new/home/ /my/old/home\nMake sure there is\nno\ntrailing\n/\non\n/my/old/home\n.\nTo change a user's login name:\n# usermod -l\nnewname\noldname\nWarning\nMake certain that you are not logged in as the user whose name you are about to change. Open a new tty (e.g.\nCtrl+Alt+F6\n) and log in as root or as another user and\nelevate to root\n.\nusermod\nshould prevent you from doing this by mistake.\nChanging a username is safe and easy when done properly, just use the\nusermod\ncommand. If the user is associated to a group with the same name, you can rename this with the\ngroupmod\ncommand.\nAlternatively, the\n/etc/passwd\nfile can be edited directly, see\n#User database\nfor an introduction to its format.\nAlso keep in mind the following notes:\nIf you are using\nsudo\nmake sure you update your\n/etc/sudoers\nto reflect the new username(s) (via the\nvisudo\ncommand as root).\nPersonal\ncrontabs\nneed to be adjusted by renaming the user's file in\n/var/spool/cron\nfrom the old to the new name, and then opening\ncrontab -e\nto change any relevant paths and have it adjust the file permissions accordingly.\nWine's\npersonal directories/files' contents in\n~/.wine/drive_c/users\n,\n~/.local/share/applications/wine/Programs\nand possibly more need to be manually renamed/edited.\nCertain Thunderbird addons, like\nEnigmail\n, may need to be reinstalled.\nAnything on your system (desktop shortcuts, shell scripts, etc.) that uses an absolute path to your home dir (i.e.\n/home/oldname\n) will need to be changed to reflect your new name. To avoid these problems in shell scripts, simply use the\n~\nor\n$HOME\nvariables for home directories.\nAlso do not forget to edit accordingly the configuration files in\n/etc/\nthat relies on your absolute path (e.g. Samba, CUPS, so on). A nice way to learn what files you need to update involves using the grep command this way:\ngrep -r\nold_user\n*\nOther examples of user management\nTo enter user information for the\nGECOS\ncomment (e.g. the full user name), type:\n# chfn\nusername\n(this way\nchfn\nruns in interactive mode).\nAlternatively the GECOS comment can be set more liberally with:\n# usermod -c \"Comment\"\nusername\nTo mark a user's password as expired, requiring them to create a new password the first time they log in, type:\n# chage -d 0\nusername\nUser accounts may be deleted with the\nuserdel\ncommand:\n# userdel -r\nusername\nThe\n-r\noption specifies that the user's home directory and mail spool should also be deleted.\nTo change the user's login shell:\n# usermod -s\n/usr/bin/bash\nusername\nTip\nThe\nadduser\nAUR\nscript allows carrying out the jobs of\nuseradd\n,\nchfn\nand\npasswd\ninteractively. See also\nFS#32893\n.\nUser database\nLocal user information is stored in the plain-text\n/etc/passwd\nfile: each of its lines represents a user account, and has seven fields delimited by colons.\naccount:password:UID:GID:GECOS:directory:shell\nWhere:\naccount\nis the user name. This field cannot be blank. Standard *NIX naming rules apply.\npassword\nis the user password.\nWarning\nThe\npasswd\nfile is world-readable, so storing passwords (hashed or otherwise) in this file is insecure. Instead, Arch Linux uses\nshadowed passwords\n: the\npassword\nfield will contain a placeholder character (\nx\n) indicating that the hashed password is saved in the access-restricted file\n/etc/shadow\n. For this reason it is recommended to always change passwords using the\npasswd\ncommand.\nUID\nis the numerical user ID. In Arch, the first login name (after root) for a so called normal user, as opposed to services, is UID 1000 by default; subsequent UID entries for users should be greater than 1000.\nGID\nis the numerical primary group ID for the user. Numeric values for GIDs are listed in\n/etc/group\n.\nGECOS\nis an optional field used for informational purposes; usually it contains the full user name, but it can also be used by services such as\nfinger\nand managed with the\nchfn\ncommand. This field is optional and may be left blank.\ndirectory\nis used by the login command to set the\n$HOME\nenvironment variable. Several services with their own users use\n/\n, but normal users usually set a directory under\n/home\n.\nshell\nis the path to the user's default\ncommand shell\n. This field is optional and defaults to\n/usr/bin/bash\n.\nExample:\narchie:x:1001:1003:Archie,\nsome comment here\n,,:/home/archie:/usr/bin/bash\nBroken down, this means: user\narchie\n, whose password is in\n/etc/shadow\n, whose UID is 1001 and whose primary group is 1003. Archie is their full name and there is a comment associated to their account; their home directory is\n/home/archie\nand they are using\nBash\n.\nThe\npwck\ncommand can be used to verify the integrity of the user database. It can sort the user list by UID at the same time, which can be helpful for comparison:\n# pwck -s\nWarning\nArch Linux defaults of the files are created as\npacnew files\nby new releases of the\nfilesystem\npackage. Unless Pacman outputs related messages for action, these\n.pacnew\nfiles can, and should, be disregarded/removed. New required default users and groups are added or re-added as needed by\nsystemd-sysusers(8)\nor the package install script.\nAutomatic integrity checks\nInstead of running\npwck\n/\ngrpck\nmanually, the\nsystemd timer\nshadow.timer\n, which is part of, and is enabled by, installation of the\nshadow\npackage, will start\nshadow.service\ndaily.\nshadow.service\nwill run\npwck(8)\nand\ngrpck(8)\nto verify the integrity of both password and group files.\nIf discrepancies are reported, group can be edited with the\nvigr(8)\ncommand and users with\nvipw(8)\n. This provides an extra margin of protection in that these commands lock the databases for editing. Note that the default text editor is vi, but an alternative editor will be used if the\nEDITOR\nenvironment variable\nis set, then that editor will be used instead.\nKeeping users on the live system in parity with systemd sysuser.d defaults\nWarning\nsystemd does not provide any official way to migrate existing accounts to fully locked system accounts\n[1]\n.\nAs packages adopt the\nchange-sysusers-to-fully-locked-system-accounts\n, package created system users generated in the past will not inherit new package defaults for the increased security of locked/expired status. These users need to be modified manually for this change.\nuser-analysis.sh\ndoes just that.\nIn addition, the script also identifies orphaned users (those created by a package no longer on the system) and can automatically delete them.\nGroup management\n/etc/group\nis the file that defines the groups on the system (see\ngroup(5)\nfor details). There is also its companion\ngshadow\nwhich is rarely used. Its details are at\ngshadow(5)\n.\nDisplay group membership with the\ngroups\ncommand:\n$ groups\nuser\nIf\nuser\nis omitted, the current user's group names are displayed.\nThe\nid\ncommand provides additional detail, such as the user's UID and associated GIDs:\n$ id\nuser\nTo list all groups on the system:\n$ cat /etc/group\nCreate new groups with the\ngroupadd\ncommand:\n# groupadd\ngroup\nNote\nIf the user is currently logged in, they must log out and in again for changes to take effect.\nAdd users to a group with the\ngpasswd\ncommand (see\nFS#58262\nregarding errors):\n# gpasswd -a\nuser\ngroup\nAlternatively, add a user to additional groups with\nusermod\n(replace\nadditional_groups\nwith a comma-separated list):\n# usermod -aG\nadditional_groups\nusername\nWarning\nIf the\n-a\noption is omitted in the\nusermod\ncommand above, the user is removed from all groups not listed in\nadditional_groups\n(i.e. the user will be member only of those groups listed in\nadditional_groups\n).\nModify an existing group with the\ngroupmod\ncommand, e.g. to rename the\nold_group\ngroup to\nnew_group\n:\n# groupmod -n\nnew_group\nold_group\nNote\nThis will change a group name but not the numerical GID of the group. Hence, all files previously owned by\nold_group\nwill be owned by\nnew_group\n.\nTo delete existing groups:\n# groupdel\ngroup\nTo remove users from a group:\n# gpasswd -d\nuser\ngroup\nThe\ngrpck\ncommand can be used to verify the integrity of the system's group files.\nWarning\nArch Linux defaults of the files are created as\n.pacnew\nfiles by new releases of the\nfilesystem\npackage. Unless Pacman outputs related messages for action, these\n.pacnew\nfiles can, and should, be disregarded/removed. New required default users and groups are added or re-added as needed by\nsystemd-sysusers(8)\nor the package install script.\nGroup list\nThis section explains the purpose of the essential groups from the\nfilesystem\npackage. There are many other groups, which will be created with\ncorrect GID\nwhen the relevant package is installed. See the main page for the software for details.\nNote\nA later removal of a package does not remove the automatically created user/group (UID/GID) again. This is intentional because any files created during its usage would otherwise be left orphaned as a potential security risk.\nUser groups\nNon-root workstation/desktop users often need to be added to some of following groups to allow access to hardware peripherals and facilitate system administration:\nGroup\nAffected files\nPurpose\nadm\nAdministration group, commonly used to give read access to protected logs. It has full read access to\njournal\nfiles.\nftp\n/srv/ftp/\nAccess to files served by\nFTP servers\n.\ngames\n/var/games\nAccess to some game software.\nhttp\n/srv/http/\nAccess to files served by\nHTTP servers\n.\nlog\nAccess to log files in\n/var/log/\ncreated by\nsyslog-ng\n.\nrfkill\n/dev/rfkill\nRight to control wireless devices power state (used by\nrfkill\n).\nsys\nRight to administer printers in\nCUPS\n.\nsystemd-journal\n/var/log/journal/*\nCan be used to provide read-only access to the systemd logs, as an alternative to\nadm\nand\nwheel\n[2]\n. Otherwise, only user generated messages are displayed.\nuucp\n/dev/ttyS[0-9]+\n,\n/dev/tts/[0-9]+\n,\n/dev/ttyUSB[0-9]+\n,\n/dev/ttyACM[0-9]+\n,\n/dev/rfcomm[0-9]+\nRS-232\nserial ports and devices connected to them.\nwheel\nAdministration group, commonly used to give privileges to perform administrative actions. It has full read access to\njournal\nfiles and the right to administer printers in\nCUPS\n. Can also be used to give access to the\nsudo\nand\nsu\nutilities (neither uses it by default).\nSystem groups\nThe following groups are used for system purposes, an assignment to users is only required for dedicated purposes:\nGroup\nAffected files\nPurpose\ndbus\nused internally by\ndbus\nkmem\n/dev/port\n,\n/dev/mem\n,\n/dev/kmem\nlocate\n/usr/bin/locate\n,\n/var/lib/locate\n,\n/var/lib/mlocate\n,\n/var/lib/slocate\nSee\nLocate\n.\nlp\n/dev/lp[0-9]*\n,\n/dev/parport[0-9]*\nAccess to parallel port devices (printers and others).\nmail\n/usr/bin/mail\nnobody\nUnprivileged group.\nproc\n/proc/\npid\n/\nA group authorized to learn processes information otherwise prohibited by\nhidepid=\nmount option of the\nproc file system\n. The group must be explicitly set with the\ngid=\nmount option.\nroot\n/*\nComplete system administration and control (root, admin).\nsmmsp\nsendmail\ngroup.\ntty\n/dev/tty\n,\n/dev/vcc\n,\n/dev/vc\n,\n/dev/ptmx\nutmp\n/run/utmp\n,\n/var/log/btmp\n,\n/var/log/wtmp\nSee\nWikipedia:utmp#utmp, wtmp and btmp\n.\nPre-systemd groups\nBefore arch migrated to\nsystemd\n, users had to be manually added to these groups in order to be able to access the corresponding devices. This way has been deprecated in favour of\nudev\nmarking the devices with a\nuaccess\ntag\nand\nlogind\nassigning the permissions to users dynamically via\nACLs\naccording to which session is currently active. Note that the session must not be broken for this to work (see\nGeneral troubleshooting#Session permissions\nto check it).\nThere are some notable exceptions which require adding a user to some of these groups: for example if you want to allow users to access the device even when they are not logged in. However, note that adding users to the groups can even cause some functionality to break (for example, the\naudio\ngroup will break fast user switching and allows applications to block software mixing).\nGroup\nAffected files\nPurpose\naudio\n/dev/audio\n,\n/dev/snd/*\n,\n/dev/rtc0\nDirect access to sound hardware, for all sessions. It is still required to make\nALSA\nand\nOSS\nwork in remote sessions, see\nALSA#User privileges\n, otherwise not recommended. Unlike on certain other distros, this group is not used for\nrealtime privileges\n.\ndisk\n/dev/sd[a-zA-Z]*[1-9]*\n,\n/dev/nvme[0-9]*p[1-9]*\n,\n/dev/mmcblk[0-9]*p[1-9]*\nAccess to block devices not affected by other groups such as\noptical\n,\nfloppy\n, and\nstorage\n.\nfloppy\n/dev/fd[0-9]*\nAccess to floppy drives.\ninput\n/dev/input/event[0-9]*\n,\n/dev/input/mouse[0-9]*\nAccess to input devices. Introduced in systemd 215\n[3]\n.\nkvm\n/dev/kvm\nAccess to virtual machines using\nKVM\n.\noptical\n/dev/sr[0-9]\n,\n/dev/sg[0-9]\nAccess to optical devices such as CD and DVD drives.\nscanner\n/var/lock/sane\nAccess to scanner hardware.\nstorage\n/dev/st[0-9]*[lma]*\n,\n/dev/nst[0-9]*[lma]*\nUsed to gain access to removable drives such as USB hard drives, flash/jump drives, MP3 players; enables the user to mount storage devices.\n[4]\nNow solely for direct access to tapes if no custom udev rules is involved.\n[5]\n[6]\n[7]\n.\nAlso required for manipulating some devices via\nudisks/udisksctl\n.\nvideo\n/dev/fb/0\n,\n/dev/misc/agpgart\nAccess to video capture devices, 2D/3D hardware acceleration, framebuffer (\nX\ncan be used\nwithout\nbelonging to this group).\nUnused groups\nThe following groups are currently not used for any purpose:\nGroup\nAffected files\nPurpose\nbin\nnone\nHistorical\ndaemon\nlock\nUsed for lockfile access. Required by e.g.\ngnokii\nAUR\n.\nmem\nnetwork\nUnused by default. Can be used e.g. for granting access to NetworkManager (see\nNetworkManager#Set up PolicyKit permissions\n).\npower\nuuidd\nusers\nThe primary group for users when user private groups are not used (generally not recommended), e.g. when creating users with\nUSERGROUPS_ENAB no\nin\n/etc/login.defs\nor the\n-N\n/\n--no-user-group\noption of\nuseradd\n.\nOther tools related to these databases\nThis article or section is a candidate for merging with\n#Shadow\n.\nNotes:\nSeparate section does not make sense. (Discuss in\nTalk:Users and groups\n)\nThe factual accuracy of this article or section is disputed.\nReason:\nDoes Arch Linux really prefer\nchage\nover\nvipw -s\nand\nvigr -s\n. (Discuss in\nTalk:Users and groups#Utilities to handle the shadow file in acrh\n)\ngetent(1)\ncan be used to read a particular record.\n$ getent group tty\nAs warned in\n#User database\n, using specific utilities such as\npasswd\nand\nchfn\n, is a better way to change the databases. Nevertheless, there are times when editing them directly is looked after. For those times,\nvipw\n,\nvigr\nare provided. It is strongly recommended to use these tailored editors over using a general text editor as they lock the databases against concurrent editing. They also help prevent invalid entries and/or syntax errors. Note that Arch Linux prefers usage of specific tools, such as\nchage\n, for modifying the shadow database over using\nvipw -s\nand\nvigr -s\nfrom\nutil-linux\n. See also\nFS#31414\n.\nlslogins(1)\nand\nlastlog2(1)\nare some of the tools for viewing utmp related files.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Users_and_groups&oldid=845405\n\"\nCategory\n:\nSecurity\nHidden categories:\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nUsers and groups\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Users_and_groups"}}
{"text": "File permissions and attributes - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nFile permissions and attributes\n6 languages\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nUsers and groups\numask\nAccess Control Lists\nCapabilities\nExtended attributes\nFile systems\nuse\npermissions\nand\nattributes\nto regulate the level of interaction that system processes can have with files and directories.\nWarning\nWhen used for security purposes, permissions and attributes only defend against attacks launched from the booted system. To protect the stored data from attackers with physical access to the machine, one must also implement\ndata-at-rest encryption\n.\nViewing permissions\nUse the\nls\ncommand's\n-l\noption to view the permissions (or\nfile mode\n) set for the contents of a directory, for example:\n$ ls -l /path/to/directory\ntotal 128\ndrwxr-xr-x 2 archie archie  4096 Jul  5 21:03 Desktop\ndrwxr-xr-x 6 archie archie  4096 Jul  5 17:37 Documents\ndrwxr-xr-x 2 archie archie  4096 Jul  5 13:45 Downloads\n-rw-rw-r-- 1 archie archie  5120 Jun 27 08:28 customers.ods\n-rw-r--r-- 1 archie archie  3339 Jun 27 08:28 todo\n-rwxr-xr-x 1 archie archie  2048 Jul  6 12:56 myscript.sh\nThe first column is what we must focus on. Taking an example value of\ndrwxrwxrwx+\n, the meaning of each character is explained in the following tables:\nd\nrwx\nrwx\nrwx\n+\nThe file type, technically not part of its permissions. See\ninfo ls -n \"What information is listed\"\nfor an explanation of the possible values.\nThe permissions that the owner has over the file, explained below.\nThe permissions that the group has over the file, explained below.\nThe permissions that all the other users have over the file, explained below.\nA single character that specifies whether an alternate access method applies to the file. When this character is a space, there is no alternate access method. A\n.\ncharacter indicates a file with a security context, but no other alternate access method. A file with any other combination of alternate access methods is marked with a\n+\ncharacter, for example in the case of\nAccess Control Lists\n.\nEach of the three permission triads (\nrwx\nin the example above) can be made up of the following characters:\nCharacter\nEffect on files\nEffect on directories\nRead permission (first character)\n-\nThe file cannot be read.\nThe directory's contents cannot be shown.\nr\nThe file can be read.\nThe directory's contents can be shown.\nWrite permission (second character)\n-\nThe file cannot be modified.\nThe directory's contents cannot be modified.\nw\nThe file can be modified.\nThe directory's contents can be modified (create new files or directories; rename or delete existing files or directories); requires the execute permission to be also set, otherwise this permission has no effect.\nExecute permission (third character)\n-\nThe file cannot be executed.\nThe directory cannot be accessed with\ncd\n.\nx\nThe file can be executed.\nThe directory can be accessed with\ncd\n; this is the only permission bit that in practice can be considered to be \"inherited\" from the ancestor directories, in fact if\nany\ndirectory in the path does not have the\nx\nbit set, the final file or directory cannot be accessed either, regardless of its permissions; see\npath_resolution(7)\nfor more information.\ns\nThe\nsetuid\nbit when found in the\nu\nser triad; the\nsetgid\nbit when found in the\ng\nroup triad; it is not found in the\no\nthers triad; it also implies that\nx\nis set.\nS\nSame as\ns\n, but\nx\nis not set; rare on regular files, and useless on directories.\nt\nThe\nsticky\nbit; it can only be found in the\no\nthers triad; it also implies that\nx\nis set.\nT\nSame as\nt\n, but\nx\nis not set; rare on regular files.\nSee\ninfo Coreutils -n \"Mode Structure\"\nand\nchmod(1)\nfor more details.\nTip\nYou can view permissions along a path with\nnamei -l\npath\n.\nExamples\nLet us see some examples to clarify:\ndrwx------\n6 archie archie  4096 Jul  5 17:37 Documents\nArchie has full access to the\nDocuments\ndirectory. They can list, create files and rename, delete any file in Documents, regardless of file permissions. Their ability to access a file depends on the file's permissions.\ndr-x------\n6 archie archie  4096 Jul  5 17:37 Documents\nArchie has full access except they can not create, rename, delete any file. They can list the files and (if the file's permissions allow it) may access an existing file in Documents.\nd-wx------\n6 archie archie  4096 Jul  5 17:37 Documents\nArchie can not do\nls\nin the\nDocuments\ndirectory but if they know the name of an existing file then they may list, rename, delete or (if the file's permissions allow it) access it. Also, they are able to create new files.\nd--x------\n6 archie archie  4096 Jul  5 17:37 Documents\nArchie is only capable of (if the file's permissions allow it) accessing those files the\nDocuments\ndirectory which they know of. They can not list already existing files or create, rename, delete any of them.\nYou should keep in mind that we elaborate on directory permissions and it has nothing to do with the individual file permissions. When you create a new file it is the directory that changes. That is why you need write permission to the directory.\nLet us look at another example, this time of a file, not a directory:\n-rw-r--r--\n1 archie web  5120 Jun 27 08:28 foobar\nHere we can see the first letter is not\nd\nbut\n-\n. So we know it is a file, not a directory. Next the owner's permissions are\nrw-\nso the owner has the ability to read and write but not execute. This may seem odd that the owner does not have all three permissions, but the\nx\npermission is not needed as it is a text/data file, to be read by a text editor such as Gedit, EMACS, or software like R, and not an executable in its own right (if it contained something like python programming code then it very well could be). The group's permissions are set to\nr--\n, so the group has the ability to read the file but not write/edit it in any way — it is essentially like setting something to read-only. We can see that the same permissions apply to everyone else as well.\nChanging permissions\nchmod\nis a command in Linux and other Unix-like operating systems that allows to\nch\nange the permissions (or access\nmod\ne) of a file or directory.\nText method\nTo change the permissions — or\naccess mode\n— of a file, use the\nchmod\ncommand in a terminal. Below is the command's general structure:\nchmod\nwho\n=\npermissions\nfilename\nWhere\nwho\nis any from a range of letters, each signifying who is being given the permission. They are as follows:\nu\n: the\nuser\nthat owns the file.\ng\n: the\nuser group\nthat the file belongs to.\no\n: the\no\nther users, i.e. everyone else.\na\n:\na\nll of the above; use this instead of typing\nugo\n.\nThe permissions are the same as discussed in\n#Viewing permissions\n(\nr\n,\nw\nand\nx\n).\nNow have a look at some examples using this command. Suppose you became very protective of the Documents directory and wanted to deny everybody but yourself, permissions to read, write, and execute (or in this case search/look) in it:\nBefore:\ndrwxr-xr-x 6 archie web  4096 Jul  5 17:37 Documents\n$ chmod g= Documents\n$ chmod o= Documents\nAfter:\ndrwx------ 6 archie web  4096 Jul  6 17:32 Documents\nHere, because you want to deny permissions, you do not put any letters after the\n=\nwhere permissions would be entered. Now you can see that only the owner's permissions are\nrwx\nand all other permissions are\n-\n.\nThis can be reverted with:\nBefore:\ndrwx------ 6 archie web  4096 Jul  6 17:32 Documents\n$ chmod g=rx Documents\n$ chmod o=rx Documents\nAfter:\ndrwxr-xr-x 6 archie web  4096 Jul  6 17:32 Documents\nIn the next example, you want to grant read and execute permissions to the group, and other users, so you put the letters for the permissions (\nr\nand\nx\n) after the\n=\n, with no spaces.\nYou can simplify this to put more than one\nwho\nletter in the same command, e.g:\n$ chmod go=rx Documents\nNote\nIt does not matter in which order you put the\nwho\nletters or the permission letters in a\nchmod\ncommand: you could have\nchmod go=rx file\nor\nchmod og=xr file\n. It is all the same.\nNow let us consider a second example, suppose you want to change a\nfoobar\nfile so that you have read and write permissions, and fellow users in the group\nweb\nwho may be colleagues working on\nfoobar\n, can also read and write to it, but other users can only read it:\nBefore:\n-rw-r--r-- 1 archie web  5120 Jun 27 08:28 foobar\n$ chmod g=rw foobar\nAfter:\n-rw-rw-r-- 1 archie web  5120 Jun 27 08:28 foobar\nThis is exactly like the first example, but with a file, not a directory, and you grant write permission (just so as to give an example of granting every permission).\nText method shortcuts\nThe\nchmod\ncommand lets add and subtract permissions from an existing set using\n+\nor\n-\ninstead of\n=\n. This is different from the above commands, which essentially re-write the permissions (e.g. to change a permission from\nr--\nto\nrw-\n, you still need to include\nr\nas well as\nw\nafter the\n=\nin the\nchmod\ncommand invocation. If you missed out\nr\n, it would take away the\nr\npermission as they are being re-written with the\n=\n. Using\n+\nand\n-\navoids this by adding or taking away from the\ncurrent\nset of permissions).\nLet us try this\n+\nand\n-\nmethod with the previous example of adding write permissions to the group:\nBefore:\n-rw-r--r-- 1 archie web 5120 Jun 27 08:28 foobar\n$ chmod g+w foobar\nAfter:\n-rw-rw-r-- 1 archie web  5120 Jun 27 08:28 foobar\nAnother example, denying write permissions to all (\na\n):\nBefore:\n-rw-rw-r-- 1 archie web  5120 Jun 27 08:28 foobar\n$ chmod a-w foobar\nAfter:\n-r--r--r-- 1 archie web  5120 Jun 27 08:28 foobar\nA different shortcut is the special\nX\nmode: this is not an actual file mode, but it is often used in conjunction with the\n-R\noption to set the executable bit only for directories, and leave it unchanged for regular files, for example:\n$ chmod -R a+rX ./data/\nCopying permissions\nIt is possible to tell\nchmod\nto copy the permissions from one class, say the owner, and give those same permissions to group or even all. To do this, instead of putting\nr\n,\nw\n, or\nx\nafter the\n=\n, put another\nwho\nletter. e.g:\nBefore:\n-rw-r--r-- 1 archie web 5120 Jun 27 08:28 foobar\n$ chmod g=u foobar\nAfter:\n-rw-rw-r-- 1 archie web 5120 Jun 27 08:28 foobar\nThis command essentially translates to \"change the permissions of group (\ng=\n), to be the same as the owning user (\n=u\n). Note that you cannot copy a set of permissions as well as grant new ones e.g.:\n$ chmod g=wu foobar\nIn that case\nchmod\nthrow an error.\nNumeric method\nchmod\ncan also set permissions using numbers.\nUsing numbers is another method which allows you to edit the permissions for all three owner, group, and others at the same time, as well as the setuid, setgid, and sticky bits. This basic structure of the code is this:\n$ chmod\nxxx\nfilename\nWhere\nxxx\nis a 3-digit number where each digit can be anything from 0 to 7. The first digit applies to permissions for owner, the second digit applies to permissions for group, and the third digit applies to permissions for all others.\nIn this number notation, the values\nr\n,\nw\n, and\nx\nhave their own number value:\nr=4\nw=2\nx=1\nTo come up with a 3-digit number you need to consider what permissions you want owner, group, and all others to have, and then total their values up. For example, if you want to grant the owner of a directory read write and execution permissions, and you want group and everyone else to have just read and execute permissions, you would come up with the numerical values like so:\nOwner:\nrwx\n=4+2+1=7\nGroup:\nr-x\n=4+0+1=5\nOther:\nr-x\n=4+0+1=5\n$ chmod 755\nfilename\nThis is the equivalent of using the following:\n$ chmod u=rwx\nfilename\n$ chmod go=rx\nfilename\nTo view the existing permissions of a file or directory in numeric form, use the\nstat(1)\ncommand:\n$ stat -c %a\nfilename\nWhere the %a option specifies output in numeric form.\nMost directories are set to\n755\nto allow reading, writing and execution to the owner, but deny writing to everyone else, and files are normally\n644\nto allow reading and writing for the owner but just reading for everyone else; refer to the last note on the lack of\nx\npermissions with non executable files: it is the same thing here.\nTo see this in action with examples consider the previous example that has been used but with this numerical method applied instead:\nBefore:\n-rw-r--r-- 1 archie web  5120 Jun 27 08:28 foobar\n$ chmod 664 foobar\nAfter:\n-rw-rw-r-- 1 archie web  5120 Jun 27 08:28 foobar\nIf this were an executable the number would be\n774\nif you wanted to grant executable permission to the owner and group. Alternatively if you wanted everyone to only have read permission the number would be\n444\n. Treating\nr\nas 4,\nw\nas 2, and\nx\nas 1 is probably the easiest way to work out the numerical values for using\nchmod\nxxx\nfilename\n, but there is also a binary method, where each permission has a binary number, and then that is in turn converted to a number. It is a bit more convoluted, but here included for completeness.\nConsider this permission set:\n-rwxr-xr--\nIf you put a 1 under each permission granted, and a 0 for every one not granted, the result would be something like this:\n-rwxrwxr-x\n111111101\nYou can then convert these binary numbers:\n000=0\t    100=4\n001=1\t    101=5\n010=2\t    110=6\n011=3\t    111=7\nThe value of the above would therefore be 775.\nConsider we wanted to remove the writable permission from group:\n-rwxr-xr-x\n111101101\nThe value would therefore be 755 and you would use\nchmod 755\nfilename\nto remove the writable permission. You will notice you get the same three digit number no matter which method you use. Whether you use text or numbers will depend on personal preference and typing speed. When you want to restore a directory or file to default permissions e.g. read and write (and execute) permission to the owner but deny write permission to everyone else, it may be faster to use\nchmod 755/644\nfilename\n. However if you are changing the permissions to something out of the norm, it may be simpler and quicker to use the text method as opposed to trying to convert it to numbers, which may lead to a mistake. It could be argued that there is not any real significant difference in the speed of either method for a user that only needs to use\nchmod\non occasion.\nYou can also use the numeric method to set the\nsetuid\n,\nsetgid\n, and\nsticky\nbits by using four digits.\nsetuid=4\nsetgid=2\nsticky=1\nFor example,\nchmod 2777\nfilename\nwill set read/write/executable bits for everyone and also enable the\nsetgid\nbit.\nBulk chmod\nGenerally directories and files should not have the same permissions. If it is necessary to bulk modify a directory tree, use\nfind\nto selectively modify one or the other.\nTo\nchmod\nonly directories to 755:\n$ find\ndirectory\n-type d -exec chmod 755 {} +\nTo\nchmod\nonly files to 644:\n$ find\ndirectory\n-type f -exec chmod 644 {} +\nChanging ownership\nchown\nchanges the owner of a file or directory, which is quicker and easier than altering the permissions in some cases.\nConsider the following example, making a new partition with\nGParted\nfor backup data. Gparted does this all as root so everything belongs to root by default. This is all well and good but when it comes to writing data to the mounted partition, permission is denied for regular users.\nbrw-rw---- 1 root disk 8,    9 Jul  6 16:02 sda9\ndrwxr-xr-x 5 root root    4096 Jul  6 16:01 Backup\nAs you can see the device in\n/dev\nis owned by root, as is the mount location (\n/media/Backup\n). To change the owner of the mount location one can do the following:\nBefore:\ndrwxr-xr-x 5 root  root 4096 Jul  6 16:01 Backup\n# chown archie /media/Backup\nAfter:\ndrwxr-xr-x 5 archie  root 4096 Jul  6 16:01 Backup\nNow the partition can have data written to it by the new owner, archie, without altering the permissions (as the owner triad already had\nrwx\npermissions).\nNote\nchown\nalways clears the setuid and setgid bits.\nNon-root users cannot use\nchown\nto \"give away\" files they own to another user.\nAccess Control Lists\nAccess Control Lists\nprovides an additional, more flexible permission mechanism for file systems by allowing to set permissions for any user or group to any file.\nUmask\nThe\numask\nutility is used to control the file-creation mode mask, which determines the initial value of file permission bits for newly created files.\nFile attributes\nApart from the file mode bits that control\nuser and group\nread, write and execute permissions, several\nfile systems\nsupport file attributes that enable further customization of allowable file operations.\nWarning\nBy default, file attributes are not preserved by\ncp\n,\nrsync\n, and other similar programs.\nThe\ne2fsprogs\npackage contains the programs\nlsattr(1)\nand\nchattr(1)\nthat list and change a file's attributes, respectively.\nThese are a few useful attributes. Not all filesystems support every attribute.\na\n- append only: File can only be opened for appending.\nc\n- compressed: Enable filesystem-level compression for the file.\ni\n- immutable: Cannot be modified, deleted, renamed, linked to. Can only be set by root.\nj\n- data journaling: Use the\njournal\nfor file data writes as well as metadata.\nm\n- no compression: Disable filesystem-level compression for the file.\nA\n- no atime update: The file's atime will not be modified.\nC\n- no copy on write: Disable copy-on-write, for filesystems that support it.\nSee\nchattr(1)\nfor a complete list of attributes and for more info on what each attribute does.\nFor example, if you want to set the immutable bit on some file, use the following command:\n# chattr +i\n/path/to/file\nTo remove an attribute on a file just change\n+\nto\n-\n.\nExtended attributes\nSee\nExtended attributes\n.\nTips and tricks\nPreserve root\nUse the\n--preserve-root\nflag to prevent\nchmod\nfrom acting recursively on\n/\n. This can, for example, prevent one from removing the executable bit systemwide and thus breaking the system. To use this flag every time, set it within an\nalias\n. See also\n[1]\n.\nSee also\nwikipedia:Chattr\nLinux File Permission Confusion\nLinux File Permission Confusion part 2\nBackup and restore file permissions in Linux\nWhy is \"chmod -R 777 /\" destructive?\nThe How and Why of User Private Groups in Unix\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=File_permissions_and_attributes&oldid=851282\n\"\nCategories\n:\nFile systems\nCommand-line\nSearch\nSearch\nFile permissions and attributes\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/File_permissions_and_attributes"}}
{"text": "Environment variables - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nEnvironment variables\n7 languages\nDeutsch\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nDefault applications\nsystemd/User#Environment variables\nAn environment variable is a named object that contains data used by one or more applications. In simple terms, it is a variable with a name and a value. The value of an environmental variable can for example be the location of all executable files in the file system, the default editor that should be used, or the system locale settings. Users new to Linux may often find this way of managing settings a bit unmanageable. However, environment variables provide a simple way to share configuration settings between multiple applications and processes in Linux.\nUtilities\nThe\ncoreutils\npackage contains the programs\nprintenv\nand\nenv\n. To list the current environmental variables with values:\n$ printenv\nNote\nSome environment variables are user-specific. Check by comparing the outputs of\nprintenv\nas an unprivileged user and as\nroot\n.\nThe\nenv\nutility can be used to run a command under a modified environment. The following example will launch\nxterm\nwith the environment variable\nEDITOR\nset to\nvim\n. This will not affect the global environment variable\nEDITOR\n.\n$ env EDITOR=vim xterm\nThe\nshell\nbuiltin\nset(1p)\nallows you to change the values of shell options, set the positional parameters and to display the names and values of shell variables.\nEach process stores their environment in the\n/proc/$PID/environ\nfile. This file contains each key value pair delimited by a nul character (\n\\x0\n). A more human readable format can be obtained with\nsed\n, e.g.\nsed 's:\\x0:\\n:g' /proc/$PID/environ\n.\nDefining variables\nTo avoid needlessly polluting the environment, you should seek to restrict the scope of variables. In fact, graphical sessions and systemd services require you to set variables in certain locations for them to take effect. The scopes of environment variables are broken down into the contexts they affect:\nGlobal\n: All programs that any user runs, not including systemd services.\nBy user\n: All programs that a particular user runs, not including user systemd services (see\nsystemd/User#Environment variables\n) or graphical applications (see\n#Graphical environment\n).\nGlobally\nUsing shell initialization files\nMost Linux distributions tell you to change or add environment variable definitions in\n/etc/profile\nor other locations. Keep in mind that there are also package-specific configuration files containing variable settings such as\n/etc/locale.conf\n. Be sure to maintain and manage the environment variables and pay attention to the numerous files that can contain environment variables. In principle, any shell script can be used for initializing environmental variables, but following traditional UNIX conventions, these statements should only be present in some particular files.\nThe following files can be used for defining global environment variables on your system, each with different limitations:\n/etc/environment\nis used by the\npam_env module\nand is shell agnostic so scripting or glob expansion cannot be used. The file only accepts\nvariable=value\npairs.\n/etc/profile\ninitializes variables for login shells\nonly\n. It does, however, run scripts (e.g. those in\n/etc/profile.d/\n) and can be used by all\nBourne shell\ncompatible shells.\nShell specific configuration files - Global configuration files of your\nshell\n, initializes variables and runs scripts. For example\nBash#Configuration files\n(e.g.\n~/.bashrc\n) or\nZsh#Startup/Shutdown files\n(e.g.\n~/.zshrc\n).\nThe following Bash helper function can be used to append a number of directories to the\nPATH\nenvironment variable. Add the function at the top of the file where you define your environment (e.g.\n~/.bashrc\n). The function will only add directories that actually exist on the filesystem, and it will avoid creating duplicate entries.\nadd_paths() {\nfor d in \"$@\"; do\n[[ -d \"$d\" && ! \"$PATH\" =~ (^|:)$d(:|$) ]] && PATH=\"$PATH:$d\"\ndone\n}\nadd_paths ~/bin ~/scripts\nMost shells (including Bash, Zsh, and\nfish\n) allow adding variables to the environment using the\nexport\ncommand. This allows defining environment variables in a common file such as\n~/my-environment.sh\n:\n~/my-environment.sh\nexport EDITOR=vim\nexport XDG_CACHE_HOME=\"$HOME/.cache\"\nexport XDG_CONFIG_HOME=\"$HOME/.config\"\nexport XDG_DATA_HOME=\"$HOME/.local/share\"\nexport XDG_STATE_HOME=\"$HOME/.local/state\"\nThis file can then be sourced from shell startup files:\n~/.bashrc\nsource ~/my-environment.sh\n~/.config/fish/config.fish\nsource ~/my-environment.sh\nUsing pam_env\nThe\nPAM\nmodule\npam_env(8)\nloads the variables to be set in the environment from the following files in order:\n/etc/security/pam_env.conf\nand\n/etc/environment\n.\nNote\nThese files are read before other files, in particular before\n~/.profile\n,\n~/.bash_profile\nand\n~/.zshenv\n.\nThe deprecated\n~/.pam_environment\nis not read anymore. See\nFS#68945\n.\n/etc/environment\nmust consist of simple\nVARIABLE\n=\nvalue\npairs on separate lines, for example:\n/etc/environment\nEDITOR=nano\n/etc/security/pam_env.conf\nhas the following format:\n/etc/security/pam_env.conf\nVARIABLE [DEFAULT=\nvalue\n] [OVERRIDE=\nvalue\n]\n@{HOME}\nand\n@{SHELL}\nare special variables that expand to what is defined in\n/etc/passwd\n. The following example illustrates how to expand the\nHOME\nenvironment variable into another variable:\n/etc/security/pam_env.conf\nXDG_CONFIG_HOME   DEFAULT=@{HOME}/.config\nNote\nThe variables\n${HOME}\nand\n${SHELL}\nare not linked to the\nHOME\nand\nSHELL\nenvironment variables, they are not set by default.\nThe format also allows to expand already defined variables in the values of other variables using\n${\nVARIABLE\n}\n, like this:\n/etc/security/pam_env.conf\nGOPATH DEFAULT=${XDG_DATA_HOME}/go\nVARIABLE\n=\nvalue\npairs are also allowed, but variable expansion is not supported in those pairs. See\npam_env.conf(5)\nfor more information.\nPer user\nYou do not always want to define an environment variable globally. For instance, you might want to add\n/home/my_user/bin\nto the\nPATH\nvariable but do not want all other users on your system to have that in their\nPATH\ntoo. Local environment variables can be defined in many different files:\nUser configuration files of your\nshell\n, for example\nBash#Configuration files\nor\nZsh#Startup/Shutdown files\n.\nUnless you are restricting the scope of the variables to terminals you open (e.g. command-line applications only), you are looking to modify the login shell.\nsystemd user environment variables\nare read from\n~/.config/environment.d/*.conf\n.\nTo add a directory to the\nPATH\nfor local usage, put following in\n~/.bash_profile\n:\nexport PATH=\"${PATH}:/home/my_user/bin\"\nTo update the variable, re-login or\nsource\nthe file:\n$ source ~/.bash_profile\n.\nNote\nThe dbus daemon and the user instance of systemd do not inherit any of the environment variables set in places like\n~/.bashrc\netc. This means that, for example, dbus activated programs like\nGNOME Files\nwill not use them by default. See\nsystemd/User#Environment variables\n.\nTip\nYou can issue\nexport -p\nto review the global and local environment variables declared for the user session.\nGraphical environment\nIf an environment variable only affects graphical applications, you may want to restrict the scope of it by only setting it within the graphical session. In order of decreasing scope:\n#Per Xorg session\nand\n#Per Wayland session\naffect the whole graphical session, certainly including the DE.\n#Per desktop environment session\naffects the applications spawned within graphical session, potentially including the DE itself.\n#Per application\naffects just a particular graphical application.\nPer desktop environment session\nSome graphical environments, (e.g.\nKDE Plasma\n) support executing shell scripts at login: they can be used to set environment variables. See\nKDE#Autostart\nfor example.\nPer Xorg session\nThe procedure for modifying the environment of the Xorg session depends on how it is started:\nMost\ndisplay managers\nsource\nxprofile\n.\nstartx\nand\nSLiM\nexecute\nxinitrc\n.\nXDM\nexecutes\n~/.xsession\n; see\nXDM#Defining the session\n.\nLightDM\n[1]\nand\nSDDM\n[2]\nadditionally source startup scripts for login shells, like\n~/.bash_profile\nfor\nbash\nor\n~/.zprofile\nand\n~/.zlogin\nfor\nzsh\n.\nThough the end of the script depends on which file it is, and any advanced syntax depends on the shell used, the basic usage is universal:\n~/.xprofile, ~/.xinitrc, or ~/.xsession\n...\nexport\nGUI_VAR\n=\nvalue\n...\nPer Wayland session\nSince\nWayland\ndoes not initiate any Xorg related files,\nGDM\nand\nKDE Plasma\nsource\nsystemd user environment variables\ninstead.\n~/.config/environment.d/envvars.conf\nGUI_VAR\n=\nvalue\nNo other display managers supporting Wayland sessions (e.g.\nSDDM\n) provide direct support for this yet. However,\nLightDM\nand\nSDDM\nsource startup scripts for login shells on Wayland sessions too.\ngreetd\nalso sources\n/etc/profile\nand\n~/.profile\n- this behavior is controlled by its\nsource_profile\nsetting, enabled by default.\nIf your display manager sources startup scripts like\n~/.bash_profile\nand you want to use\nenvironment.d\n, you can source it like so:\n~/.bash_profile\n# use systemd-environment-d-generator(8) to generate environment, and export those variables\nset -o allexport\nsource <(/usr/lib/systemd/user-environment-generators/30-systemd-environment-d-generator)\nset +o allexport\nNote\nOther generators in\n/usr/lib/systemd/user-environment-generators\nlike\n60-flatpak\nmay not quote the values of environment variables. In this case the output should be sourced with\nexport -- \"$(/usr/lib/systemd/user-environment-generators/60-flatpak)\"\nPer application\nTo set environment variables only for a specific application instead of the whole session, edit the application's\n.desktop\nfile. See\nDesktop entries#Modify environment variables\nfor instructions.\nFor\nSteam\ngames, you can configure a program's environment by editing its launch options; see\nSteam#Launch options\n.\nPer session or shell\nSometimes only temporary variables are required. One might wish to temporarily run executables from a specific directory without typing the absolute\nPATH\neach time, or use the\nPATH\nin a short temporary shell script.\nFor example, to add a session-specific directory to\nPATH\n, use:\n$ export PATH=\"${PATH}:/home/my_user/tmp/usr/bin\"\nTo add only a shell-specific directory to\nPATH\n, use:\n$ PATH=\"${PATH}:/home/my_user/tmp/usr/bin\"\nIn Bash, PATH is already exported by default, so both of the above will remain visible to subprocesses unless overwritten. To better illustrate the difference between exported and non-exported variables, consider the following:\n$ MYVAR=\"shell-only\"\n$ bash -c 'echo $MYVAR'  # prints nothing\n$ export MYVAR=\"session-wide\"\n$ bash -c 'echo $MYVAR'  # prints: session-wide\nExamples\nThe following section lists a number of common environment variables used by a Linux system and describes their values.\nXDG_CURRENT_DESKTOP\nis a\nfreedesktop.org\nvariable containing a colon separated list of strings that the current\ndesktop environment\nidentifies as\n[3]\n. Standardized values for actively developed environments are\nGNOME\n,\nGNOME-Flashback\n,\nKDE\n,\nLXDE\n,\nLXQt\n,\nMATE\n,\nTDE\n,\nUnity\n,\nXFCE\n,\nEDE\n,\nCinnamon\n,\nPantheon\n, and\nDDE\n[4]\n.\nCinnamon was registered\nlater\nthan the rest of the desktop environments. As a result, some software may still be expecting its pre-registration value\nX-CINNAMON\n, such as\nQt\n[5]\n.\nHyprland\nis informally recognized for\nHyprland\n.\nXDG_SESSION_DESKTOP\nis similar to\nXDG_CURRENT_DESKTOP\n, but only permits a single string. Despite its name,\nit is not standardized by freedesktop.org\n.\nDE\nis a legacy variable indicating the\nd\nesktop\ne\nnvironment being used. There is no central documentation for what possible values are, but\nxdg-utils\nprovides a reference for many desktop environments.\nDESKTOP_SESSION\nis another legacy variable, similar to\nDE\nbut less common. It may be a path to the session's\ndesktop entry\n, in\n/usr/share/xsessions/\n[6]\n.\nWINDOW_MANAGER\nis a variable sometimes used to\nchoose\nthe\nwindow manager\nto be used in a desktop environment, as opposed to the other variables here which are set by the already chosen display manager or desktop environment, for other programs to read.\nPATH\ncontains a colon-separated list of directories in which your system looks for executable files. When a regular command (e.g.\nls\n,\nsystemctl\nor\npacman\n) is interpreted by the shell (e.g.\nbash\nor\nzsh\n), the shell looks for an executable file with the same name as your command in the listed directories, and executes it. To run executables that are not listed in\nPATH\n, a relative or absolute path to the executable must be given, e.g.\n./a.out\nor\n/bin/ls\n.\nNote\nIt is advised not to include the current working directory (\n.\n) into your\nPATH\nfor security reasons, as it may trick the user to execute malicious commands.\nHOME\ncontains the path to the home directory of the current user. This variable can be used by applications to associate configuration files and such like with the user running it.\nPWD\ncontains the\npath to the working directory\n.\nOLDPWD\ncontains the path to the previous working directory, that is, the value of\nPWD\nbefore last\ncd\nwas executed.\nTERM\ncontains the type of the running\nterm\ninal, e.g.\nxterm-256color\n. It is used by programs running in the terminal that wish to use terminal-specific capabilities.\nMAIL\ncontains the location of incoming email. The traditional setting is\n/var/spool/mail/$LOGNAME\n.\nftp_proxy\nand\nhttp_proxy\ncontains FTP and HTTP proxy server, respectively:\nftp_proxy=\"ftp://192.168.0.1:21\"\nhttp_proxy=\"http://192.168.0.1:80\"\nMANPATH\ncontains a colon-separated list of directories in which\nman\nsearches for the man pages.\nNote\nIn\n/etc/profile\n, there is a comment that states \"Man is much better than us at figuring this out\", so this variable should generally be left unset. See\nmanpath(5)\n.\nINFODIR\ncontains a colon-separated list of directories in which the\ninfo\ncommand searches for the info pages, e.g.,\n/usr/share/info:/usr/local/share/info\nTZ\ncan be used to to set a time zone different to the system zone for a user. The zones listed in\n/usr/share/zoneinfo/\ncan be used as reference, for example\nTZ=\":/usr/share/zoneinfo/Pacific/Fiji\"\n. When pointing the\nTZ\nvariable to a zoneinfo file, it should start with a colon per\nthe GNU manual\n.\nDefault programs\nSHELL\ncontains the path to the user's\npreferred shell\n. Note that this is not necessarily the shell that is currently running. In the event that it has no value,\nBash\nwill automatically set this variable to the user's login shell as defined in\n/etc/passwd\nor to\n/bin/sh\nif this cannot be determined.\nPAGER\ncontains command to run the program used to list the contents of files, e.g.,\n/bin/less\n.\nEDITOR\ncontains the command to run the lightweight program used for editing files, e.g.,\n/usr/bin/nano\n. For example, you can write an interactive switch between\ngedit\nunder\nX\nor\nnano\n, in this example:\n[ -n \"$DISPLAY\" ] && export EDITOR=gedit || export EDITOR=nano\nVISUAL\ncontains command to run the full-fledged editor that is used for more demanding tasks, such as editing mail (e.g.,\nvi\n,\nvim\n,\nemacs\netc).\nBROWSER\ncontains the path to the web browser. Helpful to set in an interactive shell configuration file so that it may be dynamically altered depending on the availability of a graphic environment, such as\nX\n:\n[ -n \"$DISPLAY\" ] && export BROWSER=firefox || export BROWSER=links\nTip\nThese default programs can also be set conditionally if a\nWayland compositor\nis running by using the\nWAYLAND_DISPLAY\nenvironment variable.\nSee also\nGentoo:Handbook:X86/Working/EnvVar\nUbuntu Community Wiki - Environment Variables\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Environment_variables&oldid=845824\n\"\nCategory\n:\nSystem administration\nSearch\nSearch\nEnvironment variables\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Environment_variables"}}
{"text": "Locale - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nLocale\n8 languages\nDeutsch\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nTürkçe\nFrom ArchWiki\nRelated articles\nEnvironment variables\nLocalization\nLocales\nare used by\nglibc\nand other locale-aware programs or libraries for rendering text, correctly displaying regional monetary values, time and date formats, alphabetic idiosyncrasies, and other locale-specific standards.\nGenerating locales\nLocale names are typically of the form\nlanguage[_territory][.codeset][@modifier]\n, where\nlanguage\nis an\nISO 639 language code\n,\nterritory\nis an\nISO 3166 country code\n, and\ncodeset\nis a\ncharacter set\nor encoding identifier like\nISO-8859-1\nor\nUTF-8\n. See\nsetlocale(3)\n.\nFor a list of enabled locales, run:\n$ locale --all-locales\nBefore a locale can be enabled on the system, it must be generated. This can be achieved by uncommenting applicable entries in\n/etc/locale.gen\n, and running\nlocale-gen\n. Equivalently, commenting entries disables their respective locales. While making changes, consider any localisations required by other users on the system, as well as specific\n#Variables\n.\nFor example for German, uncomment\nde_DE.UTF-8 UTF-8\n(in addition to\nen_US.UTF-8 UTF-8\nwhich is commonly used as a fallback for various tools):\n/etc/locale.gen\n...\n#de_CH ISO-8859-1\nde_DE.UTF-8 UTF-8\n#de_DE ISO-8859-1\n...\n#en_SG ISO-8859-1\nen_US.UTF-8 UTF-8\n#en_US ISO-8859-1\n...\nSave the file, and generate the locale:\n# locale-gen\nNote\nlocale-gen\nalso runs with every update of\nglibc\n.\n[1]\nUTF-8\nis recommended over other character sets.\n[2]\nSetting the locale\nTo display the currently set locale and its related environmental settings, type:\n$ locale\nThe locale to be used, chosen among the previously generated ones, is set in\nlocale.conf\nfiles. Each of these files must contain a new-line separated list of\nenvironment variable\nassignments, having the same format as output by\nlocale\n.\nTo list available locales which have been previously generated, run:\n$ localedef --list-archive\nAlternatively, using\nlocalectl(1)\n:\n$ localectl list-locales\nSetting the system locale\nTo set the system locale, write the\nLANG\nvariable to\n/etc/locale.conf\n, where\nen_US.UTF-8\nbelongs to the\nfirst column\nof an uncommented entry in\n/etc/locale.gen\n:\n/etc/locale.conf\nLANG=\nen_US.UTF-8\nAlternatively, run:\n# localectl set-locale LANG=\nen_US.UTF-8\nSee\n#Variables\nand\nlocale.conf(5)\nfor details.\nOverriding system locale per user session\nThe system-wide locale can be overridden in each user session by creating or editing\n$XDG_CONFIG_HOME/locale.conf\n(usually\n~/.config/locale.conf\n).\nThe precedence of these\nlocale.conf\nfiles is defined in\n/etc/profile.d/locale.sh\n.\nTip\nThis can also allow keeping the logs in\n/var/log/\nin English while using the local language in the user environment.\nYou can create a\n/etc/skel/.config/locale.conf\nfile so that any new users added using\nuseradd\nand the\n-m\noption will have\n~/.config/locale.conf\nautomatically generated. See\nUsers and groups#Changing user defaults\n.\nMake locale changes immediate\nOnce system and user\nlocale.conf\nfiles have been created or edited, their new values will take effect for new sessions at login. To have the current environment use the new settings unset\nLANG\nand source\n/etc/profile.d/locale.sh\n:\n$ unset LANG\n$ source /etc/profile.d/locale.sh\nNote\nThe\nLANG\nvariable has to be unset first, otherwise\nlocale.sh\nwill not update the values from\nlocale.conf\n. Only new and changed variables will be updated; variables removed from\nlocale.conf\nwill still be set in the session.\nOther uses\nLocale variables can also be defined with the standard methods as explained in\nEnvironment variables\n.\nFor example, in order to test or debug a particular application during development, it could be launched with something like:\n$ LC_ALL=C.UTF-8 ./my_application.sh\nSimilarly, to set the locale for all processes run from the current shell (for example, during system installation):\n$ export LC_ALL=C.UTF-8\nVariables\nlocale.conf\nfiles support the following environment variables.\nLANG\nLANGUAGE\nLC_ADDRESS\nLC_COLLATE\nLC_CTYPE\nLC_IDENTIFICATION\nLC_MEASUREMENT\nLC_MESSAGES\nLC_MONETARY\nLC_NAME\nLC_NUMERIC\nLC_PAPER\nLC_TELEPHONE\nLC_TIME\nFull meaning of the above\nLC_*\nvariables can be found on manpage\nlocale(7)\n, whereas details of their definition are described on\nlocale(5)\n.\nNote\nPrograms follow the\npriority order\nwhen looking up locale dependent values.\nLANG: default locale\nThe locale set for this variable will be used for all the\nLC_*\nvariables that are not explicitly set.\nTip\nAssume that you are an English user in Spain, and you want your programs to handle numbers and dates according to Spanish conventions, and only the messages should be in English. Then you could set the\nLANG\nvariable to\nes_ES.UTF-8\nand the\nLC_MESSAGES\n(user interface for message translation) variable to\nen_US.UTF-8\n.\nLANGUAGE: fallback locales\nPrograms which use\ngettext\nfor translations respect the\nLANGUAGE\noption in addition to the usual variables. This allows users to specify a\nlist\nof locales that will be used in that order. If a translation for the preferred locale is unavailable, another from a similar locale will be used instead of the default. For example, an Australian user might want to fall back to British rather than US spelling:\nlocale.conf\nLANG=en_AU.UTF-8\nLANGUAGE=en_AU:en_GB:en\nNote\nMany applications do not name or alias their English locale as\nen\nor\nen_US\n, but instead make it the default locale, which is\nC\n. If in\nLANGUAGE\na non-English locale is placed after English, e.g.\nLANGUAGE=en_US:en:es_ES\n, then applications may choose the secondary locale despite English strings being available.\n[3]\nThe solution is to always explicitly place the\nC\nlocale after English. E.g.\nLANGUAGE=en_US:en:C:es_ES\n.\nLC_TIME: date and time format\nIf\nLC_TIME\nis set to\nen_US.UTF-8\n, for example, the date format will be \"MM/DD/YYYY\".  If wanting to use the\nISO 8601\ndate format of \"YYYY-MM-DD\" use:\nlocale.conf\nLC_TIME=en_DK.UTF-8\nYou can print the current timestamp using your locale date and time format with\ndate +\"%c\"\n.\nglibc\n2.29 fixed a bug,\nen_US.UTF-8\nstarted showing in 12-hour format, as was intended.  If wanting to use 24-hour format, use\nLC_TIME=C.UTF-8\n.\nNote\nPrograms do not necessarily respect this variable to format the date. For example,\ndate(1)\nuses its own parameters to do so, and\nFirefox\nstopped honouring\nLC_TIME\nwith versions 57 to 84 (\nBug 1429578\n).\nLC_COLLATE: collation\nThis variable governs the collation rules used for sorting and regular expressions.\nSetting the value to\nC.UTF-8\ncan for example make the\nls\ncommand sort dotfiles first, followed by uppercase and lowercase filenames:\nlocale.conf\nLC_COLLATE=C.UTF-8\nSee also\n[4]\n.\nLC_ALL: troubleshooting\nThe locale set for this variable will always override\nLANG\nand all the other\nLC_*\nvariables, whether they are set or not. If\nLC_ALL\nis set to\nC\nor\nC.UTF-8\n, it will also override\nLANGUAGE\n.\nLC_ALL\nis the only\nLC_*\nvariable which\ncannot\nbe set in\nlocale.conf\nfiles: it is meant to be used only for testing or troubleshooting purposes, for example in\n/etc/profile\n.\nTroubleshooting\nFor encoding problems, check\nCharacter encoding#Troubleshooting\n.\nMy system is still using wrong language\nIt is possible that the environment variables are redefined in other files than\nlocale.conf\n. See\nEnvironment variables#Defining variables\nfor details.\nIf you are using a desktop environment, such as\nGNOME\n, its language settings may be overriding the settings in\nlocale.conf\n.\nKDE\nPlasma also allows to change the UI's language through the system settings. If the desktop environment is still using the default language after the modification,\ndeleting the file at\n~/.config/plasma-localerc\n(previously:\n~/.config/plasma-locale-settings.sh\n) should resolve the issue.\nIf you are using a display manager in combination with\naccountsservice\n, follow the instructions in\nDisplay manager#Set language for user session\n.\nLightDM\nwill automatically use\naccountsservice\nto set a user's locale if it is installed. Otherwise, LightDM stores the user session configuration in\n~/.dmrc\n. It is possible that an unwanted locale setting is retrieved from there as well.\nUsing a custom locale causes problems\nWhen installing a locale that is not officially supported (e.g.,\nlocale-en_xx\nAUR\n), some problems can occur, like\ndead/compose keys not working in some applications\nor\napplications reporting missing locales\n.\nAfter installing a custom locale, manual intervention is required to resolve these problems.\nThere are\ntwo approaches\n(replace\nen_XX.UTF-8\nwith the identifier of your custom locale):\nSet LC_CTYPE\nSet\nLC_CTYPE\nto an officially supported locale (like\nen_US.UTF-8\n), e.g.:\n/etc/locale.conf\nLANG=en_XX.UTF-8\nLC_CTYPE=en_US.UTF-8\nModify the Xlib database\nModify the Xlib database by adding the following:\n/usr/share/X11/locale/locale.dir\nen_US.UTF-8/XLC_LOCALE en_XX.UTF-8\nen_US.UTF-8/XLC_LOCALE: en_XX.UTF-8\n/usr/share/X11/locale/compose.dir\nen_US.UTF-8/Compose en_XX.UTF-8\nen_US.UTF-8/Compose: en_XX.UTF-8\nMetric measurements with US locale\nIn some tools, like\nnvme-cli\n, the unit type is selected based on the\nlocale\nsettings; hence, temperatures are shown in Fahrenheit if US locales are used. If you wish to use Metric measurements with a US locale, to get temperatures in Celsius for example, adding\nLC_MEASUREMENT=metric\nto\n/etc/locale.conf\nshould work if the tool searches for\nLC_MEASUREMENT\nrather than simply the country.\n[5]\nSee also\nLocales - glibc wiki\nGentoo:Localization/Guide\nSupposedly 2008, or earlier, Gentoo wiki article\nICU's interactive collation testing\nFree Standards Group Open Internationalisation Initiative\nThe POSIX definition of a locale\nLocale environment variables\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Locale&oldid=841157\n\"\nCategory\n:\nLocalization\nSearch\nSearch\nLocale\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Locale"}}
{"text": "Time - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nTime\nFrom ArchWiki\nThis article or section is being considered for removal.\nReason:\nNot specific to Arch, see\nw:Time_(disambiguation)\n(Discuss in\nTalk:Time\n)\nTime\nmay refer to:\nthe\ntime\nbuilt-in command for Bash, discussed in\nbash(1) § Pipelines\nthe\ntime(1)\ncommand from\ntime\nSystem time\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Time&oldid=832817\n\"\nCategory\n:\nDisambiguation pages\nHidden category:\nSections flagged with Template:Remove\nSearch\nSearch\nTime\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Time"}}
{"text": "cron - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\ncron\n5 languages\nDeutsch\nFrançais\n日本語\n中文（简体）\n中文（繁體）\nFrom ArchWiki\nRelated articles\nsystemd/Timers\nFrom\nWikipedia\n:\ncron\nis the time-based job scheduler in Unix-like computer operating systems. cron enables users to schedule jobs (commands or shell scripts) to run periodically at certain times, dates or intervals. It is commonly used to automate system maintenance or administration.\nInstallation\nThere are many cron implementations, but none of them are installed by default as the base system uses\nsystemd/Timers\ninstead. See the Gentoo wiki's\ncron guide\n, which offers comparisons.\nPackages available:\ncronie\nfcron\ndcron\nAUR\nvixie-cron\nAUR\nscron-git\nAUR\nConfiguration\nActivation and autostart\nAfter installation, the daemon will not be enabled by default. The installed package likely provides a service, which can be controlled by\nsystemctl\n. For example,\ncronie\nuses\ncronie.service\n.\nCheck\n/etc/cron.daily/\nand similar directories to see which jobs are present. Activating cron service will trigger all of them.\nNote\ncronie\nprovides the\n0anacron\nhourly\njob, which allows for\ndelayed runs of other jobs\ne.g. if the computer was switched off at the moment of standard execution.\nHandling errors of jobs\ncron registers the output from\nstdout\nand\nstderr\nand attempts to send it as email to the user's spools via the\nsendmail\ncommand. Cronie disables mail output if\n/usr/bin/sendmail\nis not found. In order for mail to be written to a user's spool, there must be an smtp daemon running on the system, e.g.\nopensmtpd\n. Otherwise, you can install a package that provides the sendmail command, and configure it to send mail to a remote mail exchanger. You can also log the messages by using the\n-m\noption and writing a custom script.\nTip\nOne can send the output to local system users using\nPostfix#Local mail\n.\nEdit\nthe\ncronie.service\nunit.\nInstall\nesmtp\nAUR\n,\nmsmtp\n,\nopensmtpd\n,\nsSMTP\n, or write a custom script.\nExample with sSMTP\nsSMTP is a send-only sendmail emulator which delivers email from a local computer to an smtp server.  While there are currently no active maintainers, it is still by far the simplest way to transfer mail to a configured mailhub.  There are no daemons to run, and configuration can be as simple as editing 3 lines in a single configuration file (if your host is trusted to relay unauthenticated email through your mailhub).  sSMTP does not receive mail, expand aliases, or manage a queue.\nInstall\nssmtp\nAUR\n, which creates a symbolic link from\n/usr/bin/sendmail\nto\n/usr/bin/ssmtp\n. You must then edit\n/etc/ssmtp/ssmtp.conf\n.  See\nsSMTP\nfor details.  Creating a symbolic link to\n/usr/bin/sendmail\ninsures that programs like\nS-nail\n(or any package which provides\n/usr/bin/mail\n) will just work without modification.\nRestart\ncronie.service\nto insure that it detects that you now have a\n/usr/bin/sendmail\ninstalled.\nExample with msmtp\nInstall\nmsmtp-mta\n, which creates a symbolic link from\n/usr/bin/sendmail\nto\n/usr/bin/msmtp\n.\nRestart\ncronie.service\nto make sure it detects the new\nsendmail\ncommand. You must then provide a way for\nmsmtp\nto convert your username into an email address.\nThen either add\nMAILTO\nline to your crontab, like so:\nMAILTO=your@email.com\nor\ncreate\n/etc/msmtprc\nand append this line:\naliases /etc/aliases\nand create\n/etc/aliases\n:\nyour_username: your@email.com\n# Optional:\ndefault: your@email.com\nThen\nmodify the configuration\nof\ncronie\ndaemon by replacing the\nExecStart\ncommand with:\nExecStart=/usr/bin/crond -n -m '/usr/bin/msmtp -t'\nExample with esmtp\nInstall\nesmtp\nAUR\nand\nprocmail\nAUR\n.\nAfter installation configure the routing:\n/etc/esmtprc\nidentity\nmyself\n@myisp.com\nhostname mail.myisp.com:25\nusername\n\"myself\"\npassword\n\"secret\"\nstarttls enabled\ndefault\nmda \"/usr/bin/procmail -d %T\"\nProcmail needs root privileges to work in delivery mode but it is not an issue if you are running the cronjobs as root anyway.\nTo test that everything works correctly, create a file\nmessage.txt\nwith\n\"test message\"\nin it.\nFrom the same directory run:\n$ sendmail\nuser_name\n< message.txt\nthen:\n$ cat /var/spool/mail/\nuser_name\nYou should now see the test message and the time and date it was sent.\nThe error output of all jobs will now be redirected to\n/var/spool/mail/\nuser_name\n.\nDue to the privileged issue, it is hard to create and send emails to root (e.g.\nsu -c \"\"\n). You can ask\nesmtp\nto forward all root's email to an ordinary user with:\n/etc/esmtprc\nforce_mda=\"\nuser-name\n\"\nNote\nIf the above test did not work, you may try creating a local configuration in\n~/.esmtprc\nwith the same content.\nRun the following command to make sure it has the correct permission:\n$ chmod 710 ~/.esmtprc\nThen repeat the test with\nmessage.txt\nexactly as before.\nExample with opensmtpd\nInstall\nopensmtpd\n.\nEdit\n/etc/smtpd/smtpd.conf\n. The following configuration allows for local delivery:\nlisten on localhost\naction \"local\" mbox alias <aliases>\nmatch for local action \"local\"\nYou can proceed to test it. First\nstart\nsmtpd.service\n. Then do:\n$ echo test | sendmail user\nuser\ncan check their mail in with any\nreader\nable to handle mbox format, or just have a look at the file\n/var/spool/mail/\nuser\n. If everything goes as expected, you can\nenable\nopensmtpd for future boots.\nThis approach has the advantage of not sending local cron notifications to a remote server. On the downside, you need a new daemon running.\nNote\nAt the moment of writing the Arch opensmtpd package does not create all needed directories under\n/var/spool/smtpd\n, but the daemon will warn about that specifying the required ownerships and permissions. Just create them as suggested.\nEven though the suggested configuration does not accept remote connections, it is a healthy precaution to add an additional layer of security blocking port 25 with\niptables\nor similar.\nLong cron job\nSuppose this program is invoked by cron :\n#!/bin/sh\necho \"I had a recoverable error!\"\nsleep 1h\nWhat happens is this:\ncron runs the script\nas soon as cron sees some output, it runs your MTA, and provides it with the headers. It leaves the pipe open, because the job has not finished and there might be more output.\nthe MTA opens the connection to postfix and leaves that connection open while it waits for the rest of the body.\npostfix closes the idle connection after less than an hour and you get an error like this :\nsmtpmsg='421 … Error: timeout exceeded' errormsg='the server did not accept the mail'\nTo solve this problem you can use the command chronic or sponge from\nmoreutils\n.\nFrom their respective man page:\nchronic(1)\nchronic runs a command, and arranges for its standard out and standard error to only be displayed if the command fails (exits nonzero or crashes). If the command succeeds, any extraneous output will be hidden.\nsponge(1)\nsponge reads standard input and writes it out to the specified file. Unlike a shell redirect, sponge soaks up all its input before opening the output file… If no output file is specified, sponge outputs to stdout.\nChronic too buffers the command output before opening its standard output.\nCrontab format\nThe basic format for a crontab is:\nminute\nhour\nday_of_month\nmonth\nday_of_week\ncommand\nminute\nvalues can be from 0 to 59.\nhour\nvalues can be from 0 to 23.\nday_of_month\nvalues can be from 1 to 31.\nmonth\nvalues can be from 1 to 12.\nday_of_week\nvalues can be from 0 to 6, with 0 denoting Sunday.\nSpaces are used to separate fields. To fine-tune your schedule you may also use one of the following symbols:\nSymbol\nDescription\n*\nWildcard, specifies every possible time interval\n,\nList multiple values separated by a comma.\n-\nSpecify a range between two numbers, separated by a hyphen\n/\nSpecify a periodicity/frequency using a slash\nFor example, the line:\n*/5 9-16 * 1-5,9-12 1-5 ~/bin/i_love_cron.sh\nwill execute the script\ni_love_cron.sh\nat five minute intervals from 9 AM to 4:55 PM on weekdays except during the months of June, July, and August.\nIn addition, crontab has some special keywords:\nKeyword\nDescription\n@reboot\nat startup\n@yearly\nonce a year\n@annually\nidentical to @yearly\n@monthly\nonce a month\n@weekly\nonce a week\n@daily\nonce a day\n@midnight\nidentical to @daily\n@hourly\nonce an hour\nFor example:\n@reboot ~/bin/i_love_cron.sh\nwill execute the script\ni_love_cron.sh\nat startup.\nSee more at:\nhttps://www.adminschoice.com/crontab-quick-reference\nMore examples and advanced configuration techniques can be found below.\nBasic commands\nCrontabs should never be edited directly; instead, you should use the\ncrontab\nprogram to work with your crontabs.\nTo view your crontabs:\n$ crontab -l\nTo edit your crontabs:\n$ crontab -e\nTo remove\nall\nof your crontabs:\n$ crontab -r\nIf you have a saved crontab and would like to completely overwrite your old crontab:\n$ crontab\nsaved_crontab_filename\nTo overwrite a crontab from the command line (\nWikipedia:stdin\n):\n$ crontab -\nTo edit somebody else's crontab:\n# crontab -u\nusername\n-e\nThis same format (appending\n-u\nusername\nto a command) works for listing and deleting crontabs as well.\nExamples\nThe entry:\n01 * * * * /bin/echo Hello, world!\nruns the command\n/bin/echo Hello, world!\non the first minute of every hour of every day of every month (i.e. at 12:01, 1:01, 2:01, etc.).\nSimilarly:\n*/5 * * jan mon-fri /bin/echo Hello, world!\nruns the same job every five minutes on weekdays during the month of January (i.e. at 12:00, 12:05, 12:10, etc.).\nThe line (as noted in\ncrontab(5)\n):\n*/5 9-16 * 1-5,9-12 1-5 /home/user/bin/i_love_cron.sh\nwill execute the script\ni_love_cron.sh\nat five minute intervals from 9 AM to 5 PM (excluding 5 PM itself) every weekday (Mon-Fri) of every month except during the summer (June, July, and August).\nPeriodical settings can also be entered as in this crontab template:\n# Chronological table of program loadings\n# Edit with \"crontab\" for proper functionality, \"man 5 crontab\" for formatting\n# User: johndoe\n# mm  hh  DD  MM  W /path/progam [--option]...  ( W = weekday: 0-6 [Sun=0] )\n21  01  *   *   * /usr/bin/systemctl hibernate\n@weekly           $HOME/.local/bin/trash-empty\nHere are some self-explanatory crontab syntax examples:\n30 4 echo \"It is now 4:30 am.\"\n0 22 echo \"It is now 10 pm.\"\n30 15 25 12 echo \"It is 3:30pm on Christmas Day.\"\n30 3 * * * echo \"Remind me that it's 3:30am every day.\"\n0 * * * * echo \"It is the start of a new hour.\"\n0 6 1,15 * * echo \"At 6am on the 1st and 15th of every month.\"\n0 6 * * 2,3,5 echo \"At 6am on Tuesday, Wednesday and Thursdays.\"\n59 23 * * 1-5 echo \"Just before midnight on weekdays.\"\n0 */2 * * * echo \"Every two hours.\"\n0 20 * * 4 echo \"8pm on a Thursday.\"\n0 20 * * Thu echo \"8pm on a Thursday.\"\n*/15 9-17 * * 2-5 echo \"Every 15 minutes from 9am-5pm on weekdays.\"\n@yearly echo \"Happy New Year!\"\nDefault editor\nTo use an alternate default editor, define the\nEDITOR\nenvironment variable in a shell initialization script as described in\nEnvironment variables\n.\nAs a regular user,\nsu\nwill need to be used instead of\nsudo\nfor the environment variable to be pulled correctly:\n$ su -c \"crontab -e\"\nTo have an alias to this\nprintf\nis required to carry the arbitrary string because\nsu\nlaunches in a new shell:\nalias scron=\"su -c $(printf \"%q \" \"crontab -e\")\"\nRunning X.org server-based applications\nCron does not run under the\nX.org\nserver therefore it cannot know the environmental variable necessary to be able to start an X.org server application so they will have to be defined. One can use a program like\nxuserrun-git\nAUR\nto do it:\n17 02 * ... /usr/bin/xuserrun /usr/bin/xclock\nThis article or section is out of date.\nReason:\nDoes it still work? (Discuss in\nTalk:Cron#cron x.org aplications\n)\nOr they can be defined manually (\necho $DISPLAY\nwill give the current DISPLAY value):\n17 02 * ... env DISPLAY=:0 /usr/bin/xclock\nIf running notify-send for desktop notifications in cron, notify-send is sending values to dbus. So it needs to tell dbus to connect to the right bus.\nThe address can be found by examining DBUS_SESSION_BUS_ADDRESS environment variable and setting it to the same value. Therefore:\n17 02 * ... env DBUS_SESSION_BUS_ADDRESS=your-address notify-send 'Foo bar'\nIf done through say SSH, permission will need be given:\n# xhost +si:localuser:$(whoami)\nAsynchronous job processing\nIf you regularly turn off your computer but do not want to miss jobs, there are some solutions available (easiest to hardest):\nCronie\ncronie\ncomes with anacron included. The project homepage says:\nCronie contains the standard UNIX daemon crond that runs specified programs at scheduled times and related tools.\nIt is based on the original cron and has security and configuration enhancements like the ability to use pam and SELinux.\nDcron\nVanilla\ndcron\nAUR\nsupports asynchronous job processing. Just put it with @hourly, @daily, @weekly or @monthly with a jobname, like this:\n@hourly         ID=greatest_ever_job      echo This job is very useful.\nCronwhip\ncronwhip\nAUR\nis a script to automatically run missed cron jobs; it works with the former default cron implementation,\ndcron\n.\nSee also the\nforum thread\n.\nAnacron\nAnacron is a full replacement for\ndcron\nwhich processes jobs asynchronously.\nIt is provided by\ncronie\n. The configuration file is\n/etc/anacrontab\n. Information on the format can be found in the\nanacrontab(5)\n. Running\nanacron -T\nwill test\n/etc/anacrontab\nfor validity.\nFcron\nLike\nanacron\n,\nfcron\nassumes the computer is not always running and, unlike\nanacron\n, it can schedule events at intervals shorter than a single day which may be useful for systems which suspend/hibernate regularly (such as a laptop). Like cronwhip, fcron can run jobs that should have been run during the computer's downtime.\nWhen replacing\ncronie\nwith fcron be aware the spool directory is\n/var/spool/fcron\nand the\nfcrontab\ncommand is used instead of\ncrontab\nto edit the user crontabs. These crontabs are stored in a binary format with the text version next to them as\nfoo\n.orig in the spool directory. Any scripts which manually edit user crontabs may need to be adjusted due to this difference in behavior.\nA quick scriptlet which may aide in converting traditional user crontabs to fcron format:\ncd /var/spool/cron && (\nfor ctab in *; do\nfcrontab ${ctab} -u ${ctab}\ndone\n)\nSee also the\nforum thread\n.\nEnsuring exclusivity\nIf you run potentially long-running jobs (e.g., a backup might all of a sudden run for a long time, because of many changes or a particular slow network connection), then\nflock\n(\nutil-linux\n) can ensure that the cron job will not start a second time.\n5,35 * * * * /usr/bin/flock -n /tmp/lock.backup /root/make-backup.sh\nCronie\nThe relevant file hierarchy for cronie is the following:\n/etc/\n|----- cron.d/\n| ----- 0hourly\n|----- cron.minutely/\n|----- cron.hourly/\n| ----- 0anacron\n|----- anacrontab\n|----- cron.daily/\n|----- cron.monthly/\n|----- cron.weekly/\n|----- crontab\n|----- cron.deny\nCronie provides both\ncron\nand\nanacron\nfunctionalities:\ncron\nruns jobs at regular time intervals (down to a granularity of one minute) as long as the system is available at the specified time, while\nanacron\nexecutes commands at\nintervals specified in days.  Unlike cron, it does not assume that the system is running continuously. Whenever the system is up,\nanacron\nchecks if there are any jobs that should have been run and handles them accordingly.\nA\ncron\njob can be defined in a crontab-like file in the\n/etc/cron.d\ndirectory or added within the\n/etc/crontab\nfile. Note the latter is not present by default but is used if it exists. As instructed by\n/etc/cron.d/0hourly\n, any executable file in\n/etc/cron.hourly\nwill be run every hour (by default at minute 1 of the hour). Files in\n/etc/cron.minutely\nare executed every minute if instructed accordingly in\n/etc/cron.d/0minutely\n. The executables are typically shell scripts, symlinks to executable files can also be used.\nThe\n/etc/cron.deny\nfile includes the list of users not allowed to use crontab, without this file, only users listed in\n/etc/cron.allow\ncan use it.\nAnacron\nworks similarly, by executing the files in the\n/etc/cron.daily\n,\n/etc/cron.weekly\nand\n/etc/cron.monthly\ndirectories, placed there depending on the desired job frequency. The cron job\n/etc/cron.hourly/0anacron\nmakes sure that\nanacron\nis run once daily to perform its pending tasks.\nNote\nCronie uses\nrun-parts\nto carry out scripts in the different directories. The filenames should not include any dot (.) since\nrun-parts\nin its default mode will silently ignore them (see\nrun-parts(8)\n). The names must consist only of upper and lower-case letters, digits, underscores and minus-hyphens.\nThe output of\nsystemctl status cronie\nmight show a message such as\nCAN'T OPEN (/etc/crontab): No such file or directory\n. However, this can be ignored since cronie does not require one.\nCronie is particular about the permissions for\n/etc/cron.d/0hourly\n. None of the tasks in\n/etc/cron.d/{hourly,weekly,daily} ... etc\nwill be run (including the anacron launcher) if\n/etc/cron.d/0hourly\nis damaged or has improper permissions.\npacman -Qkk cronie\ncan show if you have any such issues.\nTip\nTo prevent the sending of output and stop email alert, add\n>/dev/null 2>&1\nat the end of the line for each cron job to redirect output to /dev/null.\n0 1 5 10 * /path/to/script.sh >/dev/null 2>&1\nYou can also set\nMAILTO=””\nvariable in your crontab file to  disable email alerts.\nDcron\nThe cron daemon parses a configuration file known as\ncrontab\n. Each user on the system can maintain a separate crontab file to schedule commands individually. The root user's crontab is used to schedule system-wide tasks (though users may opt to use\n/etc/crontab\nor the\n/etc/cron.d\ndirectory, depending on which cron implementation they choose).\n/var/spool/cron/root\n# Run command at a scheduled time\n# Edit this 'crontab -e' for error checking, man 1 crontab for acceptable format\n# <@freq>                       <tags and command>\n@hourly         ID=sys-hourly   /usr/sbin/run-cron /etc/cron.hourly\n@daily          ID=sys-daily    /usr/sbin/run-cron /etc/cron.daily\n@weekly         ID=sys-weekly   /usr/sbin/run-cron /etc/cron.weekly\n@monthly        ID=sys-monthly  /usr/sbin/run-cron /etc/cron.monthly\n# mm  hh  DD  MM  W /path/command (or tags) # W = week: 0-6, Sun=0\n21  01  *   *   * /usr/bin/systemctl suspend\nThese lines exemplify one of the formats that crontab entries can have, namely whitespace-separated fields specifying:\n@period\nID=jobname (this tag is specific to dcron)\ncommand\nThe other standard format for crontab entries is:\nminute\nhour\nday\nmonth\nday of week\ncommand\nThe crontab files themselves are usually stored as\n/var/spool/cron/username\n. For example, root's crontab is found at\n/var/spool/cron/root\nSee the crontab\nman page\nfor further information and configuration examples.\nSee also\nGentoo Linux Cron Guide\ncrontab.guru\n- online editor for cronjob expressions\ncron-notify\nAUR\nis a FreeDesktop.org-compatible notification service to periodically ask for acknowledgement before executing a command. Commands are configured in a custom configuration file.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Cron&oldid=846604\n\"\nCategory\n:\nSystem administration\nHidden category:\nPages or sections flagged with Template:Out of date\nSearch\nSearch\ncron\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Cron"}}
{"text": "Swap - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSwap\n8 languages\nDeutsch\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nfstab\nHibernation\nzswap\nzram\nSwap on video ram\nZFS#Swap volume\ndm-crypt/Swap encryption\nThis page provides an introduction to\nswap space and paging\non GNU/Linux. It covers creation and activation of swap partitions and swap files.\nFrom\nAll about Linux swap space\n:\nLinux divides its physical RAM (random access memory) into chunks of memory called pages. Swapping is the process whereby a page of memory is copied to the preconfigured space on the hard disk, called swap space, to free up that page of memory. The combined sizes of the physical memory and the swap space is the amount of virtual memory available.\nSupport for swap is provided by the Linux kernel and user-space utilities from the\nutil-linux\npackage.\nSwap space\nSwap space can take the form of a disk partition or a file. Users may create a swap space during installation or at any later time as desired. Swap space can be used for two purposes, to extend the virtual memory beyond the installed physical memory (RAM), and also for\nsuspend-to-disk\nsupport.\nWhether or not it is beneficial to extend the virtual memory with swap depends on the amount of installed physical memory. If the amount of physical memory is less than the amount of memory required to run all the desired programs, then it\nmay be\nbeneficial to enable swap. This avoids\nout of memory conditions\n, where the Linux kernel OOM killer mechanism will automatically attempt to free up memory by killing processes. To increase the amount of virtual memory to the required amount, add the necessary difference (or more) as swap space.\nThe biggest drawback of using swap when running out of memory is its lower performance, see section\n#Performance\n. Hence, enabling swap is a matter of personal preference: some prefer programs to be killed over enabling swap and others prefer enabling swap and slower system when the physical memory is exhausted.\nTo check swap status, use:\n$ swapon --show\nOr to show physical memory as well as swap usage:\n$ free -h\nSwap partition\nA\nswap partition\ncan be created with most GNU/Linux\npartitioning tools\n. Swap partitions are designated by the partition type GUID\n0657FD6D-A4AB-43C4-84E5-0933C84B4F4F\non GPT (\n8200\ntype for\ngdisk\n,\nswap\ntype for\nfdisk\n) and type ID\n82\non MBR.\nTo set up a partition as Linux swap area, the\nmkswap(8)\ncommand is used. For example:\n# mkswap /dev/sd\nxy\nWarning\nAll data on the specified partition will be lost.\nTo enable the device for paging:\n# swapon /dev/sd\nxy\nSee\nswapon(8)\nfor the options syntax.\nEnabling at boot\nTo enable the swap partition at boot time, either:\nuse\nsystemd#GPT partition automounting\nor add an entry to\n/etc/fstab\n. E.g.:\nUUID=\ndevice_UUID\nnone swap defaults 0 0\nwhere the\ndevice_UUID\nis the\nUUID\nof the swap space.\nSee\nfstab\nfor the file syntax, and\nsystemd#systemd.mount - mounting\n.\nDisabling swap\nTo deactivate specific swap space:\n# swapoff /dev/sd\nxy\nAlternatively use the\n-a\nswitch to deactivate all swap space.\nSince swap is managed by systemd, it will be activated again on the next system startup. To disable the automatic activation of detected swap space permanently, run\nsystemctl --type swap\nto find the responsible\n.swap\nunit and\nmask\nit.\nSwap file\nAs an alternative to creating an entire partition, a swap file offers the ability to vary its size on-the-fly, and is more easily removed altogether. This may be especially desirable if disk space is at a premium (e.g. a modestly-sized SSD).\nFile system\nSupports swap files\nBcachefs\nNo\nBtrfs\nYes\nF2FS\nYes\next4\nYes\nJFS\nYes\nNILFS2\nNo\nNTFS3\nYes\nReiserFS\nYes\nXFS\nYes\nZFS\nNo\nSwap file creation\nNote\nFor\nBtrfs\n, follow the procedure described in\nBtrfs#Swap file\ninstead of the steps below.\nUse\nmkswap(8)\nto create a swap file the size of your choosing (see\nPartitioning#Swap\nfor advice). For example, creating a 4 GiB swap file:\n# mkswap -U clear --size 4G --file /swapfile\nActivate the swap file:\n# swapon /swapfile\nFinally, edit the fstab configuration to add an entry for the swap file:\n/etc/fstab\n/swapfile none swap defaults 0 0\nAs an alternative to fstab, a swap unit can be created (see\nsystemd.swap(5)\n):\n/etc/systemd/system/swapfile.swap\n[Swap]\nWhat=/swapfile\n[Install]\nWantedBy=swap.target\nPerform a\ndaemon-reload\nand\nenable\nswapfile.swap\n.\nFor additional information, see\nfstab#Usage\n.\nNote\nThe swap file must be specified by its location on the file system, not by its UUID or LABEL.\nSwap file removal\nTo remove a swap file, it must be turned off first and then can be removed:\n# swapoff /swapfile\n# rm -f /swapfile\nFinally, remove the relevant entry from\n/etc/fstab\n.\nSwap encryption\nSee\ndm-crypt/Swap encryption\n.\nPerformance\nSwap operations are usually significantly slower than directly accessing data in RAM. However, disabling swap entirely to improve performance can sometimes lead to a degradation. If there is not enough physical memory available to hold everything, swapping out nothing leaves less memory available for file system caches, causing more frequent and costly disk usage.\nSwap values can be adjusted to help performance:\nSwappiness\nWhen memory usage reaches a certain threshold, the kernel starts looking at active memory and seeing what it can free up. File data can be written out to the file system (if changed), unloaded and re-loaded later; other data must be written to swap before it can be unloaded.\nThe\nswappiness\nsysctl\nparameter represents the kernel's preference for writing to swap instead of files. It can have a value between 0 and 200 (max 100 if Linux < 5.8); the default value is 60. A low value causes the kernel to prefer freeing up open files, a high value causes the kernel to try to use swap space, and a value of 100 means IO cost is assumed to be equal.\nNote\nThere is a common misconception that swappiness affects the memory threshold or prevents using swap space, but it only affects the preference for freeing up file pages over swap. See:\nthis article\nfor a more detailed explanation or the\nkernel source code\nwhere it is used.\nTo check the current swappiness value:\n$ sysctl vm.swappiness\nAlternatively, the file\n/proc/sys/vm/swappiness\ncan be read in order to obtain the raw integer value.\nTo temporarily set the swappiness value:\n# sysctl -w vm.swappiness=35\nTo set the swappiness value permanently, create a\nsysctl.d(5)\nconfiguration file. For example:\n/etc/sysctl.d/99-swappiness.conf\nvm.swappiness = 35\nTo have the\nboot loader\nset swappiness when loading the kernel, add a\nkernel parameter\n, e.g.\nsysctl.vm.swappiness=35\n.\nReasons for choosing a different swappiness can include:\nLowering the swappiness\nhas been suggested\nfor desktop responsiveness. The argument is that because a lot of perceived performance (responsiveness) is determined by how fast a program responds to user input, anonymous pages (program memory) should be kept in RAM and freeing up open files should be prioritized even at some expense of\nactual\nperformance.\nThe\nminimal reasonable swappiness\nis 1 because a swappiness of 0 causes an extreme bias against anonymous page eviction, preventing them from being scanned for reclaiming or swapping except in the most extreme cases of memory contention. It is generally not desired to not reclaim truly unused anonymous pages.\nA higher swappiness of 100 or beyond is desired (by definition) when the IO cost of swapping is equal or lower than the cost of reading from a file. This can happen when\nthe swap is not backed by the disk\n, especially in the case of\nzram\n. This can also happen when swap IO is being intercepted/cached by a lower-cost mechanism such as\nzswap\n.\nVFS cache pressure\nAnother\nsysctl\nparameter that affects swap performance is\nvm.vfs_cache_pressure\n, which controls the tendency of the kernel to reclaim the memory which is used for caching of VFS caches, versus pagecache and swap. Increasing this value increases the rate at which VFS caches are reclaimed. For more information on what it does, see the\nLinux kernel documentation\n.\nThe default value is 100, which states that filesystem cache is about as important as the other caches, so they should be reclaimed at about an equal weight. On desktops it has been argued that\nfilesystem cache is more important than the other caches\nbecause filesystem browsing times affects operation latency (perceived responsiveness) more than the other caches, resulting a suggested value of 50. On the other hand, a higher value\nhas been suggested\nwhen the VFS cache holds metadata on many small files that are not touched again. For more information on tuning this parameter, see\nOpenSUSE tuning guide\n(which recommends experimenting and checking the types of caches via\nslaptop\n).\nPriority\nIf you have more than one swap file or swap partition you should consider assigning a priority value (0 to 32767) for each swap area. The system will use swap areas of higher priority before using swap areas of lower priority. For example, if you have a faster disk and a slower disk, assign a higher priority to the swap area located on the fastest device. Priorities can be assigned in\nfstab\nvia the\npri\nparameter:\nUUID=f9fe0b69-a280-415d-a03a-a32752370dee none swap defaults,pri=100 0 0\nUUID=d7eb6062-01c8-4367-ac1d-3bf1167de8bb none swap defaults,pri=10  0 0\nOr via the\n--priority\nparameter of\nswapon\n:\n# swapon --priority 100 /dev/sda1\nIf two or more areas have the same priority, and it is the highest priority available, pages are allocated on a round-robin basis between them.\nStriping\nThere is no necessity to use\nRAID\nfor swap performance reasons. The kernel itself can stripe swapping on several devices, if you just give them the same priority in the\n/etc/fstab\nfile. Refer to\nThe Software-RAID HOWTO\nfor details.\nDiscard (a.k.a. trim)\nSee\nSolid state drive#swap\n.\nCompressed block device in RAM\nSee\nImproving performance#Swap on zram or zswap\n.\nUsing the swap space only for hibernation\nIf you only need swap as a hibernation image storage space, then you can use\nzswap\nand disable its writeback so that there are no disk writes from regular swap usage. See\nPower management/Suspend and hibernate#Disable zswap writeback to use the swap space only for hibernation\n.\nSee also\nIn defence of swap: common misconceptions\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Swap&oldid=839579\n\"\nCategory\n:\nFile systems\nSearch\nSearch\nSwap\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Swap"}}
{"text": "tmpfs - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\ntmpfs\n7 languages\nDeutsch\nEspañol\nFrançais\nItaliano\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\ntmpfs\nis a temporary filesystem that resides in memory and/or swap partition(s). Mounting directories as tmpfs can be an effective way of speeding up accesses to their files, or to ensure that their contents are automatically cleared upon reboot.\nTip\nTemporary files in tmpfs directories can be recreated at boot by using\nsystemd-tmpfiles\n.\nUsage\nSome directories where\ntmpfs(5)\nis commonly used are\n/tmp\n,\n/var/lock\nand\n/var/run\n. Do\nnot\nuse it on\n/var/tmp\n, because that directory is meant for temporary files that are preserved across reboots.\nArch uses a tmpfs\n/run\ndirectory, with\n/var/run\nand\n/var/lock\nsimply existing as symlinks for compatibility. It is also used for\n/tmp\nby the default systemd setup and does not require an entry in\nfstab\nunless a specific configuration is needed.\nglibc\n2.2 and above expects tmpfs to be mounted at\n/dev/shm\nfor\nPOSIX shared memory\n. Mounting tmpfs at\n/dev/shm\nis handled automatically by\nsystemd\nand manual configuration in\nfstab\nis not necessary.\nGenerally, tasks and programs that run frequent read/write operations can benefit from using a tmpfs directory. Some applications can even receive a substantial gain by offloading some (or all) of their data onto the shared memory. For example,\nrelocating the Firefox profile into RAM\nshows a significant improvement in performance.\nExamples\nNote\nThe actual memory/swap consumption depends on how much is used, as tmpfs partitions do not consume any memory until it is actually needed.\nBy default, a tmpfs partition has its maximum size set to half of the available RAM, however it is possible to overrule this value.\nTo explicitly set a maximum size, in this example to override the default\n/tmp\nmount, use the\nsize\nmount option:\n/etc/fstab\ntmpfs   /tmp         tmpfs   rw,nodev,nosuid,size=2G          0  0\nTo specify a more secure mounting, specify the following mount option:\n/etc/fstab\ntmpfs   /www/cache    tmpfs  rw,size=1G,nr_inodes=5k,noexec,nodev,nosuid,uid=\nuser\n,gid=\ngroup\n,mode=1700 0 0\nSee the\ntmpfs(5)\nman page and\nSecurity#File systems\nfor more information.\nReboot for the changes to take effect. Note that although it may be tempting to simply run\nmount -a\nto make the changes effective immediately, this will make any files currently residing in these directories inaccessible (this is especially problematic for running programs with lockfiles, for example). However, if all of them are empty, it should be safe to run\nmount -a\ninstead of rebooting (or mount them individually).\nAfter applying changes, verify that they took effect by looking at\n/proc/mounts\nand using\nfindmnt\n:\n$ findmnt /tmp\nTARGET SOURCE FSTYPE OPTIONS\n/tmp   tmpfs  tmpfs  rw,nosuid,nodev,relatime\nThe tmpfs can also be temporarily resized without the need to reboot, for example when a large compile job needs to run soon. In this case, run:\n# mount -o remount,size=4G /tmp\nOr resize based on RAM:\n# mount -o remount,size=80% /tmp\nDisable automatic mount\nUnder\nsystemd\n,\n/tmp\nis automatically mounted as a tmpfs, if it is not already a dedicated mountpoint (either tmpfs or on-disk) in\n/etc/fstab\n. To disable the automatic mount,\nmask\nthe\ntmp.mount\nsystemd unit.\nFiles will no longer be stored in a tmpfs, but on the block device instead. The\n/tmp\ncontents will now be preserved between reboots (they are still cleaned up after 10 days though), which might not be the desired behavior. To regain the previous behavior and clean the\n/tmp\ndirectory automatically when restarting, consider using\ntmpfiles.d(5)\n:\n/etc/tmpfiles.d/tmp.conf\n# see tmpfiles.d(5)\n# always enable /tmp directory cleaning\nD! /tmp 1777 root root 0\n# remove files in /var/tmp older than 10 days\nD /var/tmp 1777 root root 10d\n# namespace mountpoints (PrivateTmp=yes) are excluded from removal\nx /tmp/systemd-private-*\nx /var/tmp/systemd-private-*\nX /tmp/systemd-private-*/tmp\nX /var/tmp/systemd-private-*/tmp\nTroubleshooting\nOpening symlinks in tmpfs as root fails\nConsidering\n/tmp\nis using tmpfs, change the current directory to\n/tmp\n, then create a file and create a symlink to that file in the same\n/tmp\ndirectory.  Permission denied errors are to be expected when attempting to read the symlink due to\n/tmp\nhaving the sticky bit set\n.\nThis behavior can be controlled via\n/proc/sys/fs/protected_symlinks\nor simply via sysctl:\nsysctl -w fs.protected_symlinks=0\n. See\nSysctl#Configuration\nto make this permanent.\nWarning\nChanging this behavior can lead to security issues!\nTips and tricks\nAllocate more memory to accommodate profiles in /run/user/xxxx\nThe standard way of controlling the size of tmpfs in\n/run/user/\nis the\nRuntimeDirectorySize\ndirective in\n/etc/systemd/logind.conf\n(see\nlogind.conf(5)\nfor more). By default, 10% of physical memory is used but one can increase it safely. Remember that tmpfs only consumes what is actually used; the number specified here is just a maximum allowed.\nSee also\nLinux kernel documentation\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Tmpfs&oldid=847600\n\"\nCategory\n:\nFile systems\nSearch\nSearch\ntmpfs\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Tmpfs"}}
{"text": "Partitioning - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nPartitioning\n8 languages\nDeutsch\nMagyar\n日本語\nPortuguês\nРусский\nTürkçe\n中文（简体）\n中文（繁體）\nFrom ArchWiki\nRelated articles\nFile systems\nfdisk\ngdisk\nparted\nfstab\nLVM\nSwap\nArch boot process\nUnified Extensible Firmware Interface\nsystemd-repart\nFrom\nWikipedia\n:\nDisk partitioning or disk slicing is the creation of one or more regions on\nsecondary storage\n, so that each region can be managed separately.\nAn entire disk may be allocated to a single partition, or multiple ones for cases such as dual-booting, maintaining a\nswap\npartition, or to logically separate data such as audio and video files. The partitioning scheme is stored in a\npartition table\nsuch as Master Boot Record (MBR) or GUID Partition Table (GPT).\nPartition tables are created and modified using one of\nmany partitioning tools\n. The tools available for Arch Linux are listed in the\n#Partitioning tools\nsection.\nPartitions usually contain a\nfile system\ndirectly which is accomplished by creating a file system on (a.k.a.\nformatting\n) the partition. Alternatively, partitions can contain\nLVM\n,\nblock device encryption\nor\nRAID\n, which ultimately provide device files on which a file system can be placed (or the devices can be stacked further).\nAny\nblock device\n(e.g. disk, partition, LUKS device, LVM logical volume or RAID array) that directly contains a mountable file system is called a\nvolume\n.\nPartition table\nThere are two main types of partition table available. These are described below in the\n#Master Boot Record\n(MBR) and\n#GUID Partition Table\n(GPT) sections along with a discussion on how to choose between the two. A third, less common alternative is using a partitionless disk, which is also discussed.\nUse a\npartitioning tool\nto view the partition table of a\nblock device\n.\nTip\nRun\nparted\n/dev/sdX\nprint\nor\nfdisk -l\n/dev/sdX\n, where\n/dev/sdX\nis the\nblock device\nsuch as\n/dev/sda\nfor a SATA disk,\n/dev/nvme0n1\nfor a\nNVMe\ndisk or\n/dev/mmcblk0\nfor an eMMC disk. See\nDevice file#Block device names\nfor more information on block device naming.\nMaster Boot Record\nThe\nMaster Boot Record\n(MBR) is the first 512 bytes of a storage device. It contains an operating system\nboot loader\nand the storage device's partition table. It plays an important role in the\nboot process\nunder\nBIOS\nsystems. See\nWikipedia:Master boot record#Disk partitioning\nfor the MBR structure.\nNote\nThe MBR is not located in a partition; it is located at the first sector of the device (physical offset 0), preceding the first partition.\nThe boot sector present on a partitionless device or within an individual partition is called a\nvolume boot record (VBR)\ninstead.\nMaster Boot Record (bootstrap code)\nThe first 440 bytes of MBR are the\nbootstrap code area\n. On BIOS systems it usually contains the first stage of the boot loader. The bootstrap code can be backed up, restored from backup or erased\nusing dd\n.\nMaster Boot Record (partition table)\nIn the MBR partition table (also known as DOS or MS-DOS partition table) there are 3 types of partitions:\nPrimary\nExtended\nLogical\nPrimary\npartitions can be bootable and are limited to four partitions per disk or RAID volume. If the MBR partition table requires more than four partitions, then one of the primary partitions needs to be replaced by an\nextended\npartition containing\nlogical\npartitions within it.\nExtended partitions can be thought of as containers for logical partitions. A hard disk can contain no more than one extended partition. The extended partition is also counted as a primary partition so if the disk has an extended partition, only three additional primary partitions are possible (i.e. three primary partitions and one extended partition). The number of logical partitions residing in an extended partition is unlimited. A system that dual boots with Windows will require for Windows to reside in a primary partition.\nThe customary numbering scheme is to create primary partitions\nsda1\nthrough\nsda3\nfollowed by an extended partition\nsda4\n. The logical partitions on\nsda4\nare numbered\nsda5\n,\nsda6\n, etc.\nTip\nWhen partitioning a MBR disk consider leaving at least 33 512-byte sectors (16.5 KiB) of free unpartitioned space at the end of the disk in case you ever decide to\nconvert it to GPT\n. The space will be required for the backup GPT header.\nGUID Partition Table\nGUID Partition Table\n(GPT) is a partitioning scheme that is part of the\nUnified Extensible Firmware Interface\nspecification; it uses\nglobally unique identifiers\n(GUIDs), or UUIDs in the Linux world, to define partitions and\npartition types\n. It is designed to succeed the\nMaster Boot Record\npartitioning scheme method.\nAt the start of a GUID Partition Table disk there is a\nprotective Master Boot Record\n(PMBR) to protect against GPT-unaware software. This protective MBR just like an ordinary MBR has a\nbootstrap code area\nwhich can be used for BIOS/GPT booting with boot loaders that support it.\nChoosing between GPT and MBR\nGUID Partition Table (GPT) is an alternative, contemporary, partitioning style; it is intended to replace the old Master Boot Record (MBR) system. GPT has several advantages over MBR which has quirks dating back to MS-DOS times. With the recent developments to the formatting tools, it is equally easy to get good dependability and performance for GPT or MBR.\nNote\nFor GRUB or Limine to boot from a GPT-partitioned disk on a BIOS-based system, a\nBIOS boot partition\nis required.\nSome points to consider when choosing:\nTo dual-boot with Windows (both 32-bit and 64-bit) using Legacy BIOS, the MBR scheme is required.\nTo dual-boot Windows 64-bit using\nUEFI\nmode instead of BIOS, the GPT scheme is required.\nIf you are installing on older hardware, especially on old laptops, consider choosing MBR because its BIOS might not support GPT (but\nsee below\nhow to fix it).\nIf you are partitioning a disk that is larger than 2 TiB (≈2.2 TB), you need to use GPT.\nIt is recommended to always use GPT for\nUEFI\nboot, as some UEFI implementations do not support booting to the MBR while in UEFI mode.\nIf none of the above apply, choose freely between GPT and MBR. Since GPT is more modern, it is recommended in this case.\nSome advantages of GPT over MBR are:\nProvides a unique disk GUID and unique partition GUID (\nPARTUUID\n) for each partition – a good filesystem-independent way of referencing partitions and disks. GUIDs are a prerequisite for the\nDiscoverable Partitions Specification\nthat can be utilized in a systemd-enabled initramfs.\nProvides a filesystem-independent partition name (\nPARTLABEL\n).\nArbitrary number of partitions - depends on space allocated for the partition table - No need for extended and logical partitions. By default the GPT table contains space for defining 128 partitions. However if you want to define more partitions, you can allocate more space to the partition table (currently only\ngdisk\nis known to support this feature).\nUses 64-bit LBA for storing Sector numbers - maximum addressable disk size is 2 ZiB. MBR is limited to addressing 2 TiB of space per drive.\n[1]\nStores a backup header and partition table at the end of the disk that aids in\nrecovery\nin case the primary ones are damaged.\nCRC32 checksums to detect errors and corruption of the header and partition table.\nThe section on\n#Partitioning tools\ncontains a table indicating which tools are available for creating and modifying GPT and MBR tables.\nTip\nIt is possible to convert between MBR and GPT. See\ngdisk#Convert between MBR and GPT\n.\nPartitionless disk\nThis article or section needs expansion.\nReason:\nExplain when one might want to use a partitionless disk (e.g. in VMs) and when not and why. (Discuss in\nTalk:Partitioning\n)\nPartitionless disk a.k.a.\nsuperfloppy\nrefers to a storage device without a partition table, having one file system occupying the whole storage device. The boot sector present on a partitionless device is called a\nvolume boot record (VBR)\n.\nBtrfs partitioning\nBtrfs\ncan occupy an entire data storage device and replace the\nMBR\nor\nGPT\npartitioning schemes. See the\nBtrfs#Partitionless Btrfs disk\ninstructions for details.\nPartition scheme\nThis article or section needs expansion.\nReason:\nIntroduce\nLVM\n,\nmdadm\n,\ndm-crypt\n, etc. They could be placed in a new subsection together with the information about Btrfs subvolumes. (Discuss in\nTalk:Partitioning\n)\nThere are no strict rules for partitioning a hard drive, although one may follow the general guidance given below. A disk partitioning scheme is determined by various issues such as desired flexibility, speed, security, as well as the limitations imposed by available disk space. It is essentially personal preference. If you would like to dual boot Arch Linux and a Windows operating system please see\nDual boot with Windows\n.\nNote\nUEFI\nsystems typically need an\nEFI system partition\n.\nBIOS systems that are partitioned with\nGPT\nrequire a\nBIOS boot partition\nif\nGRUB\nor\nLimine\nis used as the boot loader.\nTip\nIf using\nBtrfs\n, subvolumes can be used to imitate partitions. See the\nBtrfs#Mounting subvolumes\nsection.\nSingle root partition\nThis scheme is the simplest, most flexible and should be enough for most use cases given the increase in storage size of consumer grade devices. A\nswap file\ncan be created and easily resized as needed. It usually makes sense to start by considering a single\n/\npartition and then separate out others based on specific use cases like RAID, encryption, a shared media partition, etc… See\n#Discrete partitions\nfor a description of some common to uncommon dedicated partitions.\nThe suggested minimum size is 23–32 GiB for a single root partition. More space may be needed for user files and when using a swap file. A bare minimal installation requires about 2 GiB. As examples, a simple server can fit under 4 GiB while a full\nKDE Plasma\ninstallation uses 10 GiB. Both examples require frequent\npurges of the package cache\n.\nWarning\nA separate physical (in the main partition table of the disk, not under LVM, software RAID or in a file system subvolume etc.)\n/boot partition\nis needed unless your\nboot loader\nis capable of accessing the\n/boot\ndirectory that resides in\n/\n. That means the boot loader must have support for everything starting from the block devices, stacked block devices (LVM, RAID, dm-crypt, LUKS, etc.) and ending with the file system on which the kernel(s) and initramfs image(s) reside.\nA GPT partition should have the \"Linux root (x86-64)\" type GUID\n4F68BCE3-E8CD-4DB1-96E7-FBCAF984B709\n(\n8304\ntype for\ngdisk\n). An MBR partition should have the default \"Linux\" type ID\n83\n.\nDiscrete partitions\nSeparating out a path as a partition allows for the choice of a different filesystem and mount options. In some cases like a media partition, they can also be shared between operating systems.\nBelow are some example layouts that can be used when partitioning, and the following subsections detail a few of the directories which can be placed on their own separate partition and then\nmounted\nat mount points under\n/\n. See\nfile-hierarchy(7)\nfor a full description of the contents of these directories.\n/\nThe\nroot directory\nis the top of the hierarchy, the point where the primary filesystem is mounted and from which all other filesystems stem. All files and directories appear under the root directory\n/\n, even if they are stored on different physical devices. The contents of the root filesystem must be adequate to boot, restore, recover, and/or repair the system. Therefore, certain directories under\n/\nare not candidates for separate partitions.\nThe\n/\npartition or root partition is necessary and it is the most important. The other partitions can be replaced by it.\nWarning\nDirectories essential for booting (except for\n/boot\n)\nmust\nbe on the same partition as\n/\nor mounted in early userspace by the\ninitramfs\n. These essential directories are:\n/etc\nand\n/usr\n[2]\n.\n/\ntraditionally contains the\n/usr\ndirectory, which can grow significantly depending upon how much software is installed. 15–20 GiB should be sufficient for most users with modern hard disks. If you plan to store a swap file here and do not plan on using a separate\n/var\n, you might need a larger partition size (i.e. adding the size of your RAM to be able to hibernate and an additional 8–12 GiB for\n/var\n).\nA GPT partition should have the \"Linux root (x86-64)\" type GUID\n4F68BCE3-E8CD-4DB1-96E7-FBCAF984B709\n(\n8304\nfor\ngdisk\n). An MBR partition should have the default \"Linux\" type ID\n83\n.\n/boot\nThe\n/boot\ndirectory contains the\nvmlinuz\nand\ninitramfs\nimages as well as the boot loader configuration file and boot loader stages. It also stores data that is used before the kernel begins executing user-space programs.\n/boot\nis not required for normal system operation, but only during boot and kernel upgrades (when regenerating the initial ramdisk).\nWarning\nYour\nboot loader\nmust be capable of accessing the\n/boot\npartition. That means the boot loader must have support for everything starting from the block devices, stacked block devices (LVM, RAID, dm-crypt, LUKS, etc.) and ending with the file system on which the kernel(s) and initramfs image(s) reside.\nFile systems can get new features not yet supported by\nboot loaders\n(e.g.\narchlinux/packaging/packages/grub#7\n,\nFS#79857\n,\nFS#59047\n,\nFS#58137\n,\nFS#51879\n,\nFS#46856\n,\nFS#38750\n,\nFS#21733\nand\nfscrypt\nencrypted directories), making them unsuitable for a\n/boot\npartition unless disabling incompatible features. This can be typically avoided by using\nFAT32\nsince it is supported by practically everything and it will not be getting any new features.\nSee\nArch boot process#Boot loader\nfor more information on boot loader requirements and capabilities.\nNote\nOn UEFI systems it is possible to mount the\nEFI system partition\nto\n/boot\navoiding the need to create another separate partition. See\nEFI system partition#Mount the partition\nfor more information.\nWhen using an EFI system partition as\n/boot\n, the requirements are as described in the\nEFI system partition\narticle—the correct partition type must be set.\nIn other cases, it is recommended to set the partition type to\nExtended Boot Loader (XBOOTLDR) Partition\nwhich is GPT partition type GUID\nBC13C2FF-59E6-4262-A352-B275FD6F7172\n(\nea00\ntype for\ngdisk\n,\nxbootldr\ntype for\nfdisk\n) or MBR partition type ID\nea\n.\nIn both cases the suggested size for the partition is 1 GiB, which should give enough space to house multiple kernels. If still in doubt, 4 GiB ought to be enough for anybody.\n/home\nThe\n/home\ndirectory contains user-specific configuration files, caches, application data and media files.\nSeparating out\n/home\nallows\n/\nto be re-partitioned separately, but note that you can still reinstall Arch with\n/home\nuntouched even if it is not separate—the other top-level directories just need to be removed, and then pacstrap can be run.\nYou should not share home directories between users on different distributions, because they use incompatible software versions and patches. Instead, consider sharing a media partition or at least using different home directories on the same\n/home\npartition. The size of this partition varies.\nA GPT partition should have the \"Linux home\" type GUID\n933AC7E1-2EB4-4F13-B844-0E14E2AEF915\n(\n8302\ntype for\ngdisk\n,\nhome\ntype for\nfdisk\n). An MBR partition should have the default \"Linux\" type ID\n83\n.\nSwap\nA\nswap\nis a file or partition that provides disk space used as virtual memory. Swap files and swap partitions are equally performant, but swap files are much easier to resize as needed. A swap partition can\npotentially\nbe shared between operating systems, but not if hibernation is used.\nSince computers have gained memory capacities superior to a gibibit, the previous \"twice the amount of physical RAM\" rule has become outdated. A sane\ndefault size\nis 4 GiB.\nTo use hibernation (a.k.a. suspend to disk) it is advised to create the swap partition at the size of RAM. Although the kernel will try to compress the suspend-to-disk image to fit the swap space there is no guarantee it will succeed if the used swap space is significantly smaller than RAM. See\nPower management/Suspend and hibernate#Hibernation\nfor more information.\nA GPT partition should have the \"Linux swap\" type with GUID\n0657FD6D-A4AB-43C4-84E5-0933C84B4F4F\n(\n8200\ntype for\ngdisk\n,\nswap\ntype for\nfdisk\n). An MBR partition should have the \"Linux swap\" type ID\n82\n.\n/data\nOne can consider mounting a \"data\" partition to cover various files to be shared by all users. Using the\n/home\npartition for this purpose is fine as well. The size of this partition varies.\nA GPT partition should have the default \"Linux filesystem\" type GUID\n0FC63DAF-8483-4772-8E79-3D69D8477DE4\n. An MBR partition should have the default \"Linux\" type ID\n83\n.\n/var\nThe\n/var\ndirectory stores variable data such as spool directories and files, administrative and logging data,\npacman\n's cache, etc. It is used, for example, for caching and logging, and hence frequently read or written. Keeping it in a separate partition avoids running out of disk space due to flunky logs, etc.\nIt exists to make it possible to mount\n/usr\nas read-only. Everything that historically went into\n/usr\nthat is written to during system operation (as opposed to installation and software maintenance) must reside under\n/var\n.\nNote\n/var\ncontains many small files. The choice of file system type should consider this fact if a separate partition is used.\nSince\n/var\nis frequently read or written, it is recommended that you\nconsider the location of this partition on a spinning disk\n.\n/var\nwill contain, among other data, the\npacman\ncache. Retaining these packages is helpful in case a package upgrade causes instability, requiring a\ndowngrade\nto an older, archived package. The pacman cache will grow as the system is expanded and updated, but it can be safely\ncleared\nif space becomes an issue.\n8–12 GiB on a desktop system should be sufficient for\n/var\n, depending on how much software will be installed. For users of\nNVIDIA, Wayland and GDM\n, consider adding to this partition size as to\nhave enough free space to fit your whole video memory\n.\nA GPT partition should have the \"Linux variable data\" a.k.a. \"Linux /var\" type GUID\n4D21B016-B534-45C2-A9FB-5C16E091FD2D\n(\n8310\ntype for\ngdisk\n). An MBR partition should have the default \"Linux\" type ID\n83\n.\nExample layouts\nThis article or section needs expansion.\nReason:\nImprove current examples. (Discuss in\nTalk:Partitioning#Table draft 2\n)\nThe following examples use\n/dev/sda\nas the example disk with\n/dev/sda1\nas the first partition. The block device naming scheme will differ if you are partitioning a\nNVMe\ndisk (e.g.\n/dev/nvme0n1\nwith partitions starting from\n/dev/nvme0n1p1\n) or an SD card or eMMC disk (e.g.\n/dev/mmcblk0\nwith partitions starting from\n/dev/mmcblk0p1\n). See\nDevice file#Block device names\nfor more information.\nNote\nUEFI booting does not involve any \"boot\" flag, booting relies solely on the boot entries in NVRAM.\nParted\nand its front-ends use a \"boot\" flag on GPT to indicate that a partition is an EFI system partition.\nThere is no requirement to have all required/wanted partitions on the same disk or to use the same type of partition table for all disks.\nUEFI/GPT layout example\nMount point on the installed system\nPartition\nPartition type GUID\nSuggested size\n/boot\nor\n/efi\n1\n/dev/sda1\nC12A7328-F81F-11D2-BA4B-00A0C93EC93B\n:\nEFI system partition\n1 GiB\n[SWAP]\n/dev/sda2\n0657FD6D-A4AB-43C4-84E5-0933C84B4F4F\n: Linux\nswap\nAt least 4 GiB or the size of RAM to use\nhibernation\n/\n/dev/sda3\n4F68BCE3-E8CD-4DB1-96E7-FBCAF984B709\n: Linux x86-64 root (/)\nRemainder of the device. At least 23–32 GiB.\nBIOS/MBR layout example\nMount point on the installed system\nPartition\nPartition type ID\nBoot flag\nSuggested size\n[SWAP]\n/dev/sda1\n82\n: Linux\nswap\nNo\nAt least 4 GiB or the size of RAM to use\nhibernation\n/\n/dev/sda2\n83\n: Linux\nYes\nRemainder of the device. At least 23–32 GiB.\nN/A\nUnallocated space\n2\nN/A\nN/A\nAt least 16.5 KiB at the end of the disk\nBIOS/GPT layout example\nMount point on the installed system\nPartition\nPartition type GUID\nSuggested size\nNone\n/dev/sda1\n21686148-6449-6E6F-744E-656564454649\n:\nBIOS boot partition\n3\n1 MiB\n[SWAP]\n/dev/sda2\n0657FD6D-A4AB-43C4-84E5-0933C84B4F4F\n: Linux\nswap\nAt least 4 GiB or the size of RAM to use\nhibernation\n/\n/dev/sda3\n4F68BCE3-E8CD-4DB1-96E7-FBCAF984B709\n: Linux x86-64 root (/)\nRemainder of the device. At least 23–32 GiB.\nThe ESP can be mounted to\n/efi\nif the used boot loader is capable of accessing the file system (and everything above it) on which the kernel and initramfs images are located. See\nEFI system partition#Typical mount points\nand the warning in\nArch boot process#Boot loader\nfor details.\nAn unpartitioned space of at least 33 512-byte sectors (16.5 KiB) at the end of the disk to allow\nconverting to GPT\nin the future. The space will be required for the backup GPT header. The recommendation to preserve an unpartitioned space applies to all MBR partitioned disks.\nA BIOS boot partition is only required when using\nGRUB\nor\nLimine\nfor BIOS booting from a GPT disk, it is not needed when using other boot loaders. The partition has nothing to do with\n/boot\n, and it must not be formatted with a file system or mounted.\nTools\nPartitioning tools\nThe following programs are used to create and/or manipulate device partition tables and partitions. See the linked articles for the exact commands to be used.\nThis table will help you to choose utility for your needs:\nName\nPackage\nMBR\nGPT\nCLI\nTUI\nScripting utility\nfdisk\nutil-linux\nYes\nYes\nfdisk(8)\ncfdisk(8)\nsfdisk(8)\nGPT fdisk\ngptfdisk\nNo\nYes\ngdisk(8)\ncgdisk(8)\nsgdisk(8)\nParted\nparted\nYes\nYes\nparted(8)\nNo\nparted(8)\nGUI frontends\nblivet-gui\n— Graphical tool for storage configuration. It uses\nparted\nas backend via\npython-blivet\nAUR\nand\nlibblockdev\n.\nhttps://github.com/storaged-project/blivet-gui\n||\nblivet-gui\nAUR\nGNOME Disks\n— A GNOME utility for dealing with storage devices. It uses\nparted\nas backend via\nudisks2\nand\nlibblockdev\n. Part of\ngnome\n.\nhttps://apps.gnome.org/DiskUtility/\n||\ngnome-disk-utility\nGParted\n— Partition editor for graphically managing your disk partitions. It can be used to resize, copy and move partitions without data loss. It uses\nparted\nas backend.\nhttps://gparted.org/\n||\ngparted\nKDE Partition Manager\n— Utility to help you manage the disks, partitions, and file systems on your computer. It uses\nsfdisk\nas backend via\nkpmcore\n. Part of\nkde-system\n.\nhttps://apps.kde.org/partitionmanager/\n||\npartitionmanager\nBackup\nfdisk\ncan create a backup of the partitions table. See\nfdisk#Backup and restore partition table\n.\nGPT fdisk\ncan create a binary backup consisting of the protective MBR, the main GPT header, the backup GPT header, and one copy of the partition table. See\nGPT fdisk#Backup and restore partition table\n.\nRecovery\ngpart\n— A utility that guesses the contents of a destroyed MBR partition table. Its usage is explained in the\ngpart(8)\nman page.\nhttps://github.com/baruch/gpart\n||\ngpart\nGPT fdisk\n— A partitioning tool that can restore the primary GPT header (located at the start of the disk) from the secondary GPT header (located at the end of the disk) or vice versa.\nhttps://www.rodsbooks.com/gdisk/\n||\ngptfdisk\nTestDisk\n— A utility that supports recovering lost partitions on both MBR and GPT.\nhttps://www.cgsecurity.org/index.html?testdisk.html\n||\ntestdisk\nPartition alignment\nThe rule of thumb is to align a partition's start and size to mebibytes. See\nAdvanced Format#Partition alignment\n.\nWarning\nMisaligned partitions will prevent being able to use 4096 byte sectors with\ndm-crypt/LUKS\n.\nGPT kernel support\nThe\nCONFIG_EFI_PARTITION\noption in the kernel config enables GPT support in the kernel (despite the name, EFI PARTITION which looks close to\nEFI system partition\n). This option must be built in the kernel and not compiled as a loadable module. This option is required even if GPT disks are used only for data storage and not for booting. This option is enabled by default in all Arch's\nofficially supported kernels\n. In case of a custom kernel, enable this option by doing\nCONFIG_EFI_PARTITION=y\n.\nTroubleshooting\nTricking old BIOS into booting from GPT\nSome old BIOSes (from before year 2010) attempt to parse the boot sector and refuse to boot it if it does not contain a bootable MBR partition. This is a problem if one wants to use GPT on this disk, because, from the BIOS viewpoint, it contains only one, non-bootable, MBR partition of type\nee\n(i.e., the protective MBR partition). One can mark the protective MBR entry as bootable using\nfdisk -t mbr /dev/sda\n, and it will work on some BIOSes. However, the UEFI specification prohibits the protective MBR partition entry from being bootable, and UEFI-based boards do care about this, even in the legacy boot mode. So, this matters if one wants to create a GPT-based USB flash drive that is supposed to boot both on modern UEFI-based boards and also on old BIOSes that insist on finding a bootable MBR partition. It is not possible to solve this problem using traditional tools such as\nfdisk\nor\ngdisk\n, but it is possible to create a fake MBR partition entry suitable for both kinds of BIOSes manually as a sequence of bytes.\nThe command below will overwrite the second MBR partition slot and add a bootable partition there of type 0 (i.e. unused), covering only the first sector of the device. It will not interfere with the GPT or with the first MBR partition entry which normally contains a protective MBR partition.\n# printf '\\200\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\001\\0\\0\\0' | dd of=/dev/sda bs=1 seek=462\nThe end result will look like this:\n# fdisk -t mbr -l /dev/sda\nDisk /dev/sda: 232.9 GiB, 250059350016 bytes, 488397168 sectors\nDisk model: ST3250820AS\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisklabel type: dos\nDisk identifier: 0x00000000\nDevice     Boot Start       End   Sectors   Size Id Type\n/dev/sda1           1 488397167 488397167 232.9G ee GPT\n/dev/sda2  *        0         0         1   512B  0 Empty\nPartition table entries are not in disk order.\nDrives are not visible when firmware RAID is enabled\nIf a SATA or NVMe drive is visible in firmware setup, but not to Linux (e.g.\nfdisk -l\ndoes not list it), it is possible that the controller is in firmware RAID mode.\nFor NVMe, the\njournal\nshould show something like:\nkernel: ahci 0000:00:17.0: Found 1 remapped NVMe devices.\nkernel: ahci 0000:00:17.0: Switch your BIOS from RAID to AHCI mode to use them.\nThe solution is to enter firmware setup and disable NVMe RAID mode and change the\nSATA controller operation mode\nfrom\nRAID\nto\nAHCI\n. Mind that the setting may have a different name (e.g. \"Intel Rapid Storage Technology\", \"Intel RST\", \"Intel VMD controller\" or \"VMD\") and it could also be per-controller or per-port.\nWarning\nWhen\ndual booting with Windows\n, preparations need to be made before changing the controller mode. See\nHow to Enable AHCI in Windows 8 and Windows 10 after Installation\n.\nNote\nSome firmware do not have a dedicated NVMe RAID mode setting and, despite the terms not making any sense, use the SATA controller operation mode setting for the NVMe controller too. These firmware simply interpret \"SATA operation mode\" being set to \"AHCI\" on NVMe controllers to mean \"use native operating mode without firmware RAID\".\n[3]\n[4]\n[5]\nSee also\nWikipedia:Disk partitioning\nWikipedia:Binary prefix\nUnderstanding Disk Drive Terminology\nRod Smith's page on\nWhat's a GPT?\nand\nBooting OSes from GPT\nMake the most of large drives with GPT and Linux - IBM Developer\nMicrosoft's Windows and GPT FAQ\nPartition Alignment\n(with examples)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Partitioning&oldid=847135\n\"\nCategories\n:\nFile systems\nBoot process\nSystem recovery\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nPartitioning\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Partitioning"}}
{"text": "EFI system partition - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nEFI system partition\n7 languages\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nUnified Extensible Firmware Interface\nBoot loader\nThe\nEFI system partition\n(also called ESP) is an OS independent partition that acts as the storage place for the UEFI boot loaders, applications  and drivers to be launched by the UEFI firmware. It is mandatory for UEFI boot.\nCheck for an existing partition\nIf you are installing Arch Linux on an UEFI-capable computer with an installed operating system, like\nWindows\n10 for example, it is very likely that you already have an EFI system partition.\nTo find out the disk partition scheme and the system partition, use\nfdisk\nas root on the disk you want to boot from:\n# fdisk -l /dev/sd\nx\nThe command returns:\nThe disk's partition table: it indicates\nDisklabel type: gpt\nif the partition table is\nGPT\nor\nDisklabel type: dos\nif it is\nMBR\n.\nThe list of partitions on the disk: Look for the EFI system partition in the list, it is usually at least 100 MiB in size and has the type\nEFI System\nor\nEFI (FAT-12/16/32)\n. To confirm this is the ESP,\nmount\nit and check whether it contains a directory named\nEFI\n, if it does this is definitely the ESP.\nTip\nTo find out whether it is a FAT12, FAT16 or FAT32 file system, follow\nFAT#Detecting FAT type\n.\nWarning\nWhen dual-booting, avoid reformatting the ESP if possible, as it may contain files required to boot other operating systems. If the existing ESP is smaller than the\nsuggested minimum size\n, you may need to\nreplace it with a larger one\n.\nIf you found an acceptable existing EFI system partition, simply proceed to\n#Mount the partition\n. If you did not find one, you will need to create it, proceed to\n#Create the partition\n.\nCreate the partition\nThe following two sections show how to create an EFI system partition (ESP).\nWarning\nThe EFI system partition must be a physical partition in the main partition table of the disk, not under LVM or software RAID etc.\nThe partition size should provide adequate space for storing boot loaders and other files required for booting.\nIt is recommended to make the partition 1 GiB in size to ensure it has adequate space for multiple kernels or unified kernel images, a boot loader, firmware updates files and any other operating system or OEM files. If still in doubt,\n4 GiB\nought to be enough for anybody.\nFor tools like\nLimine boot loader with Snapper integration for Btrfs\n(which supports creating multiple bootable snapshots) and\nArchiso on ESP\n(a bootable ISO image for system recovery without external media) consider an even larger size (e.g. 8 GiB).\nNote\nIt is possible to use a smaller partition, but mind the potential compatibility issues:\nFor early and/or buggy UEFI implementations the size of at least 512 MiB might be needed.\n[1]\nIf you plan to mount the partition to\n/boot\nand will not install more than one kernel, then 400 MiB will be sufficient.\nWhen\ndual booting with Windows\n, the size should be at least 300 MiB for drives with a 4096 logical sector size (\nAdvanced Format\n4Kn drives)\n[2]\nor at least 100 MiB otherwise.\n[3]\nTo ensure the partition can be formatted to FAT32, it should be at least 36 MiB on drives with 512 byte logical sector size and 260 MiB on drives with 4096 logical sector size.\n[4]\nIf none of these are relevant issues, the partition size can be as small as 2 MiB, in which case it could house nothing more than a boot loader.\nGPT partitioned disks\nEFI system partition on a\nGUID Partition Table\nis identified by the\npartition type GUID\nC12A7328-F81F-11D2-BA4B-00A0C93EC93B\n.\nChoose one\nof the following methods to create an ESP for a GPT partitioned disk:\nfdisk\n: Create a partition and use the\nt\ncommand to\nchange its partition type\nto\nEFI System\nusing the alias\nuefi\n.\ngdisk\n: Create a partition with partition type\nEF00\n.\nGNU Parted\n: Create a partition with\nfat32\nas the file system type and set the\nesp\nflag on it.\nAfter creating the partition, it should be formatted with a file system. Proceed to the\n#Format the partition\nsection below.\nMBR partitioned disks\nWarning\nIt is highly recommended to use GPT instead of MBR.\nSome firmware might not support UEFI/MBR booting due to it not being supported by\nWindows Setup\n.\nbootctl\ndoes not support installing\nsystemd-boot\nto an MBR partitioned disk; see\nsystemd issue 1125\n.\nSee also\nPartitioning#Choosing between GPT and MBR\nfor the limits of MBR and the advantages of GPT in general.\nEFI system partition on a\nMaster Boot Record\npartition table is identified by the\npartition type ID\nEF\n.\nChoose one\nof the following methods to create an ESP for a MBR partitioned disk:\nfdisk\n: Create a primary partition and and use the\nt\ncommand to\nchange its partition type\nto\nEFI (FAT-12/16/32)\n.\nGNU Parted\n: Create a primary partition with\nfat32\nas the file system type and set the\nesp\nflag on it.\nAfter creating the partition, it should be formatted with a file system. Proceed to the\n#Format the partition\nsection below.\nFormat the partition\nThe UEFI specification mandates support for the FAT12, FAT16, and FAT32 file systems (see\nUEFI specification version 2.11, section 13.3.1.1\n), but any conformant vendor can optionally add support for additional file systems; for example, the firmware in Apple\nMacs\nsupports the HFS+ file system.\nTo prevent potential issues with other operating systems and since the UEFI specification says that UEFI \"encompasses the use of FAT32 for a system partition, and FAT12 or FAT16 for removable media\"\n[5]\n, it is recommended to use\nFAT32\n. Use the\nmkfs.fat(8)\nutility from\ndosfstools\n:\n# mkfs.fat -F 32 /dev/sd\nxY\nIf you get the message\nWARNING: Number of clusters for 32 bit FAT is less than suggested minimum.\nand you cannot\ncreate\na larger ESP, reduce cluster size with\nmkfs.fat -s 2 -F 32 ...\nor\n-s 1\n; otherwise the partition may be unreadable by UEFI. See\nmkfs.fat(8)\nfor supported cluster sizes.\nFor partitions smaller than 32 MiB using FAT32 may not be possible. In which case, format it to FAT16 or even FAT12. For example, a 2 MiB ESP will only be able to support FAT12:\n# mkfs.fat -F 12 /dev/sd\nxY\nMount the partition\nThe kernels, initramfs files, and, in most cases, the processor's\nmicrocode\n, need to be accessible by the\nboot loader\nor UEFI itself to successfully boot the system. Thus if you want to keep the setup simple, your boot loader choice limits the available mount points for EFI system partition.\nNote\nIf the ESP is not mounted to\n/boot\n, make sure to not rely on the\nsystemd automount mechanism\n(including that of\nsystemd-gpt-auto-generator\n) during kernel upgrades. Always mount it manually prior to any system or kernel update, otherwise you may not be able to mount it after the update, locking you in the currently running kernel with no ability to update the copy of kernel on the ESP.\nAlternatively\npreload the required kernel modules on boot\n, e.g.:\n/etc/modules-load.d/vfat.conf\nvfat\nnls_cp437\nnls_ascii\nTypical mount points\nThe three typical scenarios for mounting the EFI system partition are:\nmount\nthe ESP to\n/boot\n:\nThis facilitates system maintenance and administration, as\n/boot\nis the default path where\nmicrocode\npackages place the CPU microcode initramfs files and where\nmkinitcpio\nplaces\nkernels\nand\ninitramfs\nimages.\nThis ensures that the above files are accessible to most\nboot loaders\n, as not all of them can access files on other volumes.\nThis prevents setting file-specific\npermissions\nand/or\nextended attributes\n, as FAT sets global permissions at mount time\nThis increases the size requirement for the ESP, as files normally installed in\n/boot\nwill join the ones used for UEFI booting.\nThis exposes the kernel and initramfs images to potentially hazardous manipulation from bootable drives or other operating systems when dual-booting.\nThis makes\nencrypting /boot\nimpossible, as the boot loader and its files have to be accessible by the firmware.\nThis makes root volume snapshots (using\nBtrfs\n,\nBcachefs\n,\nZFS\n,\nLVM\n) less effective as\n/boot\ncontent would not be included. In case of kernel updates, returning to a snapshot with older kernel version would draw the system unbootable and require manually\ndowngrading the kernel\nusing external media.\nmount\nthe ESP to\n/efi\n:\nNote\nOnly\nGRUB\nand\nrEFInd\nsupport this scheme at the moment.\nIt ensures a separation of concerns between operating system and UEFI files, which may include other operating system files that are better left alone.\nIt avoids increasing the size requirement of the ESP by not placing the files installed to\n/boot\nin it: only the EFI binaries (the boot loader (and optionally drivers) and/or the unified kernel image) will be stored on the ESP, which saves storage space.\nIt allows to preserve Linux-specific filesystem permissions for files residing in\n/boot\n, avoiding FAT limitations.\nIt allows to mount separately the ESP according to the need,\ne.g.\nonly when upgrading the\nboot loader\n.\nIf using\nsystem encryption\nwith the appropriate setup, it allows to leave only a few required files unencrypted while\n/boot\nremains protected: this can be useful for\nunified kernel images\nor\nboot loaders\nthat have file system drivers capable of accessing the kernel(s) and files that are stored elsewhere.\nmount\nthe ESP to\n/efi\nand additionally mount an \"Extended Boot Loader Partition\" (XBOOTLDR) to\n/boot\n. This can be useful when a previously created ESP is too small to hold multiple boot loaders and/or kernels but the ESP cannot be easily resized (such as when installing Linux after Windows to\ndual boot\n). This method is supported by at least\nsystemd-boot\n.\nNote\n/efi\nis a replacement\n[6]\n[7]\nfor the historical and now discouraged ESP mountpoint\n/boot/efi\n.\nThe\n/efi\ndirectory is not available by default, you will need to first\ncreate\nit before mounting the ESP to it.\nAlternative mount points\nIf you do not use one of the\n#Typical mount points\n, you will need to copy your boot files to ESP (referred to hereafter as\nesp\n).\n# mkdir -p\nesp\n/EFI/arch\n# cp -a /boot/vmlinuz-linux\nesp\n/EFI/arch/\n# cp -a /boot/initramfs-linux.img\nesp\n/EFI/arch/\n# cp -a /boot/initramfs-linux-fallback.img\nesp\n/EFI/arch/\nNote\nIf you use\nexternal microcode initramfs images\n, they will also need to be copied to the boot-entry location.\nFurthermore, you will need to keep the files on the ESP up-to-date with later kernel updates. Failure to do so could result in an unbootable system. The following sections discuss several mechanisms for automating it.\nUsing bind mount\nInstead of mounting the ESP itself to\n/boot\n, you can mount a directory of the ESP to\n/boot\nusing a bind\nmount\n(see\nmount(8)\n). This allows\npacman\nto update the kernel directly while keeping the ESP organized to your liking.\nNote\nThis requires a\nkernel\nand\nboot loader\ncompatible with FAT32. This is not an issue for a regular Arch install, but could be problematic for other distributions (namely those that require symlinks in\n/boot/\n). See the forum post\n[8]\n.\nJust like in\n#Alternative mount points\n, copy all boot files to a directory on your ESP, but mount the ESP\noutside\n/boot\n. Then bind mount the directory:\n# mount --bind\nesp\n/EFI/arch /boot\nAfter verifying success, edit your\nFstab\nto make the changes persistent:\n/etc/fstab\nesp\n/EFI/arch /boot none defaults,bind 0 0\nUsing systemd\nsystemd\nfeatures event triggered tasks. In this particular case, the ability to detect a change in path is used to sync the EFISTUB kernel and initramfs files when they are updated in\n/boot/\n. The file watched for changes is\ninitramfs-linux-fallback.img\nsince this is the last file built by mkinitcpio, to make sure all files have been built before starting the copy. The\nsystemd\npath and service files to be created are:\n/etc/systemd/system/efistub-update.path\n[Unit]\nDescription=Copy EFISTUB Kernel to EFI system partition\n[Path]\nPathChanged=/boot/initramfs-linux-fallback.img\n[Install]\nWantedBy=multi-user.target\nWantedBy=system-update.target\n/etc/systemd/system/efistub-update.service\n[Unit]\nDescription=Copy EFISTUB Kernel to EFI system partition\n[Service]\nType=oneshot\nExecStart=/usr/bin/cp -af /boot/vmlinuz-linux\nesp\n/EFI/arch/\nExecStart=/usr/bin/cp -af /boot/initramfs-linux.img\nesp\n/EFI/arch/\nExecStart=/usr/bin/cp -af /boot/initramfs-linux-fallback.img\nesp\n/EFI/arch/\nThen\nenable\nand\nstart\nefistub-update.path\n.\nTip\nFor\nSecure Boot\nwith your own keys, you can set up the service to also sign the image using\nsbsigntools\n:\nExecStart=/usr/bin/sbsign --key\n/path/to/db.key\n--cert\n/path/to/db.crt\n--output\nesp\n/EFI/arch/vmlinuz-linux /boot/vmlinuz-linux\nUsing filesystem events\nFilesystem events\ncan be used to run a script syncing the EFISTUB Kernel after kernel updates. An example with\nincron\nfollows.\n/usr/local/bin/efistub-update\n#!/bin/sh\ncp -af /boot/vmlinuz-linux\nesp\n/EFI/arch/\ncp -af /boot/initramfs-linux.img\nesp\n/EFI/arch/\ncp -af /boot/initramfs-linux-fallback.img\nesp\n/EFI/arch/\nNote\nThe first parameter\n/boot/initramfs-linux-fallback.img\nis the file to watch. The second parameter\nIN_CLOSE_WRITE\nis the action to watch for. The third parameter\n/usr/local/bin/efistub-update\nis the script to execute.\n/etc/incron.d/efistub-update.conf\n/boot/initramfs-linux-fallback.img IN_CLOSE_WRITE /usr/local/bin/efistub-update\nIn order to use this method,\nenable\nthe\nincrond.service\n.\nUsing mkinitcpio preset\nAs the presets in\n/etc/mkinitcpio.d/\nsupport shell scripting, the kernel and initramfs can be copied by just editing the presets.\nReplacing the mkinitcpio hook\nEdit the file\n/etc/mkinitcpio.d/linux.preset\n:\n/etc/mkinitcpio.d/linux.preset\n# mkinitcpio preset file for the 'linux' package\n# Directory to install the kernel, the initramfs...\nESP_DIR=\"\nesp\n/EFI/arch\"\n#ALL_config=\"/etc/mkinitcpio.conf\"\nALL_kver=\"${ESP_DIR}/vmlinuz-linux\"\nPRESETS=('default' 'fallback')\n#default_config=\"/etc/mkinitcpio.conf\"\ndefault_image=\"${ESP_DIR}/initramfs-linux.img\"\ndefault_options=\"\"\n#fallback_config=\"/etc/mkinitcpio.conf\"\nfallback_image=\"${ESP_DIR}/initramfs-linux-fallback.img\"\nfallback_options=\"-S autodetect\"\nTo test that, just run:\n# rm /boot/initramfs-linux-fallback.img /boot/initramfs-linux.img\n# mv /boot/vmlinuz-linux\nesp\n/EFI/arch/\n# mkinitcpio -p linux\nAnother example\n/etc/mkinitcpio.d/linux.preset\nESP_DIR=\"\nesp\n/EFI/arch\"\n#ALL_config=\"/etc/mkinitcpio.conf\"\nALL_kver=\"$ESP_DIR/vmlinuz-linux$suffix\"\nPRESETS=('default')\ndefault_config=\"/etc/mkinitcpio.conf\"\ndefault_image=\"$ESP_DIR/initramfs-linux$suffix.img\"\n/etc/mkinitcpio.d/linux-zen.preset\nsuffix='-zen'\nsource /etc/mkinitcpio.d/linux.preset\nUsing a mkinitcpio post hook\nA\nmkinitcpio post hook\ncan be used to copy kernels and initramfs images to a desired directory after the initramfs is generated.\nCreate\nthe following file and make it\nexecutable\n:\n/etc/initcpio/post/copy-kernel-and-initramfs\n#!/usr/bin/env bash\nkernel=\"$1\"\ninitramfs=\"$2\"\ntarget_dir=\"\nesp\n/EFI/arch\"\nfiles_to_copy=()\nfor file in \"$kernel\" \"$initramfs\"; do\nif [[ -n \"$file\" ]] && ! cmp -s -- \"$file\" \"${target_dir}/${file##*/}\"; then\nfiles_to_copy+=(\"$file\")\nfi\ndone\n(( ! ${#files_to_copy[@]} )) && exit 0\ncp -af -- \"${files_to_copy[@]}\" \"${target_dir}/\"\nUsing pacman hook\nA last option relies on the\npacman hooks\nthat are run at the end of the transaction.\nThe first file is a hook that monitors the relevant files, and it is run if they were modified in the former transaction.\n/etc/pacman.d/hooks/999-kernel-efi-copy.hook\n[Trigger]\nType = Path\nOperation = Install\nOperation = Upgrade\nTarget = usr/lib/modules/*/vmlinuz\nTarget = usr/lib/initcpio/*\nTarget = boot/*-ucode.img\n[Action]\nDescription = Copying linux and initramfs to EFI directory...\nWhen = PostTransaction\nExec = /usr/local/bin/kernel-efi-copy.sh\nThe second file is the script itself. Create the file and make it\nexecutable\n:\n/usr/local/bin/kernel-efi-copy.sh\n#!/bin/sh\n#\n# Copy kernel and initramfs images to EFI directory\n#\nESP_DIR=\"\nesp\n/EFI/arch\"\nfor file in /boot/vmlinuz*\ndo\ncp -af \"$file\" \"$ESP_DIR/$(basename \"$file\").efi\"\n[ $? -ne 0 ] && exit 1\ndone\nfor file in /boot/initramfs*\ndo\ncp -af \"$file\" \"$ESP_DIR/\"\n[ $? -ne 0 ] && exit 1\ndone\n[ -e /boot/intel-ucode.img ] && cp -af /boot/intel-ucode.img \"$ESP_DIR/\"\n[ -e /boot/amd-ucode.img ] && cp -af /boot/amd-ucode.img \"$ESP_DIR/\"\nexit 0\nTips and tricks\nReplace the partition with a larger one\nOn a disk with a preexisting operating system, the EFI system partition may be smaller than recommended in\n#Create the partition\n. E.g. Windows Setup creates a measly 100 MiB EFI system partition on non-4Kn drives.\nIn such cases, it may be a good idea to create a new, larger EFI system partition to prevent running out of space on it.\nFree up space for a new partition in Windows\nIn Windows, partitions can be either managed graphically with Disk Management (\ndiskmgmt.msc\n) or from the command line with the\ndiskpart.exe\nutility.\nRun\ndiskmgmt.msc\nas Administrator.\nRight click on the \"(C:)\" partition (the only one of the default Windows-created partitions which can be resized online) and select\nShrink Volume...\n.\nEnter\n4096\nas the amount to shrink and click\nShrink\n.\nThere should now be a 4 GiB unallocated space after the \"(C:)\" partition.\nBoot into Arch Linux or the Arch Linux installation medium to proceed to creating a new partition.\nDelete the old partition and create a new one\nFirst, make sure to backup the contents of the EFI system partition. For example, with\nesp\nbeing its mountpoint:\n# cp -a\nesp\n/esp_backup\nUnmount the EFI system partition:\n# umount\nesp\nNote\nOn an installed system, you may need to additionally\nstop\nesp\n.mount\nand\nesp\n.automount\nunits to prevent systemd from automounting it again.\nRun\nblkid\nand take note of the UUID and PARTUUID values. They will later be reused for the new partition.\n# blkid\n/dev/sd\nxY\n: UUID=\"\nXXXX-XXXX\n\" BLOCK_SIZE=\"512\" TYPE=\"vfat\" PARTLABEL=\"EFI system partition\" PARTUUID=\"\nYYYYYYYY-YYYY-YYYY-YYYY-YYYYYYYYYYYY\n\"\nDelete the old partition using\nsgdisk\nfrom\ngptfdisk\n:\n# sgdisk --delete=\nY\n/dev/sd\nx\nCreate a new partition in the largest unallocated space while reusing the old PARTUUID and PARTLABEL:\n# sgdisk --align-end --largest-new=0 --typecode=0:ef00 --change-name=0:'EFI system partition' --partition-guid=0:\nYYYYYYYY-YYYY-YYYY-YYYY-YYYYYYYYYYYY\n/dev/sd\nx\nTell the kernel to reread the partition table using\npartprobe(8)\nfrom\nparted\n:\n# partprobe /dev/sd\nx\nConfirm the new, 4 GiB in size, EFI system partition is created by listing the partitions with\nfdisk\n:\n# fdisk -l /dev/sd\nx\n...\nDevice         Start       End   Sectors  Size Type\n/dev/sd\nx\n1  158099456 166488063   8388608    4G EFI System\n/dev/sd\nx\n2     206848    239615     32768   16M Microsoft reserved\n/dev/sd\nx\n3     239616 158099455 157859840 75.3G Microsoft basic data\n/dev/sd\nx\n4  166488064 167768063   1280000  625M Windows recovery environment\n/dev/sd\nx\n5  167768064 176156671   8388608    4G Linux swap\n/dev/sd\nx\n6  176156672 243265535  67108864   32G Linux root (x86-64)\nPartition table entries are not in disk order.\nPartition numbers are not resorted when deleting and creating partitions, so the EFI system partition number on the disk will likely be the same as before.\nFormat the partition to FAT32 reusing the old UUID (while removing the dash from it):\n# mkfs.fat -F 32 -i\nXXXXXXXX\n/dev/sd\nxY\nFinally, mount the new partition and restore its contents from backup:\n# mount /dev/sd\nxY\nesp\n# cp -a /esp_backup/.\nesp\n/\nIf you previously stopped\nesp\n.automount\n,\nstart\nit again.\nSacrifice an adjacent swap partition to enlarge the ESP\nIf there is a swap partition right after the EFI system partition, you can sacrifice it to give space for enlarging the EFI system partition. E.g. with a layout similar to:\n# fdisk -l /dev/sd\nx\n...\nDevice       Start       End   Sectors  Size Type\n/dev/sd\nx\n1     2048    616447    614400  300M EFI System\n/dev/sd\nx\n2   616448   9005055   8388608    4G Linux swap\n/dev/sd\nx\n3  9005056 125827071 116822016 55.7G Linux root (x86-64)\nFirst,\ndeactivate the swap partition\nand remove it from\nfstab\n.\nUse\nfdisk\nto delete the swap partition and enlarge the EFI system partition.\nRun:\n# fdisk /dev/sd\nx\nUse the\nd\ncommand to delete the swap partition (partition number\n2\nin the example layout above).\nUse the\ne\ncommand to enlarge the EFI system partition (partition number\n1\nin the example layout above). Use the suggested default value for the new size and press\nEnter\n.\nWrite changes to disk and exit via the\nw\ncommand.\nAfter the partition is resized, you need to resize the file system in it. Since\nfatresize(1)\ndoes not work\nand libparted\ncannot resize FAT volumes of certain sizes\n, the only option is to backup the files from the existing file system and create a new one that takes up all space of the partition.\nTake note of the file system\nUUID\nto allow reusing it for the new file system:\n$ lsblk -dno UUID /dev/sd\nxY\nXXXX-XXXX\nBackup the contents of the EFI system partition. For example, with\nesp\nbeing its mountpoint:\n# cp -a\nesp\n/esp_backup\nUnmount the EFI system partition:\n# umount\nesp\nNote\nOn an installed system, you may need to additionally\nstop\nesp\n.mount\nand\nesp\n.automount\nunits to prevent systemd from automounting it again.\nWipe the file system signature from the partition to avoid any artifacts from the old file system:\n# wipefs -af /dev/sd\nxY\nFormat the partition to FAT32 reusing the old UUID (while removing the dash from it):\n# mkfs.fat -F 32 -i\nXXXXXXXX\n/dev/sd\nxY\nFinally, mount the new partition and restore its contents from backup:\n# mount /dev/sd\nxY\nesp\n# cp -a /esp_backup/.\nesp\n/\nIf you previously stopped\nesp\n.automount\n,\nstart\nit again.\nNow that the swap partition is gone, set up swap on a\nswap file\n.\nTroubleshooting\nESP on software RAID1\nIt is possible to make the ESP part of a RAID1 array, but doing so brings the risk of data corruption, and further considerations need to be taken when creating the ESP. See\n[9]\nand\n[10]\nfor details and\nUEFI booting and RAID1\nfor an in-depth guide with a solution.\nThe key part is to use\n--metadata 1.0\nin order to keep the RAID metadata at the end of the partition, otherwise the firmware will not be able to access it:\n# mdadm --create --verbose --level=1\n--metadata=1.0\n--raid-devices=2 /dev/md/ESP /dev/sda\nX\n/dev/sdb\nY\nAlternatively, as the ESP is not often updated, a secondary ESP can be managed by copying the primary ESP to the secondary one on a different disk during relevant updates. A boot entry for the secondary ESP can then be added manually using\nefibootmgr\n. See\nDebian:UEFI#RAID for the EFI System Partition\nfor an implementation example. Note that while this avoids some risks of the RAID approach, it only works when using a single OS.\nFirmware does not see the EFI directory\nIf you give the FAT file system a\nvolume name (i.e. file system label)\n, be sure to name it something other than\nEFI\n. That can trigger a bug in some firmwares (due to the volume name matching the EFI directory name) that will cause the firmware to act like the EFI directory does not exist.\nHibernation and multi boot systems\nIf you are running a multi boot system (including but not limited to\ndual booting with Windows\n) and want to be able to boot into your other system while your main Arch Linux is hibernated, you must take extra caution not to mount the ESP in both systems, as this will likely cause data corruption and I/O errors on usage.\nThere are three possible mitigation strategies:\nUse a separate EFI system partition per system. Most UEFIs support this as long as the ESPs reside on physically different disks, but hardware support and usability may vary.\nUse\nsystemd's automount mechanism\nto only mount the ESP when needed. Make sure to also specify an idle timeout (\nx-systemd.idle-timeout=\noption), otherwise systemd would not unmount the ESP after usage. However, note two limitations: First, unless you mount the ESP to\n/boot\n, you must not rely on the automount during kernel upgrades (see\nnote above\n). Second, you must make sure not to hibernate the system before systemd has auto-unmounted the ESP after usage (see\nautomatic unmount\n).\nMount the ESP at\n/efi\n, and unmount it before and remount it after hibernating the system. See\ninstructions below\n.\nBy successfully applying one of the mitigation strategies above you may hibernate this system, but not the other systems unless you apply one of the mitigation strategies to them as well. For example, applying one of the solutions to your main Arch Linux allows you to hibernate Arch Linux and boot into another e.g. Ubuntu Linux, but not to hibernate that Ubuntu Linux and boot into your main Arch Linux. Allowing this with Windows requires separate EFI system partitions.\nStrictly speaking, this issue of mounting the same filesystem multiple times at once is neither limited to the EFI system partition, nor to hibernating the system. However, it is particularly relevant for the ESP, because the ESP is expected to be shared across multiple systems. The mitigation strategies can be adapted for other use cases as well.\nUnmount and remount ESP on hibernation\nIf you choose option 3 above, you can create and\nenable\nthe following systemd system service that unmounts the ESP before hibernating the system and remounts it after resuming:\n/etc/systemd/system/efi-remount-on-hibernate.service\n[Unit]\nDescription=Unmount and remount EFI system partition on hibernation\nBefore=hibernate.target hybrid-sleep.target suspend-then-hibernate.target\nStopWhenUnneeded=yes\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecCondition=/usr/bin/systemctl is-active --quiet efi.mount\nExecStart=/usr/bin/systemctl stop efi.mount\nExecStop=/usr/bin/systemctl start efi.mount\n[Install]\nWantedBy=hibernate.target hybrid-sleep.target suspend-then-hibernate.target\nHowever, since\nefi.mount\nis pulled in as a requirement for\nlocal-fs.target\nby default, stopping\nefi.mount\nalso permanently brings down\nlocal-fs.target\n. This might have all sorts of negative side-effects, including ordering issues when shutting down the system, which might trigger systemd to auto-mask\nefi.mount\nas defective. This can be mitigated by telling systemd that\nefi.mount\nis not required by\nlocal-fs.target\n, but just wanted by it. To ensure this you must add the following mount options to\n/efi\nin\n/etc/fstab\n:\nx-systemd.wanted-by=local-fs.target,x-systemd.after=local-fs-pre.target,x-systemd.before=local-fs.target\nSee also\nThe EFI system partition and the default boot behavior\nMulti Boot Linux With One Boot Partition | John Ramsden\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=EFI_system_partition&oldid=852076\n\"\nCategory\n:\nBoot process\nSearch\nSearch\nEFI system partition\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/EFI_system_partition"}}
{"text": "Unified Extensible Firmware Interface - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nUnified Extensible Firmware Interface\n5 languages\nEspañol\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nEFI system partition\nGUID Partition Table\nSecure Boot\nUnified kernel image\nThe\nUnified Extensible Firmware Interface\n(UEFI)\nis an interface between operating systems and firmware. It provides a standard environment for booting an operating system and running pre-boot applications.\nIt is distinct from the\nMBR boot code\nmethod that was used by legacy\nBIOS\nsystems. See\nArch boot process\nfor their differences and the boot process using UEFI. To set up UEFI boot loaders, see\nArch boot process#Boot loader\n.\nNote\nEarly vendor UEFI implementations may carry more bugs than their BIOS counterparts. Consider using legacy BIOS booting for such systems if you encounter unsolvable issues.\nApple UEFI implementation does not conform to the standard. Unless stated explicitly, these instructions are general and some of them may not work or may be different for\nMacs\n.\nUEFI firmware bitness\nUnder UEFI, every program whether it is an operating system loader or a utility (e.g. a memory testing or recovery tool), should be an EFI application corresponding to the UEFI firmware bitness/architecture.\nThe vast majority of x86_64 systems, including recent Apple Macs, use x64 (64-bit) UEFI firmware. The only known devices that use IA32 (32-bit) UEFI are older (pre 2008) Apple Macs, Intel Atom System-on-Chip systems (as on 2 November 2013)\n[1]\nand some older Intel server boards that are known to operate on Intel EFI 1.10 firmware.\nAn x64 UEFI firmware does not include support for launching 32-bit EFI applications (unlike x86_64 Linux and Windows versions which include such support). Therefore the EFI application must be compiled for that specific firmware processor bitness/architecture.\nNote\nSystems with IA32 UEFI require using a\nboot loader\nthat supports mixed mode booting.\nChecking the firmware bitness\nThe firmware bitness can be checked from a booted operating system.\nFrom Linux\nOn distributions running Linux kernel 4.0 or newer, the UEFI firmware bitness can be found via the sysfs interface. Run:\n$ cat /sys/firmware/efi/fw_platform_size\nIt will return\n64\nfor a 64-bit (x64) UEFI or\n32\nfor a 32-bit (IA32) UEFI. If the file does not exist, you have not\nbooted in UEFI mode\n.\nFrom macOS\nPre-2008\nMacs\nmostly have IA32 EFI firmware while >=2008 Macs have mostly x64 EFI. All Macs capable of running Mac OS X Snow Leopard 64-bit Kernel have x64 EFI 1.x firmware.\nTo find out the arch of the EFI firmware in a Mac, type the following into the Mac OS X terminal:\n$ ioreg -l -p IODeviceTree | grep firmware-abi\nIf the command returns\nEFI32\n, it is IA32 (32-bit) EFI firmware. If it returns\nEFI64\n, it is x64 EFI firmware. Most of the Macs do not have UEFI 2.x firmware as Apple's EFI implementation is not fully compliant with UEFI 2.x specification.\nFrom Microsoft Windows\n64-bit versions of Windows do not support booting on a 32-bit UEFI. So, if you have a 32-bit version of Windows booted in UEFI mode, you have a 32-bit UEFI.\nTo check the bitness run\nmsinfo32.exe\n. In the\nSystem Summary\nsection look at the values of \"System Type\" and \"BIOS mode\".\nFor 64-bit Windows on a 64-bit UEFI, it will be\nSystem Type: x64-based PC\nand\nBIOS mode: UEFI\n. For 32-bit Windows on a 32-bit UEFI—\nSystem Type: x86-based PC\nand\nBIOS mode: UEFI\n. If the \"BIOS mode\" is not\nUEFI\n, Windows is not booted in UEFI mode.\nUEFI variables\nUEFI defines variables through which an operating system can interact with the firmware. UEFI boot variables are used by the boot loader and used by the operating system only for early system start-up. UEFI runtime variables allow an operating system to manage certain settings of the firmware like the UEFI boot manager or managing the keys for UEFI Secure Boot protocol etc. You can get the list using:\n$ efivar --list\nUEFI variables support in Linux kernel\nLinux kernel exposes UEFI variables data to userspace via\nefivarfs\n(\nEFI\nVAR\niable\nF\nile\nS\nystem) interface (\nCONFIG_EFIVAR_FS\n) - mounted using\nefivarfs\nkernel module at\n/sys/firmware/efi/efivars\n- it has no maximum per-variable size limitation and supports UEFI Secure Boot variables. Introduced in kernel 3.8.\nRequirements for UEFI variable support\nKernel should be booted in UEFI mode via the\nEFI boot stub\n(optionally using a\nboot manager\n) or by a UEFI\nboot loader\n, not via BIOS or CSM, or Apple's Boot Camp which is also a CSM.\nEFI Runtime Services support should be present in the kernel (\nCONFIG_EFI=y\n, check if present with\nzgrep CONFIG_EFI /proc/config.gz\n).\nEFI Runtime Services in the kernel SHOULD NOT be disabled via the\nkernel command line\n, i.e.\nnoefi\nkernel parameter SHOULD NOT be used.\nefivarfs\nfilesystem should be mounted at\n/sys/firmware/efi/efivars\n, otherwise follow\n#Mount efivarfs\nsection below.\nefivar\nshould list (option\n-l\n/\n--list\n) the UEFI variables without any error.\nIf UEFI Variables support does not work even after the above conditions are satisfied, try the below workarounds:\nIf listing of the UEFI variables (\nefivar -l\n) leads to\nefivar: error listing variables: Function not implemented\nand the system is booted into a\nrealtime kernel\n, add\nefi=runtime\nto the\nkernel parameters\nand reboot (efivarfs functionality is disabled by default on those kernels).\nSee\n#Userspace tools are unable to modify UEFI variable data\nfor more troubleshooting steps\nMount efivarfs\nIf\nefivarfs\nis not automatically mounted at\n/sys/firmware/efi/efivars\nby\nsystemd\nduring boot, you need to manually mount it to expose UEFI variables to\nuserspace tools\nlike\nefibootmgr\n:\n# mount -t efivarfs efivarfs /sys/firmware/efi/efivars\nNote\nThe above command should be run\nboth\noutside\n(i.e. before)\nand\ninside\nthe\nchroot\n, if any.\nSee\nefivarfs.html\nfor kernel documentation.\nUserspace tools\nThere are few tools that can access/modify the UEFI variables, namely\nefivar\n— Library and tool to manipulate UEFI variables (used by efibootmgr)\nhttps://github.com/rhboot/efivar\n||\nefivar\nefibootmgr\n— Tool to manipulate UEFI Firmware Boot Manager Settings\nhttps://github.com/rhboot/efibootmgr\n||\nefibootmgr\nuefivars\n— Dumps list of UEFI variables with some additional PCI related info (uses efibootmgr code internally)\nhttps://github.com/fpmurphy/Various/tree/master/uefivars-2.0\n||\nuefivars-git\nAUR\nefitools\n— Tools for manipulating UEFI secure boot platforms\nhttps://git.kernel.org/pub/scm/linux/kernel/git/jejb/efitools.git\n||\nefitools\nUbuntu's Firmware Test Suite\n— Test suite that performs sanity checks on Intel/AMD PC firmware\nhttps://wiki.ubuntu.com/FirmwareTestSuite/\n||\nfwts-git\nAUR\nefibootmgr\nYou will have to\ninstall\nthe\nefibootmgr\npackage.\nNote\nIf\nefibootmgr\ndoes not work on your system, you can reboot into\n#UEFI Shell\nand use\nbcfg\nto create a boot entry for the boot loader.\nIf you are unable to use\nefibootmgr\n, some UEFI firmwares allow users to directly manage UEFI boot entries from within its boot-time interface.  For example, some firmwares have an \"Add New Boot Option\" choice which enables you to select a local EFI system partition and manually enter the EFI application location e.g.\n\\EFI\\refind\\refind_x64.efi\n.\nThe below commands use\nrEFInd\nboot manager as example.\nTo add a new boot option using\nefibootmgr\n, you need to know three things:\nThe disk containing the\nEFI system partition\n(ESP). E.g.:\n/dev/sda\n,\n/dev/nvme0n1\n.\nThe partition number of the ESP on that disk. The\nY\nin\n/dev/sda\nY\nor\n/dev/nvme0n1p\nY\n.\nThe path to the EFI application (relative to the root of the ESP)\nFor example, if you want to add a boot option for\n/efi/EFI/refind/refind_x64.efi\nwhere\n/efi\nis the mount point of the ESP, run\n$ findmnt /efi\nTARGET SOURCE    FSTYPE OPTIONS\n/efi   /dev/sda1 vfat   rw,flush,tz=UTC\nIn this example,\nfindmnt(8)\nindicates that the ESP is on disk\n/dev/sda\nand has partition number 1. The path to the EFI application relative to the root of the ESP is\n/EFI/refind/refind_x64.efi\n. So you would create the boot entry as follows:\n# efibootmgr --create --disk /dev/sda --part 1 --loader '\\EFI\\refind\\refind_x64.efi' --label 'rEFInd Boot Manager' --unicode\nGet an overview of all boot entries and the boot order:\n# efibootmgr --unicode\nTo set the boot order:\n# efibootmgr --bootorder\nXXXX\n,\nXXXX\n--unicode\nWhere\nXXXX\nis the number that appears in the previous output of\nefibootmgr\ncommand.\nDelete an unwanted entry:\n# efibootmgr --delete-bootnum --bootnum\nXXXX\n--unicode\nSee\nefibootmgr(8)\nor\nefibootmgr README\nfor more info.\nNote\nUEFI specification uses backward slash\n\\\nas path separator but\nefibootmgr\ncan automatically convert UNIX-style\n/\npath separators.\nDisable UEFI variable access\nAccess to the UEFI can potentially cause harm beyond the running operating system level. There are dangerous UEFI exploits like\nLogoFAIL\nwhich allows a malicious actor to take full control over the machine. Even hardware-level bricking is possible in some cases of poor UEFI implementation\n[2]\n.\nSo, as the UEFI variables access is not required for daily system usage, you may want to disable it, to avoid potential security breaches or accidental harm.\nPossible solutions are:\nMount\nefivars\nin read-only mode using\nfstab\n. For example:\nefivarfs /sys/firmware/efi/efivars efivarfs ro,nosuid,nodev,noexec 0 0\nUse the\nnoefi\nkernel parameter\nto completely disable OS access to UEFI.\nNote\nUEFI\nuserspace tools\ncannot be used with a such setup, so perform the all necessary configurations before. Also UEFI-related commands (e.g.\nsystemctl reboot --firmware-setup\n) will not work either.\nUEFI Shell\nThe UEFI Shell is a shell/terminal for the firmware which allows launching EFI applications which include UEFI boot loaders. Apart from that, the shell can also be used to obtain various other information about the system or the firmware like memory map (memmap), modifying boot manager variables (bcfg), running partitioning programs (diskpart), loading UEFI drivers, editing text files (edit), hexedit etc.\nObtaining UEFI Shell\nYou can obtain a BSD licensed UEFI Shell from the TianoCore EDK2 project:\nShell v2:\nOn the Arch install medium:\n/shellx64.efi\n. A copy of\n/usr/share/edk2-shell/x64/Shell_Full.efi\nfrom the time the ISO was built.\nedk2-shell\nprovides x64 Shell for x64 (64-bit) UEFI and IA32 Shell for IA32 (32-bit) UEFI - compiled directly from latest TianoCore EDK2 release.\nuefi-shell-git\nAUR\nprovides x64 Shell for x64 (64-bit) UEFI and IA32 Shell for IA32 (32-bit) UEFI - compiled directly from latest TianoCore EDK2 source.\nShell v1:\nPrecompiled UEFI Shell v1 binaries\nfrom TianoCore (not updated anymore upstream as of Jan 10, 2014).\nPatched shells:\nPrecompiled UEFI Shell v2 binary with bcfg modified to work with UEFI pre-2.3 firmware\n[\ndead link\n2023-07-30—HTTP 403]\n- from Clover EFI boot loader.\nPrecompiled UEFI Shell v2 binary for compatibility with a broad range of firmwares\n- from the OpenCore boot loader. In the release archive:\nEFI/OC/Tools/OpenShell.efi\n.\nShell v2 works best in UEFI 2.3+ systems and is recommended over Shell v1 in those systems. Shell v1 should work in all UEFI systems irrespective of the spec. version the firmware follows. More information at\nShellPkg\nand the EDK2 mailing list thread—\nInclusion of UEFI shell in Linux distro iso\n.\nLaunching UEFI Shell\nFew Asus and other AMI Aptio x64 UEFI firmware based motherboards (from Sandy Bridge onwards) provide an option called\nLaunch EFI Shell from filesystem device\n. For those motherboards, copy the x64 UEFI Shell to the root of your EFI system partition, named as\nshellx64.efi\n.\nTip\nThe Arch Linux installation medium has\nshellx64.efi\nat the root of the volume.\nrEFInd\nand\nsystemd-boot\nwill automatically add a boot menu entry for the UEFI shell if\nshellx64.efi\nis in the root of the EFI system partition.\nSystems with Phoenix SecureCore Tiano UEFI firmware is known to have embedded UEFI Shell which can be launched using either\nF6\n,\nF11\nor\nF12\nkey.\nNote\nIf you are unable to launch UEFI Shell from the firmware directly using any of the above mentioned methods, create a\nFAT32\nUSB pen drive with the EFI binary copied as\n/USB_drive_mointpoint\n/EFI/BOOT/BOOTx64.EFI\n. This USB should come up in the firmware boot menu. Launching this option will launch the UEFI Shell for you.\nImportant UEFI Shell commands\nUEFI Shell commands usually support\n-b\noption which makes output pause after each page. Run\nhelp -b\nto list available internal commands. Available commands are either built into the shell or discrete EFI applications.\nFor more info see\nIntel Scripting Guide 2008\n[\ndead link\n2023-07-30—HTTP 404]\nand\nIntel \"Course\" 2011\n[\ndead link\n2023-07-30—HTTP 404]\n.\nbcfg\nbcfg\nmodifies the UEFI NVRAM entries which allows the user to change the boot entries or driver options. This command is described in detail in page 96 (Section 5.3) of the\nUEFI Shell Specification 2.2\ndocument.\nNote\nTry\nbcfg\nonly if\nefibootmgr\nfails to create working boot entries on your system.\nUEFI Shell v1 official binary does not support\nbcfg\ncommand. See\n#Obtaining UEFI Shell\nfor a modified UEFI Shell v2 binary which may work in UEFI pre-2.3 firmwares.\nTo dump a list of current boot entries:\nShell> bcfg boot dump -v\nTo add a boot menu entry for rEFInd (for example) as 4th (numbering starts from zero) option in the boot menu:\nShell> bcfg boot add 3 FS0:\\EFI\\refind\\refind_x64.efi \"rEFInd Boot Manager\"\nwhere\nFS0:\nis the mapping corresponding to the EFI system partition and\nFS0:\\EFI\\refind\\refind_x64.efi\nis the file to be launched.\nTo add an entry to boot directly into your system without a boot loader, see\nEFI boot stub#bcfg\n.\nTo remove the 4th boot option:\nShell> bcfg boot rm 3\nTo move the boot option #3 to #0 (i.e. 1st or the default entry in the UEFI Boot menu):\nShell> bcfg boot mv 3 0\nFor bcfg help text:\nShell> help bcfg -v -b\nor:\nShell> bcfg -? -v -b\nmap\nmap\ndisplays a list of device mappings i.e. the names of available file systems (\nFS0\n) and storage devices (\nblk0\n).\nBefore running file system commands such as\ncd\nor\nls\n, you need to change the shell to the appropriate file system by typing its name:\nShell> FS0:\nFS0:\\> cd EFI/\nedit\nedit\nprovides a basic text editor with an interface similar to nano, but slightly less functional. It handles UTF-8 encoding and takes care or LF vs CRLF line endings.\nFor example, to edit rEFInd's\nrefind.conf\nin the EFI system partition (\nFS0:\nin the firmware),\nShell> edit FS0:\\EFI\\refind\\refind.conf\nPress\nCtrl+e\nfor help.\nUEFI drivers\nThis article or section needs expansion.\nReason:\nExplain what are and how to use UEFI drivers. Add automatic UEFI driver loading setup with efibootmgr's\n-r\n/\n--driver\noption. (Discuss in\nTalk:Unified Extensible Firmware Interface\n)\nUEFI drivers are pieces of software that support some functionality. For example, access to NTFS formatted partitions is usually not possible from a UEFI shell. The\nefifs\npackage has drivers that support reading many more file systems from within an EFI shell. A usage example is to copy such driver to a partition that can be accessed from an UEFI shell. Then, from the UEFI shell, issuing commands such as:\nShell> load ntfs_x64.efi\nShell> map -r\nAfter the map command has been executed, the user should be able to access NTFS formatted partitions from within a UEFI shell.\nTip\nsystemd-boot\nautomatically loads UEFI drivers from\nesp\n/EFI/systemd/drivers/\n.\nrEFInd\nautomatically loads UEFI drivers from the\ndrivers\nand\ndrivers_x64\nsubdirectories of its own installation directory on the ESP. E.g.\nesp\n/EFI/refind/drivers_x64/\n. It can be configured to scan additional directories.\nUEFI bootable media\nRemove UEFI boot support from optical media\nNote\nThis section mentions removing UEFI boot support from a\nCD/DVD only\n(Optical Media booting via  EL Torito), not from a USB flash drive.\nIn order to hide the UEFI equipment on USB stick, use a partition editor after having copied the ISO to the flash drive. Remove the partition of type\nEF\n.\nDo not\naccept offers to convert to GPT.\nMost of the 32-bit EFI Macs and some 64-bit EFI Macs refuse to boot from a UEFI(X64)+BIOS bootable CD/DVD. If one wishes to proceed with the installation using optical media, it might be necessary to remove UEFI support first.\nExtract the ISO skipping the UEFI-specific directories:\n$ mkdir extracted_iso\n$ bsdtar -x --exclude=EFI/ --exclude=loader/ -f archlinux-\nversion\n-x86_64.iso -C extracted_iso\nThen rebuild the ISO, excluding the UEFI optical media booting support, using\nxorriso(1)\nfrom\nlibisoburn\n. Be sure to set the correct volume label, e.g.\nARCH_202103\n; it can be acquired using\nfile(1)\non the original ISO.\n$ xorriso -as mkisofs \\\n-iso-level 3 \\\n-full-iso9660-filenames \\\n-joliet \\\n-joliet-long \\\n-rational-rock \\\n-volid \"ARCH_\nYYYYMM\n\" \\\n-appid \"Arch Linux Live/Rescue CD\" \\\n-publisher \"Arch Linux <\nhttps://archlinux.org\n>\" \\\n-preparer \"prepared by $USER\" \\\n-eltorito-boot syslinux/isolinux.bin \\\n-eltorito-catalog syslinux/boot.cat \\\n-no-emul-boot -boot-load-size 4 -boot-info-table \\\n-isohybrid-mbr \"extracted_iso/syslinux/isohdpfx.bin\" \\\n-output archlinux-\nversion\n-x86_64-noUEFI.iso extracted_iso/\nBurn\narchlinux-\nversion\n-x86_64-noUEFI.iso\nto optical media and proceed with installation normally.\nTesting UEFI in systems without native support\nOVMF for virtual machines\nOVMF\nis a TianoCore project to enable UEFI support for Virtual Machines. OVMF contains a sample UEFI firmware and a separate non-volatile variable store for\nQEMU\n.\nYou can install\nedk2-ovmf\nfrom the extra repository.\nIt is\nadvised\nto make a local copy of the non-volatile variable store for your virtual machine:\n$ cp /usr/share/edk2/x64/OVMF_VARS.4m.fd my_OVMF_VARS.4m.fd\nTo use the OVMF firmware and this variable store, add following to your QEMU command:\n-drive if=pflash,format=raw,readonly,file=/usr/share/edk2/x64/OVMF_CODE.4m.fd \\\n-drive if=pflash,format=raw,file=my_OVMF_VARS.4m.fd\nFor example:\n$ qemu-system-x86_64 -enable-kvm -m 1G -drive if=pflash,format=raw,readonly,file=/usr/share/edk2/x64/OVMF_CODE.4m.fd -drive if=pflash,format=raw,file=my_OVMF_VARS.4m.fd …\nDUET for BIOS only systems\nDUET was a TianoCore project that enabled chainloading a full UEFI environment from a BIOS system, in a way similar to BIOS operating system booting. This method is being\ndiscussed\nextensively. Pre-build DUET images can be downloaded from one of the\nrepos\n[\ndead link\n2023-04-07—404 Page Not Found]\n. Read specific\ninstructions\n[\ndead link\n2023-04-07—404 Page Not Found]\nfor setting up DUET. However, as of November 2018, the DUET code has been removed from TianoCore git repository.\nYou can also try\nClover\nwhich provides modified DUET images that may contain some system specific fixes and is more frequently updated compared to the gitlab repos.\nTroubleshooting\nBoot back to Arch Linux when stuck with Windows\nTo boot back into Arch Linux when you are stuck with Windows, reach\nAdvanced startup\nin Windows by the Windows PowerShell command\nshutdown /r /o\n, or via\nSettings > Update & Security > Recovery > Advanced startup\nand select\nRestart now\n. When you have reached the\nAdvanced startup\nmenu, choose\nUse a device\n, which actually contains your UEFI boot options (not limited to USB or CD, but can also boot operating system in hard drive), and choose \"Arch Linux\".\nEnter firmware setup without function keys\nOn some laptops, like\nLenovo XiaoXin 15are 2020\n, using keys like\nF2\nor\nF12\ndoes not do anything. This can possibly be fixed by returning laptops to OEM to repair mainboard information, but sometimes this is not possible or not desired. There are however other means to enter firmware setup:\nWith\nsystemctl\n:\n$ systemctl reboot --firmware-setup\nThis will reboot your computer to firmware setup.\nWith\nGRUB\n: Press\nc\nfor command line and in GRUB command line use\nfwsetup\nto enter firmware setup.\nIn Windows: Enter\nAdvanced Startup\n, see\n#Boot back to Arch Linux when stuck with Windows\n.\nUserspace tools are unable to modify UEFI variable data\nIf any userspace tool is unable to modify UEFI variable data, check for existence of\n/sys/firmware/efi/efivars/dump-*\nfiles. If they exist, delete them, reboot and retry again.\nIf the above step does not fix the issue, try booting with\nefi_no_storage_paranoia\nkernel parameter to disable kernel UEFI variable storage space check that may prevent writing/modification of UEFI variables.\nWarning\nefi_no_storage_paranoia\nshould only be used when needed and should not be left as a normal boot option. The effect of this kernel command line parameter turns off a safeguard that was put in place to help avoid the bricking of machines when the NVRAM gets too full. See\nFS#34641\nfor more information.\nCannot create a new boot entry with efibootmgr\nSome kernel and\nefibootmgr\nversion combinations might refuse to create new boot entries. This could be due to lack of free space in the NVRAM. You can try the solution at\n#Userspace tools are unable to modify UEFI variable data\n.\nYou can also try to\ndowngrade\nyour\nefibootmgr\ninstall to version 0.11.0. This version works with Linux version 4.0.6. See the bug discussion\nFS#34641\n, in particular the\nclosing comment\n, for more information.\nWindows changes boot order\nIf you\ndual boot with Windows\nand your motherboard just boots Windows immediately instead of your chosen EFI application, there are several possible causes and workarounds.\nEnsure\nFast Startup\nis disabled in your Windows power options\nEnsure\nSecure Boot\nis disabled in your firmware (if you are not using a signed boot loader)\nEnsure your UEFI boot order does not have Windows Boot Manager set first e.g. using\nefibootmgr\nand what you see in the configuration tool of the UEFI. Some motherboards override by default any settings set with efibootmgr by Windows if it detects it. This is confirmed in a Packard Bell laptop.\nIf your motherboard is booting the default boot path (\n\\EFI\\BOOT\\BOOTx64.EFI\n), this file may have been overwritten with the Windows boot loader. Try setting the correct boot path e.g. using\nefibootmgr\n.\nIf the previous steps do not work, you can tell the Windows boot loader to run a different EFI application. From a Windows administrator command prompt\nbcdedit /set \"{bootmgr}\" path \"\\EFI\\\npath\n\\\nto\n\\\napp.efi\n\"\nAlternatively, deactivate the Windows Boot Manager by running\nefibootmgr -A -b\nbootnumber\nas root. Replace\nbootnumber\nwith the actual Windows Boot Manager boot number; you can see it by running\nefibootmgr\nwith no options.\nAlternatively, you can set a startup script in Windows that ensures that the boot order is set correctly every time you boot Windows.\nOpen a command prompt with administrator privileges. Run\nbcdedit /enum firmware\nand find your desired boot entry.\nCopy the identifier, including the brackets, e.g.\n{31d0d5f4-22ad-11e5-b30b-806e6f6e6963}\nCreate a batch file with the command\nbcdedit /set \"{fwbootmgr}\" DEFAULT \"\n{copied-boot-identifier}\n\"\nOpen\ngpedit.msc\nand under\nLocal Computer Policy > Computer Configuration > Windows Settings > Scripts (Startup/Shutdown)\n, choose\nStartup\nUnder the\nScripts\ntab, choose the\nAdd\nbutton, and select your batch file\nNote:\nWindows 10 Home does not officially include gpedit.msc, although there are unsupported workarounds to install it manually.\nAlternatively, Task Scheduler can be used to run a startup script in Windows:\nFollow steps 1-3 above to create the batch file.\nRun\ntaskschd.msc\n, then choose\nCreate Task...\nfrom the\nAction\nmenu.\nOn the\nGeneral\ntab:\nEnter any suitable\nName\nand\nDescription\n.\nEnsure the user account selected is an \"Administrator\", not a \"Standard User\".\nSelect \"\nRun whether user is logged in or not\n\".\nSelect \"\nRun with highest privileges\n\".\nOn the\nTriggers\ntab, choose \"\nAt startup\n\" from the menu, then click\nOK\n.\nOn the\nActions\ntab, click\nNew...\n, then\nBrowse...\n, and locate the batch file from step 1.\nOn the\nConditions tab\n, untick the\nPower\noptions so the script runs when on battery power (for laptops).\nClick\nOK\n, and enter the password of the user account selected in step 4 when prompted.\nUSB media gets struck with black screen\nThis issue can occur due to\nKMS\nissue. Try\ndisabling KMS\nwhile booting the USB.\nUEFI boot loader does not show up in firmware menu\nSome firmware do not support custom boot entries. They will instead only boot from hardcoded boot entries.\nA typical workaround is to not rely on boot entries in the NVRAM and install the boot loader to one of the common fallback paths on the EFI system partition.\nThe following sections describe the fallback paths.\nDefault boot path for removable drives\nThe UEFI specification defines default file paths for EFI binaries for booting from removable media. The relevant ones are:\nesp\n/EFI/BOOT/BOOTx64.EFI\nfor x64 UEFI\nesp\n/EFI/BOOT/BOOTIA32.EFI\nfor IA32 UEFI.\nWhile the specification defines these for removable drives only, most firmware support booting these from any drive.\nSee the appropriate\nboot loader\narticle on how to install or migrate the boot loader to the default/fallback boot path.\nMicrosoft Windows boot loader location\nOn certain UEFI motherboards like some boards with an Intel Z77 chipset, adding entries with\nefibootmgr\nor\nbcfg\nfrom the UEFI Shell will not work because they do not show up on the boot menu list after being added to NVRAM.\nThis issue is caused because the motherboards can only load Microsoft Windows. To solve this you have to place the\n.efi\nfile in the location that Windows uses.\nCopy the\nBOOTx64.EFI\nfile from the Arch Linux installation medium (\nFSO:\n) to the Microsoft directory your\nESP\npartition on your hard drive (\nFS1:\n). Do this by booting into EFI shell and typing:\nShell> mkdir FS1:\\EFI\\Microsoft\nShell> mkdir FS1:\\EFI\\Microsoft\\Boot\nShell> cp FS0:\\EFI\\BOOT\\BOOTx64.EFI FS1:\\EFI\\Microsoft\\Boot\\bootmgfw.efi\nAfter reboot, any entries added to NVRAM should show up in the boot menu.\nUEFI/BIOS is stuck on loading screen\nThis is a recurring problem with Acer laptops, which occurs if\n.efi\nfiles have not been manually authorized. See\nLaptop/Acer#Firmware Setup became inaccessible after Linux installation\n.\nBoot entries created with efibootmgr fail to show up in UEFI\nefibootmgr\ncan fail to detect EDD 3.0 and as a result create unusable boot entries in NVRAM. See\nefibootmgr issue 86\nfor the details.\nTo work around this, when creating boot entries manually, add the\n-e 3\noption to the\nefibootmgr\ncommand. E.g.\n# efibootmgr --create --disk /dev/sda --part 1 --loader '\\EFI\\refind\\refind_x64.efi' --label 'rEFInd Boot Manager' --unicode\n-e 3\nTo fix boot loader installers, like\ngrub-install\nand\nrefind-install\n, create a wrapper script\n/usr/local/bin/efibootmgr\nand make it\nexecutable\n:\n/usr/local/bin/efibootmgr\n#!/bin/sh\nexec /usr/bin/efibootmgr -e 3 \"$@\"\nUEFI boot entry disappears after removing its referenced drive\nSome firmware will remove boot entries referencing drives that are not present during boot. This could be an issue when frequently detaching/attaching drives or when booting from a removable drive.\nThe solution is to install the\nboot loader\nto\nthe default/fallback boot path\n.\nBoot entries are randomly removed\nSome motherboards may remove boot entries due to lack of free space in the NVRAM instead of giving an error at creation. To prevent this from occurring, reduce the amount of boot entries being added by minimizing your entry creation process, as well as reducing the amount of automatic drive boot entries by the\nCompatibility Support Module (CSM)\nby disabling it from your UEFI settings. See\nBBS#1608838\n.\nAnother reason why boot entries might have been removed is the fact that UEFI specification allows OEMs to do \"NVRAM maintenance\" during boot process. Those manufacturers do it simply: they just look up for EFI applications in predefined, hardcoded paths on the device. If they fail to find any, they conclude there is no operating system on the device and wipe all boot entries from NVRAM associated with it, because they assume the NVRAM contains some corrupted or outdated data. If you do not plan to install Windows and still want to load the Linux kernel directly from the firmware, one possible workaround is to create an empty file\nesp\n/EFI/BOOT/BOOTx64.EFI\n:\n# mkdir -p\nesp\n/EFI/BOOT\n# touch\nesp\n/EFI/BOOT/BOOTx64.EFI\nAnd restore the deleted boot entry. Now after reboot the motherboard will see the \"Fake OS\" and should not wipe other boot entries from NVRAM. You can change the fake operating system loader with an actual EFI application if you want, of course, as long as you keep the standard fallback name.\nLenovo ThinkPad: boot entries not persistent due to \"OS Optimized Defaults\"\nThis article or section is a candidate for merging with\nLenovo\n.\nNotes:\nBrand-specific issues should be on the dedicated page. (Discuss in\nTalk:Unified Extensible Firmware Interface\n)\nThis article or section needs expansion.\nReason:\nMissing links to the \"user reports\". (Discuss in\nTalk:Unified Extensible Firmware Interface\n)\nOn recent Lenovo ThinkPad laptops (e.g. T16 Gen 2 AMD models), users report that custom UEFI boot entries (created with\nefibootmgr\nor\nbootctl\n) are automatically deleted at each boot, with only Windows Boot Manager and Lenovo’s own entries (PXE, Recovery, Diagnostics) restored.\nThis is caused by the BIOS option \"Restart / OS Optimized Defaults\", which resets the UEFI boot variables at each reboot to defaults optimized for Windows.\nSolution: Disable \"OS Optimized Defaults\" in the BIOS/UEFI setup. After doing so, manually created boot entries persist correctly, allowing systemd-boot or other custom boot managers to work as intended.\nSee also\nUEFI Forum\n- contains the official\nUEFI Specifications\n- GUID Partition Table is part of UEFI Specification\nUEFI boot: how does that actually work, then? - A blog post by AdamW\nLinux Kernel UEFI documentation for x86_64 platforms\nIntel's page on EFI\nIntel Architecture Firmware Resource Center\n[\ndead link\n2023-07-30—HTTP 404]\nMatt Fleming - The Linux EFI Boot Stub\nMatt Fleming - Accessing UEFI Variables from Linux\nRod Smith - Linux on UEFI: A Quick Installation Guide\nUEFI Boot problems on some newer machines (LKML)\nLPC 2012 Plumbing UEFI into Linux\n[\ndead link\n2021-05-17—domain name not resolved]\nLPC 2012 UEFI Tutorial : part 1\n[\ndead link\n2021-05-17—domain name not resolved]\nLPC 2012 UEFI Tutorial : part 2\n[\ndead link\n2021-05-17—domain name not resolved]\nIntel's TianoCore Project\nfor Open-Source UEFI firmware which includes DuetPkg for direct BIOS based booting and OvmfPkg used in QEMU and Oracle VirtualBox\nFGA: The EFI boot process\nMicrosoft's Windows and GPT FAQ\nConvert Windows x64 from BIOS-MBR mode to UEFI-GPT mode without Reinstall\nCreate a Linux BIOS+UEFI and Windows x64 BIOS+UEFI bootable USB drive\nRod Smith - A BIOS to UEFI Transformation\nEFI Shells and Scripting - Intel Documentation\nUEFI Shell  - Intel Documentation\nUEFI Shell - bcfg command info\nThe bootstrap process on EFI systems\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Unified_Extensible_Firmware_Interface&oldid=845092\n\"\nCategory\n:\nBoot process\nHidden categories:\nPages with dead links\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Merge\nSearch\nSearch\nUnified Extensible Firmware Interface\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Unified_Extensible_Firmware_Interface"}}
{"text": "Core utilities - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nCore utilities\n7 languages\nEspañol\nMagyar\n日本語\nPolski\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nCommand-line shell\nGeneral recommendations\nUsers and groups\npacman\nsystemd\nCore utilities\nare the basic, fundamental tools of a\nGNU/Linux\nsystem. This article provides an incomplete overview of them, links their documentation and describes useful alternatives. The scope of this article includes, but is not limited to, the\nGNU Core Utilities\n. Most core utilities are traditional\nUnix\ntools and many were standardized by\nPOSIX\nbut have been developed further to provide more features.\nMost command-line interfaces are documented in\nman pages\n, utilities by the\nGNU Project\nare documented primarily in\nInfo manuals\n, some\nshells\nprovide a\nhelp\ncommand for shell builtin commands. Additionally most utilities print their usage when run with the\n--help\nflag.\nEssentials\nThe following table lists some important utilities which\nArch Linux\nusers should be familiar with. See also\nintro(1)\n.\nPackage\nUtility\nDescription\nDocumentation\nAlternatives\nshell built-ins\ncd\nchange directory\ncd(1p)\n#cd alternatives\nGNU\ncoreutils\nls\nlist directory\nls(1)\n,\ninfo\ntree\n,\n#ls alternatives\ncat\nconcatenate files to stdout\ncat(1)\n,\ninfo\ntac(1)\n,\n#cat alternatives\nmkdir\nmake directory\nmkdir(1)\n,\ninfo\nrmdir\nremove empty directory\nrmdir(1)\n,\ninfo\nrm\nremove files or directories\nrm(1)\n,\ninfo\nshred\nunlink(1)\ncp\ncopy files or directories\ncp(1)\n,\ninfo\n#cp alternatives\nmv\nmove files or directories\nmv(1)\n,\ninfo\nln\nmake hard or symbolic links\nln(1)\n,\ninfo\nsln(8)\n(soname recovery)\nchown\nchange file owner and group\nchown(1)\n,\ninfo\nchgrp(1)\nchmod\nchange file permissions\nchmod(1)\n,\ninfo\ndd\nconvert and copy a file\ndd(1)\n,\ninfo\n#dd alternatives\ndf\nreport file system disk space usage\ndf(1)\n,\ninfo\n#df alternatives\ndu\nestimate disk space used by files and directories\ndu(1)\n,\ninfo\n#du alternatives\nGNU\ntar\ntar\ntar archiver\ntar(1)\n,\ninfo\narchivers\nGNU\nless\nless\nterminal pager\nless(1)\nterminal pagers\nGNU\nfindutils\nfind\nsearch files or directories\nfind(1)\n,\ninfo\n,\nGregsWiki\n#find alternatives\nGNU\ndiffutils\ndiff\ncompare files line by line\ndiff(1)\n,\ninfo\n#diff alternatives\nGNU\ngrep\ngrep\nprint lines matching a pattern\ngrep(1)\n,\ninfo\n#grep alternatives\nGNU\nsed\nsed\nstream editor\nsed(1)\n,\ninfo\n,\none-liners\n[\ndead link\n2025-08-15—HTTP 404]\nsad\n,\nsd\nGNU AWK (\ngawk\n)\nAWK\npattern scanning and processing language\ngawk(1)\n,\ninfo\nAWK#Alternative implementations\nutil-linux\ndmesg\nprint or control the kernel ring buffer\ndmesg(1)\nsystemd journal\nlsblk\nlist block devices\nlsblk(8)\nmount\nmount a filesystem\nmount(8)\numount\nunmount a filesystem\numount(8)\nsu\nsubstitute user\nsu(1)\nsudo\n,\ndoas\nkill\nterminate a process\nkill(1)\npkill(1)\n,\nkillall(1)\nprocps-ng\npgrep\nlook up processes by name or attributes\npgrep(1)\npidof(1)\nps\nshow information about processes\nps(1)\ntop(1)\n,\nsystem monitors\nfree\ndisplay amount of free and used memory\nfree(1)\nPreventing data loss\nrm\n,\nmv\n,\ncp\nand shell redirections happily delete or overwrite files without asking.\nrm\n,\nmv\n, and\ncp\nall support the\n-i\nflag to prompt the user before every removal / overwrite. Some users like to enable the\n-i\nflag by default using\naliases\n. Relying upon these shell options can be dangerous, because you get used to them, resulting in potential data loss when you use another system or user that does not have them. The best way to prevent data loss is to create\nbackups\n.\nNonessentials\nThis table lists core utilities that often come in handy.\nPackage\nUtility\nDescription\nDocumentation\nAlternatives\nshell built-ins\nalias\ndefine or display aliases\nalias(1p)\ntype\nprint the type of a command\ntype(1p)\ncommand(1p)\n,\nwhereis(1)\n,\nwhich(1)\ntime\ntime a command\ntime(1p)\nGNU\ncoreutils\ntee\nread stdin and write to stdout and files\ntee(1)\n,\ninfo\npee(1)\nmktemp\nmake a temporary file or directory\nmktemp(1)\n,\ninfo\nmknod\ncreate named pipe or device node\nmknod(1)\n,\nmkfifo(1)\n,\ninfo\ntruncate\nshrink or extend the size of a file\ntruncate(1)\n,\ninfo\nfallocate(1)\nbasenc\nencoding input and output it\nbasenc(1)\n,\nbase64(1)\n,\ninfo\ncut\nprint selected parts of lines\ncut(1)\n,\ninfo\ncolrm(1)\n,\nhck\n,\nchoose\ntr\ntranslate or delete characters\ntr(1)\n,\ninfo\nuconv(1)\nod\ndump files in octal and other formats\nod(1)\n,\ninfo\nhexdump(1)\n,\nvim\n's\nxxd(1)\nsort\nsort lines\nsort(1)\n,\ninfo\nuniq\nreport or omit repeated lines\nuniq(1)\n,\ninfo\nanewer\n,\nruniq\nAUR\n,\nhuniq-git\nAUR\ncomm\ncompare two sorted files line by line\ncomm(1)\n,\ninfo\nzet\nAUR\nhead\noutput the first part of files\nhead(1)\n,\ninfo\njoin\njoin lines of two inputs on a common field\njoin(1)\n,\ninfo\ncombine(1)\nzet\nAUR\nmd5sum\ncalculate cryptography hash functions of inputs and output\nsha256sum(1)\n,\nsha512sum(1)\n,\ninfo\nshasum(1)\n,\nrhash(1)\ntail\noutput the last part of files, or follow files\ntail(1)\n,\ninfo\nwc\nprint newline, word and byte count\nwc(1)\n,\ninfo\nGNU\nbinutils\nstrings\nprint printable characters in binary files\nstrings(1)\n,\ninfo\nstringsext\nAUR\nutil-linux\ncolumn\ncolumnate file, optionally pretty-printing in table with grid\ncolumn(1)\npaste(1)\n,\ncsview\nAUR\nGNU\nfindutils\nxargs\ncombine or template arguments from stdin to invoke external command\nxargs(1)\nparallel(1)\n(\nparallel_alternatives(7)\n)\nGNU\nglibc\niconv\nconvert character encodings\niconv(1)\nrecode\n,\nuconv(1)\nGNU\nsharutils\nuudecode\nencode file into email friendly text\nuuencode(1)\n,\nuudecode(1)\n,\ninfo\nuudeview(1)\nfile\nfile\nguess file type\nfile(1)\nThe\nmoreutils\npackage provides useful tools like\nsponge(1)\nthat are missing from the GNU coreutils.\nAlternatives\nAlternative core utilities are provided by the following packages:\n9base\n— A port of various original Plan9 tools to unix.\nhttps://tools.suckless.org/9base\n||\n9base\nBusyBox\n— Utilities for rescue and embedded systems.\nhttps://busybox.net\n||\nbusybox\nHeirloom Toolchest\n— Traditional implementations of standard Unix utilities.\nhttps://heirloom.sourceforge.net\n||\nheirloom-sh\nAUR\n,\nheirloom-doctools\nAUR\nsbase\n— A suckless variant of the *nix core utilities.\nhttps://core.suckless.org/sbase\n||\nsbase-git\nAUR\nToybox\n— An all-in-one Linux command line.\nhttps://landley.net/toybox\n||\ntoybox\nAUR\nubase\n— An extension of the sbase utilities.\nhttps://core.suckless.org/ubase\n||\nubase-git\nAUR\nuutils\n— Cross-platform Rust rewrite of the GNU coreutils.\nhttps://github.com/uutils/coreutils\n||\nuutils-coreutils\ncat alternatives\nbat\n— A cat clone with syntax highlighting and Git integration.\nhttps://github.com/sharkdp/bat\n||\nbat\ncd alternatives\nautojump\n— A faster way to navigate your filesystem from the command line.\nhttps://github.com/wting/autojump\n||\nautojump\nAUR\nzoxide\n— A smart cd command that learns your habits, allowing you to navigate anywhere in just a few keystrokes.\nhttps://github.com/ajeetdsouza/zoxide\n||\nzoxide\nSee also\nBash#Auto \"cd\" when entering just a path\nand\nZsh#Remembering recent directories\n.\ndate alternatives\nThis article or section is a candidate for moving to\nList of applications/Other\n.\nNotes:\nThese are not alternatives,\ndate\nis not even mentioned on this page. (Discuss in\nTalk:Core utilities\n)\ndateutils\n— Nifty command line date and time utilities; fast date calculations and conversion in the shell.\nhttps://www.fresse.org/dateutils/\n||\ndateutils\npdd\n— Tiny datetime diff calculator.\nhttps://github.com/jarun/pdd\n||\npdd\nAUR\ncp alternatives\nUsing\nrsync#As cp/mv alternative\nallows you to resume a failed transfer, to show the transfer status, to skip already existing files and to make sure of the destination files integrity using checksums.\nls alternatives\nbroot\n— A new way to see and navigate directory trees.\nhttps://github.com/Canop/broot\n||\nbroot\nclifm\n— A file manager that can list files like ls(1) would (plus icons and RGB colors support).\nhttps://github.com/leo-arch/clifm/wiki/Advanced#files-lister-ls-mode\n||\nclifm\nAUR\neza\n— Another ls replacement with color support, tree view, git integration and other features. Based on exa, which is no longer supported.\nhttps://github.com/eza-community/eza\n||\neza\nlsd\n— Modern ls with a lot of pretty colors and awesome icons.\nhttps://github.com/Peltoche/lsd\n||\nlsd\nfind alternatives\nfd\n— Simple, fast and user-friendly alternative to find. Ignores hidden and\n.gitignore\n'd files by default.\nhttps://github.com/sharkdp/fd\n||\nfd\nfuzzy-find\n— Fuzzy completion for finding files.\nhttps://github.com/silentbicycle/ff\n||\nff-git\nAUR\nplocate\n— A much faster locate.\nhttps://plocate.sesse.net/\n||\nplocate\nrawhide\n— find files using pretty C expressions.\nhttps://raf.org/rawhide/\n||\nrawhide\nAUR\nuutils-findutils\n— Rust rewrite of findutils\nhttps://github.com/uutils/findutils\n||\nuutils-findutils\nAUR\nFor graphical file searchers, see\nList of applications/Utilities#File searching\n.\ndiff alternatives\nuutils-diffutils\n— Rust rewrite of diffutils.\nhttps://github.com/uutils/diffutils\n||\nuutils-diffutils\nAUR\nWhile\ndiffutils\ndoes not provide a word-wise diff, several other programs do:\ncwdiff\n— A GNU wdiff wrapper that colorizes the output.\nhttps://github.com/junghans/cwdiff\n||\ncwdiff\nAUR\ndwdiff\n— A word diff front-end for the diff program; supports colors.\nhttps://os.ghalkes.nl/dwdiff.html\n||\ndwdiff\nAUR\ngit\ndiff can do a word diff with\n--color-words\n, using\n--no-index\nit can also be used for files outside of Git working trees.\ngit-delta\n— A syntax-highlighting pager for git, diff, and grep output.\nhttps://dandavison.github.io/delta/\n||\ngit-delta\nicdiff\n— A colorized diff tool written in Python. \"Improved color diff\" is meant to supplement normal diff use.\nhttps://github.com/jeffkaufman/icdiff\n||\nicdiff\nAUR\nwdiff\n— A wordwise implementation of GNU diff; does not support colors.\nhttps://www.gnu.org/software/wdiff/\n||\nwdiff\nSee also\nList of applications/Utilities#Comparison, diff, merge\n.\ngrep alternatives\nmgrep\n— A multiline grep.\nhttps://sourceforge.net/projects/multiline-grep/\n||\nmgrep\nAUR\npdfgrep\n— A tool to search text in PDF files.\nhttps://pdfgrep.org/\n||\npdfgrep\nripgrep-all\n— Search in plain text and also in PDFs, E-Books, Office documents, zip, tar.gz.\nhttps://github.com/phiresky/ripgrep-all\n||\nripgrep-all\nCode searchers\nThese tools aim to replace grep for code search. They do recursive search by default, skip binary files and respect\n.gitignore\n.\nack\n— A Perl-based grep replacement, aimed at programmers with large trees of heterogeneous source code.\nhttps://beyondgrep.com/\n||\nack\nAUR\npcre2grep\n— Perl-compatible grep, but it uses the PCRE2 regular expression library.\nhttps://github.com/PCRE2Project/pcre2\n||\npcre2\nripgrep (rg)\n— A search tool that combines the usability of ag with the raw speed of grep.\nhttps://github.com/BurntSushi/ripgrep\n||\nripgrep\nThe Silver Searcher (ag)\n— Code searching tool similar to ack, but faster.\nhttps://github.com/ggreer/the_silver_searcher\n||\nthe_silver_searcher\nugrep (ug)\n— Ultrafast grep with interactive user interface, fuzzy search, boolean queries, hexdumps and more.\nhttps://github.com/Genivia/ugrep\n||\nugrep\nSee also:\ncscope\n.\nInteractive filters\nfnf\n— An interactive fuzzy finder for the terminal.\nhttps://github.com/leo-arch/fnf\n||\nfnf\nAUR\nfzf\n— General-purpose command-line fuzzy finder, powered by find by default.\nhttps://github.com/junegunn/fzf\n||\nfzf\nfzy\n— A fast, simple fuzzy text selector with an advanced scoring algorithm.\nhttps://github.com/jhawthorn/fzy\n||\nfzy\npeco\n— Simplistic interactive filtering tool.\nhttps://github.com/peco/peco\n||\npeco\npercol\n— Adds flavor of interactive filtering to the traditional pipe concept of the UNIX shell.\nhttps://github.com/mooz/percol\n||\npercol\nAUR\nskim\n— Fuzzy finder written in Rust, similar to fzf.\nhttps://github.com/lotabout/skim\n||\nskim\ndd alternatives\nThis article or section needs expansion.\nReason:\nddrescue should be added to a list below and briefly described. Given the name similarity, it would be nice to mention the differences from dd_rescue. (Discuss in\nTalk:Core utilities\n)\nSee also:\ndd\nand\nddrescue\nAlternative dd implementations\nThis subsection lists\ndd\nimplementations whose interface and default behaviour is mostly compliant with the POSIX specification of\ndd(1p)\n.\nddpt\n— A portable rewrite of\nsg_dd(8)\nby the SCSI subsystem maintainer of the Linux kernel, with optional but very specialised hardware I/O (SCSI command sets) support, plus many other features.\nhttps://sg.danny.cz/sg/ddpt.html\n||\nddpt\nAUR\nsdd\n— A dd implementation portable across UNIX environments by Joerg Schilling, that can checksum the copied data and retry reading bad blocks.\nhttps://schilytools.sourceforge.net/\n||\nschily-tools-sdd\nAUR\nSpin-offs of GNU dd\nThe GNU implementation of\ndd\nfound in\ncoreutils\nalso conforms to POSIX. This subsection lists its forks.\ndc3dd\n— Another patched version of GNU dd from the United States Department of Defense Cyber Crime Center (DC3), with similar goals and features to dcfldd.\nhttps://sourceforge.net/projects/dc3dd/\n||\ndc3dd\nAUR\ndcfldd\n—  feature-enhanced fork of GNU dd for forensics and security scenarios, includes on-the-fly hashing capability, flexible wipes, write verification, output to multiple targets at the same time, split and piped output.\nhttps://dcfldd.sourceforge.net\n||\ndcfldd\nAUR\nModernised dd analogues\nThis subsection lists\ndd\nalternatives that do not conform to POSIX (in terms of the JCL-resembling command-line syntax and\ndefault behaviour\n).\ndd_rescue\n— A feature-packed, modernised dd analogue that is suitable for daily scripting, disk cloning, and data recovery.\nhttps://www.garloff.de/kurt/linux/ddrescue/\n||\ndd_rescue\nrw\n— Minimal and portable\ndd\nanalogue with conventional command-line flags.\nhttps://sortix.org/rw/\n||\nrw\nAUR\nbuffer spin-offs\nThis subsection lists forks of\nbuffer\nAUR\n, a general-purpose I/O buffering utility similar to\ndd\nbut has a dynamic-sized buffer. It supports blockwise I/O and can be used when dumping from/to an LTO-tape to avoid shoe shining.\nmbuffer\n— Continuation of the\nbuffer\nutility with threading and other features.\nhttps://www.maier-komor.de/mbuffer.html\n||\nmbuffer\ndf alternatives\nduf\n— A disk usage/free utility.\nhttps://github.com/muesli/duf\n||\nduf\ndu alternatives\ncdu\n— du wrapper with colors and a pretty histogram.\nhttp://arsunik.free.fr/prog/cdu.html\n||\ncdu\nAUR\ndua\n— Fast\nd\nisk\nu\nsage\na\nnalyzer, supports deleting files, written in Rust.\nhttps://github.com/Byron/dua-cli\n||\ndua-cli\ndust\n— A more intuitive version of du, in Rust.\nhttps://github.com/bootandy/dust\n||\ndust\ngdu\n— Disk usage analyzer with console interface, written in Go.\nhttps://github.com/Dundee/gdu\n||\ngdu\nncdu\n— An extremely lightweight and simple ncurses based disk usage analyzer, written in Zig.\nhttps://dev.yorhel.nl/ncdu\n||\nncdu\nSee also\nList of applications/Utilities#Disk usage display\n.\nPOSIX shell utilities\nMany common packages already install most popular\nPOSIX utilities\nas dependencies, but the\nposix\nmetapackage can be installed to ensure all of them being always present.\nBeside mandatory utilities, there are also metapackages for some of the optional categories:\nposix-c-development\nposix-software-development\nposix-user-portability\nposix-xsi\nNote\nNot all optional utilities from given category are necessarily present in corresponding metapackage.\nTips and tricks\nOverride or add missing coreutils\nSome commands (\narch\n,\nkill\n, etc.) are missing from\ncoreutils\nor taken from other packages. To complete them for compatibility, install\nuutils-coreutils\nand do:\n# ln -sf /usr/bin/uu-coreutils /usr/local/bin/arch\n# echo -e \"#compdef arch=uu-arch\\n_uu-arch\" > /usr/local/share/zsh/site-functions/_arch\n# echo \"complete -c arch -w uu-arch\" > /usr/local/share/fish/vendor_completions.d/arch.fish\nSee also\nGNU Coreutils documentation\nGNU Coreutils FAQ\nCoreutils Gotchas\n: GNU coreutils maintainer's notes about some confusing behaviour in coreutils components\nPOSIX utilities\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Core_utilities&oldid=850548\n\"\nCategories\n:\nCommand-line\nLists of software\nHidden categories:\nPages with dead links\nPages or sections flagged with Template:Move\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nCore utilities\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Core_utilities"}}
{"text": "General recommendations - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nGeneral recommendations\n15 languages\nBosanski\nCatalà\nČeština\nΕλληνικά\nEspañol\nFrançais\nMagyar\nItaliano\n日本語\nPolski\nPortuguês\nРусский\nTürkçe\n中文（简体）\n中文（繁體）\nFrom ArchWiki\nRelated articles\nFrequently asked questions\nInstallation guide\nList of applications\nThis document is an annotated index of popular articles and important information for improving and adding functionalities to the installed Arch system. Readers are assumed to have read and followed the\nInstallation guide\nto obtain a basic Arch Linux installation. Having read and understood the concepts explained in\n#System administration\nand\n#Package management\nis\nrequired\nfor following the other sections of this page and the other articles in the wiki.\nSystem administration\nThis section deals with administrative tasks and system management. See\nCore utilities\nand\nCategory:System administration\nfor more.\nUsers and groups\nA new installation leaves you with only the\nsuperuser\naccount, better known as \"root\". Logging in as root for prolonged periods of time, possibly even exposing it via\nSSH\non a server,\nis insecure\n. Instead, you should create and use unprivileged user account(s) for most tasks, only using the root account for system administration. See\nUsers and groups#User management\nfor details.\nUsers and groups are a mechanism for\naccess control\n; administrators may fine-tune group membership and ownership to grant or deny users and services access to system resources. Read the\nUsers and groups\narticle for details and potential security risks.\nSecurity\nRead\nSecurity\nfor recommendations and best practices on hardening the system.\nFor a list of applications to allow running commands or starting an interactive shell as another user (e.g. root), see\nList of applications/Security#Privilege elevation\n.\nService management\nArch Linux uses\nsystemd\nas the\ninit\nprocess, which is a system and service manager for Linux. For maintaining your Arch Linux installation, it is a good idea to learn the basics about it.\nInteraction with\nsystemd\nis done through the\nsystemctl\ncommand. See\nsystemd#Basic systemctl usage\nfor more information.\nA logging system is also provided, with the command\njournalctl\n. See\njournal\nfor more information.\nSystem maintenance\nArch is a rolling release system and has rapid package turnover, so users have to take some time to do\nsystem maintenance\n.\nPackage management\nThis section contains helpful information related to package management. See\nFAQ#Package management\nand\nCategory:Package management\nfor more.\nNote\nIt is imperative to keep up to date with changes in Arch Linux that require manual intervention\nbefore\nupgrading your system. Subscribe to the\narch-announce mailing list\nor the\nrecent news RSS feed\n. Alternatively, check the front page\nArch news\nevery time before you update.\npacman\npacman\nis the Arch Linux\npac\nkage\nman\nager: it is highly encouraged to become familiar with it before reading any other articles.\nFor long term handling of cached packages, see\npacman#Cleaning the package cache\n.\nSee\npacman/Tips and tricks\nfor suggestions on how to improve your interaction with\npacman\nand package management in general.\nRepositories\nSee the\nOfficial repositories\narticle for details about the purpose of each officially maintained repository.\nIf you plan on using 32-bit applications, you will want to enable the\nmultilib\nrepository.\nThe\nUnofficial user repositories\narticle lists several other unsupported repositories.\nYou may consider installing the\npkgstats\nservice.\nMirrors\nVisit the\nMirrors\narticle for steps on taking full advantage of using the fastest and most up to date mirrors of the official repositories. As explained in the article, a particularly good advice is to routinely check the\nMirror Status\npage for a list of mirrors that have been recently synced. This can be automated with\nReflector\n.\nArch Build System\nPorts\nis a system initially used by BSD distributions consisting of build scripts that reside in a directory tree on the local system. Simply put, each port contains a script within a directory intuitively named after the installable third-party application.\nThe\nArch build system\noffers the same functionality by providing build scripts called\nPKGBUILDs\n, which are populated with information for a given piece of software: integrity hashes, project URL, version, license and build instructions. These PKGBUILDs are parsed by\nmakepkg\n, the actual program that generates packages that are cleanly manageable by\npacman\n.\nEvery package in the repositories along with those present in the AUR are subject to recompilation with\nmakepkg\n.\nArch User Repository\nWhile the Arch Build System allows the ability of building software available in the official repositories, the\nArch User Repository\n(AUR) is the equivalent for user submitted packages. It is an unsupported repository of build scripts accessible through the\nweb interface\nor through the\nAurweb RPC interface\n.\nBooting\nThis section contains information pertaining to the boot process. An overview of the Arch boot process can be found at\nArch boot process\n. See\nCategory:Boot process\nfor more.\nHardware auto-recognition\nHardware should be auto-detected by\nudev\nduring the boot process by default. A potential improvement in boot time can be achieved by disabling module auto-loading and specifying required modules manually, as described in\nKernel modules\n. Additionally,\nXorg\nshould be able to auto-detect required drivers using\nudev\n, but users have the option to configure the X server manually too.\nMicrocode\nProcessors may have\nfaulty behaviour\n, which the kernel can correct by updating the\nmicrocode\non startup. See\nMicrocode\nfor details.\nRetaining boot messages\nOnce the login prompt appears, the messages from boot are cleared, leaving users unable to gather feedback from them.\nDisable clearing of boot messages\nto overcome this limitation.\nNum Lock activation\nNum Lock\nis a toggle key found in most keyboards. For activating Num Lock's number key-assignment during startup, see\nActivating numlock on bootup\n.\nGraphical user interface\nThis section provides orientation for users wishing to run graphical applications on their system. See\nCategory:Graphical user interfaces\nfor additional resources.\nDisplay server\nThis article or section is a candidate for merging with\nArch boot process#Display manager\n.\nNotes:\nNo one installs a bare display server without something to run on it, the explanation of what's what is nice to have but this page is not the best fit for it. (Discuss in\nTalk:General recommendations\n)\nXorg\nis the public, open-source implementation of the\nX Window System\n(commonly X11, or X). It is required for running applications with graphical user interfaces (GUIs).\nWayland\nis a newer, alternative display server protocol with several\ncompositors\nto choose from. Its advantages over Xorg are enhanced security features, more efficient handling of modern graphics tasks and active development while retaining compatibility through\nXwayland\n.\nDisplay drivers\nThe default\nmodesetting\ndisplay driver will work with most video cards, but performance may be improved and additional features harnessed by installing the\nappropriate driver\nfor\nAMD\nor\nNVIDIA\nproducts.\nDesktop environments\nAlthough the display server provides the basic framework for building a graphical environment, additional components may be considered necessary for a complete user experience.\nDesktop environments\nsuch as\nKDE\n,\nGNOME\n,\nCOSMIC\n,\nXfce\n,\nCinnamon\n,\nLXDE\n, bundle together a wide range of well-integrated applications, such as a window manager or compositor, panel/taskbar, file manager, terminal emulator, text editor, icons, and other utilities. Users with less experience may wish to install a desktop environment for a more familiar environment. See\nCategory:Desktop environments\nfor additional resources.\nWindow managers or compositors\nA full-fledged desktop environment provides a complete and consistent graphical user interface, but tends to consume a good amount of system resources. Users seeking to maximize performance or otherwise simplify their environment may opt to install a\nwindow manager\nor\ncompositor\nalone and hand-pick desired extras. Using\nXorg\n, most desktop environments allow use of an alternative window manager as well.\nDynamic\n,\nstacking\n, and\ntiling\nwindow managers differ in their handling of window placement.\nDisplay manager\nMost desktop environments include a\ndisplay manager\nfor automatically starting the graphical environment and managing user logins. Users without a desktop environment can install one separately. Alternatively you may\nstart X at login\nas a simple alternative to a display manager.\nUser directories\nWell-known user directories like Downloads or Music are created by the\nxdg-user-dirs-update.service\nuser service, that is provided by\nxdg-user-dirs\nand enabled by default upon install. If your desktop environment or window manager does not pull in the package, you can\ninstall\nit and run\nxdg-user-dirs-update\nmanually as per\nXDG user directories#Creating default directories\n.\nPower management\nThis section may be of use to laptop owners or users otherwise seeking power management controls. See\nCategory:Power management\nfor more.\nSee\nPower management\nfor more general overview.\nACPI events\nUsers can configure how the system reacts to ACPI events such as pressing the power button or closing a laptop's lid. For the recommended method using\nsystemd\n, see\nPower management#ACPI events\n. For the old method, see\nacpid\n.\nCPU frequency scaling\nModern processors can decrease their frequency and voltage to reduce heat and power consumption. Less heat leads to more quiet system and prolongs the life of hardware. See\nCPU frequency scaling\nfor details.\nLaptops\nFor articles related to portable computing along with model-specific installation guides, please see\nCategory:Laptops\n. For a general overview of laptop-related articles and recommendations, see\nLaptop\n.\nSuspend and hibernate\nSee the main article:\nPower management/Suspend and hibernate\n.\nMultimedia\nCategory:Multimedia\nincludes additional resources.\nSound system\nALSA\nis a kernel\nsound system\nthat should work out the box (it just needs to be\nunmuted\n).\nSound servers\nsuch as\nPipeWire\nand\nPulseAudio\ncan offer additional features and support more complex audio configuration.\nSee\nProfessional audio\nfor advanced audio requirements.\nNetworking\nThis section is confined to small networking procedures. See\nNetwork configuration\nfor a full configuration guide and\nCategory:Networking\nfor related articles.\nDNS security\nFor better security while browsing the web, paying online, connecting to\nSSH\nservices and similar tasks consider using\nDNSSEC\n-enabled\nDNS resolver\nthat can validate signed\nDNS\nrecords, and an encrypted protocol such as\nDNS over TLS\n,\nDNS over HTTPS\nor\nDNSCrypt\n. See\nDomain name resolution\nfor details.\nSetting up a firewall\nA firewall can provide an extra layer of protection on top of the Linux networking stack. While the stock Arch kernel is capable of using\nNetfilter\n's\niptables\nand\nnftables\n, neither are enabled by default. It is highly recommended to set up some form of firewall. See\nCategory:Firewalls\nfor available guides.\nNetwork shares\nTo share files among the machines in a network, follow the\nNFS\nor the\nSSHFS\narticle.\nUse\nSamba\nto join a Windows network. To configure the machine to use Active Directory for authentication, read\nActive Directory integration\n.\nSee also\nCategory:Network sharing\n.\nInput devices\nThis section contains popular input device configuration tips. See\nCategory:Input devices\nfor more.\nKeyboard layouts\nNon-English or otherwise non-standard keyboards may not function as expected by default. The necessary steps to configure the keymap are different for virtual console and\nXorg\n, they are described in\nKeyboard configuration in console\nand\nKeyboard configuration in Xorg\nrespectively.\nMouse buttons\nOwners of advanced or unusual mice may find that not all mouse buttons are recognized by default, or may wish to assign different actions for extra buttons. Instructions can be found in\nMouse buttons\n.\nLaptop touchpads\nMany laptops use\nSynaptics\nor\nALPS\n\"touchpad\" pointing devices. For these, and several other touchpad models, you can use either the Synaptics input driver or libinput; see\nTouchpad Synaptics\nand\nlibinput\nfor installation and configuration details.\nTrackPoints\nSee the\nTrackPoint\narticle to configure your TrackPoint device.\nOptimization\nThis section aims to summarize tweaks, tools and available options useful to improve system and application performance.\nBenchmarking\nBenchmarking\nis the act of measuring performance and comparing the results to another system's results or a widely accepted standard through a unified procedure.\nImproving performance\nThe\nImproving performance\narticle gathers information and is a basic rundown about gaining performance in Arch Linux.\nSolid state drives\nThe\nSolid state drive\narticle covers many aspects of solid state drives, including configuring them to maximize their lifetimes, e.g. with\nTRIM\n.\nSystem services\nThis section relates to\ndaemons\n.\nFile index and search\nMost distributions have a\nlocate\ncommand available to be able to quickly search files. Arch Linux provides several alternatives, see\nlocate\nfor details.\nDesktop search engines\nprovide a similar service, while better integrated into\ndesktop environments\n.\nLocal mail delivery\nA default setup does not provide a way to synchronize mail. A list of mail delivery agents is available in the\nMail server\narticle.\nPrinting\nCUPS\nis a standards-based, open source printing system developed by OpenPrinting for Linux. See\nCategory:Printers\nfor printer-specific articles.\nAppearance\nThis section contains frequently-sought \"eye candy\" tweaks for an aesthetically pleasing Arch experience. See\nCategory:Eye candy\nfor more.\nFonts\nYou may wish to install a set of TrueType fonts, as only unscalable bitmap fonts are included in a basic Arch system. There are several general-purpose\nfont families\nproviding large\nUnicode\ncoverage and even\nmetric compatibility\nwith fonts from other operating systems.\nA plethora of information on the subject can be found in the\nFonts\nand\nFont configuration\narticles.\nIf spending a significant amount of time working from the virtual console (i.e. outside an X server), users may wish to change the console font to improve readability; see\nLinux console#Fonts\n.\nGTK and Qt themes\nA big part of the applications with a graphical interface for Linux systems are based on the\nGTK\nor the\nQt\ntoolkits. See those articles and\nUniform look for Qt and GTK applications\nfor ideas to improve the appearance of your installed programs and adapt it to your liking.\nConsole improvements\nThis section applies to small modifications that improve console programs' practicality. See\nCategory:Command-line shells\nfor more.\nTab-completion enhancements\nIt is recommended to properly set up extended\ntab completion\nright away, as instructed in the article of your chosen\nshell\n.\nAliases\nAliasing a command, or a group thereof, is a way of saving time when using the console. This is especially helpful for repetitive tasks that do not need significant alteration to their parameters between executions. Common time-saving aliases can be found in\nBash#Aliases\n, which are easily portable to\nzsh\nas well.\nAlternative shells\nBash\nis the shell installed by default in an Arch system. The live installation media, however, uses\nzsh\nwith the\ngrml-zsh-config\naddon package. See\nCommand-line shell#List of shells\nfor more alternatives.\nBash additions\nA list of miscellaneous Bash settings, history search and\nReadline\nmacros is available in\nBash#Tips and tricks\n.\nColored output\nThis section is covered in\nColor output in console\n.\nCompressed files\nCompressed files, or archives, are frequently encountered on a GNU/Linux system.\nTar\nis one of the most commonly used archiving tools, and users should be familiar with its syntax (Arch Linux packages, for example, are simply\nzstd\ncompressed tarballs). See\nArchiving and compression\n.\nConsole prompt\nThe console prompt (\nPS1\n) can be customized to a great extent. See\nBash/Prompt customization\nor\nZsh#Prompts\nif using Bash or Zsh, respectively.\nEmacs shell\nEmacs is known for featuring options beyond the duties of regular text editing, one of these being a full shell replacement. Consult\nEmacs#Colored output issues\nfor a fix regarding garbled characters that may result from enabling colored output.\nMouse support\nUsing a mouse with the console for copy-paste operations can be preferred over\nGNU Screen\n's traditional copy mode. Refer to\nGeneral purpose mouse\nfor comprehensive directions. Note that you can already do this in\nterminal emulators\nwith the\nclipboard\n.\nSession management\nUsing terminal multiplexers like\ntmux\nor\nGNU Screen\n, programs may be run under sessions composed of tabs and panes that can be detached at will, so when the user either kills the terminal emulator, terminates\nX\n, or logs off, the programs associated with the session will continue to run in the background as long as the terminal multiplexer server is active. Interacting with the programs requires reattaching to the session.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=General_recommendations&oldid=845966\n\"\nCategory\n:\nSystem administration\nHidden category:\nPages or sections flagged with Template:Merge\nSearch\nSearch\nGeneral recommendations\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/General_recommendations"}}
{"text": "System maintenance - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSystem maintenance\n8 languages\nEspañol\nFrançais\nItaliano\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nGeneral recommendations\nRegular system maintenance is necessary for the proper functioning of Arch over a period of time.  Timely maintenance is a practice many users get accustomed to.\nCheck for errors\nFailed systemd services\nCheck if any systemd services have failed:\n$ systemctl --failed\nSee\nsystemd#Using units\nfor more information.\nLog files\nLook for errors in the log files located in\n/var/log/\n, as well as messages logged in the systemd\njournal\n:\n# journalctl -b\nSee\nXorg#Troubleshooting\nfor information on where and how\nXorg\nlogs errors.\nBackup\nHaving backups of important data is a necessary measure to take, since human and machine processing errors are very likely to generate corruption as time passes, and also the physical media where the data is stored is inevitably destined to fail.\nSee\nSynchronization and backup programs\nfor many alternative applications that may better suit your case. See\nCategory:System recovery\nfor other articles of interest.\nIt is highly encouraged to automate backups and test the recovery process to ensure everything works as intended. For automation see\nSystem backup#Automation\n.\nConfiguration files\nBefore editing any configuration files, create a backup so that you can revert to a working version in case of problems. Editors like\nvim\nand\nemacs\ncan do this automatically. On a larger scale, consider using a\nconfiguration manager\n.\nFor\ndotfiles\n(configuration files in the home directory), see\ndotfiles#Tracking dotfiles directly with Git\n.\nList of installed packages\nMaintain a list of all installed packages so that if a complete re-installation is inevitable, it is easier to re-create the original environment.\nSee\npacman/Tips and tricks#List of installed packages\nfor details.\nPacman database\nSee\npacman/Tips and tricks#Back up the pacman database\n.\nEncryption metadata\nSee\nData-at-rest encryption#Backup for disk encryption scenarios\n.\nSystem and user data\nSee\nSystem backup\n.\nUpgrading the system\nIt is recommended to perform full system upgrades regularly via\npacman#Upgrading packages\n, to enjoy both the latest bug fixes and security updates, and also to avoid having to deal with too many package upgrades that require manual intervention at once. When requesting support from the community, it will usually be assumed that the system is up to date.\nMake sure to have the Arch install media or another Linux \"live\" CD/USB available so you can easily rescue your system if there is a problem after updating. If you are running Arch in a production environment, or cannot afford downtime for any reason, test changes to configuration files, as well as updates to software packages, on a non-critical duplicate system first. Then, if no problems arise, roll out the changes to the production system.\nIf the system has packages from the\nAUR\n, carefully upgrade all of them.\npacman\nis a powerful package management tool, but it does not attempt to handle all corner cases. Users must be vigilant and take responsibility for maintaining their own system.\nRead before upgrading the system\nBefore upgrading, users are expected to visit the\nArch Linux home page\nto check the latest news, or alternatively subscribe to the\nRSS feed\nor the\narch-announce mailing list\n. When updates require out-of-the-ordinary user intervention (more than what can be handled simply by following the instructions given by\npacman\n), an appropriate news post will be made.\nBefore upgrading fundamental software (such as the\nkernel\n,\nxorg\n,\nsystemd\n, or\nglibc\n) to a new version, look over the appropriate\nforum\nto see if there have been any reported problems.\nUsers must equally be aware that upgrading packages can raise\nunexpected\nproblems that could need immediate intervention; therefore, it is discouraged to upgrade a stable system shortly before it is required for carrying out an important task. Instead, wait to upgrade until there is enough time available to resolve any post-upgrade issues.\nTip\nYou could use a pacman hook like\ninformant\nAUR\n,\nnewscheck\nAUR\nor\narch-manwarn\nAUR\nwhich prevents you from updating if there is fresh Arch News that you have not read since the last update ran.\nAvoid certain pacman commands\nAvoid doing\npartial upgrades\n. In other words,\nnever\nrun\npacman -Sy\n; instead,\nalways\nuse\npacman -Syu\n.\nGenerally avoid using the\n--overwrite\noption with pacman. The\n--overwrite\noption takes an argument containing a glob. When used, pacman will bypass file conflict checks for files that match the glob. In a properly maintained system, it should only be used when explicitly recommended by the Arch Developers. See the\n#Read before upgrading the system\nsection.\nAvoid using the\n-d\noption with pacman.\npacman -Rdd\npackage\nskips dependency checks during package removal. As a result, a package providing a critical dependency could be removed, resulting in a broken system.\nPartial upgrades are unsupported\nArch Linux is a\nrolling release\ndistribution. That means when new\nlibrary\nversions are pushed to the repositories, the\nDevelopers\nand\nPackage Maintainers\nrebuild all the packages in the repositories that need to be rebuilt against the libraries. For example, if two packages depend on the same library, upgrading only one package might also upgrade the library (as a dependency), which might then break the other package which depends on an older version of the library.\nThat is why partial upgrades are\nnot supported\n. Do\nnot\nuse:\npacman -Sy\npackage\n,\npacman -Sy\nfollowed by\npacman -S\npackage\n(instead,\n-S\nu\nshould be used in the installation of the package).\nNote\npacman -Syuw\ncarries the same risks as\npacman -Sy\n, because it will update the\npacman\nsync database without installing the newer packages.\nThe bash script\ncheckupdates\n, included with the\npacman-contrib\npackage, provides a safe way to check for upgrades to installed packages without running a system update, and provides an option (\n-d\n) to download the pending updates to the pacman cache without synchronizing the database, thus avoiding partial upgrade issues when later attempting to use\npacman -S\npackage\nto install packages.\nWhen refreshing the package database,\nalways\ndo a full upgrade with\npacman -Syu\n.\nNote\nIf\npacman -Syu\nfails to complete the upgrade (i.e. the\n-Su\npart), the error must be\nresolved\nand the upgrade operation completed before other package management operations, as the database syncing (the\n-Sy\npart) has succeeded first.\nBe very careful when using\nIgnorePkg\nand\nIgnoreGroup\nfor the same reason. If the system has locally built packages (such as\nAUR\npackages), users will need to rebuild them when their dependencies receive a\nsoname\nbump.\nIf a partial upgrade scenario has been created, and binaries are broken because they cannot find the libraries they are linked against,\ndo not \"fix\" the problem simply by symlinking\n. Libraries receive\nsoname\nbumps when they are\nnot backwards compatible\n. A simple\npacman -Syu\nto a properly synced mirror will fix the problem as long as\npacman\nis not broken.\nAct on alerts during an upgrade\nWhen upgrading the system, be sure to pay attention to the alert notices provided by\npacman\n. If any additional actions are required by the user, be sure to take care of them right away. If a pacman alert is confusing, search the forums or check the latest news on the Arch Linux homepage (see\n#Read before upgrading the system\n) for more detailed instructions.\nDeal promptly with new configuration files\nWhen\npacman\nis invoked,\n.pacnew\nand\n.pacsave\nfiles can be created. Pacman provides notice when this happens and users must deal with these files promptly. Users are referred to the\npacman/Pacnew and Pacsave\nwiki page for detailed instructions.\nAlso, think about other configuration files you may have copied or created. If a package had an example configuration that you copied to your home directory, check to see if a new one has been created.\nRestart or reboot after upgrades\nUpgrades are typically not applied to existing processes. You must restart processes to fully apply the upgrade.\nThe\narchlinux-contrib\npackage provides a script called\ncheckservices\nwhich runs\npacdiff\nto merge\n.pacnew\nfiles then checks for processes running with outdated libraries and prompts the user if they want them to be restarted.\nThe kernel is particularly difficult to patch without a reboot. A reboot is always the most secure option, but if this is very inconvenient\nkernel live patching\ncan be used to apply upgrades without a reboot.\nRevert broken updates\nIf a package update is expected/known to cause problems, packagers will ensure that pacman displays an appropriate message when the package is updated. If experiencing trouble after an update, double-check pacman's output by looking at\n/var/log/pacman.log\n.\nTip\nYou can use a log viewer such as\nwat-git\nAUR\nto search the pacman logs.\nAt this point, only after ensuring there is no information available through pacman, there is no relevant news on\nhttps://archlinux.org/\n, and there are no forum posts regarding the update, consider seeking help on the\nforum\nor over\nIRC\n.\nDowngrading\nthe offending package to revert broken updates should be considered as a last resort.\nCheck for orphans and dropped packages\nAfter upgrading you may now have packages that are no longer needed or that are no longer in the official repositories.\nUse\npacman -Qtd\nto check for packages that were installed as a dependency but now, no other packages depend on them. If an orphaned package is still needed, it is recommended to change the\ninstallation reason\nto explicit. Otherwise, if the package is no longer needed, it can be removed. See\npacman/Tips and tricks#Removing unused packages (orphans)\nfor details.\nAdditionally, some packages may no longer be in the remote repositories, but they still may be on your local system. To list all foreign packages use\npacman -Qm\n. Note that this list will include packages that have been installed manually (e.g., from the\nAUR\n). To exclude packages that are (still) available on the AUR, use the script from\nBBS#288205\nor try the\nancient-packages\nAUR\ntool.\nUse the package manager to install software\nPacman\ndoes a much better job than you at keeping track of files. If you install things manually you\nwill\n, sooner or later, forget what you did, forget where you installed to, install conflicting software, install to the wrong locations, etc.\nInstall packages from the official repositories using the method in the\npacman#Installing packages\nsection.\nIf the program you desire is not available, check to see if someone has created a package in the\nAUR\n. Follow the method in that article for installation.\nLastly, if the program you want is not in the official repositories or in the AUR, learn how to\ncreate a package\nfor it.\nTo clean up improperly installed files, see\npacman/Tips and tricks#Identify files not owned by any package\n.\nChoose open-source drivers\nAlways try open source drivers before resorting to proprietary drivers. Most of the time, open source drivers are more stable and reliable than proprietary drivers. Open source driver bugs are fixed more easily and quickly. While proprietary drivers can offer more features and capabilities, this can come at the cost of stability. To avoid this dilemma, try to choose hardware components known to have mature open source driver support with full features. Information about hardware with open source Linux drivers is available at\nlinux-drivers.org\n.\nBe careful with unofficial packages\nUse precaution when using packages from the\nAUR\nor an\nunofficial user repository\n. Most are supplied by regular users and thus may not have the same standards as those in the official repositories.\nAlways\ncheck PKGBUILDs for sanity and signs of mistake or malicious code before building and/or installing the package.\nTo simplify maintenance, limit the amount of unofficial packages used. Make periodic checks on which are in actual use, and remove (or replace with their official counterparts) any others. See\npacman/Tips and tricks#Maintenance\nfor useful commands. Following system upgrade, use\nrebuild-detector\nto identify any unofficial packages that may need to be rebuilt.\nUpdate the mirrorlist\nUpdate pacman's mirrorlist, as the quality of mirrors can vary over time, and some might go offline or their download rate might degrade.\nSee\nmirrors\nfor details.\nClean the filesystem\nPrograms that help with this can be found in\nList of applications/Utilities#Disk cleaning\n.\nUnused large files\nWhen looking for files to remove, it is important to find the files that take up the most disk space. Programs that help with this can be found in\nList of applications/Utilities#Disk usage display\n.\nPackage cache\nRemove unwanted\n.pkg\nfiles from\n/var/cache/pacman/pkg/\nto free up disk space.\nSee\npacman#Cleaning the package cache\nfor more information.\nUnused packages\nRemove unused packages from the system to free up disk space and simplify maintenance.\nSee\n#Check for orphans and dropped packages\n.\nOld configuration files\nOld configuration files may conflict with newer software versions, or corrupt over time. Remove unneeded configurations periodically, particularly in your home directory and\n~/.config\n. For similar reasons, be careful when sharing home directories between installations.\nLook for the following directories:\n~/.config/\n-- where applications stores their configuration\n~/.cache/\n-- cache of some programs may grow in size\n~/.local/share/\n-- old files may be lying there\nSee\nXDG Base Directory support\nfor more information about these directories.\nTo keep the home directory clean from temporary files created at the wrong place, it is a good idea to manage a list of unwanted files and remove them regularly, for example with\nrmshit.py\n.\nrmlint-git\nAUR\ncan be used to find and optionally remove duplicate files, empty files, recursive empty directories and broken symlinks.\nBroken symlinks\nOld, broken symbolic links might be sitting around your system; you should remove them. Examples on achieving this can be found\nhere\nand\nhere\n. However, you should not blindly delete all broken symbolic links, as some of them serve a purpose\n[1]\n.\nTo quickly list all the broken symlinks of permanent files on your system, use:\n# find / -type d \\( -path \"/dev\" -o -path \"/proc\" -o -path \"/run\" -o -path \"/sys\" \\) -prune -o -xtype l -print\nThen inspect and remove unnecessary entries from this list.\nTips and tricks\nThe following tips are generally not required, but certain users may find them useful.\nUse proven software packages\nArch's rolling releases can be a boon for users who want to try the latest features and get upstream updates as soon as possible, but they can also make system maintenance more difficult. To simplify maintenance and improve stability, try to avoid cutting edge software and install only mature and proven software. Such packages are less likely to receive difficult upgrades such as major configuration changes or feature removals. Prefer software that has a strong and active development community, as well as a high number of competent users, in order to simplify support in the event of a problem.\nAvoid any use of the testing repository, even individual packages from testing. These packages are experimental and not suitable for a stable system. Similarly, avoid packages which are built directly from upstream development sources. These are usually found in the\nAUR\n, with names including things like: \"dev\", \"devel\", \"svn\", \"cvs\", \"git\", etc.\nInstall the linux-lts package\nThe\nlinux-lts\npackage is an alternative Arch kernel package, and is available in the\ncore\nrepository. This particular kernel version has long-term support (LTS) from upstream, including security and bug fixes. It is useful if you use out-of-tree kernel modules and want to ensure their compatibility or if you want a fallback kernel in case a new kernel version causes problems.\nTo make it available as a boot option, you will need to update your\nboot loader\n's configuration file to use the LTS kernel and ram disk:\nvmlinuz-linux-lts\nand\ninitramfs-linux-lts.img\n.\nSee also\nArch News Bash Script\nfwupd\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=System_maintenance&oldid=850140\n\"\nCategory\n:\nSystem administration\nSearch\nSearch\nSystem maintenance\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/System_maintenance"}}
{"text": "Improving performance - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nImproving performance\n8 languages\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nPolski\nFrom ArchWiki\n(Redirected from\nPerformance\n)\nRelated articles\n/Boot process\nPacman/Tips and tricks#Performance\nOpenSSH#Speeding up SSH\nOpenoffice#Speed up OpenOffice\nLaptop\nPreload\nThis article provides information on basic system diagnostics relating to performance as well as steps that may be taken to reduce resource consumption or to otherwise optimize the system with the end-goal being either perceived or documented improvements to a system's performance. See also\nGaming#Improving performance\nfor additional gaming and low latency specific advice.\nThe basics\nKnow your system\nThe best way to tune a system is to target bottlenecks, or subsystems which limit overall speed. The system specifications can help identify them.\nIf the computer becomes slow when large applications (such as LibreOffice and Firefox) run at the same time, check if the amount of RAM is sufficient. Use the following command, and check the \"available\" column:\n$ free -h\nIf boot time is slow, and applications take a long time to load at first launch (only), then the hard drive is likely to blame. The speed of a hard drive can be measured with the\nhdparm\ncommand:\n# hdparm -t /dev/sd\nX\nNote\nhdparm\nindicates only the pure read speed of a hard drive, and is not a valid benchmark. A value higher than 40MB/s (while idle) is however acceptable on an average system.\nIf CPU load is consistently high even with enough RAM available, then try to lower CPU usage by disabling running\ndaemons\nand/or processes. This can be monitored in several ways, for example with\nhtop\n,\npstree\nor any other\nsystem monitoring\ntool:\n$ htop\nIf applications using direct rendering are slow (i.e those which use the GPU, such as video players, games, or even a\nwindow manager\n), then improving GPU performance should help. The first step is to verify if direct rendering is actually enabled. This is indicated by the\nglxinfo\ncommand, part of the\nmesa-utils\npackage, which should return\ndirect rendering: Yes\nwhen used:\n$ glxinfo | grep \"direct rendering\"\nWhen running a\ndesktop environment\n, disabling (unused) visual desktop effects may reduce GPU usage. Use a more lightweight environment or create a\ncustom environment\nif the current does not meet the hardware and/or personal requirements.\nUsing an optimized\nkernel\nimproves performance. Generally,\nlinux-zen\nis a good option. However, the default kernel can be tweaked as shown in certain parts of this article to perform better.\nBenchmarking\nThe effects of optimization are often difficult to judge. They can however be measured by\nbenchmarking\ntools.\nStorage devices\nSector size\nCheck that your NVMe drives and Advanced Format hard disk drives are using the\noptimal logical sector size\n.\nPartitioning\nMake sure that your partitions are\nproperly aligned\n.\nMultiple drives\nIf you have multiple disks available, you can set them up as a software\nRAID\nfor serious speed improvements.\nCreating\nswap\non a separate disk can also help quite a bit, especially if your machine swaps frequently.\nAn SSD as a cache for an HDD\nWhen forgoing hard disk drives is not an option, a solid state drive can be added as a caching layer to improve the read and/or write speeds and reduce the noise from random access. The options to accomplish this include\nLVM#Cache\n,\nBcache\nand\nBcachefs#SSD caching\n.\nLayout on HDDs\nIf using a traditional spinning HDD, your partition layout can influence the system's performance. Sectors at the beginning of the drive (closer to the outside of the disk) are faster than those at the end. Also, a smaller partition requires less movements from the drive's head, and so speed up disk operations. Therefore, it is advised to create a small partition (15-20GiB, more or less depending on your needs) only for your system, as near to the beginning of the drive as possible. Other data (pictures, videos) should be kept on a separate partition, and this is usually achieved by separating the home directory (\n/home\n) from the system (\n/\n).\nNote\nAs with all advice on this page, measure what benefits are provided: unless\nshort stroking\nthe hard drive and using only a few percent of its total capacity, separating partitions will improve access time by only a few percent since the read/write operations will still be spread over the whole drive in general use. Comparatively, upgrading to an SSD will improve performance by more than an order of magnitude.\nChoosing and tuning your filesystem\nChoosing the best filesystem for a specific system is very important because each has its own strengths. The\nFile systems\narticle provides a short summary of the most popular ones. You can also find relevant articles in\nCategory:File systems\n.\nMount options\nThe various\n*atime\noptions can mitigate the performance penalty of\nstrictatime\n.\nOther mount options are filesystem specific, therefore see the relevant articles for the filesystems:\nExt3\nExt4#Improving performance\nJFS#Optimizations\nXFS#Performance\nBtrfs#Defragmentation\n,\nBtrfs#Compression\n, and\nbtrfs(5)\nZFS#Tuning\nNTFS#Improving performance\nTuning kernel parameters\nThere are several key tunables affecting the performance of block devices, see\nsysctl#Virtual memory\nfor more information.\nInput/output schedulers\nBackground information\nThe input/output\n(I/O)\nscheduler is the kernel component that decides in which order the block I/O operations are submitted to storage devices. It is useful to remind here some specifications of two main drive types because the goal of the I/O scheduler is to optimize the way these are able to deal with read requests:\nAn HDD has spinning disks and a head that moves physically to the required location. Therefore, random latency is quite high ranging between 3 and 12ms (whether it is a high end server drive or a laptop drive and bypassing the disk controller write buffer) while sequential access provides much higher throughput. The typical HDD throughput is about 200 I/O operations per second\n(IOPS)\n.\nAn SSD does not have moving parts, random access is as fast as sequential one, typically under 0.1ms, and it can handle multiple concurrent requests. The typical SSD throughput is greater than 10,000 IOPS, which is more than needed in common workload situations.\nIf there are many processes making I/O requests to different storage parts, thousands of IOPS can be generated while a typical HDD can handle only about 200 IOPS. There is a queue of requests that have to wait for access to the storage. This is where the I/O schedulers plays an optimization role.\nThe scheduling algorithms\nOne way to improve throughput is to linearize access: by ordering waiting requests by their logical address and grouping the closest ones. Historically this was the first Linux I/O scheduler called\nelevator\n.\nOne issue with the elevator algorithm is that it is not optimal for a process doing sequential access: reading a block of data, processing it for several microseconds then reading next block and so on. The elevator scheduler does not know that the process is about to read another block nearby and, thus, moves to another request by another process at some other location. The\nanticipatory\nI/O scheduler overcomes the problem: it pauses for a few milliseconds in anticipation of another close-by read operation before dealing with another request.\nWhile these schedulers try to improve total throughput, they might leave some unlucky requests waiting for a very long time. As an example, imagine the majority of processes make requests at the beginning of the storage space while an unlucky process makes a request at the other end of storage. This potentially infinite postponement of the process is called starvation. To improve fairness, the\ndeadline\nalgorithm was developed. It has a queue ordered by address, similar to the elevator, but if some request sits in this queue for too long then it moves to an \"expired\" queue ordered by expire time. The scheduler checks the expire queue first and processes requests from there and only then moves to the elevator queue. Note that this fairness has a negative impact on overall throughput.\nThe\nCompletely Fair Queuing (CFQ)\napproaches the problem differently by allocating a timeslice and a number of allowed requests by queue depending on the priority of the process submitting them. It supports\ncgroup\nthat allows to reserve some amount of I/O to a specific collection of processes. It is in particular useful for shared and cloud hosting: users who paid for some IOPS want to get their share whenever needed. Also, it idles at the end of synchronous I/O waiting for other nearby operations, taking over this feature from the\nanticipatory\nscheduler and bringing some enhancements. Both the\nanticipatory\nand the\nelevator\nschedulers were decommissioned from the Linux kernel replaced by the more advanced alternatives presented below.\nThe\nBudget Fair Queuing (BFQ)\nis based on CFQ code and brings some enhancements. It does not grant the disk to each process for a fixed time-slice but assigns a \"budget\" measured in number of sectors to the process and uses heuristics. It is a relatively complex scheduler, it may be more adapted to rotational drives and slow SSDs because its high per-operation overhead, especially if associated with a slow CPU, can slow down fast devices. The objective of BFQ on personal systems is that for interactive tasks, the storage device is virtually as responsive as if it was idle. In its default configuration it focuses on delivering the lowest latency rather than achieving the maximum throughput, which can sometimes greatly\naccelerate the startup of applications\non hard drives.\nKyber\nis a recent scheduler inspired by active queue management techniques used for network routing. The implementation is based on \"tokens\" that serve as a mechanism for limiting requests. A queuing token is required to allocate a request, this is used to prevent starvation of requests. A dispatch token is also needed and limits the operations of a certain priority on a given device. Finally, a target read latency is defined and the scheduler tunes itself to reach this latency goal. The implementation of the algorithm is relatively simple and it is deemed efficient for fast devices.\nKernel's I/O schedulers\nWhile some of the early algorithms have now been decommissioned, the official Linux kernel supports a number of I/O schedulers. The\nMulti-Queue Block I/O Queuing Mechanism (blk-mq)\nmaps I/O queries to multiple queues, the tasks are distributed across threads and therefore CPU cores. Within this framework the following schedulers are available:\nNone\n, where no queuing algorithm is applied.\nmq-deadline\n, the adaptation of the deadline scheduler (see below) to multi-threading.\nKyber\nBFQ\nChanging I/O scheduler\nNote\nThe best choice of scheduler depends on both the device and the exact nature of the workload. Also, the throughput in MB/s is not the only measure of performance: deadline or fairness deteriorate the overall throughput but may improve system responsiveness.\nBenchmarking\nmay be useful to indicate each I/O scheduler performance.\nTo list the available schedulers for a device and the active scheduler (in brackets):\n$ cat /sys/block/\nsda\n/queue/scheduler\nmq-deadline kyber [bfq] none\nTo list the available schedulers for all devices:\n$ grep \"\" /sys/block/\n*\n/queue/scheduler\n/sys/block/pktcdvd0/queue/scheduler:none\n/sys/block/sda/queue/scheduler:mq-deadline kyber [bfq] none\n/sys/block/sr0/queue/scheduler:[mq-deadline] kyber bfq none\nTo change the active I/O scheduler to\nbfq\nfor device\nsda\n, use:\n# echo\nbfq\n> /sys/block/\nsda\n/queue/scheduler\nThe process to change I/O scheduler, depending on whether the disk is rotating or not can be automated and persist across reboots. For example the\nudev\nrules below set the scheduler to\nbfq\nfor rotational drives,\nbfq\nfor\nSSD\n/eMMC drives and\nnone\nfor\nNVMe\ndrives:\n/etc/udev/rules.d/60-ioschedulers.rules\n# HDD\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n# SSD\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"bfq\"\n# NVMe SSD\nACTION==\"add|change\", KERNEL==\"nvme[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"none\"\nReboot or force\nudev#Loading new rules\n.\nTuning I/O scheduler\nEach of the kernel's I/O scheduler has its own tunables, such as the latency time, the expiry time or the FIFO parameters. They are helpful in adjusting the algorithm to a particular combination of device and workload. This is typically to achieve a higher throughput or a lower latency for a given utilization.\nThe tunables and their description can be found within the\nkernel documentation\n.\nTo list the available tunables for a device, in the example below\nsdb\nwhich is using\ndeadline\n, use:\n$ ls /sys/block/\nsdb\n/queue/iosched\nfifo_batch  front_merges  read_expire  write_expire  writes_starved\nTo improve\ndeadline'\ns throughput at the cost of latency, one can increase\nfifo_batch\nwith the command:\n# echo\n32\n> /sys/block/\nsdb\n/queue/iosched/\nfifo_batch\nPower management configuration and write cache\nWhen dealing with traditional rotational disks (HDDs) you may want to completely disable or lower power saving features, and check if the write cache is enabled.\nSee\nHdparm#Power management configuration\nand\nHdparm#Write cache\n.\nAfterwards, you can make a\nudev rule\nto apply them on boot-up.\nTip\nGNOME\nallows the setting of some of these parameters through the Disks application and does not require a udev rule.\nNote\nSome features might not be supported by your hard drive. If that's the case, Hdparm will notify you. Hence, simply ignore the configuration of this certain feature.\nReduce disk reads/writes\nAvoiding unnecessary access to slow storage drives is good for performance and also increasing lifetime of the devices, although on modern hardware the difference in life expectancy is usually negligible.\nNote\nA 32GB SSD with a mediocre 10x write amplification factor, a standard 10000 write/erase cycle, and\n10GB of data written per day\n, would get an\n8 years life expectancy\n. It gets better with\nbigger SSDs\nand modern controllers with less write amplification. See also\nthis endurance experiment\nwhen considering whether any particular strategy to limit disk writes is actually needed.\nShow disk writes\nThe\niotop\npackage can sort by disk writes, and show how much and how frequently programs are writing to the disk. See\niotop(8)\nfor details.\nRelocate files to tmpfs\nRelocate files, such as your browser profile, to a\ntmpfs\nfile system, for improvements in application response as all the files are now stored in RAM:\nRefer to\nProfile-sync-daemon\nfor syncing browser profiles. Certain browsers might need special attention, see e.g.\nFirefox on RAM\n.\nRefer to\nAnything-sync-daemon\nfor syncing any specified folder.\nRefer to\nMakepkg#Improving build times\nfor improving compile times by building packages in tmpfs.\nFile systems\nRefer to corresponding\nfile system\npage in case there were performance improvements instructions, see the list at\n#Choosing and tuning your filesystem\n.\nSwap space\nSee\nSwap#Performance\nfor details.\nWriteback interval and buffer size\nSee\nSysctl#Virtual memory\nfor details.\nDisable core dumps\nSee\nCore dump#Disabling automatic core dumps\n.\nStorage I/O scheduling with ionice\nMany tasks such as backups do not rely on a short storage I/O delay or high storage I/O bandwidth to fulfill their task, they can be classified as background tasks. On the other hand quick I/O is necessary for good UI responsiveness on the desktop. Therefore it is beneficial to reduce the amount of storage bandwidth available to background tasks, whilst other tasks are in need of storage I/O. This can be achieved by making use of the Linux I/O scheduler BFQ, which allows setting different priorities for processes.\nThe I/O priority of a background process can be reduced to the \"Idle\" level by starting it with\n$ ionice -c 3\ncommand\nSee\na short introduction to ionice\nand\nionice(1)\nfor more information.\nTrimming\nFor optimal performance, empty blocks of solid state drives should be discarded (a.k.a. trimmed) periodically to optimize random write speeds. See\nSolid state drive#TRIM\nfor more information.\nNetwork\nKernel networking: see\nSysctl#Improving performance\nNIC: see\nNetwork configuration#Set device MTU and queue length\nDNS: consider using a caching DNS resolver, see\nDomain name resolution#DNS servers\nSamba: see\nSamba#Improve throughput\nCPU\nOverclocking\nOverclocking\nimproves the computational performance of the CPU by increasing its peak clock frequency. The ability to overclock depends on the combination of CPU model and motherboard model. It is most frequently done through the BIOS. Overclocking also has disadvantages and risks. It is neither recommended nor discouraged here.\nMany Intel chips will not correctly report their clock frequency to acpi_cpufreq and most other utilities. This will result in excessive messages in\ndmesg\n, which can be avoided by unloading and blacklisting the kernel module\nacpi_cpufreq\n.\nTo read their clock speed use\ni7z\nfrom the\ni7z\nAUR\npackage. To check for correct operation of an overclocked CPU, it is recommended to do\nstress testing\n.\nFrequency scaling\nSee\nCPU frequency scaling\n.\nCPU scheduler\nThe default CPU scheduler in the mainline Linux kernel is\nEEVDF\n.\nThis article or section needs expansion.\nReason:\nAdd CFS, the previous default scheduler, to the list. (Discuss in\nTalk:Improving performance\n)\nProject C\n— Cross-project for refactoring BMQ into Project C, with re-creation of PDS based on the Project C code base. So it is a merge of the two projects, with a subsequent update of the PDS as Project C. Recommended as a more recent development.\nhttps://cchalpha.blogspot.com/\n||\nlinux-prjc\nAUR\nBORE\n— The BORE scheduler focuses on sacrificing some fairness for lower latency in scheduling interactive tasks, it is built on top of CFS and is only adjusted for vruntime code updates, so the overall changes are quite small compared to other unofficial CPU schedulers.\nhttps://github.com/firelzrd/bore-scheduler\n||\nlinux-cachyos-bore\nAUR\nSCX\n— Allows dynamic injection of various CPU schedulers without requiring a system reset.\nhttps://github.com/sched-ext/scx\n||\nscx-scheds\nReal-time kernel\nSome applications such as running a TV tuner card at full HD resolution (1080p) may benefit from using a\nrealtime kernel\n.\nAdjusting priorities of processes\nSee also\nnice(1)\nand\nrenice(1)\n.\nAnanicy\nAnanicy CPP\nis a daemon, available as\nananicy-cpp\nor\nananicy-cpp-git\nAUR\n, for auto adjusting the nice levels of executables. The nice level represents the priority of the executable when allocating CPU resources.\nWarning\nGameMode\nand\nAnanicy CPP\nboth adjust the nice levels of processes. However, combining both tools is not recommended.\n[1]\ncgroups\nSee\ncgroups\n.\nLimitCPU\nLimitCPU\nis a program to limit the CPU usage percentage of a specific process. After installing\nlimitcpu\nAUR\n, you may limit the CPU usage of a process's PID using a scale of 0 to 100 times the number of CPU cores that the computer has. For example, with eight CPU cores the percentage range will be 0 to 800. Usage:\n$ limitcpu -l 50 -p 5081\nirqbalance\nThe purpose of\nirqbalance\nis to distribute hardware interrupts across processors on a multiprocessor system in order to increase performance. It can be\ncontrolled\nby the provided\nirqbalance.service\n.\nWarning\nIn some cases, irqbalance can interfere with power saving and can lead to stuttering or bad framerates in video games\n[2]\n.\nTurn off CPU exploit mitigations\nWarning\nDo not apply this setting without considering the vulnerabilities it opens up. Among other things, if this option is enabled, you\nmust not rely on a virtual machine to isolate untrusted programs\n. See\nthis\nand\nthis\nfor more information.\nTurning off CPU exploit mitigations may improve performance. Use below\nkernel parameter\nto disable them all:\nmitigations=off\nThe explanations of all the switches it toggles are given at\nkernel.org\n. You can use\nspectre-meltdown-checker\nAUR\nor\nlscpu(1)\n(from\nutil-linux\n) for vulnerability check.\nNote\nWhen using an Intel CPU from generation 10 and later, or AMD Ryzen series 1000 and later, the performance uplift from disabling mitigations is only up to 5% instead of the up to 25% for the previous CPU generations. See\nthe general review from early 2021\n,\nthe test on Rocket Lake\nand\nthe test on Alder Lake\nTuning compilation for your CPU\nDepending on your CPU, you may be able to gain a small performance boost by compiling software tuned for your native CPU\nmicroarchitecture\nwith the flag\n-march=native\n, but any binaries you compile with this flag will be slow or broken on other CPU microarchitectures. If you use this option and want to switch or upgrade your CPU, you need to either recompile your binaries or choose a new CPU that uses the same microarchitecture as your old one. You can\napply this option by default for makepkg\n.\nIf you\ncompile your own kernel\n, you can also enable this option during kernel compilation with the\nCONFIG_X86_NATIVE_CPU\noption. Although, results are hardly significant as the kernel\nforbids\nextended vector instructions in generic code, which are responsible for the most of performance improvement in regular binaries.\nGraphics\nXorg configuration\nGraphics performance may depend on the settings in\nxorg.conf(5)\n; see the\nNVIDIA\n,\nAMDGPU\nand\nIntel\narticles. Improper settings may stop Xorg from working, so caution is advised.\nMesa configuration\nThe performance of the Mesa drivers can be configured via\ndrirc\n.\nadriconf\n(Advanced DRI Configurator) is a GUI tool to configure Mesa drivers by setting options and writing them to the standard drirc file.\nHardware video acceleration\nHardware video acceleration\nmakes it possible for the video card to decode/encode video.\nOverclocking\nAs with CPUs, overclocking can directly improve performance, but is generally recommended against. There are several packages, such as\nrovclock\nAUR\n(ATI cards),\nrocm-smi-lib\n(recent AMD cards),\nnvclock\nAUR\n(old NVIDIA - up to Geforce 9), and\nnvidia-utils\nfor recent NVIDIA cards.\nSee\nAMDGPU#Overclocking\nor\nNVIDIA/Tips and tricks#Enabling overclocking in nvidia-settings\n.\nEnabling PCIe resizable BAR\nNote\nOn some systems enabling PCIe resizable BAR can result in a significant loss of performance. Benchmark your system to make sure it increases performance.\nThe\nCompatibility Support Module (CSM)\nmust be disabled for this to take effect.\nThe PCI specification allows larger\nBase Address Registers\n(BARs) to be used for exposing PCI devices memory to the PCI Controller. This can result in a performance increase for video cards. Having access to the full video memory improves performance, but also enables optimizations in the graphics driver. The combination of resizable BAR, above 4G decoding and these driver optimizations are what AMD calls\nAMD Smart Access Memory\n, available at first on AMD Series 500 chipset motherboards, later expanded to AMD Series 400 and Intel Series 300 and later through UEFI updates. This setting may not be available on all motherboards, and is known to sometimes cause boot problems on certain boards.\nIf the BAR has a 256M size, the feature is not enabled or not supported:\n# dmesg | grep BAR=\n[drm] Detected VRAM RAM=8176M, BAR=256M\nTo enable it, enable the setting named \"Above 4G Decode\" or \">4GB MMIO\" in your motherboard settings. Verify that the BAR is now larger:\n# dmesg | grep BAR=\n[drm] Detected VRAM RAM=8176M, BAR=8192M\nRAM, swap and OOM handling\nClock frequency and timings\nRAM can run at different clock frequencies and timings, which can be configured in the BIOS. Memory performance depends on both values. Selecting the highest preset presented by the BIOS usually improves the performance over the default setting. Note that increasing the frequency to values not supported by both motherboard and RAM vendor is overclocking, and similar risks and disadvantages apply, see\n#Overclocking\n.\nRoot on RAM overlay\nThis article or section is out of date.\nReason:\nThe liveroot script appears to be unmaintained, but this approach should still work. (Discuss in\nTalk:Improving performance#Section_5.2: liveroot hasn't been updated since 2016\n)\nIf running off a slow writing medium (USB, spinning HDDs) and storage requirements are low, the root may be run on a RAM overlay ontop of read only root (on disk). This can vastly improve performance at the cost of a limited writable space to root. See\nliveroot\nAUR\n.\nSwap on zram or zswap\nSimilar benefits (at similar costs) can be achieved using\nzswap\nor\nswap on zram\n. The two are generally similar in intent although not operation:\nzswap operates as a compressed RAM cache and neither requires (nor permits) extensive userspace configuration. It works in conjunction with a swap device by acting as its cache. Pages that would normally enter swap can enter zswap instead.\nzram is a kernel module which can be used to create a compressed block device in RAM. This compressed block device can be used as a swap device, with no other swap device required to back it up. It comes with many options, including the possibility of using a backing device for holding cold pages.\nBecause both options involve the\nswap\nsubsystem, configuration that affects swap also affects these systems. For example,\nswappiness\ndetermines whether the kernel should prioritize dropping file cache or moving pages to swap when memory pressure is high. Because zswap intercepts the action of moving pages to swap and zram acts as the swap, the option would also determine how often these two mechanisms are used.\nUsing the graphics card's RAM\nIn the unlikely case that you have very little RAM and a surplus of video RAM, you can use the latter as swap. See\nSwap on video RAM\n.\nImproving system responsiveness under low-memory conditions\nThis article or section needs expansion.\nReason:\nThe\nsystemd.service(5)\nwatchdog settings should be mentioned and crosslinked, see also\nSystemd#Notifying about failed services\n). (Discuss in\nTalk:Improving performance\n)\nOn traditional GNU/Linux system, especially for graphical workstations, when allocated memory is overcommitted, the overall system's responsiveness may degrade to a nearly unusable state before either triggering the in-kernel out-of-memory (OOM)-killer or a sufficient amount of memory got free (which is unlikely to happen quickly when the system is unresponsive, as you can hardly close any memory-hungry applications which may continue to allocate more memory). The behaviour also depends on specific setups and conditions, returning to a normal responsive state may take from a few seconds to more than half an hour, which could be a pain to wait in serious scenario like during a conference presentation.\nWhile the behaviour of the kernel as well as the userspace things under low-memory conditions may improve in the future as discussed on\nkernel\nand\nFedora\nmailing lists, users can use more feasible and effective options than hard-resetting the system or tuning the\nvm.overcommit_*\nsysctl\nparameters:\nManually trigger the kernel OOM-killer with\nMagic SysRq key\n, namely\nAlt+SysRq+f\n.\nUse a userspace OOM daemon to tackle these automatically (or interactively).\nWarning\nTriggering OOM killer to kill running applications may lose your unsaved works.  It is up to you that either you are patient enough to wait in hope that applications will finally free the memory normally, or you want to bring back unresponsive system as soon as possible.\nSometimes a user may prefer OOM daemon to SysRq because with kernel OOM-killer you cannot prioritize the process to (or not) terminate. To list some OOM daemons:\nsystemd-oomd\n— Provided by\nsystemd\nas\nsystemd-oomd.service\nthat uses cgroups-v2 and pressure stall information (PSI) to monitor and take action on processes before an OOM occurs in kernel space.\nhttps://github.com/systemd/systemd\n,\nsystemd-oomd(8)\n||\nsystemd\nearlyoom\n— Simple userspace OOM-killer implementation written in C.\nhttps://github.com/rfjakob/earlyoom\n||\nearlyoom\noomd\n— OOM-killer implementation based on\nPSI\n, requires Linux kernel version 4.20+. Configuration is in JSON and is quite complex. Confirmed to work in Facebook's production environment.\nhttps://github.com/facebookincubator/oomd\n||\noomd\nAUR\nnohang\n— Sophisticated OOM handler written in Python, with optional PSI support, more configurable than earlyoom.\nhttps://github.com/hakavlad/nohang\n||\nnohang-git\nAUR\nlow-memory-monitor\n— GNOME developer's effort that aims to provide better communication to userspace applications to indicate the low memory state, besides that it could be configured to trigger the kernel OOM-killer.  Based on PSI, requires Linux 5.2+.\nhttps://gitlab.freedesktop.org/hadess/low-memory-monitor/\n||\nlow-memory-monitor-git\nAUR\nuresourced\n— A small daemon that enables cgroup based resource protection for the active graphical user session.\nhttps://gitlab.freedesktop.org/benzea/uresourced\n||\nuresourced\nAUR\nbustd\n— Very lightweight userspace OOM-killer, useful for slower machines. Based on PSI, requires Linux 4.2+.\nhttps://github.com/vrmiguel/bustd\n||\nbustd\nAUR\nSee also\nRed Hat Performance Tuning Guide\nLinux Performance Measurements using vmstat\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Improving_performance&oldid=854315\n\"\nCategories\n:\nHardware\nSystem administration\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nImproving performance\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Performance"}}
{"text": "Improving performance - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nImproving performance\n8 languages\nEspañol\nFrançais\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nPolski\nFrom ArchWiki\nRelated articles\n/Boot process\nPacman/Tips and tricks#Performance\nOpenSSH#Speeding up SSH\nOpenoffice#Speed up OpenOffice\nLaptop\nPreload\nThis article provides information on basic system diagnostics relating to performance as well as steps that may be taken to reduce resource consumption or to otherwise optimize the system with the end-goal being either perceived or documented improvements to a system's performance. See also\nGaming#Improving performance\nfor additional gaming and low latency specific advice.\nThe basics\nKnow your system\nThe best way to tune a system is to target bottlenecks, or subsystems which limit overall speed. The system specifications can help identify them.\nIf the computer becomes slow when large applications (such as LibreOffice and Firefox) run at the same time, check if the amount of RAM is sufficient. Use the following command, and check the \"available\" column:\n$ free -h\nIf boot time is slow, and applications take a long time to load at first launch (only), then the hard drive is likely to blame. The speed of a hard drive can be measured with the\nhdparm\ncommand:\n# hdparm -t /dev/sd\nX\nNote\nhdparm\nindicates only the pure read speed of a hard drive, and is not a valid benchmark. A value higher than 40MB/s (while idle) is however acceptable on an average system.\nIf CPU load is consistently high even with enough RAM available, then try to lower CPU usage by disabling running\ndaemons\nand/or processes. This can be monitored in several ways, for example with\nhtop\n,\npstree\nor any other\nsystem monitoring\ntool:\n$ htop\nIf applications using direct rendering are slow (i.e those which use the GPU, such as video players, games, or even a\nwindow manager\n), then improving GPU performance should help. The first step is to verify if direct rendering is actually enabled. This is indicated by the\nglxinfo\ncommand, part of the\nmesa-utils\npackage, which should return\ndirect rendering: Yes\nwhen used:\n$ glxinfo | grep \"direct rendering\"\nWhen running a\ndesktop environment\n, disabling (unused) visual desktop effects may reduce GPU usage. Use a more lightweight environment or create a\ncustom environment\nif the current does not meet the hardware and/or personal requirements.\nUsing an optimized\nkernel\nimproves performance. Generally,\nlinux-zen\nis a good option. However, the default kernel can be tweaked as shown in certain parts of this article to perform better.\nBenchmarking\nThe effects of optimization are often difficult to judge. They can however be measured by\nbenchmarking\ntools.\nStorage devices\nSector size\nCheck that your NVMe drives and Advanced Format hard disk drives are using the\noptimal logical sector size\n.\nPartitioning\nMake sure that your partitions are\nproperly aligned\n.\nMultiple drives\nIf you have multiple disks available, you can set them up as a software\nRAID\nfor serious speed improvements.\nCreating\nswap\non a separate disk can also help quite a bit, especially if your machine swaps frequently.\nAn SSD as a cache for an HDD\nWhen forgoing hard disk drives is not an option, a solid state drive can be added as a caching layer to improve the read and/or write speeds and reduce the noise from random access. The options to accomplish this include\nLVM#Cache\n,\nBcache\nand\nBcachefs#SSD caching\n.\nLayout on HDDs\nIf using a traditional spinning HDD, your partition layout can influence the system's performance. Sectors at the beginning of the drive (closer to the outside of the disk) are faster than those at the end. Also, a smaller partition requires less movements from the drive's head, and so speed up disk operations. Therefore, it is advised to create a small partition (15-20GiB, more or less depending on your needs) only for your system, as near to the beginning of the drive as possible. Other data (pictures, videos) should be kept on a separate partition, and this is usually achieved by separating the home directory (\n/home\n) from the system (\n/\n).\nNote\nAs with all advice on this page, measure what benefits are provided: unless\nshort stroking\nthe hard drive and using only a few percent of its total capacity, separating partitions will improve access time by only a few percent since the read/write operations will still be spread over the whole drive in general use. Comparatively, upgrading to an SSD will improve performance by more than an order of magnitude.\nChoosing and tuning your filesystem\nChoosing the best filesystem for a specific system is very important because each has its own strengths. The\nFile systems\narticle provides a short summary of the most popular ones. You can also find relevant articles in\nCategory:File systems\n.\nMount options\nThe various\n*atime\noptions can mitigate the performance penalty of\nstrictatime\n.\nOther mount options are filesystem specific, therefore see the relevant articles for the filesystems:\nExt3\nExt4#Improving performance\nJFS#Optimizations\nXFS#Performance\nBtrfs#Defragmentation\n,\nBtrfs#Compression\n, and\nbtrfs(5)\nZFS#Tuning\nNTFS#Improving performance\nTuning kernel parameters\nThere are several key tunables affecting the performance of block devices, see\nsysctl#Virtual memory\nfor more information.\nInput/output schedulers\nBackground information\nThe input/output\n(I/O)\nscheduler is the kernel component that decides in which order the block I/O operations are submitted to storage devices. It is useful to remind here some specifications of two main drive types because the goal of the I/O scheduler is to optimize the way these are able to deal with read requests:\nAn HDD has spinning disks and a head that moves physically to the required location. Therefore, random latency is quite high ranging between 3 and 12ms (whether it is a high end server drive or a laptop drive and bypassing the disk controller write buffer) while sequential access provides much higher throughput. The typical HDD throughput is about 200 I/O operations per second\n(IOPS)\n.\nAn SSD does not have moving parts, random access is as fast as sequential one, typically under 0.1ms, and it can handle multiple concurrent requests. The typical SSD throughput is greater than 10,000 IOPS, which is more than needed in common workload situations.\nIf there are many processes making I/O requests to different storage parts, thousands of IOPS can be generated while a typical HDD can handle only about 200 IOPS. There is a queue of requests that have to wait for access to the storage. This is where the I/O schedulers plays an optimization role.\nThe scheduling algorithms\nOne way to improve throughput is to linearize access: by ordering waiting requests by their logical address and grouping the closest ones. Historically this was the first Linux I/O scheduler called\nelevator\n.\nOne issue with the elevator algorithm is that it is not optimal for a process doing sequential access: reading a block of data, processing it for several microseconds then reading next block and so on. The elevator scheduler does not know that the process is about to read another block nearby and, thus, moves to another request by another process at some other location. The\nanticipatory\nI/O scheduler overcomes the problem: it pauses for a few milliseconds in anticipation of another close-by read operation before dealing with another request.\nWhile these schedulers try to improve total throughput, they might leave some unlucky requests waiting for a very long time. As an example, imagine the majority of processes make requests at the beginning of the storage space while an unlucky process makes a request at the other end of storage. This potentially infinite postponement of the process is called starvation. To improve fairness, the\ndeadline\nalgorithm was developed. It has a queue ordered by address, similar to the elevator, but if some request sits in this queue for too long then it moves to an \"expired\" queue ordered by expire time. The scheduler checks the expire queue first and processes requests from there and only then moves to the elevator queue. Note that this fairness has a negative impact on overall throughput.\nThe\nCompletely Fair Queuing (CFQ)\napproaches the problem differently by allocating a timeslice and a number of allowed requests by queue depending on the priority of the process submitting them. It supports\ncgroup\nthat allows to reserve some amount of I/O to a specific collection of processes. It is in particular useful for shared and cloud hosting: users who paid for some IOPS want to get their share whenever needed. Also, it idles at the end of synchronous I/O waiting for other nearby operations, taking over this feature from the\nanticipatory\nscheduler and bringing some enhancements. Both the\nanticipatory\nand the\nelevator\nschedulers were decommissioned from the Linux kernel replaced by the more advanced alternatives presented below.\nThe\nBudget Fair Queuing (BFQ)\nis based on CFQ code and brings some enhancements. It does not grant the disk to each process for a fixed time-slice but assigns a \"budget\" measured in number of sectors to the process and uses heuristics. It is a relatively complex scheduler, it may be more adapted to rotational drives and slow SSDs because its high per-operation overhead, especially if associated with a slow CPU, can slow down fast devices. The objective of BFQ on personal systems is that for interactive tasks, the storage device is virtually as responsive as if it was idle. In its default configuration it focuses on delivering the lowest latency rather than achieving the maximum throughput, which can sometimes greatly\naccelerate the startup of applications\non hard drives.\nKyber\nis a recent scheduler inspired by active queue management techniques used for network routing. The implementation is based on \"tokens\" that serve as a mechanism for limiting requests. A queuing token is required to allocate a request, this is used to prevent starvation of requests. A dispatch token is also needed and limits the operations of a certain priority on a given device. Finally, a target read latency is defined and the scheduler tunes itself to reach this latency goal. The implementation of the algorithm is relatively simple and it is deemed efficient for fast devices.\nKernel's I/O schedulers\nWhile some of the early algorithms have now been decommissioned, the official Linux kernel supports a number of I/O schedulers. The\nMulti-Queue Block I/O Queuing Mechanism (blk-mq)\nmaps I/O queries to multiple queues, the tasks are distributed across threads and therefore CPU cores. Within this framework the following schedulers are available:\nNone\n, where no queuing algorithm is applied.\nmq-deadline\n, the adaptation of the deadline scheduler (see below) to multi-threading.\nKyber\nBFQ\nChanging I/O scheduler\nNote\nThe best choice of scheduler depends on both the device and the exact nature of the workload. Also, the throughput in MB/s is not the only measure of performance: deadline or fairness deteriorate the overall throughput but may improve system responsiveness.\nBenchmarking\nmay be useful to indicate each I/O scheduler performance.\nTo list the available schedulers for a device and the active scheduler (in brackets):\n$ cat /sys/block/\nsda\n/queue/scheduler\nmq-deadline kyber [bfq] none\nTo list the available schedulers for all devices:\n$ grep \"\" /sys/block/\n*\n/queue/scheduler\n/sys/block/pktcdvd0/queue/scheduler:none\n/sys/block/sda/queue/scheduler:mq-deadline kyber [bfq] none\n/sys/block/sr0/queue/scheduler:[mq-deadline] kyber bfq none\nTo change the active I/O scheduler to\nbfq\nfor device\nsda\n, use:\n# echo\nbfq\n> /sys/block/\nsda\n/queue/scheduler\nThe process to change I/O scheduler, depending on whether the disk is rotating or not can be automated and persist across reboots. For example the\nudev\nrules below set the scheduler to\nbfq\nfor rotational drives,\nbfq\nfor\nSSD\n/eMMC drives and\nnone\nfor\nNVMe\ndrives:\n/etc/udev/rules.d/60-ioschedulers.rules\n# HDD\nACTION==\"add|change\", KERNEL==\"sd[a-z]*\", ATTR{queue/rotational}==\"1\", ATTR{queue/scheduler}=\"bfq\"\n# SSD\nACTION==\"add|change\", KERNEL==\"sd[a-z]*|mmcblk[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"bfq\"\n# NVMe SSD\nACTION==\"add|change\", KERNEL==\"nvme[0-9]*\", ATTR{queue/rotational}==\"0\", ATTR{queue/scheduler}=\"none\"\nReboot or force\nudev#Loading new rules\n.\nTuning I/O scheduler\nEach of the kernel's I/O scheduler has its own tunables, such as the latency time, the expiry time or the FIFO parameters. They are helpful in adjusting the algorithm to a particular combination of device and workload. This is typically to achieve a higher throughput or a lower latency for a given utilization.\nThe tunables and their description can be found within the\nkernel documentation\n.\nTo list the available tunables for a device, in the example below\nsdb\nwhich is using\ndeadline\n, use:\n$ ls /sys/block/\nsdb\n/queue/iosched\nfifo_batch  front_merges  read_expire  write_expire  writes_starved\nTo improve\ndeadline'\ns throughput at the cost of latency, one can increase\nfifo_batch\nwith the command:\n# echo\n32\n> /sys/block/\nsdb\n/queue/iosched/\nfifo_batch\nPower management configuration and write cache\nWhen dealing with traditional rotational disks (HDDs) you may want to completely disable or lower power saving features, and check if the write cache is enabled.\nSee\nHdparm#Power management configuration\nand\nHdparm#Write cache\n.\nAfterwards, you can make a\nudev rule\nto apply them on boot-up.\nTip\nGNOME\nallows the setting of some of these parameters through the Disks application and does not require a udev rule.\nNote\nSome features might not be supported by your hard drive. If that's the case, Hdparm will notify you. Hence, simply ignore the configuration of this certain feature.\nReduce disk reads/writes\nAvoiding unnecessary access to slow storage drives is good for performance and also increasing lifetime of the devices, although on modern hardware the difference in life expectancy is usually negligible.\nNote\nA 32GB SSD with a mediocre 10x write amplification factor, a standard 10000 write/erase cycle, and\n10GB of data written per day\n, would get an\n8 years life expectancy\n. It gets better with\nbigger SSDs\nand modern controllers with less write amplification. See also\nthis endurance experiment\nwhen considering whether any particular strategy to limit disk writes is actually needed.\nShow disk writes\nThe\niotop\npackage can sort by disk writes, and show how much and how frequently programs are writing to the disk. See\niotop(8)\nfor details.\nRelocate files to tmpfs\nRelocate files, such as your browser profile, to a\ntmpfs\nfile system, for improvements in application response as all the files are now stored in RAM:\nRefer to\nProfile-sync-daemon\nfor syncing browser profiles. Certain browsers might need special attention, see e.g.\nFirefox on RAM\n.\nRefer to\nAnything-sync-daemon\nfor syncing any specified folder.\nRefer to\nMakepkg#Improving build times\nfor improving compile times by building packages in tmpfs.\nFile systems\nRefer to corresponding\nfile system\npage in case there were performance improvements instructions, see the list at\n#Choosing and tuning your filesystem\n.\nSwap space\nSee\nSwap#Performance\nfor details.\nWriteback interval and buffer size\nSee\nSysctl#Virtual memory\nfor details.\nDisable core dumps\nSee\nCore dump#Disabling automatic core dumps\n.\nStorage I/O scheduling with ionice\nMany tasks such as backups do not rely on a short storage I/O delay or high storage I/O bandwidth to fulfill their task, they can be classified as background tasks. On the other hand quick I/O is necessary for good UI responsiveness on the desktop. Therefore it is beneficial to reduce the amount of storage bandwidth available to background tasks, whilst other tasks are in need of storage I/O. This can be achieved by making use of the Linux I/O scheduler BFQ, which allows setting different priorities for processes.\nThe I/O priority of a background process can be reduced to the \"Idle\" level by starting it with\n$ ionice -c 3\ncommand\nSee\na short introduction to ionice\nand\nionice(1)\nfor more information.\nTrimming\nFor optimal performance, empty blocks of solid state drives should be discarded (a.k.a. trimmed) periodically to optimize random write speeds. See\nSolid state drive#TRIM\nfor more information.\nNetwork\nKernel networking: see\nSysctl#Improving performance\nNIC: see\nNetwork configuration#Set device MTU and queue length\nDNS: consider using a caching DNS resolver, see\nDomain name resolution#DNS servers\nSamba: see\nSamba#Improve throughput\nCPU\nOverclocking\nOverclocking\nimproves the computational performance of the CPU by increasing its peak clock frequency. The ability to overclock depends on the combination of CPU model and motherboard model. It is most frequently done through the BIOS. Overclocking also has disadvantages and risks. It is neither recommended nor discouraged here.\nMany Intel chips will not correctly report their clock frequency to acpi_cpufreq and most other utilities. This will result in excessive messages in\ndmesg\n, which can be avoided by unloading and blacklisting the kernel module\nacpi_cpufreq\n.\nTo read their clock speed use\ni7z\nfrom the\ni7z\nAUR\npackage. To check for correct operation of an overclocked CPU, it is recommended to do\nstress testing\n.\nFrequency scaling\nSee\nCPU frequency scaling\n.\nCPU scheduler\nThe default CPU scheduler in the mainline Linux kernel is\nEEVDF\n.\nThis article or section needs expansion.\nReason:\nAdd CFS, the previous default scheduler, to the list. (Discuss in\nTalk:Improving performance\n)\nProject C\n— Cross-project for refactoring BMQ into Project C, with re-creation of PDS based on the Project C code base. So it is a merge of the two projects, with a subsequent update of the PDS as Project C. Recommended as a more recent development.\nhttps://cchalpha.blogspot.com/\n||\nlinux-prjc\nAUR\nBORE\n— The BORE scheduler focuses on sacrificing some fairness for lower latency in scheduling interactive tasks, it is built on top of CFS and is only adjusted for vruntime code updates, so the overall changes are quite small compared to other unofficial CPU schedulers.\nhttps://github.com/firelzrd/bore-scheduler\n||\nlinux-cachyos-bore\nAUR\nSCX\n— Allows dynamic injection of various CPU schedulers without requiring a system reset.\nhttps://github.com/sched-ext/scx\n||\nscx-scheds\nReal-time kernel\nSome applications such as running a TV tuner card at full HD resolution (1080p) may benefit from using a\nrealtime kernel\n.\nAdjusting priorities of processes\nSee also\nnice(1)\nand\nrenice(1)\n.\nAnanicy\nAnanicy CPP\nis a daemon, available as\nananicy-cpp\nor\nananicy-cpp-git\nAUR\n, for auto adjusting the nice levels of executables. The nice level represents the priority of the executable when allocating CPU resources.\nWarning\nGameMode\nand\nAnanicy CPP\nboth adjust the nice levels of processes. However, combining both tools is not recommended.\n[1]\ncgroups\nSee\ncgroups\n.\nLimitCPU\nLimitCPU\nis a program to limit the CPU usage percentage of a specific process. After installing\nlimitcpu\nAUR\n, you may limit the CPU usage of a process's PID using a scale of 0 to 100 times the number of CPU cores that the computer has. For example, with eight CPU cores the percentage range will be 0 to 800. Usage:\n$ limitcpu -l 50 -p 5081\nirqbalance\nThe purpose of\nirqbalance\nis to distribute hardware interrupts across processors on a multiprocessor system in order to increase performance. It can be\ncontrolled\nby the provided\nirqbalance.service\n.\nWarning\nIn some cases, irqbalance can interfere with power saving and can lead to stuttering or bad framerates in video games\n[2]\n.\nTurn off CPU exploit mitigations\nWarning\nDo not apply this setting without considering the vulnerabilities it opens up. Among other things, if this option is enabled, you\nmust not rely on a virtual machine to isolate untrusted programs\n. See\nthis\nand\nthis\nfor more information.\nTurning off CPU exploit mitigations may improve performance. Use below\nkernel parameter\nto disable them all:\nmitigations=off\nThe explanations of all the switches it toggles are given at\nkernel.org\n. You can use\nspectre-meltdown-checker\nAUR\nor\nlscpu(1)\n(from\nutil-linux\n) for vulnerability check.\nNote\nWhen using an Intel CPU from generation 10 and later, or AMD Ryzen series 1000 and later, the performance uplift from disabling mitigations is only up to 5% instead of the up to 25% for the previous CPU generations. See\nthe general review from early 2021\n,\nthe test on Rocket Lake\nand\nthe test on Alder Lake\nTuning compilation for your CPU\nDepending on your CPU, you may be able to gain a small performance boost by compiling software tuned for your native CPU\nmicroarchitecture\nwith the flag\n-march=native\n, but any binaries you compile with this flag will be slow or broken on other CPU microarchitectures. If you use this option and want to switch or upgrade your CPU, you need to either recompile your binaries or choose a new CPU that uses the same microarchitecture as your old one. You can\napply this option by default for makepkg\n.\nIf you\ncompile your own kernel\n, you can also enable this option during kernel compilation with the\nCONFIG_X86_NATIVE_CPU\noption. Although, results are hardly significant as the kernel\nforbids\nextended vector instructions in generic code, which are responsible for the most of performance improvement in regular binaries.\nGraphics\nXorg configuration\nGraphics performance may depend on the settings in\nxorg.conf(5)\n; see the\nNVIDIA\n,\nAMDGPU\nand\nIntel\narticles. Improper settings may stop Xorg from working, so caution is advised.\nMesa configuration\nThe performance of the Mesa drivers can be configured via\ndrirc\n.\nadriconf\n(Advanced DRI Configurator) is a GUI tool to configure Mesa drivers by setting options and writing them to the standard drirc file.\nHardware video acceleration\nHardware video acceleration\nmakes it possible for the video card to decode/encode video.\nOverclocking\nAs with CPUs, overclocking can directly improve performance, but is generally recommended against. There are several packages, such as\nrovclock\nAUR\n(ATI cards),\nrocm-smi-lib\n(recent AMD cards),\nnvclock\nAUR\n(old NVIDIA - up to Geforce 9), and\nnvidia-utils\nfor recent NVIDIA cards.\nSee\nAMDGPU#Overclocking\nor\nNVIDIA/Tips and tricks#Enabling overclocking in nvidia-settings\n.\nEnabling PCIe resizable BAR\nNote\nOn some systems enabling PCIe resizable BAR can result in a significant loss of performance. Benchmark your system to make sure it increases performance.\nThe\nCompatibility Support Module (CSM)\nmust be disabled for this to take effect.\nThe PCI specification allows larger\nBase Address Registers\n(BARs) to be used for exposing PCI devices memory to the PCI Controller. This can result in a performance increase for video cards. Having access to the full video memory improves performance, but also enables optimizations in the graphics driver. The combination of resizable BAR, above 4G decoding and these driver optimizations are what AMD calls\nAMD Smart Access Memory\n, available at first on AMD Series 500 chipset motherboards, later expanded to AMD Series 400 and Intel Series 300 and later through UEFI updates. This setting may not be available on all motherboards, and is known to sometimes cause boot problems on certain boards.\nIf the BAR has a 256M size, the feature is not enabled or not supported:\n# dmesg | grep BAR=\n[drm] Detected VRAM RAM=8176M, BAR=256M\nTo enable it, enable the setting named \"Above 4G Decode\" or \">4GB MMIO\" in your motherboard settings. Verify that the BAR is now larger:\n# dmesg | grep BAR=\n[drm] Detected VRAM RAM=8176M, BAR=8192M\nRAM, swap and OOM handling\nClock frequency and timings\nRAM can run at different clock frequencies and timings, which can be configured in the BIOS. Memory performance depends on both values. Selecting the highest preset presented by the BIOS usually improves the performance over the default setting. Note that increasing the frequency to values not supported by both motherboard and RAM vendor is overclocking, and similar risks and disadvantages apply, see\n#Overclocking\n.\nRoot on RAM overlay\nThis article or section is out of date.\nReason:\nThe liveroot script appears to be unmaintained, but this approach should still work. (Discuss in\nTalk:Improving performance#Section_5.2: liveroot hasn't been updated since 2016\n)\nIf running off a slow writing medium (USB, spinning HDDs) and storage requirements are low, the root may be run on a RAM overlay ontop of read only root (on disk). This can vastly improve performance at the cost of a limited writable space to root. See\nliveroot\nAUR\n.\nSwap on zram or zswap\nSimilar benefits (at similar costs) can be achieved using\nzswap\nor\nswap on zram\n. The two are generally similar in intent although not operation:\nzswap operates as a compressed RAM cache and neither requires (nor permits) extensive userspace configuration. It works in conjunction with a swap device by acting as its cache. Pages that would normally enter swap can enter zswap instead.\nzram is a kernel module which can be used to create a compressed block device in RAM. This compressed block device can be used as a swap device, with no other swap device required to back it up. It comes with many options, including the possibility of using a backing device for holding cold pages.\nBecause both options involve the\nswap\nsubsystem, configuration that affects swap also affects these systems. For example,\nswappiness\ndetermines whether the kernel should prioritize dropping file cache or moving pages to swap when memory pressure is high. Because zswap intercepts the action of moving pages to swap and zram acts as the swap, the option would also determine how often these two mechanisms are used.\nUsing the graphics card's RAM\nIn the unlikely case that you have very little RAM and a surplus of video RAM, you can use the latter as swap. See\nSwap on video RAM\n.\nImproving system responsiveness under low-memory conditions\nThis article or section needs expansion.\nReason:\nThe\nsystemd.service(5)\nwatchdog settings should be mentioned and crosslinked, see also\nSystemd#Notifying about failed services\n). (Discuss in\nTalk:Improving performance\n)\nOn traditional GNU/Linux system, especially for graphical workstations, when allocated memory is overcommitted, the overall system's responsiveness may degrade to a nearly unusable state before either triggering the in-kernel out-of-memory (OOM)-killer or a sufficient amount of memory got free (which is unlikely to happen quickly when the system is unresponsive, as you can hardly close any memory-hungry applications which may continue to allocate more memory). The behaviour also depends on specific setups and conditions, returning to a normal responsive state may take from a few seconds to more than half an hour, which could be a pain to wait in serious scenario like during a conference presentation.\nWhile the behaviour of the kernel as well as the userspace things under low-memory conditions may improve in the future as discussed on\nkernel\nand\nFedora\nmailing lists, users can use more feasible and effective options than hard-resetting the system or tuning the\nvm.overcommit_*\nsysctl\nparameters:\nManually trigger the kernel OOM-killer with\nMagic SysRq key\n, namely\nAlt+SysRq+f\n.\nUse a userspace OOM daemon to tackle these automatically (or interactively).\nWarning\nTriggering OOM killer to kill running applications may lose your unsaved works.  It is up to you that either you are patient enough to wait in hope that applications will finally free the memory normally, or you want to bring back unresponsive system as soon as possible.\nSometimes a user may prefer OOM daemon to SysRq because with kernel OOM-killer you cannot prioritize the process to (or not) terminate. To list some OOM daemons:\nsystemd-oomd\n— Provided by\nsystemd\nas\nsystemd-oomd.service\nthat uses cgroups-v2 and pressure stall information (PSI) to monitor and take action on processes before an OOM occurs in kernel space.\nhttps://github.com/systemd/systemd\n,\nsystemd-oomd(8)\n||\nsystemd\nearlyoom\n— Simple userspace OOM-killer implementation written in C.\nhttps://github.com/rfjakob/earlyoom\n||\nearlyoom\noomd\n— OOM-killer implementation based on\nPSI\n, requires Linux kernel version 4.20+. Configuration is in JSON and is quite complex. Confirmed to work in Facebook's production environment.\nhttps://github.com/facebookincubator/oomd\n||\noomd\nAUR\nnohang\n— Sophisticated OOM handler written in Python, with optional PSI support, more configurable than earlyoom.\nhttps://github.com/hakavlad/nohang\n||\nnohang-git\nAUR\nlow-memory-monitor\n— GNOME developer's effort that aims to provide better communication to userspace applications to indicate the low memory state, besides that it could be configured to trigger the kernel OOM-killer.  Based on PSI, requires Linux 5.2+.\nhttps://gitlab.freedesktop.org/hadess/low-memory-monitor/\n||\nlow-memory-monitor-git\nAUR\nuresourced\n— A small daemon that enables cgroup based resource protection for the active graphical user session.\nhttps://gitlab.freedesktop.org/benzea/uresourced\n||\nuresourced\nAUR\nbustd\n— Very lightweight userspace OOM-killer, useful for slower machines. Based on PSI, requires Linux 4.2+.\nhttps://github.com/vrmiguel/bustd\n||\nbustd\nAUR\nSee also\nRed Hat Performance Tuning Guide\nLinux Performance Measurements using vmstat\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Improving_performance&oldid=854315\n\"\nCategories\n:\nHardware\nSystem administration\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nImproving performance\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Improving_performance"}}
{"text": "Silent boot - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nSilent boot\n4 languages\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nPlymouth\nThis page is for those who prefer to limit the verbosity of their system to a strict minimum, either for aesthetics or other reasons. Following this guide will remove all text from the bootup process.\nVideo demonstration\nKernel parameters\nChange the\nkernel parameters\nusing the configuration options of your\nboot loader\n, to include the following parameters:\nquiet\nNote\nAdding\nvga=current\nas a kernel argument avoids weird behaviors like\nFS#32309\n. Keep in mind that this conflicts with\nKMS\n, so only use this argument if you are affected by said bug.\nIf you are still getting messages printed to the console, it may be\ndmesg\nsending you what it thinks are important messages. You can change the level at which these messages will be printed by using\nquiet loglevel=\nlevel\n, where\nlevel\nis any number between 0 and 7, where 0 is the most critical, and 7 is debug levels of printing.\nquiet loglevel=3\nNote that this only seems to work if both\nquiet\nand\nloglevel=\nlevel\nare used, and they must be in that order (quiet first). The loglevel parameter will only change that which is printed to the console, the levels of\ndmesg\nitself will not be affected and will still be available through the journal as well as\ndmesg\n. For more information, see\nkernel parameters\n.\nIf you also want to stop systemd from printing its version number when booting, you should also append\nudev.log_level=3\nto your kernel parameters. If systemd is used in an\ninitramfs\n, append\nrd.udev.log_level=3\ninstead. See\nsystemd-udevd.service(8) § KERNEL COMMAND LINE\nfor details.\nIf you are using the\nsystemd\nhook in the\ninitramfs\n, you may get systemd messages during initramfs initialization. You can pass\nsystemd.show_status=false\nto disable them, or\nsystemd.show_status=auto\nto only suppress successful messages (so in case of errors you can still see them). Actually,\nauto\nis already passed to\nsystemd.show_status=auto\nwhen\nquiet\nis used, however for some motive sometimes systemd inside initramfs does not get it. Below are the parameters that you need to pass to your kernel to get a completely clean boot with systemd in your\ninitramfs\n:\nquiet loglevel=3 systemd.show_status=auto rd.udev.log_level=3\nAlso\ntouch ~/.hushlogin\nto remove the Last login message.\nUsers of\nplymouth\nmust use both the\nquiet\nand\nsplash\nkernel parameter, otherwise the\ndetails\nfallback theme is used and shows systemd messages.\nRemove console cursor blinking\nThe console cursor at boot keeps blinking if you follow these instructions. This can be solved by passing\nvt.global_cursor_default=0\nto the kernel\n[1]\n.\nTo recover the cursor in the TTY, run:\n# setterm -cursor on >> /etc/issue\nsysctl\nTo hide any kernel messages from the console, add or modify the\nkernel.printk\nline according to\n[2]\n:\n/etc/sysctl.d/20-quiet-printk.conf\nkernel.printk = 3 3 3 3\nagetty\nTo hide agetty printed issue and \"login:\" prompt line from the console\n[3]\n, create a\ndrop-in snippet\nfor\ngetty@tty1.service\n.\n/etc/systemd/system/getty@tty1.service.d/skip-prompt.conf\n[Service]\nExecStart=\nExecStart=-/sbin/agetty\n--skip-login\n--nonewline --noissue --autologin\nusername\n--noreset --noclear - ${TERM}\nstartx\nTo hide\nstartx\nmessages, you could redirect its output to\n/dev/null\nin your shell profile file (like\n~/.bash_profile\nin\nBash\nor\n~/.zprofile\nin\nZsh\n):\nif [ -z \"$DISPLAY\" ] && [ \"$XDG_VTNR\" = 1 ]; then\nexec startx &>/dev/null\nfi\nNote\nRedirection is broken with rootless login. See\nXorg#Session log redirection\n.\nfsck\nTo hide fsck messages during boot, let systemd check the root filesystem. For this, replace\nudev\nhook with\nsystemd\nand remove the\nfsck\nhook:\nHOOKS=(base\nsystemd\nautodetect microcode modconf kms keyboard\nsd-vconsole\nblock filesystems)\nin\n/etc/mkinitcpio.conf\nand\nregenerate the initramfs\n.\nSee\nsystemd-fsck@.service(8)\nfor more info on the options you can pass to\nsystemd-fsck\n- you can change how often the service will check (or not) your filesystems.\nMake GRUB silent\nTo hide GRUB welcome and boot messages, you may install unofficial\ngrub-silent\nAUR\npackage.\nAfter the installation, it is required to reinstall\nGRUB\nto necessary partition first.\nThen, take an example as\n/etc/default/grub.silent\n, and make necessary changes to\n/etc/default/grub\n.\nBelow three lines are necessary:\n/etc/default/grub\nGRUB_DEFAULT=0\nGRUB_TIMEOUT=0\nGRUB_RECORDFAIL_TIMEOUT=$GRUB_TIMEOUT\nNote\nIf you set\nGRUB_TIMEOUT=0\nand\nGRUB_HIDDEN_TIMEOUT=1\n(or any positive value), set\nGRUB_RECORDFAIL_TIMEOUT=$GRUB_HIDDEN_TIMEOUT\ninstead of\nGRUB_RECORDFAIL_TIMEOUT=$GRUB_TIMEOUT\n. Otherwise pressing\nEsc\non boot to show GRUB menu will not work.\nLastly, regenerate the\ngrub.cfg\nfile.\nRetaining or disabling the vendor logo from UEFI\nModern UEFI systems display a vendor logo on boot until handing over control to the\nboot loader\n—e.g. Lenovo laptops display a bright red Lenovo logo. This vendor logo is typically blanked by the boot loader—if standard GRUB is used—or by the kernel.\nTo prevent the kernel from blanking the vendor logo, Linux 4.19 introduced a new configuration option\nFRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER\nthat retains the contents of the framebuffer until text needs to be printed on the framebuffer console. Since version\n4.19.arch1\n, the official Arch Linux kernels are compiled with\nCONFIG_FRAMEBUFFER_CONSOLE_DEFERRED_TAKEOVER=y\n.\nWhen combined with a low loglevel (to prevent text from being printed), the vendor logo can be retained while the system is initialized. Note that GRUB in the standard configuration blanks the screen; consider booting directly an\nEFI boot stub\nand thus leverage deferred takeover.\nVideo demonstration\nThe kernel command line should use\nloglevel=3\nor\nrd.udev.log_level=3\nas mentioned above. Note that if you often receive\nCore temperature above threshold, cpu clock throttled\nmessages in the kernel log, you need to use log level 2 to silence these at boot time. Alternatively, if you compile your own kernel, adjust the log level of the message in\narch/x86/kernel/cpu/mcheck/therm_throt.c\n.\nIf you use\nIntel graphics\n, see also\nIntel graphics#Fastboot\n.\nFurther reading:\nPhoronix: Linux 4.19 Adds Deferred Console Takeover Support For FBDEV - Cleaner Boot Process\nHans de Goede: Adding deferred fbcon console takeover to the Fedora kernels\nDisabling deferred takeover\nIf the new behavior leads to issues, you can disable deferred takeover by using the\nfbcon=nodefer\nkernel parameter\n.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Silent_boot&oldid=847118\n\"\nCategory\n:\nBoot process\nSearch\nSearch\nSilent boot\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Silent_boot"}}
{"text": "Kernel parameters - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nKernel parameters\n6 languages\nEspañol\nMagyar\n日本語\nPortuguês\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nKernel\nThere are three ways to pass options to the kernel and thus control its behaviour:\nWhen building the kernel—in the kernel's\nconfig\nfile. See\nKernel#Compilation\nfor details.\nWhen starting the kernel—using command line parameters (usually through a\nboot loader\n, or as well in\nunified kernel image\n).\nAt runtime—through the files in\n/proc/sys/\n(see\nsysctl\n) and\n/sys/\n.\nNote\nThe options of loadable modules can be set via\n.conf\nfiles in\n/etc/modprobe.d/\n. See\nKernel module#Using modprobe.d\n.\nBetween the three methods, the configurable options differ in availability, their name and the method in which they are specified. This page only explains the second method (kernel command line parameters) and shows a list of the most used kernel parameters in Arch Linux.\nMost parameters are associated with subsystems and work only if the kernel is configured with those subsystems built in. They also depend on the presence of the hardware they are associated with.\nKernel command line parameters either have the format\nparameter\n, or\nparameter\n=\nvalue\n, or\nmodule\n.\nparameter\n=\nvalue\n.\nNote\nYou can check the parameters your system was booted up with by running\ncat /proc/cmdline\nand see if it includes your changes.\nAll kernel parameters are case-sensitive.\nBoot loader configuration\nNote\nThe Arch Linux\ninstallation medium\nuses\nsystemd-boot\nfor\nUEFI\nsystems, and\nSyslinux\nfor\nBIOS\nones.\nKernel parameters can be set either temporarily by editing the boot entry in the boot loader boot selection menu, or permanently by modifying the boot loader configuration file.\nThe following examples add the\nquiet\nand\nsplash\nparameters to the\nClover\n,\nGRUB\n,\nGRUB Legacy\n,\nLILO\n,\nLimine\n,\nrEFInd\n,\nSyslinux\nand\nsystemd-boot\nboot loaders.\nClover\nAdd them to\nesp\n/EFI/CLOVER/config.plist\n:\n<string>initrd=\\initramfs-linux.img root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\n</string>\nGRUB\nPress\ne\nwhen the menu shows up and add them on the\nlinux\nline:\nlinux /boot/vmlinuz-linux root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nPress\nCtrl+x\nto boot with these parameters.\nTo make the change persistent after reboot, you could\nmanually edit /boot/grub/grub.cfg\nwith the exact line from above, or if using\ngrub-mkconfig\n:\nEdit\n/etc/default/grub\nand append your kernel options between the quotes in the\nGRUB_CMDLINE_LINUX_DEFAULT\nline:\nGRUB_CMDLINE_LINUX_DEFAULT=\"\nquiet splash\n\"\nAnd then automatically re-generate the\ngrub.cfg\nfile with:\n# grub-mkconfig -o /boot/grub/grub.cfg\nGRUB Legacy\nPress\ne\nwhen the menu shows up and add them on the\nkernel\nline:\nkernel /boot/vmlinuz-linux root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nPress\nb\nto boot with these parameters.\nTo make the change persistent after reboot, edit\n/boot/grub/menu.lst\nand add them to the\nkernel\nline, exactly like above.\nLILO\nAdd them to\n/etc/lilo.conf\nusing\nappend\nor\naddappend\n:\nimage=/boot/vmlinuz-linux\n...\nappend=\"\nquiet splash\n\"\nLimine\nTo temporarily add kernel parameters, press\ne\nwhen the boot entry selection screen appears and modify the\ncmdline\nline:\ncmdline: root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nTo apply changes permanently, edit the\nkernel_cmdline\nline in the Limine configuration file:\n/+Arch Linux\n...\nkernel_cmdline: root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nkernel_cmdline\nis alias of\ncmdline\nrEFInd\nPress\nInsert\n,\nF2\n,\nTab\n, or\n+\non the desired menu entry and press it again on the submenu entry. Add kernel parameters at the end of the string:\nroot=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw initrd=\\boot\\initramfs-linux.img\nquiet splash\nPress\nEnter\nto boot with these parameters.\nTo make the change persistent after reboot, edit\n/boot/refind_linux.conf\nand append them between the quotes in all required lines, for example\n\"Boot using default options\"   \"root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\n\"\nIf you have disabled auto-detection of OSes in rEFInd and are defining OS stanzas instead in\nesp\n/EFI/refind/refind.conf\nto load your OSes, you can edit it like:\nmenuentry \"Arch Linux\" {\n...\noptions  \"root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\n\"\n...\n}\nSyslinux\nPress\nTab\nwhen the menu shows up and add them at the end of the string:\nlinux /boot/vmlinuz-linux root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw initrd=/boot/initramfs-linux.img\nquiet splash\nPress\nEnter\nto boot with these parameters.\nTo make the change persistent after reboot, edit\n/boot/syslinux/syslinux.cfg\nand add them to the\nAPPEND\nline:\nAPPEND root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nsystemd-boot\nPress\ne\nwhen the menu appears and add the parameters to the end of the string:\ninitrd=\\initramfs-linux.img root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nPress\nEnter\nto boot with these parameters.\nNote\nIf you have not set a value for menu timeout, you will need to hold\nSpace\nwhile booting for the systemd-boot menu to appear.\nIf you cannot edit the parameters from the boot menu, you may need to edit\n/boot/loader/loader.conf\nand add\neditor 1\nto enable editing.\nTo make the change persistent after reboot, edit\n/boot/loader/entries/arch.conf\n(assuming you set up your\nEFI system partition\n) and add them to the\noptions\nline:\noptions root=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 rw\nquiet splash\nIf you are using a\nunified kernel image\nto boot, edit\n/etc/kernel/cmdline\n.\ndracut\ndracut\nis capable of embedding the kernel parameters in the initramfs, thus allowing to omit them from the boot loader configuration. See\ndracut#Kernel command line options\n. Note that this only works for parameters understood by dracut, like\nroot=\nand\nrd.*\n. They do not become real kernel parameters.\nEFI boot stub\nSee\nEFI boot stub#Using UEFI directly\n.\nHijacking cmdline\nEven without access to your boot loader it is possible to change your kernel parameters to enable debugging (if you have root access). This can be accomplished by overwriting\n/proc/cmdline\nwhich stores the kernel parameters. However\n/proc/cmdline\nis not writable even as root, so this hack is accomplished by using a bind mount to mask the path.\nNote\nThis trick only hijacks userspace processes which read\n/proc/cmdline\n. It does not work for parameters read by the kernel itself. For example, adding\ndebug\nthis way will not enable kernel debugging.\nFirst create a file containing the desired kernel parameters:\n/root/cmdline\nroot=UUID=0a3407de-014b-458b-b5c1-848e92a327a3 ro console=tty1 logo.nologo debug\nThen use a bind mount to overwrite the parameters:\n# mount --bind -o ro /root/cmdline /proc/cmdline\nYou can\ncat /proc/cmdline\nto confirm that your change was successful.\nParameter list\nThis list is not comprehensive. In addition to the kernel itself, other programs can also read parameters from\n/proc/cmdline\nand change their behavior.\nFor a mostly complete list of options understood by the kernel and\nboot loaders\n, see\nThe kernel's command-line parameters\n. A basic list is in\nbootparam(7)\n.\nFor options understood by\nsystemd\n, see\nkernel-command-line(7)\n.\nFor options understood by\nmkinitcpio\nwith a busybox based initial ramdisk, see\nmkinitcpio(8) § EARLY INIT ENVIRONMENT\nand\nMkinitcpio#Runtime_customization\n.\nFor options understood by\ndracut\n, see\ndracut.cmdline(7)\n.\nparameter\nDescription\ninit\nRun specified binary instead of\n/sbin/init\nas init process. The\nsystemd-sysvcompat\npackage symlinks\n/sbin/init\nto\n/usr/lib/systemd/systemd\nto use\nsystemd\n. Set it to\n/bin/sh\nto boot to the shell.\ninitrd\nSpecify the location of the initial ramdisk. For UEFI\nboot managers\nand an\nEFI boot stub\n, the path must be specified using backslashes (\n\\\n) as path separators.\ncryptdevice\nSpecify the location of a\ndm-crypt\n-encrypted partition plus a\ndevice mapper\nname.\ndebug\nEnable kernel debugging (events log level).\nlsm\nSet the initialisation order of the Linux security modules, used to enable\nAppArmor\n,\nSELinux\nor\nTOMOYO\n.\nmaxcpus\nMaximum number of processors that an SMP kernel will bring up during bootup.\nmem\nForce usage of a specific amount of memory to be used.\nnetdev\nNetwork devices parameters.\nnomodeset\nDisable\nKernel mode setting\n.\npanic\nTime before automatic reboot on kernel panic.\nresume\nSpecify a swap device to use when waking from\nhibernation\n.\nro\nMount root device read-only on boot. This is\nmkinitcpio\n's default\n1\n.\nroot\nRoot file system. See\ninit/do_mounts.c\nfor kernel's supported device name formats. Note that an\ninitramfs\nwith\nudev\nsupports\nmore name formats\n. A setup compatible with\nsystemd#GPT partition automounting\nallows to omit the parameter entirely or to alternatively use\nroot=dissect\n.\nrootflags\nRoot file system mount options. Useful for setting options that cannot be applied by remounting (i.e. by\nsystemd-remount-fs.service(8)\n). For example, the\ndiscard\noption of an\nXFS\nroot volume or\nsubvol=\noption of\nBtrfs when using a subvolume as root\n.\nrw\nMount root device read-write on boot. This is the kernel's default\n1\n.\nsystemd.unit\nBoot to a\nspecified target\n.\nvideo\nOverride framebuffer video defaults.\nThe kernel uses\nrw\nif neither\nro\nor\nrw\nare explicitly set on kernel command line (see\nbootparam(7) § General non-device-specific boot arguments\n). However,\nmkinitcpio\nuses\nro\nas the default value overriding the kernel's default (see\nmkinitcpio(8) § EARLY INIT ENVIRONMENT\n). Boot loaders may also have their own configured default, for example,\ngrub-mkconfig\nuses\nrw\n(see\nFS#36275\nas a reference).\nNote\nrw\nis required when using mkinitcpio's\nfsck hook\n(see\n[1]\n) or\nwhen using F2FS as the root file system\n.\nSee also\nbootparam(7)\nkernel-command-line(7)\nPower saving#Kernel parameters\nKernel Boot Command-Line Parameter Reference\n—the chapter 9 of the\nLinux Kernel in a Nutshell\nby\nGreg Kroah-Hartman\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Kernel_parameters&oldid=849188\n\"\nCategory\n:\nKernel\nSearch\nSearch\nKernel parameters\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Kernel_parameters"}}
{"text": "sysctl - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nsysctl\n3 languages\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nsysctl\nis a tool for examining and changing\nkernel parameters\nat runtime. sysctl is implemented in\nprocfs\n, the virtual process file system at\n/proc/\n.\nInstallation\nThe\nprocps-ng\npackage should already be\ninstalled\n, as it is a dependency of the\nbase\nmeta package\n.\nConfiguration\nThe\nsysctl\npreload/configuration file can be created at\n/etc/sysctl.d/99-sysctl.conf\n. For\nsystemd\n,\n/etc/sysctl.d/\nand\n/usr/lib/sysctl.d/\nare drop-in directories for kernel sysctl parameters. The naming and source directory decide the order of processing, which is important since the last parameter processed may override earlier ones. For example, parameters in a\n/usr/lib/sysctl.d/50-default.conf\nwill be overriden by equal parameters in\n/etc/sysctl.d/50-default.conf\nand any configuration file processed later from both directories.\nTo load all configuration files manually, execute:\n# sysctl --system\nwhich will also output the applied hierarchy. A single parameter file can also be loaded explicitly with:\n# sysctl --load=\nfilename.conf\nSee\nthe new configuration files\nand more specifically\nsysctl.d(5)\nfor more information.\nThe parameters available are those listed under\n/proc/sys/\n. For example, the\nkernel.sysrq\nparameter refers to the file\n/proc/sys/kernel/sysrq\non the file system. The\nsysctl --all\ncommand can be used to display all currently available values.\nNote\nIf you have the kernel documentation installed (\nlinux-docs\n), you can find detailed information about sysctl settings in\n/usr/lib/modules/$(uname -r)/build/Documentation/admin-guide/sysctl/\n. An online version is referred by the\n#See also\nsection of this article. It is highly recommended reading these before changing sysctl settings.\nSettings can be changed through file manipulation or using the\nsysctl(8)\nutility. For example, to temporarily enable the\nmagic SysRq key\n:\n# sysctl kernel.sysrq=1\nor:\n# echo \"1\" > /proc/sys/kernel/sysrq\nSee\nLinux kernel documentation\nfor details about\nkernel.sysrq\n.\nTo preserve changes between reboots,\nadd\nor modify the appropriate lines in\n/etc/sysctl.d/99-sysctl.conf\nor another applicable parameter file in\n/etc/sysctl.d/\n.\nTip\nSome parameters that can be applied may depend on kernel modules which in turn might not be loaded. For example parameters in\n/proc/sys/net/bridge/*\ndepend on the\nbr_netfilter\nmodule. If it is not loaded at runtime (or after a reboot), those will\nsilently\nnot be applied. See\nKernel modules\n.\nSecurity\nSee also\nSecurity#Kernel hardening\n, as well as the rest of this article.\nNetworking\nImproving performance\nIncreasing the size of the receive queue.\nThe received frames will be stored in this queue after taking them from the ring buffer on the network card.\nIncreasing this value for high speed cards may help prevent losing packets:\nnet.core.netdev_max_backlog = 16384\nNote\nIn real time application like SIP routers, this option requires a high speed CPU otherwise the data in the queue will be out of date.\nIncrease the maximum connections\nThe upper limit on how many connections the kernel will accept (default 4096):\nnet.core.somaxconn = 8192\nWarning\nIncreasing this value may only increase performance on high-loaded servers and may cause a slow processing rate (e.g. a single threaded blocking server) or insufficient number of worker threads/processes\n[1]\n.\nIncrease the memory dedicated to the network interfaces\nThis article or section needs expansion.\nReason:\nExplain what are the units for each option (bytes or kilobytes or memory pages?) (Discuss in\nTalk:Sysctl\n)\nThe factual accuracy of this article or section is disputed.\nReason:\nThis section seems motivated by the Cloudflare blog post, but\nRed Hat's tuned profile\nsuggests even smaller values and claims \"this seems only necessary at 40Gb speeds\". Hence, these settings do not seem useful for commodity hardware. (Discuss in\nTalk:Sysctl\n)\nBy default the Linux network stack is not configured for high speed large file transfer across WAN links (i.e. handle more network packets) and setting the correct values may save memory resources:\nnet.core.rmem_default = 1048576\nnet.core.rmem_max = 16777216\nnet.core.wmem_default = 1048576\nnet.core.wmem_max = 16777216\nnet.core.optmem_max = 65536\nnet.ipv4.tcp_rmem = 4096 1048576 2097152\nnet.ipv4.tcp_wmem = 4096 65536 16777216\nIt is also possible increase the default\n4096\nUDP limits:\nnet.ipv4.udp_rmem_min = 8192\nnet.ipv4.udp_wmem_min = 8192\nSee the following sources for more information and recommend values:\nhttp://www.nateware.com/linux-network-tuning-for-2013.html\nhttps://blog.cloudflare.com/the-story-of-one-latency-spike/\nEnable TCP Fast Open\nThis article or section needs expansion.\nReason:\nMention the option to \"enable all listeners to support Fast Open by default without explicit TCP_FASTOPEN socket option\", i.e. value\n1027\n(0x1+0x2+0x400). (Discuss in\nTalk:Sysctl#TCP Fast Open\n)\nTCP Fast Open is an extension to the transmission control protocol (TCP) that helps reduce network latency by enabling data to be exchanged during the sender’s initial TCP SYN\n[2]\n. Using the value\n3\ninstead of the default\n1\nallows TCP Fast Open for both incoming and outgoing connections:\nnet.ipv4.tcp_fastopen = 3\nTweak the pending connection handling\ntcp_max_syn_backlog\nis the maximum queue length of pending connections 'Waiting Acknowledgment'.\nIn the event of a synflood DOS attack, this queue can fill up pretty quickly, at which point\nTCP SYN cookies\nwill kick in allowing your system to continue to respond to legitimate traffic, and allowing you to gain access to block malicious IPs.\nIf the server suffers from overloads at peak times, you may want to increase this value a little bit:\nnet.ipv4.tcp_max_syn_backlog = 8192\ntcp_max_tw_buckets\nis the maximum number of sockets in TIME_WAIT state.\nAfter reaching this number the system will start destroying the socket that are in this state.\nIncrease this to prevent simple DOS attacks:\nnet.ipv4.tcp_max_tw_buckets = 2000000\ntcp_tw_reuse\nsets whether TCP should reuse an existing connection in the TIME-WAIT state for a new outgoing connection if the new timestamp is strictly bigger than the most recent timestamp recorded for the previous connection.\nThe default value is\n2\n, means it's enabled for loopback connections only. You can set it to\n1\nto enable for all connections, this helps avoid from running out of available network sockets:\nnet.ipv4.tcp_tw_reuse = 1\nSpecify how many seconds to wait for a final FIN packet before the socket is forcibly closed.  This is strictly a violation  of  the TCP specification, but required to prevent denial-of-service attacks.  In Linux 2.2, the default value was 180\n[3]\n:\nnet.ipv4.tcp_fin_timeout = 10\ntcp_slow_start_after_idle\nsets whether TCP should start at the default window size only for new connections or also for existing connections that have been idle for too long.\nThis setting kills persistent single connection performance and could be turned off:\nnet.ipv4.tcp_slow_start_after_idle = 0\nChange TCP keepalive parameters\nThis article or section is out of date.\nReason:\nfilesystem\n2025.05.03-1 sets\nnet.ipv4.tcp_keepalive_time\nto\n120\nin\n/usr/lib/sysctl.d/10-arch.conf\n. See\n[4]\n. (Discuss in\nTalk:Sysctl\n)\nTCP keepalive\nis a mechanism for TCP connections that help to determine whether the other end has stopped responding or not. TCP will send the keepalive probe that contains null data to the network peer several times after a period of idle time. If the peer does not respond, the socket will be closed automatically. By default, TCP keepalive process waits for two hours (7200 secs) for socket activity before sending the first keepalive probe, and then resend it every 75 seconds. As long as there is TCP/IP socket communications going on and active, no keepalive packets are needed.\nNote\nWith the following settings, your application will detect dead TCP connections after 120 seconds (60s + 10s + 10s + 10s + 10s + 10s + 10s).\nnet.ipv4.tcp_keepalive_time = 60\nnet.ipv4.tcp_keepalive_intvl = 10\nnet.ipv4.tcp_keepalive_probes = 6\nEnable MTU probing\nThe longer the\nmaximum transmission unit (MTU)\nthe better for performance, but the worse for reliability.\nThis is because a lost packet means more data to be retransmitted and because many routers on the Internet cannot deliver very long packets:\nnet.ipv4.tcp_mtu_probing = 1\nSee\nhttps://blog.cloudflare.com/path-mtu-discovery-in-practice/\nfor more information.\nTCP timestamps\nWarning\nTCP timestamps protect against wrapping sequence numbers (at gigabit speeds) and round trip time calculation implemented in TCP. It is not recommended to turn off TCP timestamps as it may cause a security risk\n[5]\n.\nDisabling timestamp generation will reduce spikes and may give a performance boost on gigabit networks:\nnet.ipv4.tcp_timestamps = 0\nTCP Selective Acknowledgement\nTCP Selective Acknowledgement (TCP SACK), controlled by the boolean\ntcp_sack\n, allows the receiving side to give the sender more detail about lost segments, reducing volume of retransmissions. This is useful on high latency networks, but disable this to improve throughput on high-speed LANs. Also disable\ntcp_dsack\n, if you aren't sending SACK you certainly don't want to send duplicates! Forward Acknowledgement works on top of SACK and will be disabled if SACK is.\n[6]\nnet.ipv4.tcp_sack = 1\nEnable BBR\nThe\nBBR congestion control algorithm\ncan help achieve higher bandwidths and lower latencies for internet traffic. First,\nload\nthe\ntcp_bbr\nmodule.\nNote\nBBR GitHub says\n, \"This is not an official Google product.\"\nnet.core.default_qdisc = cake\nnet.ipv4.tcp_congestion_control = bbr\nIncrease the Ephemeral port range\nThe factual accuracy of this article or section is disputed.\nReason:\nHow does this change improve performance? (Discuss in\nTalk:Sysctl#net.ipv4.ip_local_port_range\n)\nThe\nWikipedia:Ephemeral port\nis typically used by the Transmission Control Protocol (TCP), User Datagram Protocol (UDP), or the Stream Control Transmission Protocol (SCTP) as the port assignment for the client end of a client–server communication.\nnet.ipv4.ip_local_port_range = 30000 65535\nTCP/IP stack hardening\nThe following specifies a parameter set to tighten network security options of the kernel for the IPv4 protocol and related IPv6 parameters where an equivalent exists.\nFor some use-cases, for example using the system as a\nrouter\n, other parameters may be useful or required as well.\nTCP SYN cookie protection\nHelps protect against SYN flood attacks. Only kicks in when\nnet.ipv4.tcp_max_syn_backlog\nis reached. More details at, for example,\n[7]\n. As of\nlinux\n5.10, it is set by default.\nnet.ipv4.tcp_syncookies = 1\nTCP rfc1337\nThe factual accuracy of this article or section is disputed.\nReason:\nThis does not seem to be part of the TCP standard? The description may not be accurate.\n[8]\n(Discuss in\nTalk:Sysctl#net.ipv4.tcp_rfc1337\n)\nProtect against tcp time-wait assassination hazards, drop RST packets for sockets in the time-wait state. Not widely supported outside of Linux,  but conforms to RFC:\nnet.ipv4.tcp_rfc1337 = 1\nReverse path filtering\nBy enabling reverse path filtering, the kernel will do source validation of the packets received from all the interfaces on the machine. This can protect from attackers that are using IP spoofing methods to do harm.\nThe kernel's default value is\n0\n(no source validation), but systemd ships\n/usr/lib/sysctl.d/50-default.conf\nthat sets\nnet.ipv4.conf.all.rp_filter\nto\n2\n(loose mode)\n[9]\n.\nThe following will set the reverse path filtering mechanism to value\n1\n(strict mode):\nnet.ipv4.conf.default.rp_filter = 1\nnet.ipv4.conf.all.rp_filter = 1\nThe relationship and behavior of\nnet.ipv4.conf.default.*\n,\nnet.ipv4.conf.\ninterface\n.*\nand\nnet.ipv4.conf.all.*\nis explained in\nip-sysctl.html\n.\nLog martian packets\nA\nmartian packet\nis an IP packet which specifies a source or destination address that is reserved for special-use by Internet Assigned Numbers Authority (IANA). See\nReserved IP addresses\nfor more details.\nOften martian and unroutable packet may be used for a dangerous purpose. Logging these packets for further inspection may be useful\n[10]\n:\nnet.ipv4.conf.default.log_martians = 1\nnet.ipv4.conf.all.log_martians = 1\nNote\nThis can fill up your logs with a lot of information, it is advisable to only enable this for testing.\nDisable ICMP redirects\nBackground is at\nWhat are ICMP redirects? Should they be blocked?\nTo disable ICMP redirect acceptance:\nnet.ipv4.conf.all.accept_redirects = 0\nnet.ipv4.conf.default.accept_redirects = 0\nnet.ipv4.conf.all.secure_redirects = 0\nnet.ipv4.conf.default.secure_redirects = 0\nnet.ipv6.conf.all.accept_redirects = 0\nnet.ipv6.conf.default.accept_redirects = 0\nTo disable ICMP redirect sending when on a non router:\nnet.ipv4.conf.all.send_redirects = 0\nnet.ipv4.conf.default.send_redirects = 0\nIgnore ICMP echo requests\nTo disable ICMP echo (aka ping) requests:\nnet.ipv4.icmp_echo_ignore_all = 1\nnet.ipv6.icmp.echo_ignore_all = 1\nNote\nBeware this may cause issues with monitoring tools and/or applications relying on ICMP echo responses.\nOther\nAllow unprivileged users to create IPPROTO_ICMP sockets\nThis article or section is out of date.\nReason:\n/usr/lib/sysctl.d/50-default.conf\nsets\nnet.ipv4.ping_group_range\nto\n0 2147483647\n. (Discuss in\nTalk:Sysctl\n)\nThe IPPROTO_ICMP (\nicmp(7)\n) socket type adds the possibility to send ICMP_ECHO messages and receive corresponding ICMP_ECHOREPLY messages without the need to open a\nraw(7)\nsocket, an operation which requires the CAP_NET_RAW\ncapability\nor the SUID bit with a proper privileged owner. These ICMP_ECHO messages are sent by the\nping\napplication thus making the IPPROTO_ICMP socket also known as ping socket in addition to ICMP Echo socket.\nping_group_range\ndetermines the GID range of groups which their users are allowed to create IPPROTO_ICMP sockets. Additionally, the owner of the CAP_NET_RAW capability is also allowed to create IPPROTO_ICMP sockets. By default this range is\n1 0\nwhich means no one is allowed to create IPPROTO_ICMP sockets except root. To take advantage of this setting programs which currently uses raw sockets need to ported to use IPPROTO_ICMP sockets instead. For example, QEMU uses IPPROTO_ICMP for SLIRP aka User-mode networking, so allowing the user running QEMU to create IPPROTO_ICMP sockets means it is possible to ping from the guest.\nTo allow only users which are members of the group with GID 100 to create IPPROTO_ICMP sockets:\nnet.ipv4.ping_group_range = 100 100\nTo allow all the users in the system to create IPPROTO_ICMP sockets:\nnet.ipv4.ping_group_range = 0 65535\nVirtual memory\nThere are several key parameters to tune the operation of the\nvirtual memory\nsubsystem of the Linux kernel and the write out of dirty data to disk. See the official\nLinux kernel documentation\nfor more information. For example:\nvm.dirty_ratio = 10\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which a process which is generating disk writes will itself start writing out dirty data.\nvm.dirty_background_ratio = 5\nContains, as a percentage of total available memory that contains free pages and reclaimable pages, the number of pages at which the background kernel flusher threads will start writing out dirty data.\nAs noted in the comments for the parameters, one needs to consider the total amount of RAM when setting these values. For example, simplifying by taking the installed system RAM instead of available memory:\nWarning\nHigher ratio values may increase performance, it also increases the risk of data loss.\nSetting this value to\n0\nmay cause higher latency on disks and spikes.\nSee\nhttps://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/\nfor more information.\nConsensus is that setting\nvm.dirty_ratio\nto 10% of RAM is a sane value if RAM is say 1 GB (so 10% is 100 MB). But if the machine has much more RAM, say 16 GB (10% is 1.6 GB), the percentage may be out of proportion as it becomes several seconds of writeback on spinning disks. A more sane value in this case may be\n3\n(3% of 16 GB is approximately 491 MB).\nSimilarly, setting\nvm.dirty_background_ratio\nto\n5\nmay be just fine for small memory values, but again, consider and adjust accordingly for the amount of RAM on a particular system.\nVFS cache\nDecreasing the\nvirtual file system\n(VFS) cache parameter value may improve system responsiveness:\nvm.vfs_cache_pressure = 50\nThe value controls the tendency of the kernel to reclaim the memory which is used for caching of directory and inode objects (VFS cache). Lowering it from the default value of 100 makes the kernel less inclined to reclaim VFS cache (do not set it to 0, this may produce out-of-memory conditions).\nMDADM\nSee\nRAID#Change sync speed limits\n.\nTroubleshooting\nSmall periodic system freezes\nSet dirty bytes to small enough value (for example 4 MiB):\nvm.dirty_background_bytes = 4194304\nvm.dirty_bytes = 4194304\nNote\nThe\ndirty_background_bytes\nand\ndirty_bytes\nparameters are counterparts of\ndirty_background_ratio\nand\ndirty_ratio\n(as seen in\n#Virtual memory\n). Only one of the parameters may be specified at a time.\nSee also\nsysctl(8)\nand\nsysctl.conf(5)\nLinux kernel documentation for /proc/sys/\nKernel Documentation:\nIP Sysctl\nKernel network parameters for sysctl\nsysctl-explorer.net – an initiative to facilitate the access of Linux' sysctl reference documentation\nDisable Source Routing - Red Hat Customer Portal\nSUSE handbook about Security Features in the Kernel\nLinux sysctl Tuning\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Sysctl&oldid=834787\n\"\nCategories\n:\nKernel\nCommands\nHidden categories:\nPages or sections flagged with Template:Expansion\nPages or sections flagged with Template:Accuracy\nPages or sections flagged with Template:Out of date\nSearch\nSearch\nsysctl\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Sysctl"}}
{"text": "udev - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nudev\n6 languages\nDeutsch\nFrançais\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nKernel\nLinux firmware\nudisks\nudev\n(\nuser space\n/dev\n) is a user space system that enables the operating system administrator to register user space handlers for events. The events received by\nudev\n's daemon are mainly generated by the\nLinux kernel\nin response to physical events relating to peripheral devices.\nAs such,\nudev\nmain purpose is to act upon peripheral detection and hot-plugging, including actions that return control to the kernel, e.g. loading\nkernel modules\nor device\nfirmware\n. Another component of this detection is adjusting the permissions of the device to be accessible to non-root users and groups.\nudev\nmanages device nodes in the\n/dev\ndirectory by adding, symlinking and renaming them.\nNote\nThe kernel module loading order is not preserved across boots\n, because\nudev\nhandles separate events concurrently (in parallel). For example, if a machine has multiple block devices, device nodes may change designations between reboots—i.e.\n/dev/sda\nmay on next boot become\n/dev/sdb\n.\nTip\nRely on\n…/by-id/…\n,\n…/by-path/…\n,\n…/by-uuid/…\nand similar persistent identifiers.\nInstallation\nudev\nis part of\nsystemd\nand thus installed by default. See\nsystemd-udevd.service(8)\nfor more information.\nIntroduction to udev rules\nudev\nrules written by the administrator go in\n/etc/udev/rules.d/\n, their file name has to end with\n.rules\n. The\nudev\nrules shipped with various packages are found in\n/usr/lib/udev/rules.d/\n. If there are two files by the same name under\n/usr/lib\nand\n/etc\n, the ones in\n/etc\ntake precedence.\nTo learn about\nudev\nrules, refer to the\nudev(7)\nmanual. Also see\nWriting udev rules\nand some practical examples are provided within the guide:\nWriting udev rules - Examples\n.\nExample\nBelow is an example of a rule that creates a symlink\n/dev/video-cam\nwhen a webcamera is connected.\nLet say this camera is currently connected and has loaded with the device name\n/dev/video2\n. The reason for writing this rule is that at the next boot, the device could show up under a different name, like\n/dev/video0\n.\n$ udevadm info --attribute-walk --path=$(udevadm info --query=path --name=/dev/video2)\nUdevadm info starts with the device specified by the devpath and then walks up the chain of parent devices.\nIt prints for every device found, all possible attributes in the udev rules key format.\nA rule to match, can be composed by the attributes of the device and the attributes from one single parent device.\nlooking at device '/devices/pci0000:00/0000:00:04.1/usb3/3-2/3-2:1.0/video4linux/video2':\nKERNEL==\"video2\"\nSUBSYSTEM==\"video4linux\"\n...\nlooking at parent device '/devices/pci0000:00/0000:00:04.1/usb3/3-2/3-2:1.0':\nKERNELS==\"3-2:1.0\"\nSUBSYSTEMS==\"usb\"\n...\nlooking at parent device '/devices/pci0000:00/0000:00:04.1/usb3/3-2':\nKERNELS==\"3-2\"\nSUBSYSTEMS==\"usb\"\nATTRS{idVendor}==\"05a9\"\nATTRS{manufacturer}==\"OmniVision Technologies, Inc.\"\nATTRS{removable}==\"unknown\"\nATTRS{idProduct}==\"4519\"\nATTRS{bDeviceClass}==\"00\"\nATTRS{product}==\"USB Camera\"\n...\nTo identify the webcamera, from the\nvideo4linux\ndevice we use\nKERNEL==\"video2\"\nand\nSUBSYSTEM==\"video4linux\"\n, then walking up two levels above, we match the webcamera using vendor and product ID's from the usb parent\nSUBSYSTEMS==\"usb\"\n,\nATTRS{idVendor}==\"05a9\"\nand\nATTRS{idProduct}==\"4519\"\n. Note that this matching is case sensitive, so\n\"05A9\"\ncan not be used to match the\nidVendor\nin this example.\nWe are now able to create a rule match for this device as follows:\n/etc/udev/rules.d/83-webcam.rules\nKERNEL==\"video[0-9]*\", SUBSYSTEM==\"video4linux\", SUBSYSTEMS==\"usb\", ATTRS{idVendor}==\"05a9\", ATTRS{idProduct}==\"4519\", SYMLINK+=\"video-cam\"\nHere we create a symlink using\nSYMLINK+=\"video-cam\"\nbut we could easily set user\nOWNER=\"john\"\nor group using\nGROUP=\"video\"\nor set the permissions using\nMODE=\"0660\"\n.\nIf you intend to write a rule to do something when a device is being removed, be aware that device attributes may not be accessible. In this case, you will have to work with preset device\nenvironment variables\n. To monitor those environment variables, execute the following command while unplugging your device:\n$ udevadm monitor --property --udev\nIn this command's output, you will see value pairs such as\nID_VENDOR_ID\nand\nID_MODEL_ID\n, which match the previously used attributes\nidVendor\nand\nidProduct\n. A rule that uses device environment variables instead of device attributes may look like this:\n/etc/udev/rules.d/83-webcam-removed.rules\nACTION==\"remove\", SUBSYSTEM==\"usb\", ENV{ID_VENDOR_ID}==\"05a9\", ENV{ID_MODEL_ID}==\"4519\", RUN+=\"\n/path/to/your/script\n\"\nList the attributes of a device\nTo get a list of all of the attributes of a device you can use to write rules, run this command:\n$ udevadm info --attribute-walk --name=\ndevice_name\nReplace\ndevice_name\nwith the device present in the system, such as\n/dev/sda\nor\n/dev/ttyUSB0\n.\nIf you do not know the device name you can also list all attributes of a specific system path:\n$ udevadm info --attribute-walk --path=/sys/class/backlight/acpi_video0\nTo narrow down the search for a device, figure out the class and run:\n$ ls /dev/\nclass\n/by-id\nYou can use the symlink outright or what it points as the input to\n--name\n. For example:\n$ udevadm info --attribute-walk --name=/dev/input/by-id/usb-foostan_Corne-event-kbd\nTo get the path of a bare USB device which does not populate any subordinate device you have to use the full USB device path. Start monitor mode and then plug in the USB device to get it:\n$ udevadm monitor\n...\nKERNEL[26652.638931] add      /devices/pci0000:00/0000:00:01.2/0000:02:00.0/0000:03:05.0/0000:05:00.0/usb1/1-3 (usb)\nKERNEL[26652.639153] add      /devices/pci0000:00/0000:00:01.2/0000:02:00.0/0000:03:05.0/0000:05:00.0/usb1/1-3/1-3:1.0 (usb)\n...\nYou can just choose the deepest path and\n--attribute-walk\nwill show all parent's attributes anyway:\n$ udevadm info --attribute-walk --path=\n/devices/pci0000:00/0000:00:01.2/0000:02:00.0/0000:03:05.0/0000:05:00.0/usb1/1-3/1-3:1.0\nTesting rules before loading\n# udevadm test $(udevadm info --query=path --name=\ndevice_name\n) 2>&1\nThis will not perform all actions in your new rules but it will however process symlink rules on existing devices which might come in handy if you are unable to load them otherwise. You can also directly provide the path to the device you want to test the\nudev\nrule for:\n# udevadm test /sys/class/backlight/acpi_video0/\nLoading new rules\nudev\nautomatically detects changes to rules files, so changes take effect immediately without requiring\nudev\nto be restarted. However, the rules are not re-triggered automatically on already existing devices. Hot-pluggable devices, such as USB devices, will probably have to be reconnected for the new rules to take effect, or at least unloading and reloading the ohci-hcd and ehci-hcd kernel modules and thereby reloading all USB drivers.\nIf rules fail to reload automatically:\n# udevadm control --reload\nTo manually force\nudev\nto trigger your rules:\n# udevadm trigger\nComponents of udev rules\nAction matching\nACTION==\"\"\nis used to only match against a device when something specific is happening, usually when it is appearing or disappearing. There are eight types of actions that can be raised for udev rules to match against:\nadd/remove\nWhen device nodes (in /dev/) are created/removed\nbind/unbind\nWhen a driver is attached/detached from a device\nchange\nOnly raised manually by drivers on a \"device state change\", has no standard meaning; see\n#The change action\noffline\nWhen a device (usually\nmemory\nor\nCPUs\n) becomes locked for hot-unplugging\nonline\nWhen a previously offline device is unlocked\nmove\nWhen a device (usually a network interface) is renamed,\nhopefully never\nThe change action\nThe change action is somewhat special, because not all drivers use it the same way, if at all. A change event is only emitted as a result of the driver manually raising a userspace event (or uevent) of type\nKOBJ_CHANGE\n. This normally signals that\nsomething\nhas happened to that device, but it takes some additional information to determine what exactly.\nSince that event is only raised under a limited number of situations, here is a (best-effort, non-exhaustive) list of subsystems that do raise change events, and under what conditions.\nSUBSYSTEM\nEvent trigger\nEvent-specific property\nDocumentation\ntypec\nChange in alt-mode, USB-PD role or data role\nNone\nusb_role\nRole change (for a USB OTG or Type-C device)\nUSB_ROLE_SWITCH=\nvalued at\nnone\n,\nhost\nor\ndevice\n, based on the new role\nblock\nMedia changes for a disc drive or an SD card reader\nDISK_MEDIA_CHANGE=1\nfor a new disc/card or\nDISK_EJECT_REQUEST=1\nwhen the media is being unloaded\ndrm\nDevice detected as \"wedged\" (hanged and cannot be recovered by the driver)\nWEDGED=\nwith a list of available reset methods, like\nrebind\nor\nbus-reset\nDevice wedging\ndrm\nMonitor hot-plugged (plugged or unplugged)\nHOTPLUG=1\n, sometimes also\nCONNECTOR=\nwith the internal ID of the connector\ndrm\nConnector property change (such as HDCP status)\nCONNECTOR=\nand\nPROPERTY=\nwith their respective internal IDs\nbacklight\nBrightness changed\nSOURCE=\nvalued at\nsysfs\n,\nhotkey\nor\nunknown\nbased on what triggered the change.\npower_supply\nPower supply state changed (power supply plugged/unplugged, battery charging/discharging, etc.)\nNone\nrfkill\nRadio turned on or off by killswitch, button or menu\nNone\nthunderbolt\nTunneling mode change\nTUNNEL_EVENT=\nwith the state of the tunnel, possibly\nTUNNEL_DETAILS=\nas well\nThunderbolt tunneling events\nAny device with a\npower/\nattribute group\nGaining or losing the ability to do remote wakeup\n1\n(i.e: when the entire\npower/wakeup*\nattribute set appears or disappears)\nNone\nDevice Power Management Basics\n, though the uevent itself is not documented\nAny (synthetic uevent)\nWriting\nchange $(uuidgen) FOO=BAR HELLO=WORLD\nto the uevent file of any sysfs device\n2\nSYNTH_UUID=\nwith the UUID written to the file, also\nSYNTH_ARG_HELLO=WORLD\nfor any key-value pair after the UUID\nsysfs-uevent\nGaining or losing the ability to do remote wakeup is interesting in cases such as USB, since unconfigured USB devices cannot issue wakeups in this state. See\n#Force USB device features to be re-added after suspend\n.\nBoth\nudevadm trigger\nand the\nOPTIONS+=\"watch\"\nudev rule directive will cause synthetic change events to be raised through this mechanism, with\nENV{SYNTH_UUID}==\"0\"\nin both cases.\nDevice attributes\nDevice attributes, listed as\nATTR{my_attr}==\"...\"\n(or\nATTRS{my_attr}==\"...\"\nfor parent devices) in udev rules and\nudevadm info --attribute-walk\n, correspond to all the device information that is made available through\nsysfs\n, which exposes information from the \"kobject\" classes used by the kernel to keep track of device state. This means that there is no need for udev-specific tools to examine these, and that a simple\nls /sys/class/thermal/thermal_zone0/\nor\ncat /sys/class/input/input0/name\nis all that is needed to explore device attributes, and some can even be changed with something like\necho 1 > \"/sys/class/leds/input2::capslock/brightness\"\n. It is, however, a lot more conveinient to use\nudevadm info --attribute-walk /sys/class/input/mouse0\n, which has the advantage of showing all matchable attributes for that device all at once in the same format that udev rules expect (as well as the attributes for any parent devices, also in their readily usable format).\nMost of these attributes have well-documented meanings, behaviors and accepted values based on what kernel submodule is handling the device, such as\nsysfs-bus-usb\nfor USB devices and\nsysfs-class-typec\nfor USB type-C\nports\n, for instance. Other attributes are present as subtrees, such as\nsysfs-devices-physical_location\nor\nsysfs-devices-power\n, which use slashes to separate levels, just like directories, giving\nATTR{power/control}==\"auto\"\n.\nEvent environment\nThe \"environment\" of an event is a set of device properties and event properties (and rarely global properties), both written as\nENV{MY_PROPERTY}==\"...\"\nin udev rules and both reported as\nE: MY_PROPERTY=...\nby\nudevadm monitor --property\nand\nudevadm info\n(without\n--attribute-walk\n). Despite being called \"environment\", they have nothing to do with\nenvironment variables\n(although they do get passed as environment variables to programs started by\nRUN+=\"...\"\n). These contain context information added to an event by the kernel module or other udev rules to make that information available to downstream rules or components. The only difference between event properties and device properties is that devices properties are stored and can be examined with\nudevadm info\n, whereas event properties are transient and can only be seen if the event is caught by\nudevadm monitor --property\n. A lot of device properties are also available as device attributes with similar names.\nUnlike with attributes, udev rules are allowed to set event properties arbitrarily, and there is also no concept of \"parent properties\" to inspect beyond the ones that are set on the event (which is why there is no\nENVS{...}==\"\"\ndirective). Note that\nsetting a property with a udev rule sets a device property\n, which will be stored until the device is removed and will thus appear in every event raised by that device (unless the property's name starts with a period, like\nENV{.PART_SUFFIX\n}, which will be added to the\nevent properties\nwith the leading dot in the name and be usable by other rules, but not stored).\nDevice tags\nTags (added using\nTAG+=\"foo\"\n, removed with\nTAG-=\"foo\"\n, matched with\nTAG==\"foo\"\n) are used by userspace software interacting with udev to list and identify all devices they should be acting upon. Those can also be arbitrary, but there are a few well-known ones.\nTag\nSoftware listening\nMeaning\nDocumentation\nsystemd\nsystemd\nSystemd should create a device unit for this device\nsystemd.device(5)\nseat\nsystemd-logind\nDevice is eligible to be assigned to a seat, and\nENV{ID_SEAT\n} indicates which seat it is currently assigned to, if any\nsd-login(3)\nmaster-of-seat\nsystemd-logind\nsd-login(3)\nuaccess\n70-uaccess.rules\nand\n73-seat-late.rules\nUsers should have read and write permissions granted on this device (via\nAccess Control Lists\n) while it is assigned to their seat\nsee\n#Allowing regular users to use devices\npower-switch\nsystemd-logind\nDevice will be watched for lid and key events to trigger suspend, screen lock and other such things\nlogind.conf(5)\n(HandlePowerKey)\nHardware database\nudev's hardware database (\nhwdb\n) contains any configuration data specific to device models, such as keyboard scancodes, mice DPI, and USB classes/models. The database is compiled from files with\n.hwdb\nextension located in directories\n/usr/lib/udev/hwdb.d/\n,\n/run/udev/hwdb.d/\nand\n/etc/udev/hwdb.d/\n. See\nhwdb(7)\nfor details.\nEach\n.hwdb\nfile can apply properties to one or more devices based on hardware ID glob patterns. You may obtain device identification info by running\nevemu-describe(1)\nas the root user. This command is provided by the\nevemu\npackage.\nevdev devices\nevdev\ndevices (including keyboards and mice) can be matched with the\nevdev:\nprefix in one of the following formats:\nUsing the kernel\nmodalias\n:\nevdev:input:b\n<bus_id>\nv\n<vendor_id>\np\n<product_id>\ne\n<version_id>\n-\n<input_modalias>\nwith the following 4-digit hex uppercase fields:\n<vendor_id>\n,\n<product_id>\nand\n<version_id>\n: vendor, product and version IDs matching the output of the\nlsusb\ncommand.\n<bus_id>\nis the 4-digit hex bus id and should be 0003 for usb devices. The possible\n<bus_id>\nvalues are defined in\n/usr/include/linux/input.h\n(you can run\nawk '/BUS_/ {print $2, $3}' /usr/include/linux/input.h\nto get a list).\n<input_modalias>\nis an arbitrary length input-modalias describing the device capabilities. The other fields are sufficient to uniquely identify the device, so you can use a glob here.\nIf you have the device currently plugged into your computer then you can get the whole modalias at once using sysfs, as demonstrated in\n#Remap specific device\n.\nInput driver device name and DMI data match:\nevdev:name:\n<input device name>\n:dmi:bvn*:bvr*:bd*:svn\n<vendor>\n:pn*\nwhere\n<input_device_name>\nis the name device specified by the driver and\n<vendor>\nis the firmware-provided string exported by the kernel DMI modalias.\nKeyboard devices\nThe\nscancodes-to-keycodes\nmapping for keyboards is defined in\n/usr/lib/udev/hwdb.d/60-keyboard.hwdb\n. The format of each line in the block body is\nKEYBOARD_KEY_\n<scancode>\n=\n<keycode>\n, where:\nThe value of\n<scancode>\nis hexadecimal, but without the leading\n0x\n(i.e. specify\na0\ninstead of\n0xa0\n).\nThe value of\n<keycode>\nis the lower-case keycode name string as listed in\n/usr/include/linux/input-event-codes.h\n(see the\nKEY_\n<KEYCODE>\nvariables), with a sorted list is available at\n[1]\n. It is not possible to specify decimal value in\n<keycode>\n.\nExamples\nRemap specific device\nSuppose you want to remap scancodes for a keyboard that you currently have plugged in. You should already have the evdev path (e.g.\n/dev/input/event17\n), and you can follow\nKeyboard input#Identifying scancodes\nto obtain the\nscancode\n(e.g.\n70039\nfor caps lock). Now, using the event number, you can query\nsysfs\nfor the modalias:\ncat /sys/class/input/event17/device/modalias\ninput:b0003v32ACp0012e0111-e0,1,4,1...\nThis device could be matched with the following hwdb rule:\n/etc/udev/hwdb.d/90-remap.hwdb\nevdev:input:b0003v32ACp0012e0111*\nKEYBOARD_KEY_70039=rightctrl # This example maps the 70039 scancode to the \"rightctrl\" keycode.\nRemap all devices\nSuppose we want to remap a couple of common keys for all AT keyboards:\n/etc/udev/hwdb.d/90-custom-keyboard.hwdb\nevdev:atkbd:*\nKEYBOARD_KEY_10=suspend\nKEYBOARD_KEY_a0=search\nDisable key\nTo block the\nSleep\nkey, bind it to the \"reserved\" keyword. Alternatively, you can use \"unknown\" to map it to the\nNoSymbol\nkey. For example:\n/etc/udev/hwdb.d/90-block-sleep.hwdb\nevdev:input:b0003v03F0p020C* # hp 5308 keyboard controller\nKEYBOARD_KEY_10082=reserved\nUpdating the Hardware Database Index\nAfter changing the configuration files, the hardware database index,\nhwdb.bin\nneeds to be rebuilt by running:\n# systemd-hwdb update\nThis creates\n/etc/udev/hwdb.bin\n, which takes precedence over the existing\n/usr/lib/udev/hwdb.bin\n. Upon system upgrade, both files will be automatically kept up-to-date with the same contents:\n/usr/lib/udev/hwdb.bin\nis rebuilt by the\n30-systemd-hwdb.hook\npacman hook\non each\nsystemd\nupgrade, and immediately effected by\n30-systemd-udev-reload.hook\n.\n/etc/udev/hwdb.bin\nis rebuilt by\nsystemd-hwdb-update.service\non the next boot after the upgrade (see\nsystemd-update-done.service(8)\n), since it detects we have manually generated it.\nReloading the Hardware Database Index\nThe kernel loads\nhwdb.bin\nas part of the boot process, rebooting the system will promise the loading of the updated\nhwdb.bin\n.\nWith\nudevadm\nit is possible to load new properties from the updated\nhwdb.bin\nby running\n# udevadm trigger\nBe aware that with\nudevadm\nonly added or changed properties are loaded so if we delete a property from the configuration file, rebuild\nhwdb.bin\nand run\nudevadm trigger\nas the root user, then the deleted property still kept by the kernel, at least until a reboot.\nQuerying the database\nYou can check that your configuration was loaded either by pressing keys, or by running\nudevadm info\n. For the USB keyboard in the above example, this outputs the mapping we configured as follows:\n# udevadm info /dev/input/by-path/*-usb-*-kbd | grep KEYBOARD_KEY\nE: KEYBOARD_KEY_70039=leftalt\nE: KEYBOARD_KEY_700e2=leftctrl\nTips and tricks\nMounting drives in rules\nTo mount removable drives, do not call\nmount\nfrom\nudev\nrules. This is ill-advised for two reasons:\nsystemd by default runs\nsystemd-udevd.service\nwith a separate \"mount namespace\" (see\nnamespaces(7)\n), which means that mounts will not be visible to the rest of the system.\nEven if you change the service parameters to fix this (commenting out the\nPrivateMounts\nand\nMountFlags\nlines), there is another problem which is that processes started from Udev are killed after a few seconds. In case of FUSE filesystems, such as\nNTFS-3G\n,\nmount\nstarts a user-space process to handle the filesystem internals; when this is killed you will get\nTransport endpoint not connected\nerrors if you try to access the filesystem.\nThere are some options that work:\nStart a custom systemd service from the Udev rule; the systemd service can invoke a script which can start any number of long-running processes (like FUSE). A concise example which automatically mounts USB disks under\n/media\nis\nudev-media-automount\n. A variant of the same idea is explained in\nthis blog post\n.\nUse\nsystemd-mount\ninstead of\nmount\nin your Udev rule. This is\nrecommended by systemd developers\n. For example this Udev rule should mount USB disks under\n/media\n:\nACTION==\"add\", SUBSYSTEMS==\"usb\", SUBSYSTEM==\"block\", ENV{ID_FS_USAGE}==\"filesystem\", RUN{program}+=\"/usr/bin/systemd-mount --no-block --automount=yes --collect $devnode /media\"\nUse a package like\nudisks\nor\nudiskie\n. These are very powerful, but difficult to set up. Also, they are meant to be used in single user sessions, since they make some filesystems available under the ownership of the unprivileged user whose session is currently active.\nSpawning long-running processes\nPrograms started by udev will block further events from that device, and any tasks spawned from a udev rule will be killed after event handling is completed. If you need to spawn a long-running process with udev, the intended way is to have a\nsystemd\nunit which handles running the actual command, and a udev rule that merely signals that this unit should run. However, using\nsystemctl\nin a udev rule is discouraged, since it is meant for user interaction and may block, among other things.\nThe correct way of doing this is to have the rule tag the device as needing a systemd device unit (see\nsystemd.device(5)\n) using\nTAG+=\"systemd\"\nand adding an device property of either\nENV{SYSTEMD_WANTS}+=\nfor services that would run with\nsystemctl --system\nor\nENV{SYSTEMD_USER_WANTS}+=\nfor services that should run with\nsystemctl --user\n. For example:\nSUBSYSTEM==\"tty\", ACTION==\"add\", ATTRS{manufacturer}==\"Pulse-Eight\", ATTRS{product}==\"CEC Adapter\", TAG+=\"systemd\", ENV{SYSTEMD_WANTS}+=\"inputattach-cec@$devnode.service\"\n/etc/systemd/system/inputattach-cec@.service\n[Unit]\nDescription=Configure USB serial device at %I\n[Service]\nType=simple\nExecStart=/usr/bin/inputattach --pulse8-cec %I\nSYSTEMD_WANTS\nis equivalent to the\nWants=\ndirective elsewhere in systemd, meaning the device will not be affected if the service fails, does not exists, or completes successfully at any point.\nAllowing regular users to use devices\nWarning\nDo not set the\nuaccess\ntag on input or block devices; those have their own access control mechanisms and unprivileged users should not have raw access to those. For instance, unprivileged raw keyboard access would make keylogging trivial, and unprivileged raw disk access would completely negate filesystem security.\nWhen a\nkernel\ndriver initializes a device, the default state of the device node is to be owned by\nroot:root\n, with permissions\n600\n.\n[2]\nThis makes devices inaccessible to regular users unless the driver changes the default, or a udev rule in user space changes the permissions.\nThe\nOWNER\n,\nGROUP\n, and\nMODE\nudev values can be used to provide access, though one encounters the issue of how to make a device usable to all users without an overly permissive mode. Ubuntu's approach is to create a\nplugdev\ngroup that devices are added to, but this practice is not only discouraged by the systemd developers,\n[3]\nbut considered a bug when shipped in udev rules on Arch (\nFS#35602\n) and broken starting from systemd 258\n[4]\n[5]\n. Another approach historically employed, as described in\nUsers and groups#Pre-systemd groups\n, is to have different groups corresponding to categories of devices.\nThe modern recommended approach for systemd systems is to use a\nMODE\nof\n660\nto let the group use the device, and then attach a\nTAG\nnamed\nuaccess\n[6]\n. This special tag makes udev apply a\ndynamic user ACL\nto the device node, which coordinates with\nsystemd-logind(8)\nto make the device usable to logged-in users. For an example of a udev rule implementing this:\n/etc/udev/rules.d/71-device-name.rules\nACTION!=\"remove\", SUBSYSTEMS==\"usb\", ATTRS{idVendor}==\"\nvendor_id\n\", ATTRS{idProduct}==\"\nproduct_id\n\", MODE=\"0660\", TAG+=\"uaccess\"\nNote\nFor any rule adding the\nuaccess\ntag to be effective, the name of the file it is defined in\nhas to lexically precede\n/usr/lib/udev/rules.d/73-seat-late.rules\n.\nExecute when HDMI cable is plugged in or unplugged\nCreate the rule\n/etc/udev/rules.d/95-hdmi-plug.rules\nwith the following content:\nACTION==\"change\", SUBSYSTEM==\"drm\", ENV{DISPLAY}=\":0\", ENV{XAUTHORITY}=\"/home/\nusername\n/.Xauthority\", RUN+=\"\n/path/to/script.sh\n\"\nNote\nIf the rule triggers before the X server starts, it may not work as intended. See\n#X programs in RUN rules hang when no X server is present\n.\nExecute on VGA cable plug in\nCreate the rule\n/etc/udev/rules.d/95-monitor-hotplug.rules\nwith the following content to launch\narandr\non plug in of a VGA monitor cable:\nKERNEL==\"card0\", SUBSYSTEM==\"drm\", ENV{DISPLAY}=\":0\", ENV{XAUTHORITY}=\"/home/\nusername\n/.Xauthority\", RUN+=\"/usr/bin/arandr\"\nSome display managers store the\n.Xauthority\noutside the user home directory. You will need to update the\nENV{XAUTHORITY}\naccordingly. As an example\nGNOME Display Manager\nlooks as follows:\n$ printenv XAUTHORITY\n/run/user/1000/gdm/Xauthority\nNote\nIf the rule triggers before the X server starts, it may not work as intended. See\n#X programs in RUN rules hang when no X server is present\n.\nDetect new eSATA drives\nIf your eSATA drive is not detected when you plug it in, there are a few things you can try. You can reboot with the eSATA plugged in. Or you could try:\n# echo 0 0 0 | tee /sys/class/scsi_host/host*/scan\nOr you could install\nscsiadd\nAUR\n(from the AUR) and try:\n# scsiadd -s\nHopefully, your drive is now in\n/dev\n. If it is not, you could try the above commands while running:\n# udevadm monitor\nto see if anything is actually happening.\nMark internal SATA ports as eSATA\nIf you connected an eSATA bay or another eSATA adapter, the system will still recognize this disk as an internal SATA drive.\nGNOME\nand\nKDE\nwill ask you for your root password all the time. The following rule will mark the specified SATA-Port as an external eSATA-Port. With that, a normal GNOME user can connect their eSATA drives to that port like a USB drive, without any root password and so on.\n/etc/udev/rules.d/10-esata.rules\nDEVPATH==\"/devices/pci0000:00/0000:00:1f.2/host4/*\", ENV{UDISKS_SYSTEM}=\"0\"\nNote\nThe\nDEVPATH\ncan be found after connection the eSATA drive with the following commands (replace\nsdb\naccordingly):\n$ udevadm info --query=path /dev/sdb\n/devices/pci0000:00/0000:00:1f.2/host4/target4:0:0/4:0:0:0/block/sdb\n$ find /sys/devices/ -name sdb\n/sys/devices/pci0000:00/0000:00:1f.2/host4/target4:0:0/4:0:0:0/block/sdb\nSetting static device names\nBecause\nudev\nloads all modules asynchronously, they are initialized in a different order. This can result in devices randomly switching names. A\nudev\nrule can be added to use static device names.\nSee also\nPersistent block device naming\nfor block devices and\nNetwork configuration#Change interface name\nfor network devices.\nVideo device\nFor setting up the webcam in the first place, refer to\nWebcam setup\n.\nUsing multiple webcams will assign video devices as\n/dev/video*\nrandomly on boot. The recommended solution is to create symlinks using a\nudev\nrule as in the\n#Example\n:\n/etc/udev/rules.d/83-webcam.rules\nKERNEL==\"video[0-9]*\", SUBSYSTEM==\"video4linux\", SUBSYSTEMS==\"usb\", ATTRS{idVendor}==\"05a9\", ATTRS{idProduct}==\"4519\", SYMLINK+=\"video-cam1\"\nKERNEL==\"video[0-9]*\", SUBSYSTEM==\"video4linux\", SUBSYSTEMS==\"usb\", ATTRS{idVendor}==\"046d\", ATTRS{idProduct}==\"08f6\", SYMLINK+=\"video-cam2\"\nNote\nUsing names other than\n/dev/video*\nwill break preloading of\nv4l1compat.so\nand perhaps\nv4l2convert.so\nPrinter\nIf you use multiple printers,\n/dev/lp[0-9]\ndevices will be assigned randomly on boot, which will break e.g.\nCUPS\nconfiguration.\nYou can create the following rule, which will create symlinks under\n/dev/lp/by-id\nand\n/dev/lp/by-path\n, similar to\nPersistent block device naming\nscheme:\n/etc/udev/rules.d/60-persistent-printer.rules\nACTION==\"remove\", GOTO=\"persistent_printer_end\"\n# This should not be necessary\n#KERNEL!=\"lp*\", GOTO=\"persistent_printer_end\"\nSUBSYSTEMS==\"usb\", IMPORT{builtin}=\"usb_id\"\nENV{ID_TYPE}!=\"printer\", GOTO=\"persistent_printer_end\"\nENV{ID_SERIAL}==\"?*\", SYMLINK+=\"lp/by-id/$env{ID_BUS}-$env{ID_SERIAL}\"\nIMPORT{builtin}=\"path_id\"\nENV{ID_PATH}==\"?*\", SYMLINK+=\"lp/by-path/$env{ID_PATH}\"\nLABEL=\"persistent_printer_end\"\nIdentifying a disk by its serial\nTo perform some action on a specific disk device\n/dev/sd\nX\nidentified permanently by its unique serial\nID_SERIAL_SHORT\nas displayed with\nudevadm info /dev/sd\nX\n, one can use the below rule. It is passing as a parameter the device name found if any to illustrate:\n/etc/udev/rules.d/69-disk.rules\nACTION==\"add\", KERNEL==\"sd[a-z]\", ENV{ID_SERIAL_SHORT}==\"\nX5ER1ALX\n\", RUN+=\"/path/to/script /dev/%k\"\nWaking from suspend with USB device\nA udev rule can be useful to enable the\nwakeup triggers\nof a USB device, like a mouse or a keyboard, so that it can be used to wake the system from sleep.\nNote\nBy default, the USB host controllers are all enabled for wakeup. The status can be checked using\ncat /proc/acpi/wakeup\n. The rule below is in this case not necessary but can be used as a template to perform other actions, like disabling the wakeup functionality for example.\nFirst, identify the vendor and product identifiers of the USB device. They will be used to recognize it in the udev rule. For example:\n$ lsusb | grep Logitech\nBus 007 Device 002: ID\n046d\n:\nc52b\nLogitech, Inc. Unifying Receiver\nThen, find where the device is connected to using:\n$ grep\nc52b\n/sys/bus/usb/devices/*/idProduct\n/sys/bus/usb/devices/\n1-1.1.1.4/\nidProduct:c52b\nNow create the rule to change the\npower/wakeup\nattribute of both the device and the USB controller it is connected to whenever it is added:\n/etc/udev/rules.d/50-wake-on-device.rules\nACTION==\"add\", SUBSYSTEM==\"usb\", DRIVERS==\"usb\", ATTRS{idVendor}==\"\n046d\n\", ATTRS{idProduct}==\"\nc52b\n\", ATTR{power/wakeup}=\"enabled\", ATTR{driver/\n1-1.1.1.4\n/power/wakeup}=\"enabled\"\nForce USB device features to be re-added after suspend\nUSB devices need to be reset after exiting a suspended state (whether from the system resuming from sleep or from a port being turned off when the device was idle for power saving), which the Linux kernel\nhandles mostly transparently\nin a process called\nreset-resume\n, so that USB drives do not look like they have been disconnected and reconnected every time. This is mostly desirable, but some devices, like USB TTY interfaces, do need to be manually reconfigured after being power cycled, which is not signalled by any uevent from the relevent drivers.\nThe one uevent that does get raised, however, is the one from losing and regaining power/wakeup, since USB devices are unusable while unconfigured and would be unable to wake up the system from sleep in this state. These two events have no unique event properties, but the first one can still be easily identified because\nDEVNUM\nis set to zero (which is not a valid device number)\nimmediately before\nthe device is unconfigured and loses\npower/wakeup\n, raising the uevent. When that happens, one can simply touch the\nbConfigurationValue\nsysfs attribute to\nforce the system to reconfigure\nthe device\nnon-transparently\n, as if it had been disconnected during sleep, which unbinds all drivers and removes all children devices before adding them back when the device is ready again.\n# The actual rule to be run\nACTION==\"add\" SUBSYSTEM==\"tty\" SUBSYSTEMS=\"usb\" ATTRS{manufacturer}==\"Foo\" ATTRS{product}==\"Bar\" TAG+=\"systemd\" ENV{SYSTEMD_WANTS}=\"setup-usb-tty@$devnode.service\"\n# The rule that will get the above rule to re-run when the computer comes out of sleep\n# Can't use $attr{bConfigurationValue} in ATTR{}, so make sure to replace\n# both \"1\" by whatever configuration value is being used when\n# the device is functionnal.\nACTION==\"change\" SUBSYSTEM==\"usb\" ENV{DEVNUM}==\"000\" ATTR{manufacturer}==\"Foo\" ATTR{product}==\"Bar\" ATTR{bConfigurationValue}==\"1\" ATTR{bConfigurationValue}=\"1\"\nTriggering events\nThis article or section is a candidate for merging with\n#Testing rules before loading\n.\nNotes:\nsimilar trick (Discuss in\nTalk:Udev\n)\nIt can be useful to trigger various\nudev\nevents. For example, you might want to simulate a USB device disconnect on a remote machine. In such cases, use\nudevadm trigger\n:\n# udevadm trigger --verbose --type=subsystems --action=remove --subsystem-match=usb --attr-match=\"idVendor=abcd\"\nThis command will trigger a USB remove event on all USB devices with vendor ID\nabcd\n.\nTriggering desktop notifications from a udev rule\nTo trigger a desktop notification from a\nudev\nrule, use\nsystemd-run(1)\nas explained in\nDesktop notifications#Send notifications to another user\n:\nCreate the file:\n/etc/udev/rules.d/99-powersupply_notification.rules\n# Rule for when switching to battery\nACTION==\"change\", SUBSYSTEM==\"power_supply\", ATTRS{type}==\"Mains\", ATTRS{online}==\"0\", RUN+=\"/usr/bin/systemd-run --machine=\ntarget_user\n@.host --user notify-send 'Changing Power States' 'Using battery power'\"\n# Rule for when switching to AC\nACTION==\"change\", SUBSYSTEM==\"power_supply\", ATTRS{type}==\"Mains\", ATTRS{online}==\"1\", RUN+=\"/usr/bin/systemd-run --machine=\ntarget_user\n@.host --user notify-send 'Changing Power States' 'Using AC power'\"\nTo launch multiple or long commands, an\nexecutable\nscript can be given to\nsystemd-run\n:\n/usr/local/bin/from_battery.sh\n#!/bin/sh\npaplay /usr/share/sounds/freedesktop/stereo/power-unplug.oga\nnotify-send --icon=/usr/share/icons/Adwaita/symbolic/legacy/battery-good-symbolic.svg 'Changing Power States' 'Using battery power' --expire-time=4000\nNote\nIf the rule triggers before the X server starts, it may not work as intended. See\n#X programs in RUN rules hang when no X server is present\n.\nTroubleshooting\nBlacklisting modules\nIn rare cases,\nudev\ncan make mistakes and load the wrong modules. To prevent it from doing this, you can\nblacklist\nmodules. Once blacklisted,\nudev\nwill never load that module – not at boot-time and not even later on when a hot-plug event is received (e.g., you plug in your USB flash drive).\nDebug output\nTo get hardware\ndebug\ninfo, use the\nkernel parameter\nudev.log-priority=debug\n. Alternatively you can set\n/etc/udev/udev.conf\nudev_log=\"debug\"\nThis option can also be compiled into your initramfs by adding the configuration file to your\nFILES\narray:\n/etc/mkinitcpio.conf\nFILES=(... /etc/udev/udev.conf)\nand then\nregenerate the initramfs\n.\nudevd hangs at boot\nAfter migrating to LDAP or updating an LDAP-backed system,\nudevd\ncan hang at boot at the message \"Starting UDev Daemon\". This is usually caused by\nudevd\ntrying to look up a name from LDAP but failing, because the network is not up yet. The solution is to ensure that all system group names are present locally.\nExtract the group names referenced in\nudev\nrules and the group names actually present on the system:\n# grep -Fr GROUP /etc/udev/rules.d/ /usr/lib/udev/rules.d/ | sed 's:.*GROUP=\"\\([-a-z_]\\{1,\\}\\)\".*:\\1:' | sort -u >udev_groups\n# cut -d: -f1 /etc/gshadow /etc/group | sort -u >present_groups\nTo see the differences, do a side-by-side diff:\n# diff -y present_groups udev_groups\n...\nnetwork\t\t\t\t\t\t\t      <\nnobody\t\t\t\t\t\t\t      <\nntp\t\t\t\t\t\t\t      <\noptical\t\t\t\t\t\t\t\toptical\npower\t\t\t\t\t\t\t      |\tpcscd\nrfkill\t\t\t\t\t\t\t      <\nroot\t\t\t\t\t\t\t\troot\nscanner\t\t\t\t\t\t\t\tscanner\nsmmsp\t\t\t\t\t\t\t      <\nstorage\t\t\t\t\t\t\t\tstorage\n...\nIn this case, the\npcscd\ngroup is for some reason not present in the system.\nAdd the missing groups\n. Also, make sure that local resources are looked up before resorting to LDAP.\n/etc/nsswitch.conf\nshould contain the following line:\ngroup: files ldap\nSome devices, that should be treated as removable, are not\nYou need to create a custom\nudev\nrule for that particular device. To get definitive information of the device you can use either\nID_SERIAL\nor\nID_SERIAL_SHORT\n(remember to change\n/dev/sdb\nif needed):\n$ udevadm info --query=property --property=ID_SERIAL,ID_SERIAL_SHORT --name=/dev/sdb\nThen we set\nUDISKS_AUTO=\"1\"\nto mark the device for automounting and\nUDISKS_SYSTEM=\"0\"\nto mark the device as \"removable\". See\nudisks(8)\nfor details.\n/etc/udev/rules.d/99-removable.rules\nENV{ID_SERIAL_SHORT}==\"\nserial_number\n\", ENV{UDISKS_AUTO}=\"1\", ENV{UDISKS_SYSTEM}=\"0\"\nRemember to reload\nudev\nrules with\nudevadm control --reload\n. Next time you plug your device in, it will be treated as an external drive.\nSound problems with some modules not loaded automatically\nSome users have traced this problem to old entries in\n/etc/modprobe.d/sound.conf\n. Try cleaning that file out and trying again.\nThe\nOSS emulation\nmodules\nsnd_pcm_oss\nand\nsnd_seq_oss\nare not automatically loaded by default.\nOptical drives have group ID set to \"disk\"\nIf the group ID of your optical drive is set to\ndisk\nand you want to have it set to\noptical\n, you have to create a custom\nudev\nrule:\n/etc/udev/rules.d\n# permissions for SCSI CD devices\nSUBSYSTEMS==\"scsi\", KERNEL==\"s[rg][0-9]*\", ATTRS{type}==\"5\", GROUP=\"optical\"\nX programs in RUN rules hang when no X server is present\nWhen\nxrandr\nor another X-based program tries to connect to an X server, it falls back to a TCP connection on failure. However, due to\nIPAddressDeny\nin the\nsystemd-udev service configuration\n, this hangs. Eventually the program will be killed and event processing will resume.\nIf the rule is for a drm device and the hang causes event processing to complete once the X server has started, this can cause 3D acceleration to stop working with a\nfailed to authenticate magic\nerror.\nSee also\nudev(7)\nAn Introduction to udev\nudev mailing list information\nScripting with udev\nWriting udev rules\nDevice and Module Handling on an LFS System\nRunning GUI or accessing display variables from udev rules\nopenSUSE udev documentation\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Udev&oldid=853888\n\"\nCategory\n:\nHardware detection and troubleshooting\nHidden category:\nPages or sections flagged with Template:Merge\nSearch\nSearch\nudev\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Udev"}}
{"text": "udisks - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nudisks\n4 languages\nDeutsch\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nudev\nMount\nPolkit\nFile manager functionality\nudisks\nprovides a daemon\nudisksd\n, that implements D-Bus interfaces used to query and manipulate storage devices, and a command-line tool\nudisksctl\n, used to query and use the daemon.\nInstallation\nInstall\nthe\nudisks2\npackage.\nudisksd(8)\nis started on-demand by\nD-Bus\nand should not be enabled explicitly. It can be controlled through the command-line with\nudisksctl(1)\n.\nConfiguration\nPermissions\nActions a user can perform using udisks are restricted with\npolkit\n. If the\nuser session\nis not activated or present (for example, when controlling udisks from a\nsystemd/User\nservice), adjust polkit rules accordingly.\nSee\nhttps://github.com/coldfix/udiskie/wiki/Permissions\nfor common udisks permissions for the\nstorage\ngroup, and\n[1]\nfor a more restrictive example. If you are using\nDolphin\n, you may see\n[2]\n.\nDefault mount options\nIt is possible to define default mount options in\n/etc/udisks2/mount_options.conf\n. Create the file if it does not already exist. The built-in defaults and some examples can be seen in\n/etc/udisks2/mount_options.conf.example\n.\n[3]\nThe options can target specific filesystem types. For example, mount\nbtrfs\nfilesystems with zstd compression enabled:\n/etc/udisks2/mount_options.conf\n[defaults]\nbtrfs_defaults=compress=zstd\nNote\nLines override the corresponding built-in defaults. Make sure not to accidentally remove mount options this way.\nUsage\nTo manually mount a removable drive, for example\n/dev/sdc\n:\n$ udisksctl mount -b /dev/sdc1\nTo unmount:\n$ udisksctl unmount -b /dev/sdc1\nSee\nudisksctl help\nfor more.\nTips and tricks\nMount helpers\nThe automatic mounting of devices is easily achieved with udisks wrappers. See also\nList of applications/Utilities#Mount tools\n.\nNote\nDesktop environments\n, such as\nGNOME\nand\nPlasma\nmay also provide a udisks wrapper.\nbashmount\n— A bash script to mount and manage removable media as a regular user.\nhttps://github.com/jamielinux/bashmount\n||\nbashmount\nAUR\nudiskie\n— Automounter with optional notifications, tray icon and support for password protected\nLUKS devices\n. See the\nudiskie wiki\nfor details\nhttps://github.com/coldfix/udiskie\n||\nudiskie\nudiskie-dmenu\n— dmenu interface for\nudiskie\n.\nhttps://github.com/fogine/udiskie-dmenu\n||\nudiskie-dmenu-git\nAUR\nudisksvm\n— GUI wrapper written in Python3 and using the Qt5 framework. It uses mouse clicks to mount, unmount removable devices or eject a CD/DVD. See the\nREADME\nfile for details.\nhttps://github.com/berbae/udisksvm\n||\nudisksvm\nAUR\nudevadm monitor\nYou may use\nudevadm monitor\nto monitor block events and mount drives when a new block device is created. Stale mount points are automatically removed by\nudisksd\n, such that no special action is required on deletion.\n#!/bin/sh\npathtoname() {\nudevadm info -p /sys/\"$1\" | awk -v FS== '/DEVNAME/ {print $2}'\n}\nstdbuf -oL -- udevadm monitor --udev -s block | while read -r -- _ _ event devpath _; do\nif [ \"$event\" = add ]; then\ndevname=$(pathtoname \"$devpath\")\nudisksctl mount --block-device \"$devname\" --no-user-interaction\nfi\ndone\nMount to /media\nBy default, udisks2 mounts removable drives under the ACL controlled directory\n/run/media/$USER/\n. If you wish to mount to\n/media\ninstead, use this rule:\n/etc/udev/rules.d/99-udisks2.rules\n# UDISKS_FILESYSTEM_SHARED\n# ==1: mount filesystem to a shared directory (/media/VolumeName)\n# ==0: mount filesystem to a private directory (/run/media/$USER/VolumeName)\n# See udisks(8)\nENV{ID_FS_USAGE}==\"filesystem|other|crypto\", ENV{UDISKS_FILESYSTEM_SHARED}=\"1\"\nSince\n/media\n, unlike\n/run\n, is not mounted by default as a\ntmpfs\n, you may also wish to create a\ntmpfiles.d\nsnippet to clean stale mountpoints at every boot:\n/etc/tmpfiles.d/media.conf\nD /media 0755 root root 0 -\nMount loop devices\nTo easily mount ISO images, use the following command:\n$ udisksctl loop-setup -r -f\nimage.iso\nThis will create a read only loop device and show the ISO image ready to mount. Remove the\n-r\nflag to be able to write to it. The name of the created loop device is output by the above\nloop-setup\ncommand.\nYou can unmount, and remount, the image as long as the specific loop device is in place. When done working with the specific loop device, use\n$ udisksctl loop-delete -b\n/dev/loop0\nto delete it. Substitute\n/dev/loop0\nwith the name of the specific loop device.\nLoop devices are cheap. Therefore, many loop devices can be created in practice without worrying about a denial of service issue. See\n[4]\n.\nHide selected partitions\nIf you wish to prevent certain partitions or drives appearing on the desktop, you can create a\nudev rule\n, for example\n/etc/udev/rules.d/10-local.rules\n:\nKERNEL==\"sda1\", ENV{UDISKS_IGNORE}=\"1\"\nKERNEL==\"sda2\", ENV{UDISKS_IGNORE}=\"1\"\nshows all partitions with the exception of\nsda1\nand\nsda2\non your desktop.\nBecause block device names can change between reboots, it is also possible to use\nUUIDs\nto hide partitions or whole devices. Matching by UUID is only possible after\n/usr/lib/udev/rules.d/60-persistent-storage.rules\nhas been processed, so make sure to choose a file name that will be ordered after it. For example:\n/etc/udev/rules.d/61-hide-partitions.rules\nSUBSYSTEM==\"block\", ENV{ID_FS_UUID}==\"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXXX\", ENV{UDISKS_IGNORE}=\"1\"\nThe above line is also useful to hide multi device btrfs filesystems, as all the devices from a single btrfs filesystem will share the same UUID across the devices but will have different SUB_UUID for each individual device.\nApply ATA settings\nAt start-up and when a drive is connected, udisksd will apply configuration stored in the file\n/etc/udisks2/\nIDENTIFIER\n.conf\nwhere\nIDENTIFIER\nis the value of the Drive:Id property for the drive. Currently ATA settings are supported. See\nudisks(8)\nfor available options. These settings have essentially the same effect as those of\nhdparm\n, but they are persistent as long as the udisks daemon is autostarted.\nFor example, to set standby timeout to 240 (20 minutes) for a drive, add the following:\n/etc/udisks2/\nDriveId\n.conf\n[ATA]\nStandbyTimeout=240\nTo obtain the DriveId for your drive, use\nudevadm info --query=all --name=\nsdx\n| grep ID_SERIAL | sed \"s/_/-/g\"\nAlternatively, use a GUI utility to manage the configuration file, such as\ngnome-disk-utility\n.\nSetting noatime by default\nThis article or section is a candidate for merging with\n#Default mount options\n.\nNotes:\nSame topic. (Discuss in\nTalk:Udisks\n)\nThis article or section needs language, wiki syntax or style improvements. See\nHelp:Style\nfor reference.\nReason:\nDiscussion of the\nnoatime\nvs\nrelatime\neffects should not duplicate\nfstab#atime options\n. (Discuss in\nTalk:Udisks\n)\nIf most of the devices mounted with Udisks are flash memories, like USB sticks and SD cards, configuring Udisks to not update files' access time may be beneficial. It causes additional and unexpected writes, despite the memory has apparently only been read. The default\nrelatime\nmount option limits excessive writes for main storage. It does not prevent updates if the access time is older than 24 hours, which is often the case on removable media. To set\nnoatime\nas the default for\nall\nUdisks mounts, add:\n/etc/udisks2/mount_options.conf\n[defaults]\ndefaults=noatime\nThis option may be overridden later for specific mounts that do require atime: either in  mount-specific\n/etc/udisks2/mount_options.conf\nsection or through a\nudev\nrule setting\nENV{UDISKS_MOUNT_OPTIONS_DEFAULTS}=\"relatime\"\n.\nTroubleshooting\nHidden devices\nUdisks2 hides certain devices from the user by default. If this is undesired or otherwise problematic, copy\n/usr/lib/udev/rules.d/80-udisks2.rules\nto\n/etc/udev/rules.d/80-udisks2.rules\nand remove the following section in the copy:\n# ------------------------------------------------------------------------\n# ------------------------------------------------------------------------\n# ------------------------------------------------------------------------\n# Devices which should not be display in the user interface\n[...]\nBroken standby timer\nThe udisks daemon polls\nS.M.A.R.T.\ndata from drives regularly. Hard drives with a longer standby timeout than the polling interval may fail to enter standby. Drives that are already spun down are usually not affected. There seems no way to disable polling or change the interval as for\nudisks2\nby now. See\n[5]\n,\n[6]\n.\nHowever, Standby timeout applied by udisks2 seems to be unaffected. To set standby timeout via udisks, see\n#Apply ATA settings\n.\nOther possible workarounds could be setting the timeout below the polling interval (10 minutes) or forcing a manual spindown using\nhdparm -y /dev/\nsdx\n.\nNTFS mount failing\nThe factual accuracy of this article or section is disputed.\nReason:\nAs stated in the\n/etc/udisks2/mount_options.conf.example\nfile, these are the builtin mount options (i.e. the defaults). They do not need to be explicitly set. KDE may not land on the setting. (Discuss in\nTalk:Udisks#udisk2 with NTFS support\n)\nIf mounting a ntfs partition fails with the error:\nError mounting /dev/sdXY at [...]: wrong fs type, bad option, bad superblock on /dev/sdXY, missing codepage or helper program, or other error\nand in the kernel log with\njournalctl\n/\ndmesg\nran as root:\nntfs: (device sdXY): parse_options(): Unrecognized mount option windows_names.\nThe problem is (as of udisks 2.10), the default is using the NTFS-3G driver, and there are 2 solutions for this:\n1: Install NTFS-3G, and restart your machine.\n2: Configure udisks2. By default, udisks2 is not configured on an Arch system, and no defaults are defined for non-native filesystems. The easiest way to do so, is to copy\n/etc/udisks2/mount.options.conf.example\nto\n/etc/udisks2/mount.options.conf\nand uncomment the following lines:\n/etc/udisks2/mount_options.conf\n[defaults]\n# 'ntfs' signature, the new 'ntfs3' kernel driver\nntfs:ntfs3_defaults=uid=$UID,gid=$GID\nntfs:ntfs3_allow=uid=$UID,gid=$GID,umask,dmask,fmask,iocharset,discard,nodiscard,sparse,nosparse,hidden,nohidden,sys_immutable,showmeta,noshowmeta,prealloc,noprealloc,hide_dot_files,nohide_dot_files,windows_names,nocase,case\nand restart the udisk2 daemon, or restart your machine.\nNTFS file creation failing (filename-dependent)\nudisks 2.8.2 introduced a breaking change by adding\nwindows_names\nto NTFS mount options, preventing creation of Win32-incompatible filenames such as\nnul\n,\nscreenshot 23-08-21 19:22.jpg\n. Among other things, this causes\nSteam Proton to stop initializing\n. To revert this behavior, use:\n/etc/udisks2/mount_options.conf\n[defaults]\nntfs:ntfs_defaults=uid=$UID,gid=$GID\nBad filenames generally do not cause issues in Windows unless accessed.\nchkdsk\nwill treat these names as errors and move the renamed files to\nfound.nnn\nfolders under filesystem root.\nAutomatically turn off an external HDD at shutdown\nIf an external HDD is not powered off properly at system shutdown, it may be desirable to fix the issue.\nEnable\nudisks2.service\n.\nA service to invoke our script might look like so:\n/etc/systemd/system/handle_external_hdds.service\n[Unit]\nRequires=udisks2.service\nRequires=graphical.target\nAfter=graphical.target\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStop=/usr/local/bin/handle_external_hdds.sh\n[Install]\nWantedBy=graphical.target\nEnable\nhandle_external_hdds.service\nDo a systemd\ndaemon-reload\nto apply the new setting.\nReboot or restart\ngraphical.target\nto check if works.\nAn example script to handle an arbitrary amount of partitions on a single disk looks like so:\n/usr/local/bin/handle_external_hdds.sh\n#!/bin/bash -u\ndeclare -a uuids=(\nuuid_list\n)\n# Only proceed if the drive is present.\nif [[ ! -L \"/dev/disk/by-uuid/${uuids[0]}\" ]]; then\nexit 0\nfi\nfor uuid in \"${uuids[@]}\"; do\nif findmnt \"/dev/disk/by-uuid/$uuid\"; then\numount \"/dev/disk/by-uuid/$uuid\"\nfi\ndone\n# udisksctl powers off proper drive even if its partition is supplied\nudisksctl power-off -b \"/dev/disk/by-uuid/${uuids[0]}\"\nuuid_list\nis a list of space delimited UUIDs corresponding to partitions of the device to check, e.g.\n\"\nuuid_1\n\" \"\nuuid_2\n\"\n.\nSlow unmount or corruption of removable media without any writes\nEven if nothing seems to be written to a USB stick, memory card, or other removable media, file access times may still be updated. This is a change that needs to be flushed to the device. If that is of concern, consider\nsetting the noatime option\nfor all Udisks mounts.\nSee also\nGentoo:udisks\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Udisks&oldid=852741\n\"\nCategory\n:\nHardware detection and troubleshooting\nHidden categories:\nPages or sections flagged with Template:Merge\nPages or sections flagged with Template:Style\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\nudisks\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Udisks"}}
{"text": "polkit - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\npolkit\n6 languages\nDeutsch\nFrançais\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nRelated articles\nSession\nSudo\nUsers and groups\nFrom\npolkit homepage\n:\npolkit is an application-level toolkit for defining and handling the policy that allows unprivileged processes to speak to privileged processes: It is a framework for centralizing the decision making process with respect to granting access to privileged operations for unprivileged applications.\nPolkit is used for controlling system-wide privileges. It provides an organized way for non-privileged processes to communicate with privileged ones. In contrast to systems such as sudo, it does not grant root permission to an entire process, but rather allows a finer level of control of centralized system policy.\nPolkit works by delimiting distinct actions, e.g. running GParted, and delimiting users by group or by name, e.g. members of the wheel group. It then defines how – if at all – those users are allowed those actions, e.g. by identifying as members of the group by typing in their passwords.\nInstallation\nInstall\nthe\npolkit\npackage.\nAuthentication agents\nAn authentication agent is used to make the user of a session prove that they really are the user (by authenticating as the user) or an administrative user (by authenticating as an administrator). The\npolkit\npackage contains\npkttyagent\n, a textual authentication agent which is used as a general fallback.\nIf you are using a graphical environment, make sure that a graphical authentication agent is installed and\nautostarted\non login (e.g. via\nxinitrc\n).\nCinnamon\n,\nDeepin\n,\nHyprland\n,\nGNOME\n,\nGNOME Flashback\n,\nKDE\n,\nLXDE\n,\nLXQt\n,\nMATE\n, and\nXfce\nhave an authentication agent already.\nIn other\ndesktop environments\n, you have to choose one of the following implementations:\nhyprpolkitagent\n, which provides\n/usr/lib/hyprpolkitagent/hyprpolkitagent\nlxqt-policykit\n, which provides\n/usr/bin/lxqt-policykit-agent\nlxsession\n, which provides\n/usr/bin/lxpolkit\nmate-polkit\n, which provides\n/usr/lib/mate-polkit/polkit-mate-authentication-agent-1\npolkit-gnome\n, which provides\n/usr/lib/polkit-gnome/polkit-gnome-authentication-agent-1\npolkit-kde-agent\n, which provides\n/usr/lib/polkit-kde-authentication-agent-1\npantheon-polkit-agent\n, which provides\n/usr/lib/policykit-1-pantheon/io.elementary.desktop.agent-polkit\nsoteria-git\nAUR\n, which provides\n/usr/lib/soteria-polkit/soteria\nxfce-polkit\nAUR\nor\nxfce-polkit-git\nAUR\n, which provides\n/usr/lib/xfce-polkit/xfce-polkit\nTip\nBefore continuing, check your autostart configuration with a look at the process list. For example, with\npgrep -af polkit-gnome\n.\nConfiguration\nWarning\nDo not amend the default permission files of packages, as these may be overwritten on package upgrades.\nPolkit definitions can be divided into two kinds:\nActions\nare defined in XML\n.policy\nfiles located in\n/usr/share/polkit-1/actions\n. Each action has a set of default permissions attached to it (e.g. you need to identify as an administrator to use the GParted action). The defaults can be overruled but editing the actions files is NOT the correct way.\nAuthorization rules\nare defined in JavaScript\n.rules\nfiles. They are found in two places:\n3rd party packages can use\n/usr/share/polkit-1/rules.d\n.\n/etc/polkit-1/rules.d\nis for local configuration.\nPolkit operates on top of the existing permissions systems in Linux – group membership, administrator status – it does not replace them. The .rules files designate a subset of users, refer to one (or more) of the actions specified in the actions files, and determine with what restrictions these actions can be taken by those users. As an example, a rules file could overrule the default requirement for all users to authenticate as an admin when using GParted, determining that some specific user does not need to. A different example: A certain user is not allowed to use GParted at all.\nNote\nThis does not preclude running GParted by means which do not respect polkit, such as the command line. Therefore, polkit should be used to expand access to privileged services for unprivileged users, rather than try to curtail the rights of (semi-)privileged users. For security purposes,\nsudoers\nis still the way to go.\nActions\nTip\nTo display Policykit actions in a graphical interface, install the\npolkit-explorer-git\nAUR\npackage.\nThe actions available to you via polkit will depend on the packages you have installed. Some are used in multiple desktop environments\n(org.freedesktop.*)\n, some are DE-specific\n(org.gnome.*)\nand some are specific to a single program\n(org.gnome.gparted.policy)\n. The command\npkaction\nlists all the actions defined in\n/usr/share/polkit-1/actions\nfor quick reference.\nTo get an idea of what polkit can do, here are a few commonly used groups of actions:\nsystemd-logind\n(org.freedesktop.login1.policy)\nactions regulated by polkit include powering off, rebooting, suspending and hibernating the system, including when other users may still be logged in.\nudisks\n(org.freedesktop.udisks2.policy)\nactions regulated by polkit include mounting file systems and unlocking encrypted devices.\nNetworkManager\n(org.freedesktop.NetworkManager.policy)\nactions regulated by polkit include turning on and off the network, Wi-Fi or mobile broadband.\nEach action is defined in an\n<action>\ntag in a .policy file. The\norg.gnome.gparted.policy\ncontains a single action and looks like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE policyconfig PUBLIC\n\"-//freedesktop//DTD PolicyKit Policy Configuration 1.0//EN\"\n\"http://www.freedesktop.org/software/polkit/policyconfig-1.dtd\">\n<policyconfig>\n<action id=\"org.gnome.gparted\">\n<message>Authentication is required to run the GParted Partition Editor</message>\n<icon_name>gparted</icon_name>\n<defaults>\n<allow_any>auth_admin</allow_any>\n<allow_inactive>auth_admin</allow_inactive>\n<allow_active>auth_admin</allow_active>\n</defaults>\n<annotate key=\"org.freedesktop.policykit.exec.path\">/usr/bin/gparted</annotate>\n<annotate key=\"org.freedesktop.policykit.exec.allow_gui\">true</annotate>\n</action>\n</policyconfig>\nThe attribute\nid\nis the actual command sent to\nD-Bus\n, the\nmessage\ntag is the explanation to the user when authentication is required and the\nicon_name\nis sort of obvious.\nThe\ndefaults\ntag is where the permissions or lack thereof are located. It contains three settings:\nallow_any\n,\nallow_inactive\n, and\nallow_active\n. Both inactive and active here refer to local sessions on local consoles or displays, whereas the\nallow_any\nsetting is used for all others, including remote sessions (SSH, VNC, etc.).\nFor each of these settings the following options are available:\nno\n: The user is not authorized to carry out the action. There is therefore no need for authentication.\nyes\n: The user is authorized to carry out the action without any authentication.\nauth_self\n: Authentication is required but the user need not be an administrative user.\nauth_admin\n: Authentication as an administrative user is required.\nauth_self_keep\n: The same as auth_self but, like sudo, the authorization lasts a few minutes.\nauth_admin_keep\n: The same as auth_admin but, like sudo, the authorization lasts a few minutes.\nThese are default setting and unless overruled in later configuration will be valid for all users.\nSee the\npolkit(8)\nman page for a detailed explanation.\nAs can be seen from the GParted action, users are required to authenticate as administrators in order to use GParted, regardless of whether the session is active or inactive.\nAuthorization rules\nAdd custom rules or override defaults in\n/etc/polkit-1/rules.d\n. Rules must have\nroot:polkitd\nownership. After adding a new rule,\nreload\npolkit.service\n.\nThe\naddRule()\nmethod is used for adding a function that may be called whenever an authorization check for action and subject is performed. Functions are called in the order they have been added until one of the functions returns a value. Hence, to add an authorization rule that is processed before other rules, put it in a file in\n/etc/polkit-1/rules.d\nwith a name that sorts before other rules files, for example\n00-early-checks.rules\n.\nThe layout of the .rules files is fairly self-explanatory:\n/* Allow users in admin group to run GParted without authentication */\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.gnome.gparted\" &&\nsubject.isInGroup(\"admin\")) {\nreturn polkit.Result.YES;\n}\n});\nInside the function, we check for the specified action ID\n(org.gnome.gparted)\nand for the user's group\n(admin)\n, then return a value \"yes\".\nAdministrator identities\nThe\naddAdminRule()\nmethod is used for adding a function that may be called whenever administrator authentication is required. The function is used to specify what identities may be used for administrator authentication for the authorization check identified by action and subject. Functions added are called in the order they have been added until one of the functions returns a value.\nThe default configuration for administrator identities is contained in the file\n/usr/share/polkit-1/rules.d/50-default.rules\nso any changes to that configuration should be made by copying the file to the\n/etc/polkit-1/rules.d\ndirectory and editing that file:\n/etc/polkit-1/rules.d/50-default.rules\npolkit.addAdminRule(function(action, subject) {\nreturn [\"unix-group:wheel\"];\n});\nThe only part to edit (once copied) is the return array of the function: as whom should a user authenticate when asked to authenticate as an administrative user? If they are a member of the group designated as admins, they only need enter their own password. If some other user, e.g. root, is the only admin identity, they would need to enter the root password. The format of the user identification is the same as the one used in designating authorities.\nThe Arch default is to make all members of the group\nwheel\nadministrators. A rule like below will have polkit ask for the root password instead of the users password for Admin authentication.\n/etc/polkit-1/rules.d/49-rootpw_global.rules\n/* Always authenticate Admins by prompting for the root\n* password, similar to the rootpw option in sudo\n*/\npolkit.addAdminRule(function(action, subject) {\nreturn [\"unix-user:root\"];\n});\nExamples\nAllow a user to use the org.freedesktop.timedate1.set-timezone action\nTo allow a user named\narchie\nto use the\norg.freedesktop.timedate1.set-timezone\naction without authentication, create the following polkit rule file as root:\n/etc/polkit-1/rules.d/49-allow-archie-set-timezone.rules\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.freedesktop.timedate1.set-timezone\" &&\nsubject.user == \"archie\") {\nreturn polkit.Result.YES;\n}\n});\nAfter saving the rule file, the policy should take effect immediately. You can test it by setting the timezone using the\ntimedatectl\n:\n[archie]$ timedatectl set-timezone America/New_York\nIf the operation completes without asking for authentication, then the rule works as intended. If the action does not seem to be allowed, ensure there are no conflicting rules with higher precedence (lower number prefixes) in\n/etc/polkit-1/rules.d/\n.\nDebugging/logging\nTo enable logging with\npolkit.log()\nfunction, remove the\n--no-debug\nflag from the\nExecStart\ncommand of\npolkit.service\nfile; either by\nediting\nthe unit temporarily (with\nsystemctl --runtime\n) or permanently with:\n/etc/systemd/system/polkit.service.d/debug.conf\n[Service]\nExecStart=\nExecStart=/usr/lib/polkit-1/polkitd --log-level=notice\nThe following rule logs detailed information about any requested access:\n/etc/polkit-1/rules.d/00-log-access.rules\npolkit.addRule(function(action, subject) {\npolkit.log(\"action=\" + action);\npolkit.log(\"subject=\" + subject);\n});\nTo manually test rules, use\npkcheck\n:\n[1]\n$ pkcheck -u -p $$ --enable-internal-agent -a\naction\nDisable suspend and hibernate\nThe factual accuracy of this article or section is disputed.\nReason:\nsystemctl(1)\nfalls back to starting\nsuspend.target\n/\nhibernate.target\ndirectly if logind is unavailable. To actually disable systemd-sleep,\nPower management/Suspend and hibernate#Disable sleep completely\nshould be used. (Discuss in\nTalk:Polkit\n)\nThe following rule disables suspend and hibernate for all users.\n/etc/polkit-1/rules.d/10-disable-suspend.rules\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.freedesktop.login1.suspend\" ||\naction.id == \"org.freedesktop.login1.suspend-multiple-sessions\" ||\naction.id == \"org.freedesktop.login1.hibernate\" ||\naction.id == \"org.freedesktop.login1.hibernate-multiple-sessions\")\n{\nreturn polkit.Result.NO;\n}\n});\nBypass password prompt\nTo achieve something similar to the\nsudo\nNOPASSWD\noption and get authorized solely based on\nuser/group\nidentity, you can create custom rules in\n/etc/polkit-1/rules.d/\n. This allows you to override password authentication either\nonly for specific actions\nor\nglobally\n. See\n[2]\nfor an example rule set.\nGlobally\nCreate the following file as root:\n/etc/polkit-1/rules.d/49-nopasswd_global.rules\n/* Allow members of the wheel group to execute any actions\n* without password authentication, similar to \"sudo NOPASSWD:\"\n*/\npolkit.addRule(function(action, subject) {\nif (subject.isInGroup(\"wheel\")) {\nreturn polkit.Result.YES;\n}\n});\nReplace\nwheel\nby any group of your preference.\nThis will result in automatic authentication for\nany\naction requiring admin rights via Polkit. As such, be careful with the group you choose to give such rights to.\nThere is also\nAUTH_ADMIN_KEEP\nwhich allows to keep the authorization for 5 minutes. However, the authorization is per process, hence if a new process asks for an authorization within 5 minutes the new process will ask for the password again anyway. In particular,\nrun0\nand\npkexec\ndo not keep authorization such as\nsudo\n. The feature is supported at\npolkit-git\n(see\n[3]\n).\nFor specific actions\nCreate the following file as root:\n/etc/polkit-1/rules.d/49-nopasswd_limited.rules\n/* Allow members of the wheel group to execute the defined actions\n* without password authentication, similar to \"sudo NOPASSWD:\"\n*/\npolkit.addRule(function(action, subject) {\nif ((action.id == \"org.gnome.gparted\" ||\naction.id == \"org.libvirt.unix.manage\") &&\nsubject.isInGroup(\"wheel\"))\n{\nreturn polkit.Result.YES;\n}\n});\nThe\naction.id\ns selected here are just (working) examples for GParted and\nLibvirt\n, but you can replace them by any other of your liking as long as they exist (custom made or supplied by a package), and so can you define any group instead of\nwheel\n.\nThe\n||\noperator is used to delimit actions (logical OR), and\n&&\nmeans logical AND and must be kept as the last operator.\nUdisks\nFile managers\nmay ask for a password when trying to mount a storage device, or yield a\nNot authorized\nor similar error. See\nUdisks#Configuration\nfor details.\nAllow management of individual systemd units by regular users\nBy checking for certain values passed to the polkit policy check, you can give specific users or groups the ability to manage specific units. As an example, you might want regular users to start and stop\nwpa_supplicant\n:\n/etc/polkit-1/rules.d/10-wifimanagement.rules\npolkit.addRule(function(action, subject) {\nif (action.id == \"org.freedesktop.systemd1.manage-units\") {\nif (action.lookup(\"unit\") == \"wpa_supplicant.service\") {\nvar verb = action.lookup(\"verb\");\nif (verb == \"start\" || verb == \"stop\" || verb == \"restart\") {\nreturn polkit.Result.YES;\n}\n}\n}\n});\nSee also\nPolkit manual page\nThe Polkit authentication framework\n(openSUSE Leap Security guide)\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=Polkit&oldid=854422\n\"\nCategory\n:\nSecurity\nHidden category:\nPages or sections flagged with Template:Accuracy\nSearch\nSearch\npolkit\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/Polkit"}}
{"text": "D-Bus - ArchWiki\nHome\nPackages\nForums\nWiki\nGitLab\nSecurity\nAUR\nDownload\nJump to content\nArchWiki\nSearch\nSearch\nD-Bus\n5 languages\nDeutsch\nMagyar\n日本語\nРусский\n中文（简体）\nFrom ArchWiki\nThis article or section needs expansion.\nReason:\nMention disabling of dbus services through use of\nsystemctl mask\nand overrides in\n/etc/dbus-1/services\n(Discuss in\nTalk:D-Bus\n)\nD-Bus\nis a message bus system that provides an easy way for inter-process communication. It consists of a daemon, which can be run both system-wide and for each user session, and a set of libraries to allow applications to use D-Bus.\ndbus\nis pulled and installed as a dependency of\nsystemd\nand user session bus is\nstarted automatically\nfor each user.\nImplementations\nArch provides two D-Bus message broker implementations. Initially, user will be asked to choose a desired\ndbus-units\nprovider during installation of\nsystemd\npackage. Only one implementation can be installed at a time.\ndbus-broker\ndbus-broker\nis currently the default implementation for Arch\n[1]\n[2]\n. It is a drop-in replacement for the\nreference implementation\n, which aims \"to provide high performance and reliability, while keeping compatibility to the D-Bus reference implementation\".\nSelect\ndbus-broker-units\nwhen asked for\ndbus-units\nprovider, or\ninstall\nit explicitly.\nNote\ndbus-broker\ncurrently does not have\nsupport\nfor\nAppArmor\n. However, officially supported kernels\ndo not support AppArmor mediation for D-Bus\n, either.\nReference implementation\nThe reference implementation\nis still officially supported by Arch.\nSelect\ndbus-daemon-units\nwhen asked for\ndbus-units\nprovider, or\ninstall\nit explicitly.\nTips and tricks\nOverride dbus service\nThis is useful when specifying a particular service among other services providing the same well-known bus name. See\nKeePass#Autostart\nand\nKDE Wallet#Automatic D-Bus activation\nfor example.\nD-Bus services can be masked by setting\nExec=/bin/false\nin service files of\n$XDG_DATA_HOME/dbus-1/services\n. For example, to mask gvfsd,\n$ cp /usr/share/dbus-1/services/org.gtk.vfs.Daemon.service ~/.local/share/dbus-1/services\n$ sed -i 's|^Exec=.*|Exec=/bin/false|' ~/.local/share/dbus-1/services/org.gtk.vfs.Daemon.service\nIf the service is already launched, the override will not work. The existing service's process must be killed, or launched earlier.\nDebugging\nBustle\n— Draws sequence diagrams of D-Bus activity. It shows signal emissions, method calls and their corresponding returns, with time stamps for each individual event and the duration of each method call.\nhttps://apps.gnome.org/Bustle/\n||\nbustle\nD-Feet\n— Easy to use D-Bus debugger GUI tool. Discontinued.\nhttps://wiki.gnome.org/Apps/DFeet\n||\nd-feet\nAUR\nD-Spy\n— Easy to use D-Bus debugger GUI tool. D-Spy can be used to inspect D-Bus interfaces of running programs and invoke methods on those interfaces.\nhttps://apps.gnome.org/Dspy/\n||\nd-spy\nQt D-Bus Viewer\n— GUI D-Bus debugger. Can be used to inspect D-Bus services and invoke methods on them.\nhttps://doc.qt.io/qt-6/qdbusviewer.html\n||\nqt6-tools\nYou can also use\nbusctl(1)\nfrom\nsystemd\n.\nSee also\nhttps://freedesktop.org/wiki/Software/dbus/\nhttps://freedesktop.org/wiki/IntroductionToDBus/\nhttps://uyha.github.io/technical/dbus-systemd.html\nsystemd uses DBus as the mechanism to interact with it. This article introduces just enough DBus concepts and the usage of\nbusctl\nto communicate with systemd.\nRetrieved from \"\nhttps://wiki.archlinux.org/index.php?title=D-Bus&oldid=851652\n\"\nCategory\n:\nSystem administration\nHidden category:\nPages or sections flagged with Template:Expansion\nSearch\nSearch\nD-Bus\nAdd topic", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://wiki.archlinux.org/title/D-Bus"}}
