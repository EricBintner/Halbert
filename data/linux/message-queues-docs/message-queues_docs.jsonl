{"text": "RabbitMQ Documentation | RabbitMQ\nSkip to main content\nRabbitMQ is developed by\nVMware Tanzu\n. Get 24/7 enterprise support backed by the core engineering team.\nVersion: 4.2\nOn this page\nRabbitMQ\n4.2\nDocumentation\nWelcome to RabbitMQ documentation!\nnote\nYou are currently viewing the documentation for\nRabbitMQ\n4.2.1\n.\nDocumentation is Versioned\nUse the drop-down menu on the top right of any page\nClick the\nhamburger\nicon at the top left and then click\nBack to main menu\nto select the documentation version for the RabbitMQ release that you are\nusing. We update each version of documentation with the latest patch\ninformation for that release.\nTable of Contents\nUse the navigation on the left\nClick the\nhamburger\nicon at the top left\nto browse through documentation for your release of RabbitMQ. This table of\ncontents is structured so it can be used by the two main RabbitMQ users:\nDevelopers and Administrators.\nIf you are a Developer\n​\nYou might want to start with\nGetting Started\nif you are new to\nRabbitMQ. These tutorials will guide you on how to use RabbitMQ.\nIf you are familiar with RabbitMQ, go directly to the\nHow to Use RabbitMQ\ninformation to start exploring it.\nIf you are an Administrator\n​\nThe table of contents for administrators is structured this way:\nThe\nHow to Manage RabbitMQ\nsection provides documentation for configuring\nand managing the RabbitMQ broker.\nThe\nHow to Monitor RabbitMQ\nsection includes information which will guide\nyou on how to setup monitoring for RabbitMQ and the applications that use it.\nIf you are a Developer\nIf you are an Administrator", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://www.rabbitmq.com/docs/documentation"}}
{"text": "Apache Kafka\nApache Kafka\nToggle navigation\nApache Kafka Quickstart\nEverything you need to know about Kafka in 10 minutes\n(clicking the image will load a video from YouTube)\nThe contents of this website are © 2025\nApache Software Foundation\nunder the terms of the\nApache License v2\n.\nApache Kafka, Kafka, and the Kafka logo are either registered trademarks or trademarks of The Apache Software Foundation\nin the United States and other countries.\nSecurity\n|\nDonate\n|\nThanks\n|\nEvents\n|\nLicense\n|\nPrivacy", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://kafka.apache.org/quickstart"}}
{"text": "Apache Kafka\nApache Kafka\nToggle navigation\n<\nDocumentation\nKafka 4.1 Documentation\nPrior releases:\n0.7.x\n,\n0.8.0\n,\n0.8.1.X\n,\n0.8.2.X\n,\n0.9.0.X\n,\n0.10.0.X\n,\n0.10.1.X\n,\n0.10.2.X\n,\n0.11.0.X\n,\n1.0.X\n,\n1.1.X\n,\n2.0.X\n,\n2.1.X\n,\n2.2.X\n,\n2.3.X\n,\n2.4.X\n,\n2.5.X\n,\n2.6.X\n,\n2.7.X\n,\n2.8.X\n,\n3.0.X\n,\n3.1.X\n,\n3.2.X\n,\n3.3.X\n,\n3.4.X\n,\n3.5.X\n,\n3.6.X\n,\n3.7.X\n,\n3.8.X\n,\n3.9.X\n.\n4.0.X\n.\n1. Getting Started\n1.1 Introduction\n1.2 Use Cases\nHere is a description of a few of the popular use cases for Apache Kafka®.\nFor an overview of a number of these areas in action, see\nthis blog post\n.\nMessaging\nKafka works well as a replacement for a more traditional message broker.\nMessage brokers are used for a variety of reasons (to decouple processing from data producers, to buffer unprocessed messages, etc).\nIn comparison to most messaging systems Kafka has better throughput, built-in partitioning, replication, and fault-tolerance which makes it a good\nsolution for large scale message processing applications.\nIn our experience messaging uses are often comparatively low-throughput, but may require low end-to-end latency and often depend on the strong\ndurability guarantees Kafka provides.\nIn this domain Kafka is comparable to traditional messaging systems such as\nActiveMQ\nor\nRabbitMQ\n.\nWebsite Activity Tracking\nThe original use case for Kafka was to be able to rebuild a user activity tracking pipeline as a set of real-time publish-subscribe feeds.\nThis means site activity (page views, searches, or other actions users may take) is published to central topics with one topic per activity type.\nThese feeds are available for subscription for a range of use cases including real-time processing, real-time monitoring, and loading into Hadoop or\noffline data warehousing systems for offline processing and reporting.\nActivity tracking is often very high volume as many activity messages are generated for each user page view.\nMetrics\nKafka is often used for operational monitoring data.\nThis involves aggregating statistics from distributed applications to produce centralized feeds of operational data.\nLog Aggregation\nMany people use Kafka as a replacement for a log aggregation solution.\nLog aggregation typically collects physical log files off servers and puts them in a central place (a file server or HDFS perhaps) for processing.\nKafka abstracts away the details of files and gives a cleaner abstraction of log or event data as a stream of messages.\nThis allows for lower-latency processing and easier support for multiple data sources and distributed data consumption.\nIn comparison to log-centric systems like Scribe or Flume, Kafka offers equally good performance, stronger durability guarantees due to replication,\nand much lower end-to-end latency.\nStream Processing\nMany users of Kafka process data in processing pipelines consisting of multiple stages, where raw input data is consumed from Kafka topics and then\naggregated, enriched, or otherwise transformed into new topics for further consumption or follow-up processing.\nFor example, a processing pipeline for recommending news articles might crawl article content from RSS feeds and publish it to an \"articles\" topic;\nfurther processing might normalize or deduplicate this content and publish the cleansed article content to a new topic;\na final processing stage might attempt to recommend this content to users.\nSuch processing pipelines create graphs of real-time data flows based on the individual topics.\nStarting in 0.10.0.0, a light-weight but powerful stream processing library called\nKafka Streams\nis available in Apache Kafka to perform such data processing as described above.\nApart from Kafka Streams, alternative open source stream processing tools include\nApache Storm\nand\nApache Samza\n.\nEvent Sourcing\nEvent sourcing\nis a style of application design where state changes are logged as a\ntime-ordered sequence of records. Kafka's support for very large stored log data makes it an excellent backend for an application built in this style.\nCommit Log\nKafka can serve as a kind of external commit-log for a distributed system. The log helps replicate data between nodes and acts as a re-syncing\nmechanism for failed nodes to restore their data.\nThe\nlog compaction\nfeature in Kafka helps support this usage.\nIn this usage Kafka is similar to\nApache BookKeeper\nproject.\n1.3 Quick Start\n1.4 Ecosystem\nThere are a plethora of tools that integrate with Kafka outside the main distribution. The\necosystem page\nlists many of these, including stream processing systems, Hadoop integration, monitoring, and deployment tools.\n1.5 Upgrading From Previous Versions\n1.6 KRaft vs ZooKeeper\n1.7 Compatibility\n1.8 Docker\n2. APIs\n3. Configuration\n4. Design\n5. Implementation\n6. Operations\n7. Security\n8. Kafka Connect\n9. Kafka Streams\nKafka Streams is a client library for processing and analyzing data stored in Kafka. It builds upon important stream processing concepts such as properly distinguishing between event time and processing time, windowing support, exactly-once processing semantics and simple yet efficient management of application state.\nKafka Streams has a\nlow barrier to entry\n: You can quickly write and run a small-scale proof-of-concept on a single machine; and you only need to run additional instances of your application on multiple machines to scale up to high-volume production workloads. Kafka Streams transparently handles the load balancing of multiple instances of the same application by leveraging Kafka's parallelism model.\nTo learn more about Kafka Streams, visit the\nKafka Streams page\n.\nThe contents of this website are © 2025\nApache Software Foundation\nunder the terms of the\nApache License v2\n.\nApache Kafka, Kafka, and the Kafka logo are either registered trademarks or trademarks of The Apache Software Foundation\nin the United States and other countries.\nSecurity\n|\nDonate\n|\nThanks\n|\nEvents\n|\nLicense\n|\nPrivacy", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://kafka.apache.org/documentation/"}}
{"text": "Welcome | NATS Docs\nNATS Docs\nCtrl\nk\nNATS.io\nNATS by Example\nGitHub\nSlack\nTwitter\nMore\nWelcome\nRelease Notes\nWhat's New!\nNATS Concepts\nOverview\nWhat is NATS\nSubject-Based Messaging\nCore NATS\nJetStream\nSubject Mapping and Partitioning\nNATS Service Infrastructure\nSecurity\nConnectivity\nUsing NATS\nNATS Tools\nDeveloping With NATS\nRunning Workloads on NATS\nRunning a NATS service\nInstalling, running and deploying a NATS Server\nEnvironmental considerations\nNATS and Docker\nNATS and Kubernetes\nNATS Server Clients\nConfiguring NATS Server\nManaging and Monitoring your NATS Server Infrastructure\nReference\nFAQ\nNATS Protocols\nRoadmap\nContributing\nLegacy\nnats-account-server\nPowered by GitBook\nOn this page\nThe official\nNATS\ndocumentation\n10,000 foot view\nGuided tour\nContribute\nAdditional questions?\nWas this helpful?\nEdit\nWelcome\nThe official\nNATS\ndocumentation\nNATS is a simple, secure and high performance open source data layer for cloud native applications, IoT messaging, and microservices architectures.\nWe feel that it should be the backbone of your communication between services. It doesn't matter what language, protocol, or platform you are using; NATS is the best way to connect your services.\n10,000 foot view\nPublish and subscribe to messages at millions of messages per second. At most once delivery.\nSupports fan-in/out delivery patterns\nRequest/reply\nEvery major language is supported\nPersistence via JetStream\nat least once delivery or\nexactly once\ndelivery\nwork queues\nstream processing\ndata replication\ndata retention\ndata deduplication\nHigher order data structures\nKey/Value with watchers, versioning, and TTL\nObject storage with versioning\nSecurity\nTLS\nJWT-based zero trust security\nClustering\nHigh availability\nFault tolerance\nAuto-discovery\nProtocols supported\nTCP\nMQTT\nWebSockets\nAll of this in a single binary that is easy to deploy and manage. No external dependencies, just drop it in and add a configuration file to point to other NATS servers and you are ready to go. In fact, you can even embed NATS in your application (for Go users)!\nGuided tour\nIn general we recommend trying to solve your problems first using\nCore NATS\n.\nIf you need to share state between services, take a look at the\nKV\nor\nObject Store\nin JetStream.\nWhen you need lower level access to persistence streams, move on to using\nJetStream\ndirectly for more advanced messaging patterns.\nLearn about\ndeployment strategies\nSecure your deployments with\nzero trust security\nContribute\nNATS is Open Source as is this documentation. Please\nlet us know\nif you have updates and/or suggestions for these docs. You can also create a Pull Request using the\nEdit on GitHub\nlink on each page.\nAdditional questions?\nFeel free to chat with us on Slack\nslack.nats.io\n.\nThank you from the entire NATS Team of Maintainers for your interest in NATS!\nNext\nWhat's New!\nLast updated\n3 months ago\nWas this helpful?", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.nats.io/"}}
{"text": "What is NATS | NATS Docs\nNATS Docs\nCtrl\nk\nNATS.io\nNATS by Example\nGitHub\nSlack\nTwitter\nMore\nWelcome\nRelease Notes\nWhat's New!\nNATS Concepts\nOverview\nWhat is NATS\nWalkthrough Setup\nSubject-Based Messaging\nCore NATS\nJetStream\nSubject Mapping and Partitioning\nNATS Service Infrastructure\nSecurity\nConnectivity\nUsing NATS\nNATS Tools\nDeveloping With NATS\nRunning Workloads on NATS\nRunning a NATS service\nInstalling, running and deploying a NATS Server\nEnvironmental considerations\nNATS and Docker\nNATS and Kubernetes\nNATS Server Clients\nConfiguring NATS Server\nManaging and Monitoring your NATS Server Infrastructure\nReference\nFAQ\nNATS Protocols\nRoadmap\nContributing\nLegacy\nnats-account-server\nPowered by GitBook\nOn this page\nNATS Client Applications\nNATS Service Infrastructure\nConnecting NATS Client applications to the NATS servers\nSimple messaging design\nNATS Quality of service (QoS)\nWas this helpful?\nEdit\nWhat is NATS\nSoftware applications and services need to exchange data. NATS is an infrastructure that allows such data exchange, segmented in the form of messages. We call this a \"\nmessage oriented middleware\n\".\nWith NATS, application developers can:\nEffortlessly build distributed and scalable client-server applications.\nStore and distribute data in realtime in a general manner. This can flexibly be achieved across various environments, languages, cloud providers and on-premises systems.\nNATS Client Applications\nDevelopers use one of the NATS client libraries in their application code to allow them to publish, subscribe, request and reply between instances of the application or between completely separate applications. Those applications are generally referred to as 'client applications' or sometimes just as 'clients' throughout this manual (since from the point of view of the NATS server, they are clients).\nNATS Service Infrastructure\nThe NATS services are provided by one or more NATS server processes that are configured to interconnect with each other and provide a\nNATS service infrastructure\n. The NATS service infrastructure can scale from a single NATS server process running on an end device (the\nnats-server\nprocess is less than 20 MB in size!) all the way to a public global super-cluster of many clusters spanning all major cloud providers and all regions of the world such as Synadia's NGS.\nConnecting NATS Client applications to the NATS servers\nTo connect a NATS client application with a NATS service, and then subscribe or publish messages to subjects, it only needs to be configured with:\nURL:\nA\n'NATS URL'\n. This is a string (in a URL format) that specifies the IP address and port where the NATS server(s) can be reached, and what kind of connection to establish (plain TCP, TLS, or Websocket).\nAuthentication\n(if needed):\nAuthentication\ndetails for the application to identify itself with the NATS server(s). NATS supports multiple authentication schemes (username/password, decentralized JWT, token, TLS certificates and Nkey with challenge).\nSimple messaging design\nNATS makes it easy for applications to communicate by sending and receiving messages. These messages are addressed and identified by subject strings, and do not depend on network location.\nData is encoded and framed as a message and sent by a publisher. The message is received, decoded, and processed by one or more subscribers.\nWith this simple design, NATS lets programs share common message-handling code, isolate resources and interdependencies, and scale by easily handling an increase in message volume, whether those are service requests or stream data.\nNATS Quality of service (QoS)\nNATS offers multiple qualities of service, depending on whether the application uses just the\nCore NATS\nfunctionality or also leverages the added functionalities enabled by\nNATS JetStream\n(JetStream is built into\nnats-server\nbut may not be enabled on all service infrastructures).\nAt most once QoS:\nCore NATS\noffers an\nat most once\nquality of service. If a subscriber is not listening on the subject (no subject match), or is not active when the message is sent, the message is not received. This is the same level of guarantee that TCP/IP provides.\nCore NATS\nis a fire-and-forget messaging system. It will only hold messages in memory and will never write messages directly to disk.\nAt-least / exactly once QoS:\nIf you need higher qualities of service (\nat least once\nand\nexactly once\n), or functionalities such as persistent streaming, de-coupled flow control, and Key/Value Store, you can use\nNATS JetStream\n, which is built in to the NATS server (but needs to be enabled). Of course, you can also always build additional reliability into your client applications yourself with proven and scalable reference designs such as acks and sequence numbers.\nPrevious\nCompare NATS\nNext\nWalkthrough Setup\nLast updated\n3 years ago\nWas this helpful?", "metadata": {"source_type": "vendor_docs", "trust": "vendor_docs", "os": "linux", "distro": "ubuntu-22.04", "license": "CC BY-SA (assumed; verify per site)", "attribution_url": "https://docs.nats.io/nats-concepts/intro"}}
